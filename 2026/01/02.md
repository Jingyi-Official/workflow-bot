# Daily Paper Digest Â· 2026-01-02
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [LiveTalk: Real-Time Multimodal Interactive Video Diffusion via Improved On-Policy Distillation](https://arxiv.org/pdf/2512.23576v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation

### 2. Motivation & Gaps
- The paper addresses the need for real-time interactive long video generation, which is a significant challenge in the field of video synthesis.

### 3. Core Idea
- The core idea is to develop a framework that allows for the generation of long videos in real-time, enabling interactive applications.

### 4. Method
- **Pipeline**: The method involves a novel autoregressive diffusion model that generates video frames sequentially while maintaining coherence.
- **Architecture / Loss / Training**: The architecture employs a loss function that balances frame coherence and real-time generation speed.
- **Complexity / Resources**: The model is designed to be efficient, requiring moderate computational resources to achieve real-time performance.

</details>

### [SoulX-LiveTalk: Real-Time Infinite Streaming of Audio-Driven Avatars via Self-Correcting Bidirectional Distillation](https://arxiv.org/pdf/2512.23379v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Audio-driven avatar video generation

### 2. Motivation & Gaps
- The paper addresses the challenge of generating avatar videos that can adapt to infinite-length audio inputs.

### 3. Core Idea
- The core idea is to develop a method for generating avatar videos that can continuously adapt to audio inputs of any length, ensuring seamless and realistic animations.

### 4. Method
- **Pipeline**: The method involves a novel diffusion-based approach that integrates audio features with visual generation techniques.
- **Architecture / Loss / Training**: The architecture employs a loss function that balances audio-visual coherence and visual fidelity during training.
- **Complexity / Resources**: The model is designed to be resource-efficient, allowing for real-time generation on standard hardware.

</details>

### [StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars](https://arxiv.org/pdf/2512.22065v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- talking avatar generation

### 2. Motivation & Gaps
- This work focuses on talking avatar generation for constructive, human-centered applications.

### 3. Core Idea
- The system supports real-time generation of talking avatars while ensuring ethical considerations are addressed.

### 4. Method
- **Pipeline**: The method involves a denoising process and variational autoencoder (VAE) for video generation.
- **Architecture / Loss / Training**: The architecture incorporates adversarial distillation and consistency-aware discriminators to enhance performance.
- **Complexity / Resources**: The model is evaluated using two H800 GPUs.

</details>

## video understanding

### [SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time](https://arxiv.org/pdf/2512.25075v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation with Temporal Control

### 2. Motivation & Gaps
- The paper addresses the challenge of generating videos with coherent camera motion and temporal dynamics, providing a dataset and methods to enhance temporal control.

### 3. Core Idea
- The proposed method, SpaceTimePilot, enables disentangled control over camera motion and temporal dynamics in video generation.

### 4. Method
- **Pipeline**: The method involves rendering multi-view video sequences and applying temporal warping for training.
- **Architecture / Loss / Training**: Utilizes a 1D-Conv embedding for time embedding to preserve scene dynamics while generating accurate camera motion.
- **Complexity / Resources**: Requires significant computational resources for rendering and training on large datasets.

</details>

### [Randomization Times under Quantum Chaotic Hamiltonian Evolution](https://arxiv.org/pdf/2512.25074v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the randomization time of quantum states under chaotic dynamics

### 2. Motivation & Gaps
- The study aims to define and identify the intrinsic randomization time generated by quantum dynamics, focusing on the transition from unentangled to Haar-random states.

### 3. Core Idea
- The study reveals that non-random Hamiltonians can randomize states faster than their charge-conserving counterparts, with significant implications for quantum dynamics.

### 4. Method
- **Pipeline**: Define a temporal ensemble of states evolved from unentangled states and analyze their observables over time.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Utilizes the Mixed Field Ising Model with periodic boundary conditions and specific initial conditions.

</details>

### [Classification of Interacting Topological Crystalline Superconductors in Three Dimensions and Beyond](https://arxiv.org/pdf/2512.25069v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Classifying three-dimensional interacting fermionic SPTs and topological crystalline superconductors

### 2. Motivation & Gaps
- The paper addresses the classification of fully gapped topological superconductors protected by crystalline symmetries, filling a gap between abstract classifications and practical definitions.

### 3. Core Idea
- Developing a framework for classifying three-dimensional interacting fermionic SPTs using domain-wall decoration and fermionic crystalline equivalence principles.

### 4. Method
- **Pipeline**: Utilizes a domain-wall decoration framework and fermionic crystalline equivalence principle to classify topological crystalline superconductors.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The complexity involves checking multiple symmetry groups and their interactions, requiring significant computational resources.

</details>

## model collapse

### [Edit3r: Instant 3D Scene Editing from Sparse Unposed Images](https://arxiv.org/pdf/2512.25071v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D scene reconstruction and editing from unposed images

### 2. Motivation & Gaps
- Existing methods struggle with robustness and consistency in 3D scene editing, particularly under varying input conditions.

### 3. Core Idea
- Edit3r unifies reconstruction and instruction-driven editing of 3D scenes by predicting edited 3D Gaussian splats in a single pass, enabling fast and coherent rendering.

### 4. Method
- **Pipeline**: Decouples 2D editing from feed-forward reconstruction, allowing different editors at test time.
- **Architecture / Loss / Training**: Utilizes a SAM2-based recoloring strategy and an asymmetric input scheme for supervision.
- **Complexity / Resources**: Lightweight 3D regularization on Gaussian centers ensures robust multi-view coherence.

</details>
