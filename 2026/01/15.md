# Daily Paper Digest Â· 2026-01-15
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [Technological Advances in Two Generations of Consumer-Grade VR Systems: Effects on User Experience and Task Performance](https://arxiv.org/pdf/2601.09610v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Comparing user experience between two generations of IVR systems

### 2. Motivation & Gaps
- The study investigates the relationship between technological improvements in IVR systems and user experience, emphasizing the need for user-centered evaluation.

### 3. Core Idea
- Technological advances in IVR systems do not necessarily enhance user experience, and user-centered factors may have a more significant impact.

### 4. Method
- **Pipeline**: User-centered study design comparing two generations of IVR systems.
- **Architecture / Loss / Training**: Both systems were evaluated in their commercially available configurations, using the same modern software stack for consistency.
- **Complexity / Resources**: Utilized HTC Vive and HTC Vive Pro 2 systems with various specifications for tracking and display.

</details>

### [Understanding the Consequences of VTuber Reincarnation](https://arxiv.org/pdf/2601.08972v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Analyze the impact of VTuber reincarnation on fan communities and propose strategies for mitigating negative effects.

### 2. Motivation & Gaps
- The study investigates the schism in fan communities caused by the reincarnation of VTubers, highlighting the differing attachments fans have to the Nakanohito and the persona.

### 3. Core Idea
- The schism between Nakanohito-centric and persona-centric fans leads to community fractures, necessitating strategies for VTubers and agencies to retain audiences and mitigate harassment.

### 4. Method
- **Pipeline**: We employ a qualitative approach based on manual review of 1200 harassment chat messages.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The dataset includes 1,972 VTubers, 728,604 livestream sessions, and 4,552,865,327 interaction records.

</details>

### [Instruction-Driven 3D Facial Expression Generation and Transition](https://arxiv.org/pdf/2601.08179v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D head avatar generation

### 2. Motivation & Gaps
- The paper addresses the challenge of generating realistic 3D head avatars from monocular RGB videos, which is a complex task due to the lack of depth information.

### 3. Core Idea
- The core idea is to utilize neural networks to create detailed 3D head avatars from single RGB video inputs, leveraging advanced techniques in computer vision.

### 4. Method
- **Pipeline**: The method involves preprocessing the input video, extracting features, and using a neural network to generate the 3D model.
- **Architecture / Loss / Training**: The architecture employs a loss function that balances realism and fidelity to the input video, trained on a diverse dataset of facial expressions.
- **Complexity / Resources**: The method requires significant computational resources for training, including high-performance GPUs and a large dataset of annotated videos.

</details>

## video understanding

### [Value-Aware Numerical Representations for Transformer Language Models](https://arxiv.org/pdf/2601.09706v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Numerical reasoning in language models

### 2. Motivation & Gaps
- The paper investigates the ability of language models to perform numerical reasoning and the impact of various training methodologies on this capability.

### 3. Core Idea
- The study proposes a framework for enhancing the numerical reasoning abilities of language models through improved training techniques and data representation.

### 4. Method
- **Pipeline**: The proposed method involves a systematic approach to training language models with a focus on numerical tasks.
- **Architecture / Loss / Training**: Utilizes a regression-like loss on number tokens to improve performance.
- **Complexity / Resources**: The method is designed to be resource-efficient while maintaining high accuracy.

</details>

### [SAM3-DMS: Decoupled Memory Selection for Multi-target Video Segmentation of SAM3](https://arxiv.org/pdf/2601.09699v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Multi-target video segmentation

### 2. Motivation & Gaps
- The paper addresses the limitations of the original SAM3 model in multi-target video segmentation, particularly focusing on memory pollution issues during simultaneous inference.

### 3. Core Idea
- The introduction of a training-free decoupled memory selection strategy to enhance the robustness of multi-target video segmentation.

### 4. Method
- **Pipeline**: The DMS strategy evaluates each target's status independently, ensuring memory updates are based on individual tracking performance.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Achieved with virtually no additional GPU memory overhead.

</details>

### [Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering](https://arxiv.org/pdf/2601.09697v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation and Interpolation

### 2. Motivation & Gaps
- The paper addresses the challenges of generating high-quality videos with varying frame rates and camera trajectories.

### 3. Core Idea
- The proposed method utilizes keyframe density prediction and 3D reconstruction to generate videos with different camera trajectories efficiently.

### 4. Method
- **Pipeline**: Keyframe generation followed by 3D reconstruction and video rendering.
- **Architecture / Loss / Training**: The architecture includes a camera embedding module, a DINOv2 encoder, and a transformer, with a loss function that minimizes noise prediction across frames.
- **Complexity / Resources**: Training was performed on a single NVIDIA GH200 Superchip for 5 hours with a batch size of 128.

</details>

## model collapse

### [Revisiting Jahn--Teller Transitions in Correlated Oxides with Monte Carlo Modeling](https://arxiv.org/pdf/2601.09705v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate orbital ordering and phase diagrams in perovskites

### 2. Motivation & Gaps
- The study aims to explore the orbital ordering in various perovskite materials and validate existing phase diagrams.

### 3. Core Idea
- The research focuses on the C-type orbital order in perovskites and its implications for understanding phase transitions.

### 4. Method
- **Pipeline**: Monte Carlo simulations with simulated annealing
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Simulations were run for 5 Ã— 10^6 iterations with varying Tmax.

</details>

### [ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation](https://arxiv.org/pdf/2601.09703v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Code Summarization

### 2. Motivation & Gaps
- The paper addresses the need for effective code summarization techniques that can leverage contextual information from code.

### 3. Core Idea
- The proposed method utilizes a multi-relational graph neural network to enhance the contextual understanding of code for summarization tasks.

### 4. Method
- **Pipeline**: The method involves preprocessing code into a graph structure, applying the graph neural network, and generating summaries.
- **Architecture / Loss / Training**: The architecture employs a loss function that focuses on both accuracy and contextual relevance during training.
- **Complexity / Resources**: The method requires moderate computational resources, primarily for training the graph neural network.

</details>
