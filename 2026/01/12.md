# Daily Paper Digest Â· 2026-01-12
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [What do the metrics mean? A critical analysis of the use of Automated Evaluation Metrics in Interpreting](https://arxiv.org/pdf/2601.05864v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Evaluate the quality of interpreting in specific contexts

### 2. Motivation & Gaps
- The paper discusses the limitations of automated evaluation metrics (AEMs) in measuring interpreting quality, emphasizing the need for context-specific assessments.

### 3. Core Idea
- Interpreting AEMs cannot serve as reliable measures of interpreting quality on their own and must be used in conjunction with context-aware assessments.

### 4. Method
- **Pipeline**: Multi-method, holistic evaluation of interpreting quality in authentic settings.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: N/A

</details>

### [LayerGS: Decomposition and Inpainting of Layered 3D Human Avatars via 2D Gaussian Splatting](https://arxiv.org/pdf/2601.05853v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Generative modeling for clothed human representation

### 2. Motivation & Gaps
- The paper addresses the need for accurate and realistic modeling of clothed humans, which is essential for various applications in computer vision and graphics.

### 3. Core Idea
- The proposed model integrates topology-aware techniques to enhance the generative process for realistic clothed human representations.

### 4. Method
- **Pipeline**: The method involves a generative model that incorporates topology information to improve the realism of the generated clothing on human avatars.
- **Architecture / Loss / Training**: Utilizes a combination of adversarial loss and reconstruction loss to train the model effectively.
- **Complexity / Resources**: The model requires moderate computational resources, leveraging GPU acceleration for training.

</details>

### [GaussianSwap: Animatable Video Face Swapping with 3D Gaussian Splatting](https://arxiv.org/pdf/2601.05511v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Face Swapping

### 2. Motivation & Gaps
- The paper introduces GaussianSwap, a framework for video face swapping that constructs a 3DGS-based head avatar from a target video while transferring identity from a source image.

### 3. Core Idea
- Empowering face manipulation through 3D head avatar reconstruction to inspire advancements in other face generation tasks.

### 4. Method
- **Pipeline**: The method involves using FLAME tracking to obtain camera poses and parameters, which are then used to animate a 3DGS avatar.
- **Architecture / Loss / Training**: The architecture employs a combination of identity embeddings from ArcFace, FaceNet, and Dlib to compute identity loss.
- **Complexity / Resources**: The method requires significant computational resources for training and evaluation, leveraging pre-trained models from competing methods.

</details>

## video understanding

### [Probing Cosmic Expansion and Early Universe with Einstein Telescope](https://arxiv.org/pdf/2601.06017v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the potential of next-generation gravitational wave observatories in cosmology.

### 2. Motivation & Gaps
- Current gravitational wave detectors are limited in their ability to measure cosmic expansion and the Hubble constant due to small sample sizes of standard sirens.

### 3. Core Idea
- Next-generation observatories like ET will significantly enhance the precision of cosmological measurements through gravitational wave detections.

### 4. Method
- **Pipeline**: Utilizing a combination of gravitational wave detections and electromagnetic surveys to achieve high-precision cosmological measurements.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Expected to require substantial computational resources for data analysis and cross-correlation with galaxy catalogs.

</details>

### [Simulations of collision and sloshing in the galaxy group NGC 5098/5096](https://arxiv.org/pdf/2601.06011v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Hydrodynamic simulations of galaxy interactions

### 2. Motivation & Gaps
- Modelling galaxy groups in the literature is not common. This task is particularly challenging because even a single galaxy can perturb the IGM and non-gravitational processes such as AGN feedback can generate cavities that complicate the interpretation of the collision scenario.

### 3. Core Idea
- Our work demonstrates that the gravitational interaction with NGC 5096 provides a coherent explanation for the sloshing features in NGC 5098.

### 4. Method
- **Pipeline**: Tailored hydrodynamic N-body simulations exploring initial condition parameter space.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Simulations require significant computational resources to model different collision scenarios.

</details>

### [The Molecular Structure of Thought: Mapping the Topology of Long Chain-of-Thought Reasoning](https://arxiv.org/pdf/2601.06002v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- In-context learning (ICL) and reasoning dynamics analysis

### 2. Motivation & Gaps
- The paper explores the effectiveness of in-context learning in approximating the semantic structure of teacher models and analyzes reasoning dynamics in both human and model contexts.

### 3. Core Idea
- Investigating the effect of bond lengths on reasoning quality and summarizing reasoning processes from LLMs.

### 4. Method
- **Pipeline**: Querying black-box teacher models with identical prompts to analyze reasoning.
- **Architecture / Loss / Training**: Summarizing Long Chain-of-Thought traces to reduce recoverable rationale.
- **Complexity / Resources**: Training on summarized 20K samples.

</details>

## model collapse

### [AdaFuse: Adaptive Ensemble Decoding with Test-Time Scaling for LLMs](https://arxiv.org/pdf/2601.06022v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Machine Translation, Open-Domain Question Answering, Reading Comprehension

### 2. Motivation & Gaps
- The paper addresses the challenges of efficiently ensembling large language models while maintaining performance.

### 3. Core Idea
- ADAFUSE improves performance by using a diversity-aware ensemble scaling approach.

### 4. Method
- **Pipeline**: The method involves generating candidate word spans and scoring them across models using adaptive decoding.
- **Architecture / Loss / Training**: Utilizes Mistral-7B-Instruct-v0.3 and LLaMA-3.1-8B-Instruct as base models.
- **Complexity / Resources**: Total compute budget for all experiments is approximately 500 A100 GPU-hours.

</details>

### [Mobility Trajectories from Network-Driven Markov Dynamics](https://arxiv.org/pdf/2601.06020v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Modeling human mobility patterns using network-driven Markov dynamics

### 2. Motivation & Gaps
- The study aims to explore the dynamics of human mobility by utilizing network-driven Markov models, addressing the limitations of existing models in capturing individual-level behavior.

### 3. Core Idea
- The paper proposes a framework that combines network structure and individual behavior to model human mobility dynamics more accurately.

### 4. Method
- **Pipeline**: The method involves constructing a column-stochastic matrix to represent mobility transitions and applying Markov dynamics to model daily mobility patterns.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The model requires computational resources for matrix operations and simulations of mobility patterns.

</details>

### [LookAroundNet: Extending Temporal Context with Transformers for Clinically Viable EEG Seizure Detection](https://arxiv.org/pdf/2601.06016v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Automated seizure detection

### 2. Motivation & Gaps
- The paper addresses the need for effective seizure detection methods using EEG data, highlighting the limitations of existing approaches.

### 3. Core Idea
- The core idea of LookAroundNet is to utilize a transformer-based architecture for improved seizure detection in EEG signals by leveraging context from surrounding time steps.

### 4. Method
- **Pipeline**: The method involves preprocessing EEG data, applying the LookAroundNet architecture, and evaluating performance using various metrics.
- **Architecture / Loss / Training**: The architecture consists of convolutional layers followed by transformer encoder layers, optimized using AdamW with a learning rate of 5e-4.
- **Complexity / Resources**: The model requires significant computational resources due to its transformer architecture, including multiple layers and attention heads.

</details>
