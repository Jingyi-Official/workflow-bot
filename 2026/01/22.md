# Daily Paper Digest Â· 2026-01-22
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [Real-time Facial Communication Restores Cooperation After Defection in Social Dilemmas](https://arxiv.org/pdf/2601.15211v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the impact of real-time facial communication on cooperation in social dilemmas.

### 2. Motivation & Gaps
- The study aims to explore how real-time facial expressions can influence cooperation in repeated social dilemmas, particularly in the context of the Prisoner's Dilemma.

### 3. Core Idea
- Utilizing real-time facial expression analysis to enhance cooperation in social dilemmas through dynamic emotional feedback.

### 4. Method
- **Pipeline**: Participants engage in a repeated Prisoner's Dilemma while their facial expressions are captured and analyzed in real-time to influence their partner's decisions.
- **Architecture / Loss / Training**: The Affectiva AFFDEX emotion recognition algorithm is employed, utilizing a deep learning-based computer vision pipeline.
- **Complexity / Resources**: The method requires controlled lighting and fixed participant positioning to ensure accurate facial expression analysis.

</details>

### [GAT-NeRF: Geometry-Aware-Transformer Enhanced Neural Radiance Fields for High-Fidelity 4D Facial Avatars](https://arxiv.org/pdf/2601.14875v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Human reconstruction from RGB-D images

### 2. Motivation & Gaps
- The paper addresses the challenge of accurately reconstructing human figures from a single RGB-D image, which is a complex task due to the variability in human shapes and poses.

### 3. Core Idea
- The proposed model leverages neural implicit representations to achieve high-fidelity human reconstruction from a single RGB-D image.

### 4. Method
- **Pipeline**: The method involves preprocessing the RGB-D image, applying the neural implicit model, and optimizing the output for accuracy.
- **Architecture / Loss / Training**: The architecture utilizes a combination of implicit neural representations and loss functions tailored for human shape and pose accuracy.
- **Complexity / Resources**: The model is designed to be computationally efficient, requiring moderate resources for training and inference.

</details>

### [CAG-Avatar: Cross-Attention Guided Gaussian Avatars for High-Fidelity Head Reconstruction](https://arxiv.org/pdf/2601.14844v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D head reconstruction and expression synthesis

### 2. Motivation & Gaps
- The paper addresses limitations in 3D Gaussian Splatting-based avatars, particularly the inaccuracies in local deformations from global conditioning, which lead to artifacts on rigid structures like teeth.

### 3. Core Idea
- A Conditionally Adaptive Fusion Module that uses cross-attention to generate a unique, spatially-aware driving signal for each Gaussian primitive, effectively disentangling expression dynamics.

### 4. Method
- **Pipeline**: The framework is implemented using PyTorch, leveraging a differentiable Gaussian rasterizer and a parsing network for accurate segmentation.
- **Architecture / Loss / Training**: The total loss is a composite of photometric loss and perceptual loss, ensuring rendering fidelity and training stability.
- **Complexity / Resources**: Utilizes a single NVIDIA RTX 4090 GPU for training with a fixed number of iterations.

</details>

## video understanding

### [Towards Understanding Best Practices for Quantization of Vision-Language Models](https://arxiv.org/pdf/2601.15287v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Quantization of multimodal architectures

### 2. Motivation & Gaps
- This work systematically investigates the effects of quantization on vision-language models, focusing on how different components respond to reduced precision.

### 3. Core Idea
- Different quantization methods significantly affect the importance of model components, particularly favoring the LLM in certain tasks.

### 4. Method
- **Pipeline**: The study employs uniform quantization and state-of-the-art methods like GPTQ and AWQ to analyze component importance.
- **Architecture / Loss / Training**: The architectural layout and component interplay shape quantization patterns, redistributing importance based on roles and dependencies.
- **Complexity / Resources**: The study does not capture end-to-end latency or hardware-specific optimizations.

</details>

### [Walk through Paintings: Egocentric World Models from Internet Priors](https://arxiv.org/pdf/2601.15284v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Referring Video Object Segmentation

### 2. Motivation & Gaps
- The paper addresses the challenges in video object segmentation, particularly in maintaining structural consistency during navigation and manipulation tasks.

### 3. Core Idea
- The proposed models aim to improve video object segmentation by enhancing structural consistency and reducing the computational resources required compared to existing methods.

### 4. Method
- **Pipeline**: The models are trained on A100 GPUs with specific learning rates for different layers, utilizing a combination of datasets for training and evaluation.
- **Architecture / Loss / Training**: The models use a learning rate of 1e-5 for most parameters and 1e-4 for action projection layers in SVD, while Cosmos uses 1e-6 and 1e-5 respectively.
- **Complexity / Resources**: The SVD and Cosmos models are trained on 8 A100 GPUs, significantly less than the 64 H100 GPUs used by NWM.

</details>

### [LuxRemix: Lighting Decomposition and Remixing for Indoor Scenes](https://arxiv.org/pdf/2601.15283v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Light Editing and Harmonization

### 2. Motivation & Gaps
- The paper addresses the need for realistic and fine-grained light editing control in image processing, which is not fully achieved by existing models.

### 3. Core Idea
- The LuxRemix-SV approach enables realistic and fine-grained light editing control via light mask conditioning.

### 4. Method
- **Pipeline**: The method involves decomposing scene lighting into ambient and multiple one-light-at-a-time (OLAT) components, followed by consistent propagation across views.
- **Architecture / Loss / Training**: The final objective is a weighted sum of three losses: photometric loss, composition consistency loss, and spatial smoothness loss.
- **Complexity / Resources**: The method requires significant computational resources for training, including 4,000 initial iterations followed by additional optimization.

</details>

## model collapse

### [Tracing the Galactic Disk with Gaia DR3: A Deep Study of Berkeley 17, 18, and 39 Open Star Clusters](https://arxiv.org/pdf/2601.15289v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the properties of open clusters Be17, Be18, and Be39 using Gaia DR3 data

### 2. Motivation & Gaps
- The study aims to provide a comprehensive analysis of the stellar populations and dynamics of selected open clusters, which are crucial for understanding the chemical evolution of the Galactic disk.

### 3. Core Idea
- Utilize the latest Gaia DR3 data to conduct a detailed analysis of the photometric, spectroscopic, and dynamical properties of three open clusters.

### 4. Method
- **Pipeline**: Data extraction from Gaia DR3, followed by photometric and astrometric analysis of clusters Be17, Be18, and Be39.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Utilized a 50' radius area around cluster coordinates to extract data for approximately 89647, 95903, and 64154 stars from the Gaia DR3 catalog.

</details>

### [Iterative Refinement Improves Compositional Image Generation](https://arxiv.org/pdf/2601.15286v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Image Generation Evaluation

### 2. Motivation & Gaps
- The study aims to improve the accuracy and effectiveness of image generation and editing models by addressing common errors and limitations observed in existing systems.

### 3. Core Idea
- The iterative refinement approach for image generation outperforms parallel-only methods across various models and prompt complexities.

### 4. Method
- **Pipeline**: The method involves generating an initial image, evaluating it against a set of criteria, and iteratively refining it based on user prompts and verifier scores.
- **Architecture / Loss / Training**: The architecture employs a combination of generative models and reinforcement learning to optimize the refinement process.
- **Complexity / Resources**: Utilizes various models including Qwen-Image, GPT-Image-One, and Gemini-2.5 for different stages of the image generation and evaluation process.

</details>
