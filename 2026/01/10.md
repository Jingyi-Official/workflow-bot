# Daily Paper Digest ¬∑ 2026-01-10
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [RelightAnyone: A Generalized Relightable 3D Gaussian Head Model](https://arxiv.org/pdf/2601.03357v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Portrait reconstruction and relighting

### 2. Motivation & Gaps
- The paper addresses the challenge of relighting 3D head models using a generalized approach that leverages Gaussian representations.

### 3. Core Idea
- The model enables self-supervised lighting alignment and captures high-frequency, person-specific details through finetuning.

### 4. Method
- **Pipeline**: The pipeline involves a two-stage training process with specific loss balancing weights and an Adam optimizer.
- **Architecture / Loss / Training**: The model uses regularization terms LœÅ and Lmono to enforce a meaningful decomposition of diffuse albedo and shading.
- **Complexity / Resources**: Trained on 4 Quadro RTX 6000/8000 GPUs with a batch size of 16, typically converging within 3000 iterations.

</details>

### [CaricatureGS: Exaggerating 3D Gaussian Splatting Faces With Gaussian Curvature](https://arxiv.org/pdf/2601.03319v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- 3D Gaussian Splatting for caricaturization

### 2. Motivation & Gaps
- The paper addresses the need for effective caricaturization techniques in 3D modeling, particularly focusing on the exaggeration of facial features using Gaussian splatting.

### 3. Core Idea
- The core idea is to utilize Gaussian splatting techniques to create exaggerated caricatures of 3D faces by manipulating Gaussian curvature.

### 4. Method
- **Pipeline**: The method involves optimizing a 3D Gaussian Splatting model for each subject, followed by caricaturization through solving the Poisson equation.
- **Architecture / Loss / Training**: The training follows a specific protocol with a focus on optimizing the Gaussian splatting model over multiple iterations.
- **Complexity / Resources**: Experiments are conducted on a single NVIDIA RTX 3090 with 24 GB VRAM, requiring approximately 4 hours of optimization per subject.

</details>

### [Avatar Exposure and Strategic Coordination in Virtual Reality: Evidence from a Threshold Public Goods Experiment](https://arxiv.org/pdf/2601.02214v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Investigating social presence and recycling motivation in virtual reality

### 2. Motivation & Gaps
- The study aims to explore first-order social presence and its impact on recycling motivation within a virtual reality context.

### 3. Core Idea
- To assess the relationship between social presence and recycling motivation in a virtual reality environment.

### 4. Method
- **Pipeline**: Participants engage in a virtual reality task involving recycling while their social presence is measured.
- **Architecture / Loss / Training**: The VR environment was developed using Unity, with a focus on collaborative interactions and user familiarity.
- **Complexity / Resources**: Utilized Meta Quest 3 HMD and hand-held controllers for interaction, requiring a controlled setup for effective collaboration.

</details>

## video understanding

### [Mesh4D: 4D Mesh Reconstruction and Tracking from Monocular Video](https://arxiv.org/pdf/2601.05251v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- 4D Mesh Reconstruction and Tracking

### 2. Motivation & Gaps
- The paper addresses the challenge of reconstructing and tracking 4D meshes from monocular video input, aiming to improve the quality and efficiency of 4D reconstruction methods.

### 3. Core Idea
- The proposed method utilizes a deformation variational autoencoder (VAE) and a deformation diffusion model to reconstruct and track 4D meshes from monocular video, leveraging pre-trained weights from large-scale 3D datasets.

### 4. Method
- **Pipeline**: The method involves segmenting the foreground moving object, reconstructing the canonical shape, and applying a deformation diffusion model to generate the 4D mesh.
- **Architecture / Loss / Training**: The architecture includes a deformation VAE and a deformation diffusion model, trained with AdamW optimizer and specific learning rates and batch sizes.
- **Complexity / Resources**: Training is conducted on 4 NVIDIA H100 GPUs with a total training time of approximately one week.

</details>

### [Pixel-Perfect Visual Geometry Estimation](https://arxiv.org/pdf/2601.05246v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Monocular depth estimation

### 2. Motivation & Gaps
- The paper addresses the challenges in monocular depth estimation by proposing a method that mixes datasets to improve zero-shot cross-dataset transfer.

### 3. Core Idea
- The core idea is to mix multiple datasets to enhance the robustness and accuracy of monocular depth estimation models in zero-shot scenarios.

### 4. Method
- **Pipeline**: The proposed method involves a pipeline that integrates various datasets and applies a novel training strategy to improve depth estimation performance.
- **Architecture / Loss / Training**: Utilizes a combination of loss functions tailored for depth estimation to optimize the model during training.
- **Complexity / Resources**: The method is designed to be computationally efficient, allowing for real-time applications with moderate resource requirements.

</details>

### [RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation](https://arxiv.org/pdf/2601.05241v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Robot Manipulation

### 2. Motivation & Gaps
- The paper addresses the challenges in robot manipulation tasks, particularly in enhancing the performance of Diffusion Policy through effective data augmentation methods.

### 3. Core Idea
- The proposed visual identity prompting enriches generated tabletop scenes with diverse and realistic objects.

### 4. Method
- **Pipeline**: The method involves collecting real and augmented demonstration data, training the policy with various augmentation techniques, and evaluating performance in both open and cluttered environments.
- **Architecture / Loss / Training**: The architecture employs a video diffusion model for data augmentation, with specific training settings for different augmentation methods.
- **Complexity / Resources**: The method requires a multi-camera setup and significant computational resources for training and evaluation.

</details>

## model collapse

### [Unveiling the 3D structure of the central molecular zone from stellar kinematics and photometry: The 50 and 20 km/s clouds](https://arxiv.org/pdf/2601.05252v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Investigate the line-of-sight location of the 50 and 20 km/s clouds in the CMZ using stellar kinematics and photometric data.

### 2. Motivation & Gaps
- The study aims to understand the physical connection between the clouds and the ridge in the Central Molecular Zone (CMZ).

### 3. Core Idea
- The clouds and the ridge are physically connected structures that obscure stars on the far side of the NSD.

### 4. Method
- **Pipeline**: Built proper motion maps and applied a GMM approach to analyze the ¬µl distribution.
- **Architecture / Loss / Training**: Utilized PARSEC and MIST models with Gaussian smoothing parameters for fitting.
- **Complexity / Resources**: Conducted 1,000 Monte Carlo simulations to estimate contributions and uncertainties.

</details>

### [QNeRF: Neural Radiance Fields on a Simulated Gate-Based Quantum Computer](https://arxiv.org/pdf/2601.05250v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Neural Radiance Fields representation

### 2. Motivation & Gaps
- The paper explores the use of neural radiance fields for scene representation, particularly focusing on high-resolution scenes.

### 3. Core Idea
- Introducing QMip-NeRF to improve the representation of scenes with higher resolution.

### 4. Method
- **Pipeline**: The method involves training neural radiance fields on a simulated quantum gate-based framework.
- **Architecture / Loss / Training**: The architecture remains compatible with a wide class of NeRF variants, trained for up to 15 epochs.
- **Complexity / Resources**: The training requires approximately 15 hours per scene.

</details>
