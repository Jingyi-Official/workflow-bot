# Daily Paper Digest ¬∑ 2026-01-11
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [RelightAnyone: A Generalized Relightable 3D Gaussian Head Model](https://arxiv.org/pdf/2601.03357v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Portrait reconstruction and relighting

### 2. Motivation & Gaps
- The paper addresses the challenge of relighting 3D head models using a generalized approach that leverages Gaussian representations.

### 3. Core Idea
- The model enables self-supervised lighting alignment and captures high-frequency, person-specific details through finetuning.

### 4. Method
- **Pipeline**: The pipeline involves a two-stage training process with specific loss balancing weights and an Adam optimizer.
- **Architecture / Loss / Training**: The model uses regularization terms LœÅ and Lmono to enforce a meaningful decomposition of diffuse albedo and shading.
- **Complexity / Resources**: Training with more subjects improves results, leading to cleaner albedo and better identity preservation.

</details>

### [CaricatureGS: Exaggerating 3D Gaussian Splatting Faces With Gaussian Curvature](https://arxiv.org/pdf/2601.03319v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- 3D Gaussian Splatting and Caricaturization

### 2. Motivation & Gaps
- The paper addresses the need for effective caricaturization techniques in 3D modeling, particularly focusing on Gaussian splatting methods.

### 3. Core Idea
- The core idea is to utilize Gaussian splatting techniques to create exaggerated caricatures of 3D faces by manipulating Gaussian curvature.

### 4. Method
- **Pipeline**: The method involves optimizing a 3D Gaussian Splatting model through iterative training and applying caricaturization techniques at the beginning of the training process.
- **Architecture / Loss / Training**: The architecture follows a shared template across subjects, utilizing a Poisson equation for deformation and a specific learning rate schedule.
- **Complexity / Resources**: Experiments are conducted on a single NVIDIA RTX 3090 with 24 GB VRAM, optimizing each subject's model for approximately 120,000 iterations.

</details>

### [Avatar Exposure and Strategic Coordination in Virtual Reality: Evidence from a Threshold Public Goods Experiment](https://arxiv.org/pdf/2601.02214v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Investigating social presence and recycling motivation in virtual reality

### 2. Motivation & Gaps
- The study aims to explore first-order social presence and its impact on recycling motivation within a virtual reality context.

### 3. Core Idea
- To assess the relationship between social presence and recycling motivation in a virtual reality environment.

### 4. Method
- **Pipeline**: Participants engage in a virtual reality task involving recycling while their social presence is measured.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Utilized Virtual Reality to maintain experimental control while simulating realistic social contexts.

</details>

## video understanding

### [Mesh4D: 4D Mesh Reconstruction and Tracking from Monocular Video](https://arxiv.org/pdf/2601.05251v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- 4D Mesh Reconstruction and Tracking

### 2. Motivation & Gaps
- The paper addresses the challenge of reconstructing and tracking 4D meshes from monocular video input, aiming to improve the quality and efficiency of 4D reconstruction methods.

### 3. Core Idea
- The proposed method utilizes a deformation variational autoencoder (VAE) and a deformation diffusion model to reconstruct and track 4D meshes from monocular video, leveraging pre-trained weights from a large-scale 3D generator.

### 4. Method
- **Pipeline**: The method involves segmenting the foreground moving object, reconstructing the canonical shape, and applying a deformation diffusion model to generate the 4D mesh.
- **Architecture / Loss / Training**: The architecture includes a deformation VAE and a deformation diffusion model, trained with AdamW optimizer and specific learning rates and batch sizes.
- **Complexity / Resources**: Training is conducted on 4 NVIDIA H100 GPUs with a total training time of approximately one week.

</details>

### [Pixel-Perfect Visual Geometry Estimation](https://arxiv.org/pdf/2601.05246v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Monocular depth estimation

### 2. Motivation & Gaps
- The paper addresses the challenges in monocular depth estimation, particularly in achieving robustness across different datasets.

### 3. Core Idea
- The core idea is to mix datasets to enhance the robustness of monocular depth estimation models in zero-shot scenarios.

### 4. Method
- **Pipeline**: The proposed method involves a novel training pipeline that integrates multiple datasets to improve model performance.
- **Architecture / Loss / Training**: Utilizes a combination of loss functions tailored for depth estimation tasks.
- **Complexity / Resources**: The method is designed to be computationally efficient, requiring moderate resources for training.

</details>

### [RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation](https://arxiv.org/pdf/2601.05241v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Robot Learning and Policy Evaluation

### 2. Motivation & Gaps
- The paper addresses the challenges in robot learning, particularly in enhancing policy performance through data augmentation methods.

### 3. Core Idea
- The proposed visual identity prompting enriches generated tabletop scenes with diverse and realistic objects.

### 4. Method
- **Pipeline**: The method involves capturing RGB frames, data augmentation through video diffusion, and training policies with augmented data.
- **Architecture / Loss / Training**: Models are trained using a batch size of 64 for 2500 steps without augmentation and 5000 steps with augmentation.
- **Complexity / Resources**: Utilizes a multi-camera system and requires significant computational resources for training and evaluation.

</details>

## model collapse

### [Unveiling the 3D structure of the central molecular zone from stellar kinematics and photometry: The 50 and 20 km/s clouds](https://arxiv.org/pdf/2601.05252v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Investigate the line-of-sight location of the 50 and 20 km/s clouds in the CMZ using stellar kinematics and photometric data.

### 2. Motivation & Gaps
- The study aims to understand the physical connection between the clouds and the ridge in the Central Molecular Zone (CMZ).

### 3. Core Idea
- The clouds obscure stars on the far side of the NSD, suggesting a potential physical connection between them.

### 4. Method
- **Pipeline**: Built proper motion maps and applied a GMM approach to analyze the ¬µl distribution.
- **Architecture / Loss / Training**: Utilized PARSEC and MIST models for fitting luminosity functions.
- **Complexity / Resources**: Employed Monte Carlo simulations to estimate uncertainties in stellar population contributions.

</details>

### [QNeRF: Neural Radiance Fields on a Simulated Gate-Based Quantum Computer](https://arxiv.org/pdf/2601.05250v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Neural Radiance Fields representation

### 2. Motivation & Gaps
- The paper explores the use of neural radiance fields for scene representation, particularly focusing on high-resolution outputs.

### 3. Core Idea
- Introducing QMip-NeRF to improve the representation of scenes with higher resolution compared to classical Mip-NeRF.

### 4. Method
- **Pipeline**: The method involves training neural radiance fields on a simulated quantum gate-based framework.
- **Architecture / Loss / Training**: Utilizes a specific architecture designed for quantum simulations with loss functions tailored for radiance field representation.
- **Complexity / Resources**: Requires significant computational resources, approximately 15 hours per scene for training.

</details>
