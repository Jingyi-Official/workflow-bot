# Daily Paper Digest Â· 2026-01-31
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [Remember Me, Not Save Me: A Collective Memory System for Evolving Virtual Identities in Augmented Reality](https://arxiv.org/pdf/2601.20437v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Understanding collective dialogue and digital identity emergence

### 2. Motivation & Gaps
- The paper explores how collective dialogue transforms into coherent digital identity through technical innovations.

### 3. Core Idea
- The system achieved stable ISTP personality emergence from recorded interactions, highlighting the importance of trust and digital memory.

### 4. Method
- **Pipeline**: The system employs a dual memory path with conflict detection but not resolution to manage contradictions in AI personality.
- **Architecture / Loss / Training**: The DCM model transforms dialogues into weighted memory graphs, retaining contradictions through a Narrative Tension Mechanism.
- **Complexity / Resources**: The mathematical weighting formula balances frequency, emotion, and resonance in collective memory formation.

</details>

### [Splat-Portrait: Generalizing Talking Heads with Gaussian Splatting](https://arxiv.org/pdf/2601.18633v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Talking head synthesis

### 2. Motivation & Gaps
- The paper addresses the challenges in creating realistic talking head avatars using advanced techniques.

### 3. Core Idea
- The core idea is to utilize Gaussian splatting techniques to enhance the realism and efficiency of talking head synthesis.

### 4. Method
- **Pipeline**: The method involves a pipeline that integrates Gaussian splatting with existing neural rendering techniques.
- **Architecture / Loss / Training**: The architecture employs a loss function that balances realism and computational efficiency during training.
- **Complexity / Resources**: The method is designed to be resource-efficient, allowing for real-time applications.

</details>

### [SelfieAvatar: Real-time Head Avatar reenactment from a Selfie Video](https://arxiv.org/pdf/2601.18851v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Head avatar generation and detail reconstruction

### 2. Motivation & Gaps
- The paper addresses the need for high-fidelity head avatar generation from selfie videos, focusing on detail reconstruction.

### 3. Core Idea
- A head avatar generation framework utilizing a detailed reconstruction model with multiple losses for texture recovery and avatar image generation.

### 4. Method
- **Pipeline**: The method involves a detailed reconstruction model integrated with a StyleGAN-based generator.
- **Architecture / Loss / Training**: Several losses are applied on different dimensions and fields during training.
- **Complexity / Resources**: Utilizes multiple StyleGAN-based networks and requires a 3-minute selfie video for training.

</details>

## video understanding

### [UEval: A Benchmark for Unified Multimodal Generation](https://arxiv.org/pdf/2601.22155v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- open-ended tasks in UEval

### 2. Motivation & Gaps
- The paper discusses the advancements in unified multimodal models that integrate various modalities for understanding and generation tasks.

### 3. Core Idea
- Produce step-by-step visual guides for various tasks.

### 4. Method
- **Pipeline**: The method involves a unified framework that integrates various modalities and tasks into a single model.
- **Architecture / Loss / Training**: Utilizes a combination of loss functions tailored for multimodal tasks to optimize training.
- **Complexity / Resources**: The model requires significant computational resources for training and inference due to its complexity.

</details>

### [Do VLMs Perceive or Recall? Probing Visual Perception vs. Memory with Classic Visual Illusions](https://arxiv.org/pdf/2601.22150v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Analyzing illusion-specific biases in models

### 2. Motivation & Gaps
- The study investigates how different models respond to visual illusions when only the illusion-inducing elements are presented.

### 3. Core Idea
- The research reveals that certain models exhibit extreme template bias when responding to visual illusions, particularly in the absence of visual evidence.

### 4. Method
- **Pipeline**: The study employs a perturbation pipeline to isolate the contribution of visual factors in illusions.
- **Architecture / Loss / Training**: Perception-first architectures that explicitly compare visual evidence before drawing conclusions.
- **Complexity / Resources**: The study evaluates 15 recent models from four families, including OpenAI, Anthropic, Google, and Qwen.

</details>

### [JUST-DUB-IT: Video Dubbing via Joint Audio-Visual Diffusion](https://arxiv.org/pdf/2601.22143v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation and Dubbing

### 2. Motivation & Gaps
- The paper addresses the challenges in generating accurate video content, particularly focusing on multilingual prompts and the synchronization of audio and visual elements.

### 3. Core Idea
- The model employs a dual learning rate strategy and masked loss training to enhance audio-visual alignment and focus on speaker-specific features.

### 4. Method
- **Pipeline**: The model is trained on preprocessed video-audio pairs with a focus on speaker-specific features and scene context.
- **Architecture / Loss / Training**: Masked loss training with a 10:1 ratio between foreground and background regions.
- **Complexity / Resources**: Trained for 2,000 steps with batch size 1, gradient checkpointing, and mixed-precision on video-audio pairs at 960x544 resolution.

</details>

## model collapse

### [RedSage: A Cybersecurity Generalist LLM](https://arxiv.org/pdf/2601.22159v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Cybersecurity Benchmarking and Evaluation

### 2. Motivation & Gaps
- The paper addresses the need for specialized language models in cybersecurity, highlighting the limitations of general-purpose models in this domain.

### 3. Core Idea
- RedSage is designed to improve performance in cybersecurity tasks by leveraging specialized training and evaluation protocols.

### 4. Method
- **Pipeline**: The RedSage pipeline includes continued pretraining, supervised fine-tuning, and deployment of a decision-making optimizer.
- **Architecture / Loss / Training**: The architecture employs a transformer-based model with specific loss functions tailored for cybersecurity tasks.
- **Complexity / Resources**: The total computational cost for the RedSage-8B pipeline is approximately 4,096 GPU-hours.

</details>

### [One-step Latent-free Image Generation with Pixel Mean Flows](https://arxiv.org/pdf/2601.22158v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Image Generation

### 2. Motivation & Gaps
- The paper addresses the challenges in image generation by proposing a novel method that leverages pixel mean flows.

### 3. Core Idea
- The core idea is to utilize pixel mean flows for latent-free image generation, enhancing the efficiency and quality of generated images.

### 4. Method
- **Pipeline**: The method involves a training pipeline that incorporates configurations and hyper-parameters tailored for optimal performance.
- **Architecture / Loss / Training**: The architecture employs perceptual loss based on LPIPS and ConvNeXt-V2, with a focus on maintaining several EMA decay rates during inference.
- **Complexity / Resources**: The implementation is based on JAX and TPUs, ensuring efficient resource utilization.

</details>

### [Discovering Hidden Gems in Model Repositories](https://arxiv.org/pdf/2601.22157v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Model Evaluation and Discovery

### 2. Motivation & Gaps
- The research focuses on improving model evaluation and discovery by leveraging existing model populations without applying population-level methods.

### 3. Core Idea
- Existing model populations contain valuable models that can outperform commonly used models without the need for population-level methods.

### 4. Method
- **Pipeline**: The method involves selecting models from popular model trees, evaluating them under consistent conditions, and using a custom scheduler for efficient model discovery.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The evaluation involves a budget allocation across various tasks and a custom query selection process.

</details>
