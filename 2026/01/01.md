# Daily Paper Digest Â· 2026-01-01
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [LiveTalk: Real-Time Multimodal Interactive Video Diffusion via Improved On-Policy Distillation](https://arxiv.org/pdf/2512.23576v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation

### 2. Motivation & Gaps
- The paper addresses the need for real-time interactive long video generation, which is a significant challenge in the field of video synthesis.

### 3. Core Idea
- The core idea is to develop a method for generating long videos interactively in real-time, leveraging autoregressive models to ensure coherence and responsiveness.

### 4. Method
- **Pipeline**: The method involves a pipeline that integrates audio input and user interactions to generate video content dynamically.
- **Architecture / Loss / Training**: The architecture employs a loss function that balances quality and coherence across generated frames.
- **Complexity / Resources**: The method is designed to be computationally efficient, allowing for real-time generation on standard hardware.

</details>

### [SoulX-LiveTalk: Real-Time Infinite Streaming of Audio-Driven Avatars via Self-Correcting Bidirectional Distillation](https://arxiv.org/pdf/2512.23379v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Audio-driven avatar video generation

### 2. Motivation & Gaps
- The paper addresses the challenge of generating avatar videos that can adapt to infinite lengths based on audio input.

### 3. Core Idea
- The proposed method utilizes a novel approach to generate avatar videos that can seamlessly adapt to varying audio inputs over an infinite duration.

### 4. Method
- **Pipeline**: The method involves a pipeline that processes audio input and generates corresponding avatar video frames in real-time.
- **Architecture / Loss / Training**: The architecture employs a loss function that optimizes for both visual fidelity and audio synchronization.
- **Complexity / Resources**: The model is designed to be resource-efficient, allowing for real-time generation on standard hardware.

</details>

### [StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars](https://arxiv.org/pdf/2512.22065v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- talking avatar generation

### 2. Motivation & Gaps
- This work focuses on talking avatar generation for constructive, human-centered applications.

### 3. Core Idea
- The system supports real-time generation of talking avatars while ensuring ethical considerations are met.

### 4. Method
- **Pipeline**: The method involves a denoising process and variational autoencoder (VAE) for video generation.
- **Architecture / Loss / Training**: The architecture is trained with a focus on maintaining identity and improving temporal consistency.
- **Complexity / Resources**: The model is evaluated using two H800 GPUs.

</details>

## video understanding

### [SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time](https://arxiv.org/pdf/2512.25075v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation with Temporal Control

### 2. Motivation & Gaps
- The paper addresses the challenge of generating coherent videos with diverse temporal controls and camera motions.

### 3. Core Idea
- The proposed method, SpaceTimePilot, enables disentangled control over camera motion and temporal dynamics through a novel dataset and embedding strategies.

### 4. Method
- **Pipeline**: The method involves rendering multi-view video sequences and applying temporal warping for training.
- **Architecture / Loss / Training**: Utilizes 1D-Conv embedding for time embedding to preserve scene dynamics while generating accurate camera motion.
- **Complexity / Resources**: Requires significant computational resources for rendering and training on large datasets.

</details>

### [Randomization Times under Quantum Chaotic Hamiltonian Evolution](https://arxiv.org/pdf/2512.25074v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the randomization time of quantum states under chaotic dynamics

### 2. Motivation & Gaps
- The study aims to define and identify the intrinsic randomization time generated by quantum dynamics, focusing on the transition from unentangled to Haar-random states.

### 3. Core Idea
- Characterize randomization by comparing the distribution of observables against Haar-random states rather than just late-time distributions.

### 4. Method
- **Pipeline**: Define a temporal ensemble of states evolved from unentangled states and analyze their observables over time.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Utilizes the Mixed Field Ising Model with periodic boundary conditions and specific initial conditions.

</details>

### [Classification of Interacting Topological Crystalline Superconductors in Three Dimensions and Beyond](https://arxiv.org/pdf/2512.25069v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- To classify 2+1D interacting fermionic symmetry protected topological (FSPT) states.

### 2. Motivation & Gaps
- The paper discusses the classification of 2+1D FSPT protected by internal discrete symmetry, focusing on the roles of various cochains in this classification.

### 3. Core Idea
- The classification is characterized by a triplet (n1, n2, Î½3) representing different fermionic decorations and their interactions under symmetry transformations.

### 4. Method
- **Pipeline**: The method involves analyzing the symmetry transformations and their effects on the fermionic states and decorations.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The complexity arises from the need to account for various symmetry actions and their implications on the fermionic states.

</details>

## model collapse

### [Edit3r: Instant 3D Scene Editing from Sparse Unposed Images](https://arxiv.org/pdf/2512.25071v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D scene reconstruction and editing

### 2. Motivation & Gaps
- Existing methods struggle with robustness and consistency in 3D scene editing, particularly under varying input conditions.

### 3. Core Idea
- Edit3r unifies reconstruction and instruction-driven editing of 3D scenes from unposed, instruction-edited images using a single-pass prediction of edited 3D Gaussian splats.

### 4. Method
- **Pipeline**: Decouples 2D editing from feed-forward reconstruction, allowing different editors at test time.
- **Architecture / Loss / Training**: Utilizes a SAM2-based recoloring strategy and an asymmetric input scheme for supervision.
- **Complexity / Resources**: Lightweight 3D regularization on Gaussian centers to maintain multi-view coherence.

</details>
