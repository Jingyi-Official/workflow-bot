# Daily Paper Digest Â· 2026-02-04
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [Ontology-to-tools compilation for executable semantic constraint enforcement in LLM agents](https://arxiv.org/pdf/2602.03439v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Ontology and knowledge graph construction using large language models

### 2. Motivation & Gaps
- The paper addresses the need for efficient methods to construct ontologies and knowledge graphs, leveraging the capabilities of large language models (LLMs).

### 3. Core Idea
- Utilizing LLMs to automate the construction of ontologies and knowledge graphs, improving efficiency and accuracy in data integration.

### 4. Method
- **Pipeline**: The proposed method involves preprocessing text data, applying LLMs for entity recognition and relationship extraction, and constructing the ontology.
- **Architecture / Loss / Training**: The architecture employs a transformer-based model with a focus on minimizing loss during training through supervised learning techniques.
- **Complexity / Resources**: The method requires significant computational resources, including GPU acceleration for training large models.

</details>

### [OFERA: Blendshape-driven 3D Gaussian Control for Occluded Facial Expression to Realistic Avatars in VR](https://arxiv.org/pdf/2602.01748v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Real-time reconstruction of occluded facial expressions as photorealistic 3D Gaussian avatars

### 2. Motivation & Gaps
- The importance of system-level integration for practical avatar deployment in VR, highlighting the need for coordination across sensing, representation, and rendering stages.

### 3. Core Idea
- OFERA integrates headset-available sensing, calibrated parameter mapping, and lightweight real-time communication to enable realistic avatar control in VR.

### 4. Method
- **Pipeline**: An end-to-end pipeline that takes blendshape data from a VR headset and renders a Gaussian avatar with realistic expressions in real-time.
- **Architecture / Loss / Training**: The architecture includes BDA, EPM, and MiA modules, with a focus on real-time performance and reducing distribution mismatch.
- **Complexity / Resources**: The system is constrained by the blendshape space and requires careful calibration across different VR headsets.

</details>

### [Streamlined Facial Data Collection based on Utterance and Emotional Data for Human-to-Avatar Reconstruction](https://arxiv.org/pdf/2602.01729v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Avatar Generation

### 2. Motivation & Gaps
- This study demonstrates that focusing on essential data inputs, specifically utterance and emotional expression data, can generate realistic avatars with significantly reduced data requirements.

### 3. Core Idea
- By targeting expressions most relevant to conversational interaction, we streamlined the data acquisition process, improving efficiency without compromising avatar quality.

### 4. Method
- **Pipeline**: Combination of spontaneous speech and direct emotional expression to achieve a balance between quality and efficiency.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Reduced data requirements by approximately 61% compared to extensive data collection methods.

</details>

## video understanding

### [A Unified Categorical Description of Quantum Hall Hierarchy and Anyon Superconductivity](https://arxiv.org/pdf/2602.03848v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the superconductivity near non-Abelian fractional spin Hall insulators.

### 2. Motivation & Gaps
- The study explores the relationship between superconductivity and non-Abelian fractional spin Hall insulators in twisted bilayer MoTe2.

### 3. Core Idea
- The paper proposes that superconductivity can emerge in systems that are proximate to non-Abelian fractional spin Hall insulators, particularly in twisted bilayer MoTe2.

### 4. Method
- **Pipeline**: The research employs theoretical modeling and numerical simulations to analyze the superconducting properties.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The study requires advanced computational resources for simulations and theoretical analysis.

</details>

### [Understanding and Exploiting Weight Update Sparsity for Communication-Efficient Distributed RL](https://arxiv.org/pdf/2602.03839v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Distributed Model Synchronization

### 2. Motivation & Gaps
- The paper addresses the challenges of efficiently synchronizing model weights in distributed systems, particularly focusing on the trade-offs between cold-start latency, storage requirements, and upload bandwidth.

### 3. Core Idea
- PULSE introduces a decoupled design for model synchronization that allows independent scaling of training and inference, utilizing a combination of full checkpoints and delta updates to optimize performance and resource usage.

### 4. Method
- **Pipeline**: The synchronization process involves publishing checkpoints from training nodes and synchronizing them on inference nodes using either a fast path for recent updates or a slow path for cold starts.
- **Architecture / Loss / Training**: The architecture employs a multi-level integrity verification system to ensure the correctness of the model weights during transmission.
- **Complexity / Resources**: The protocol balances the trade-offs of cold-start latency, storage requirements, and upload bandwidth, with a maximum storage requirement of approximately 151GB for a 7B model.

</details>

### [PrevizWhiz: Combining Rough 3D Scenes and 2D Video to Guide Generative Video Previsualization](https://arxiv.org/pdf/2602.03838v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Generative Video Previsualization

### 2. Motivation & Gaps
- The paper aims to illustrate the capabilities of PrevizWhiz in generating diverse cinematic shots and styles for previsualization in filmmaking.

### 3. Core Idea
- PrevizWhiz integrates 3D blocking and 2D video to enhance the previsualization process in filmmaking, allowing for a variety of shot types and visual styles.

### 4. Method
- **Pipeline**: The system utilizes 3D blocking, resemblance-based restyling, and optional video-driven motion to generate outputs.
- **Architecture / Loss / Training**: Utilizes a generative model architecture with specific loss functions to optimize the quality of generated outputs.
- **Complexity / Resources**: Requires carefully curated datasets and caption labeling, which are uneven across styles and demographics.

</details>

## model collapse

### [EventNeuS: 3D Mesh Reconstruction from a Single Event Camera](https://arxiv.org/pdf/2602.03847v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Geometry Reconstruction and Novel View Synthesis

### 2. Motivation & Gaps
- Existing methods struggle with preserving fine surface details and accurate geometry reconstruction from event streams.

### 3. Core Idea
- EventNeuS leverages a hybrid sampling strategy and advanced metrics to achieve superior geometry reconstruction and novel view synthesis from event streams.

### 4. Method
- **Pipeline**: Hybrid sampling strategy for evaluation points and advanced metrics for geometry comparison.
- **Architecture / Loss / Training**: Utilizes SDF and color field networks with Marching Cubes for mesh extraction.
- **Complexity / Resources**: The implementation uses TinyCUDA-NN for efficient encoding and requires significant computational resources for training.

</details>

### [PLATE: Plasticity-Tunable Efficient Adapters for Geometry-Aware Continual Learning](https://arxiv.org/pdf/2602.03846v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- two-task continual learning protocol

### 2. Motivation & Gaps
- The paper addresses the challenges of continual learning in language models, focusing on the need for efficient adaptation without catastrophic forgetting.

### 3. Core Idea
- The proposed method utilizes orthogonal subspace learning to enhance the continual learning capabilities of language models, allowing them to adapt to new tasks while preserving knowledge from previous tasks.

### 4. Method
- **Pipeline**: Initialize base model and heads, train on two tasks with various methods and configurations.
- **Architecture / Loss / Training**: The architecture is based on a multi-layer perceptron with specific adaptations for continual learning, focusing on minimizing loss across tasks.
- **Complexity / Resources**: The method is designed to be resource-efficient, leveraging existing model architectures and requiring minimal additional computational resources.

</details>

### [Parallel-Probe: Towards Efficient Parallel Thinking via 2D Probing](https://arxiv.org/pdf/2602.03845v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Efficient parallel reasoning in large language models

### 2. Motivation & Gaps
- This work establishes 2D probing as a powerful interface for understanding and controlling parallel reasoning, opening a new research direction toward principled, efficient parallel thinking of large language models.

### 3. Core Idea
- The introduction of 2D probing as a black-box interface to monitor reasoning trajectories, enabling principled control over parallel generation through deviation-based branch pruning and consensus-based early stopping.

### 4. Method
- **Pipeline**: Utilizes 2D probing to dynamically coordinate parallel generation.
- **Architecture / Loss / Training**: Training-free online controller leveraging global probing signals.
- **Complexity / Resources**: Extensive experiments across multiple model scales and reasoning benchmarks.

</details>
