# Daily Paper Digest Â· 2026-02-26
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [ViSTAR: Virtual Skill Training with Augmented Reality with 3D Avatars and LLM coaching agent](https://arxiv.org/pdf/2602.22077v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- AR training system for athletic practice

### 2. Motivation & Gaps
- The study aims to enhance individual skill training in sports using AR technology, focusing on isolated technical drills.

### 3. Core Idea
- ViSTAR integrates 3D motion reconstruction with LLM-based verbal feedback to support self-guided athletic practice.

### 4. Method
- **Pipeline**: Utilizes a single external RGB camera for motion capture and feedback delivery.
- **Architecture / Loss / Training**: Random Forest classifier trained on synthetic motion pairs generated by injecting joint-level perturbations.
- **Complexity / Resources**: Lightweight setup using readily available off-the-shelf equipment without specialized sensors.

</details>

### [WildGHand: Learning Anti-Perturbation Gaussian Hand Avatars from Monocular In-the-Wild Videos](https://arxiv.org/pdf/2602.20556v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Dynamic scene rendering and 3D content creation

### 2. Motivation & Gaps
- The paper addresses the challenges in rendering dynamic scenes using 3D Gaussian splatting techniques.

### 3. Core Idea
- Utilizing 3D Gaussian splatting to enhance the rendering of dynamic scenes in real-time applications.

### 4. Method
- **Pipeline**: The method involves capturing dynamic scenes and applying Gaussian splatting techniques for rendering.
- **Architecture / Loss / Training**: The architecture employs four prediction heads to estimate Gaussian attributes and refine hand-specific parameters.
- **Complexity / Resources**: The method requires significant computational resources for real-time processing.

</details>

### [BigMaQ: A Big Macaque Motion and Animation Dataset Bridging Image and 3D Pose Representations](https://arxiv.org/pdf/2602.19874v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Dynamic Pose Estimation

### 2. Motivation & Gaps
- The paper addresses the challenge of accurately estimating the poses of a four-legged avatar using a reduced set of joints, focusing on improving the realism of the poses and the efficiency of the model.

### 3. Core Idea
- The core idea is to optimize a mesh model for dynamic pose estimation by adapting individual parameters and using a combination of loss functions to ensure realistic poses and smooth transitions.

### 4. Method
- **Pipeline**: The method involves initializing model parameters, optimizing them using Adam, and adapting the mesh for individual subjects based on multi-view data.
- **Architecture / Loss / Training**: The architecture employs various loss functions including keypoint reprojection loss, silhouette reprojection loss, pose and bone constraints, and smoothness loss.
- **Complexity / Resources**: Action tracking, label generation, and surface fitting was executed on a single NVIDIA Geforce RTX 3090 GPU. A single optimization step in surface fitting takes 0.019 s, resulting in an effective per-frame runtime of 6.65 s for our default 350-epoch setting.

</details>

## video understanding

### [WHOLE: World-Grounded Hand-Object Lifted from Egocentric Videos](https://arxiv.org/pdf/2602.22209v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- hand-object contact detection in cluttered scenes

### 2. Motivation & Gaps
- The paper addresses the challenge of reconstructing hand-held objects in 3D from egocentric videos, focusing on the interaction between hands and objects.

### 3. Core Idea
- The proposed method utilizes a 4-layer transformer decoder for hand-to-object diffusion, enabling effective reconstruction of hand-object interactions from video data.

### 4. Method
- **Pipeline**: The model processes sequences jointly using a non-autoregressive approach, incorporating various auxiliary losses to enhance realism.
- **Architecture / Loss / Training**: The architecture includes a diffusion variable with a 73-dimensional vector and is trained with a combination of DDPM loss and auxiliary objectives such as Interaction Loss, Consistency Loss, and Temporal Smoothness.
- **Complexity / Resources**: The model has 12.35M parameters and requires a single NVIDIA RTX 6000 GPU for processing, with a peak memory footprint of 14GB.

</details>

### [Solaris: Building a Multiplayer Video World Model in Minecraft](https://arxiv.org/pdf/2602.22208v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Language Model Evaluation

### 2. Motivation & Gaps
- The evaluation of Video Language Models (VLMs) focuses on their accuracy in answering queries from different perspectives in video episodes.

### 3. Core Idea
- The Self Forcing algorithm allows for clean predictions from noisy states in video sequences, optimizing memory usage during training.

### 4. Method
- **Pipeline**: The model generates video autoregressively while employing a stochastic gradient truncation strategy.
- **Architecture / Loss / Training**: DMD loss is applied to the sequence of estimates with gradients backpropagated from the final truncation step.
- **Complexity / Resources**: Maintains constant memory complexity with respect to the number of diffusion steps.

</details>

### [Reimagining Data Work: Participatory Annotation Workshops as Feminist Practice](https://arxiv.org/pdf/2602.22196v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Participatory annotation of media narratives related to feminicide and violence

### 2. Motivation & Gaps
- The discussion highlights the tension between the necessity of including evidence of abuse and the potential harm of excessive graphic details in reporting.

### 3. Core Idea
- The need for a new category in the taxonomy that addresses the balance between necessary details and excessive graphic content in reporting femicides.

### 4. Method
- **Pipeline**: Conducting workshops to collaboratively annotate media articles related to feminicide.
- **Architecture / Loss / Training**: Uso de arquitecturas de modelos de lenguaje preentrenados con ajuste fino en datos de feminicidio.
- **Complexity / Resources**: The workshops require resources for facilitation, materials, and participant engagement.

</details>

## model collapse

### [Neu-PiG: Neural Preconditioned Grids for Fast Dynamic Surface Reconstruction on Long Sequences](https://arxiv.org/pdf/2602.22212v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Point Cloud Reconstruction

### 2. Motivation & Gaps
- The paper addresses the challenges in point cloud reconstruction, particularly focusing on the effects of grid levels and input noise on reconstruction quality.

### 3. Core Idea
- Neu-PiG employs a hierarchical latent representation to efficiently capture both coarse and fine geometric structures, demonstrating robustness to input noise and varying resolutions.

### 4. Method
- **Pipeline**: The method involves a neural model that processes point clouds through a series of transformations and optimizations to achieve high-quality reconstructions.
- **Architecture / Loss / Training**: The architecture includes a temporal deformation model that influences reconstruction quality and stability, with various latent dimensionalities and network capacities evaluated.
- **Complexity / Resources**: The model complexity is managed through careful tuning of latent dimensions and network capacity, ensuring efficient resource utilization.

</details>

### [Computing with many encoded logical qubits beyond break-even](https://arxiv.org/pdf/2602.22211v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Quantum Simulation Experiments

### 2. Motivation & Gaps
- The paper discusses the fidelity and acceptance rates of quantum simulation experiments using logical qubits in a periodic lattice.

### 3. Core Idea
- To analyze the performance of various quantum simulation experiments and propose alternative fault-tolerant preparation techniques for resource states.

### 4. Method
- **Pipeline**: Conduct quantum simulation experiments with varying total Trotter steps and analyze fidelity and acceptance rates.
- **Architecture / Loss / Training**: The protocol is designed to be fault-tolerant to single weight-2 faults, ensuring that errors do not propagate and affect the logical state.
- **Complexity / Resources**: Utilizes a total of 1000 shots for fidelity estimation, with specific allocations for different tests.

</details>
