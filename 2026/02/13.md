# Daily Paper Digest Â· 2026-02-13
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [OMEGA-Avatar: One-shot Modeling of 360Â° Gaussian Avatars](https://arxiv.org/pdf/2602.11693v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Expression Reenactment

### 2. Motivation & Gaps
- The goal of Expression Reenactment is to transfer the pose and expression from a driving image to the source image while preserving the source identity and maintaining high fidelity.

### 3. Core Idea
- To create a complete canonical 3D Gaussian avatar by combining Gaussian primitives from vertex and UV branches, and animating it using parameters extracted from a driving image.

### 4. Method
- **Pipeline**: The method involves training on the VFHQ dataset, generating pseudo-multi-view data, and using a face tracker to extract parameters for animation.
- **Architecture / Loss / Training**: The total objective function includes L_reconstruction, L_perceptual, L_mv, and L_local, with hyperparameters to balance contributions.
- **Complexity / Resources**: The model is trained on two NVIDIA H100 GPUs for 250,000 iterations with a batch size of 6.

</details>

### [ReaDy-Go: Real-to-Sim Dynamic 3D Gaussian Splatting Simulation for Environment-Specific Visual Navigation with Moving Obstacles](https://arxiv.org/pdf/2602.11575v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Surface reconstruction

### 2. Motivation & Gaps
- The paper addresses the need for efficient and high-fidelity methods in surface reconstruction.

### 3. Core Idea
- The core idea is to utilize planar-based gaussian splatting to enhance the efficiency and fidelity of surface reconstruction processes.

### 4. Method
- **Pipeline**: The method involves a pipeline that integrates gaussian splatting techniques with planar representations.
- **Architecture / Loss / Training**: The architecture employs a loss function tailored for optimizing surface fidelity during training.
- **Complexity / Resources**: The method is designed to be computationally efficient, requiring moderate resources for implementation.

</details>

### [3DXTalker: Unifying Identity, Lip Sync, Emotion, and Spatial Dynamics in Expressive 3D Talking Avatars](https://arxiv.org/pdf/2602.10516v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Emotion-driven speech animation

### 2. Motivation & Gaps
- The paper addresses the challenge of modeling fine-grained emotional dynamics in speech, which is often subtle and context-dependent.

### 3. Core Idea
- Introducing audio-rich representations that capture frame-wise amplitude and emotion cues to enhance expressive diversity and alignment with user intent.

### 4. Method
- **Pipeline**: The framework incorporates a center motion trajectory for expressive flexibility and robust dynamic control.
- **Architecture / Loss / Training**: Utilizes a dual-branch architecture for emotion disentanglement and employs a loss function that emphasizes lip synchronization and emotional expressivity.
- **Complexity / Resources**: The method requires significant computational resources for rendering and processing audio-visual data.

</details>

## video understanding

### [Ubiquitous yet forgotten: broad absorptions in the optical spectra of low-mass X-ray binaries](https://arxiv.org/pdf/2602.12282v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Analysis of optical spectra in low-mass X-ray binaries

### 2. Motivation & Gaps
- The study focuses on the evolution of broad absorptions in the optical spectra during outbursts of low-mass X-ray binaries.

### 3. Core Idea
- To analyze the spectral evolution of low-mass X-ray binaries during outbursts and identify key parameters affecting the spectra.

### 4. Method
- **Pipeline**: Spectroscopic analysis of optical data collected during outbursts.
- **Architecture / Loss / Training**: Likelihood function defined as chi-squared from model comparison.
- **Complexity / Resources**: Utilized multiple telescopes including GTC+OSIRIS, T-FLWO, and others for data collection.

</details>

### [Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment](https://arxiv.org/pdf/2602.12281v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Rephrase Generation for Robot Manipulation Instructions

### 2. Motivation & Gaps
- The paper discusses the generation of rephrased instructions for robot manipulation tasks using visual language models (VLMs) to improve instruction clarity and execution.

### 3. Core Idea
- Utilizing VLMs to generate concise and contextually grounded rephrases of user instructions for improved robot manipulation performance.

### 4. Method
- **Pipeline**: Rephrase generation occurs at boot time, reducing inference latency by processing scene reasoning and linguistic diversification offline.
- **Architecture / Loss / Training**: Utilizes pre-trained image and text encoders with frozen parameters during training to reduce computational costs.
- **Complexity / Resources**: Generating 8 rephrases takes approximately 11 seconds.

</details>

### [UniT: Unified Multimodal Chain-of-Thought Test-time Scaling](https://arxiv.org/pdf/2602.12279v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Automated data collection for multimodal chain-of-thought training trajectories

### 2. Motivation & Gaps
- The paper presents a framework for generating multimodal chain-of-thought training data to improve image generation and editing tasks.

### 3. Core Idea
- The proposed framework coordinates multiple models in an iterative loop to generate and refine images based on user prompts, ensuring high-quality outputs through verification and content memory.

### 4. Method
- **Pipeline**: An iterative loop involving an Image Gen Model, Vision-language Model, and Image Editing Model to produce and refine images.
- **Architecture / Loss / Training**: Training requires 700 H100 GPU hours on 12K filtered trajectories with an average of 3.6 refinement rounds.
- **Complexity / Resources**: The framework utilizes multiple models and requires significant computational resources for training and image generation.

</details>

## model collapse

### [AttentionRetriever: Attention Layers are Secretly Long Document Retrievers](https://arxiv.org/pdf/2602.12278v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Multilingual text retrieval using long-context representation and reranking models

### 2. Motivation & Gaps
- Existing long document retrieval datasets have limitations in terms of average document length and number of evidences.

### 3. Core Idea
- To construct a dataset with significantly larger average document lengths and evidences for improved multilingual text retrieval.

### 4. Method
- **Pipeline**: AttentionRetriever for long document retrieval.
- **Architecture / Loss / Training**: Utilizes attention scoring, embedding scoring, and entity graph.
- **Complexity / Resources**: While slower than sparse models, it achieves similar latency to larger dense models.

</details>
