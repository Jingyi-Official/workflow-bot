# Daily Paper Digest Â· 2026-02-03
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [OFERA: Blendshape-driven 3D Gaussian Control for Occluded Facial Expression to Realistic Avatars in VR](https://arxiv.org/pdf/2602.01748v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Real-time reconstruction of occluded facial expressions as photorealistic 3D Gaussian avatars

### 2. Motivation & Gaps
- The importance of system-level integration for practical avatar deployment in VR, highlighting the need for coordination across sensing, representation, and rendering stages.

### 3. Core Idea
- OFERA integrates headset-available sensing, calibrated parameter mapping, and lightweight real-time communication to enable realistic avatar control in VR.

### 4. Method
- **Pipeline**: An end-to-end pipeline that takes blendshape data from a VR headset and renders a Gaussian avatar with realistic expressions in real-time.
- **Architecture / Loss / Training**: The fidelity of facial deformations depends on the representation capacity of the underlying Gaussian avatar backbone model.
- **Complexity / Resources**: The system involves constraints from multiple stages of representation and parameter transformation, which can limit expressiveness.

</details>

### [Streamlined Facial Data Collection based on Utterance and Emotional Data for Human-to-Avatar Reconstruction](https://arxiv.org/pdf/2602.01729v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Avatar Generation

### 2. Motivation & Gaps
- This study demonstrates that focusing on essential data inputs, specifically utterance and emotional expression data, can generate realistic avatars with significantly reduced data requirements.

### 3. Core Idea
- By targeting expressions most relevant to conversational interaction, we streamlined the data acquisition process, improving efficiency without compromising avatar quality.

### 4. Method
- **Pipeline**: Combination of spontaneous speech and direct emotional expression to achieve a balance between quality and efficiency.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Reduced data requirements by approximately 61% compared to extensive data collection methods.

</details>

### [VRGaussianAvatar: Integrating 3D Gaussian Avatars into VR](https://arxiv.org/pdf/2602.01674v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D avatar reconstruction and rendering in virtual reality

### 2. Motivation & Gaps
- The paper addresses the challenges of creating realistic 3D avatars for virtual reality environments, focusing on the integration of 3D Gaussian splatting techniques.

### 3. Core Idea
- The core idea is to utilize a 3D Gaussian splatting approach to create detailed and expressive avatars that can be rendered in real-time within virtual reality environments.

### 4. Method
- **Pipeline**: The method involves a reconstruction pipeline that uses pre-trained encoders to extract features from RGB images, which are then decoded into 3D Gaussian parameters.
- **Architecture / Loss / Training**: The architecture employs a transformer-based network with specific loss weights for masked pixel loss, perceptual loss, and face ID loss, among others.
- **Complexity / Resources**: The system runs on a Unity-based frontend and a Python-based backend, requiring significant computational resources for real-time rendering.

</details>

## video understanding

### [Motivation, Attention, and Visual Platform Design: How Moral Contagions Spread on TikTok and Instagram in the 2024 United States Presidential Election](https://arxiv.org/pdf/2602.02479v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Observational analysis of moral foundations and sharing behaviors on social media

### 2. Motivation & Gaps
- Understanding how algorithmic design, network topology, and moral foundation deployment interact to determine which issues get moralized is essential for political practice and democratic theory.

### 3. Core Idea
- As political communication shifts from text-based to visual-first platforms, understanding the dynamics of moralization in social media is crucial.

### 4. Method
- **Pipeline**: Analysis of over 3 million posts across TikTok and Instagram.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Utilized the TikTok Researcher API and Meta Content Library for data collection.

</details>

### [HumanX: Toward Agile and Generalizable Humanoid Interaction Skills from Human Videos](https://arxiv.org/pdf/2602.02473v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Humanoid control and imitation learning

### 2. Motivation & Gaps
- The paper addresses the challenge of enabling humanoid robots to accurately imitate complex interactions present in reference data, particularly focusing on sequential contacts.

### 3. Core Idea
- The proposed method utilizes a composite reward function that incorporates various imitation rewards to enhance the humanoid's ability to replicate human-like interactions with objects.

### 4. Method
- **Pipeline**: The method employs a reinforcement learning pipeline that integrates multiple reward components for body and object motion imitation.
- **Architecture / Loss / Training**: The architecture is designed to optimize a composite reward function that includes body motion, object motion, relative motion, and contact graph imitation rewards.
- **Complexity / Resources**: The method requires significant computational resources for training due to the complexity of the reward functions and the need for accurate simulation of humanoid dynamics.

</details>

### [Relationship-Aware Hierarchical 3D Scene Graph for Task Reasoning](https://arxiv.org/pdf/2602.02456v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D scene graph generation

### 2. Motivation & Gaps
- The paper addresses the need for effective 3D scene graph generation from indoor reconstructions.

### 3. Core Idea
- The core idea is to develop a framework that can generate 3D semantic scene graphs from indoor reconstructions effectively.

### 4. Method
- **Pipeline**: The method involves processing 3D indoor reconstructions to extract semantic information and construct scene graphs.
- **Architecture / Loss / Training**: The architecture utilizes a transformer-based model with specific loss functions tailored for scene graph generation.
- **Complexity / Resources**: The method requires moderate computational resources, primarily for training the transformer model.

</details>

## model collapse

### [Reward-free Alignment for Conflicting Objectives](https://arxiv.org/pdf/2602.02495v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Safety Alignment Evaluation

### 2. Motivation & Gaps
- This work discusses safety-alignment evaluation and includes brief excerpts of model-generated content that may be harmful or sexually explicit.

### 3. Core Idea
- The paper introduces a framework for aligning model outputs with safety and helpfulness objectives while addressing conflicting user intents.

### 4. Method
- **Pipeline**: Supervised fine-tuning followed by preference alignment using a safety-alignment evaluation framework.
- **Architecture / Loss / Training**: Utilizes full-parameter fine-tuning for all methods and models.
- **Complexity / Resources**: Training setup includes a maximum response length of 2048 and a batch size of 64.

</details>

### [MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training](https://arxiv.org/pdf/2602.02494v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Non-invasive brain-to-text decoding

### 2. Motivation & Gaps
- Invasive brain-computer interfaces pose significant risks and scalability issues, while non-invasive methods like MEG and EEG allow for large-scale data collection and lower accessibility barriers.

### 3. Core Idea
- Long-context pre-training improves non-invasive brain-to-text decoding by leveraging abundant pre-training data to enhance model performance despite the challenges of noisy signals.

### 4. Method
- **Pipeline**: Data collection from MEG and EEG, followed by long-context pre-training and fine-tuning for decoding tasks.
- **Architecture / Loss / Training**: Cross-entropy on masked tokens during pre-training and D-SigLIP during fine-tuning.
- **Complexity / Resources**: Utilizes NVIDIA A100, L40S, or H100 GPUs for training.

</details>

### [PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss](https://arxiv.org/pdf/2602.02493v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Image Generation

### 2. Motivation & Gaps
- The paper addresses the limitations of existing latent diffusion models by introducing a new pixel diffusion approach that incorporates perceptual losses.

### 3. Core Idea
- The core idea is to utilize pixel diffusion techniques combined with perceptual losses to improve the quality of generated images over traditional latent diffusion methods.

### 4. Method
- **Pipeline**: The method involves a training step using a DiT network and a sampling step to generate images based on class labels or textual prompts.
- **Architecture / Loss / Training**: The architecture employs a combination of L2 loss, LPIPS loss, P-DINO loss, and REPA loss during training.
- **Complexity / Resources**: The method requires significant computational resources for training and inference due to the complexity of the pixel diffusion process.

</details>
