# Daily Paper Digest Â· 2026-02-14
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [OMEGA-Avatar: One-shot Modeling of 360Â° Gaussian Avatars](https://arxiv.org/pdf/2602.11693v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Expression Reenactment

### 2. Motivation & Gaps
- The goal of Expression Reenactment is to transfer the pose and expression from a driving image to the source image while preserving the source identity and maintaining high fidelity.

### 3. Core Idea
- To create a complete canonical 3D Gaussian avatar by combining Gaussian primitives from vertex and UV branches, and animating it using parameters extracted from a driving image.

### 4. Method
- **Pipeline**: The framework utilizes a pre-trained diffusion model to generate pseudo-multi-view data for training, ensuring geometric and appearance constraints.
- **Architecture / Loss / Training**: The total objective function includes L_reconstruction, L_perceptual, L_mv, and L_local, with hyperparameters to balance contributions.
- **Complexity / Resources**: The model is trained on two NVIDIA H100 GPUs for 250,000 iterations with a batch size of 6.

</details>

### [ReaDy-Go: Real-to-Sim Dynamic 3D Gaussian Splatting Simulation for Environment-Specific Visual Navigation with Moving Obstacles](https://arxiv.org/pdf/2602.11575v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Surface reconstruction

### 2. Motivation & Gaps
- The paper addresses the need for effective training of visual navigation policies in dynamic environments.

### 3. Core Idea
- ReaDy-Go generates photorealistic navigation datasets by combining various components to enhance navigation performance in both simulation and real-world scenarios.

### 4. Method
- **Pipeline**: Combines a GS scene, a human animation module, an expert planner, and a human planner to create datasets.
- **Architecture / Loss / Training**: The navigation policy consists of ten convolutional layers with residual connections and three MLP layers, trained with the Adam optimizer.
- **Complexity / Resources**: Requires approximately 80kâ€“120k data samples per environment and uses a learning rate of 10^-4.

</details>

### [3DXTalker: Unifying Identity, Lip Sync, Emotion, and Spatial Dynamics in Expressive 3D Talking Avatars](https://arxiv.org/pdf/2602.10516v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Emotion-driven speech animation

### 2. Motivation & Gaps
- The paper addresses the challenge of modeling fine-grained emotional dynamics in speech, which is often subtle and context-dependent.

### 3. Core Idea
- Introducing audio-rich representations that capture frame-wise amplitude and emotion cues for better emotional expression in speech.

### 4. Method
- **Pipeline**: The framework incorporates a center motion trajectory for expressive flexibility and robust dynamic control.
- **Architecture / Loss / Training**: Incorporates geometric constraints for stable identity and motion dynamics.
- **Complexity / Resources**: Requires significant computational resources for rendering and processing audio and visual data.

</details>

## video understanding

### [Ubiquitous yet forgotten: broad absorptions in the optical spectra of low-mass X-ray binaries](https://arxiv.org/pdf/2602.12282v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Analysis of optical spectra in low-mass X-ray binaries

### 2. Motivation & Gaps
- The study focuses on the evolution of broad absorptions in the optical spectra during outbursts of low-mass X-ray binaries.

### 3. Core Idea
- To analyze the spectral evolution of low-mass X-ray binaries during outbursts and identify key parameters affecting the spectra.

### 4. Method
- **Pipeline**: Spectroscopic analysis of optical data collected during outbursts.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Utilized data from GTC+OSIRIS and other telescopes for comprehensive analysis.

</details>

### [Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment](https://arxiv.org/pdf/2602.12281v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Rephrase Generation for Robot Manipulation Instructions

### 2. Motivation & Gaps
- The paper discusses the generation of rephrased instructions for robot manipulation tasks using visual language models (VLMs) to improve instruction clarity and execution.

### 3. Core Idea
- Utilizing VLMs to generate concise and contextually grounded rephrases of user instructions to enhance robot manipulation task performance.

### 4. Method
- **Pipeline**: Rephrase generation occurs at boot time, reducing inference latency and ensuring smooth execution.
- **Architecture / Loss / Training**: The verifier employs pre-trained image and text encoders, with a focus on scaling the text encoder for improved performance.
- **Complexity / Resources**: Generating 8 rephrases takes approximately 11 seconds.

</details>

### [UniT: Unified Multimodal Chain-of-Thought Test-time Scaling](https://arxiv.org/pdf/2602.12279v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Automated data collection for multimodal chain-of-thought training trajectories

### 2. Motivation & Gaps
- The paper presents a pipeline for generating multimodal chain-of-thought training data to improve image generation models.

### 3. Core Idea
- The proposed framework coordinates multiple models in an iterative loop to generate and refine images based on user prompts, ensuring quality through verification and editing.

### 4. Method
- **Pipeline**: An iterative loop involving an Image Gen Model, Vision-language Model, and Image Editing Model to produce and refine images.
- **Architecture / Loss / Training**: The training requires 700 H100 GPU hours and involves 12K multimodal trajectories with an average of 3.6 refinement rounds.
- **Complexity / Resources**: The pipeline utilizes multiple models and requires significant computational resources for training and image generation.

</details>

## model collapse

### [AttentionRetriever: Attention Layers are Secretly Long Document Retrievers](https://arxiv.org/pdf/2602.12278v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Multilingual text retrieval using long-context representation and reranking models

### 2. Motivation & Gaps
- Existing long document retrieval datasets have limitations in terms of document length and number of evidences, necessitating the development of a new dataset and model.

### 3. Core Idea
- To develop a generalized long-context text representation and reranking model that improves multilingual text retrieval performance.

### 4. Method
- **Pipeline**: AttentionRetriever model that incorporates attention scoring, embedding scoring, and entity graph.
- **Architecture / Loss / Training**: Utilizes a combination of attention mechanisms and contextual embeddings to enhance retrieval accuracy.
- **Complexity / Resources**: While slower than sparse models, it achieves comparable latency to larger dense models.

</details>
