# Daily Paper Digest Â· 2026-02-12
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [3DXTalker: Unifying Identity, Lip Sync, Emotion, and Spatial Dynamics in Expressive 3D Talking Avatars](https://arxiv.org/pdf/2602.10516v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Emotion-driven speech animation

### 2. Motivation & Gaps
- Current audio features may not fully capture the complexity of speech-driven emotions, which are often subtle and context-dependent.

### 3. Core Idea
- Introducing audio-rich representations that capture frame-wise amplitude and emotion cues for better emotional expression in speech.

### 4. Method
- **Pipeline**: Utilizes a framework that incorporates both audio features and visual dynamics for speech animation.
- **Architecture / Loss / Training**: Focuses on optimizing for expressive flexibility and robust dynamic control.
- **Complexity / Resources**: Requires advanced computational resources for real-time processing and rendering.

</details>

### [Toward Fine-Grained Facial Control in 3D Talking Head Generation](https://arxiv.org/pdf/2602.09736v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Dynamic scene rendering

### 2. Motivation & Gaps
- The paper addresses the need for real-time rendering of dynamic scenes using advanced Gaussian splatting techniques.

### 3. Core Idea
- Utilizing 4D Gaussian splatting to enhance the rendering of dynamic scenes in real-time applications.

### 4. Method
- **Pipeline**: The method involves capturing dynamic scenes and applying Gaussian splatting techniques to render them efficiently.
- **Architecture / Loss / Training**: The architecture employs a loss function tailored for optimizing Gaussian representations during training.
- **Complexity / Resources**: The method is designed to be computationally efficient, suitable for real-time applications with limited resources.

</details>

### [AUHead: Realistic Emotional Talking Head Generation via Action Units Control](https://arxiv.org/pdf/2602.09534v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Emotion-guided facial expression generation

### 2. Motivation & Gaps
- Facial Action Units (AUs) provide a standardized framework for describing facial muscle movements, but existing methods may not fully leverage AU guidance for generating natural expressions.

### 3. Core Idea
- AUHead produces expressive talking-head videos with strong emotional fidelity and stable identity preservation.

### 4. Method
- **Pipeline**: The method involves extracting AU sequences from emotional audio, aligning them with neutral audio, and using them as guidance for facial expression generation.
- **Architecture / Loss / Training**: AUHead is trained using a combination of AU guidance and audio inputs to optimize expression generation.
- **Complexity / Resources**: The method requires computational resources for processing audio and generating facial expressions, but specific resource requirements are not detailed.

</details>

## video understanding

### [SurfPhase: 3D Interfacial Dynamics in Two-Phase Flows from Sparse Videos](https://arxiv.org/pdf/2602.11154v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Two-Stage Interfacial Reconstruction with Bubble-Guided Velocity Estimation

### 2. Motivation & Gaps
- The paper addresses the challenge of reconstructing dynamic fluid interfaces from sparse video data, which is crucial for understanding two-phase flows.

### 3. Core Idea
- The proposed SurfPhase algorithm utilizes a two-stage approach for reconstructing interfacial dynamics by leveraging bubble-guided velocity estimation from sparse video inputs.

### 4. Method
- **Pipeline**: The method consists of two main stages: initial reconstruction from sparse views followed by refined reconstruction with additional views and video refinement via a diffusion model.
- **Architecture / Loss / Training**: The optimization involves minimizing a combination of appearance and geometric losses to ensure accurate reconstruction.
- **Complexity / Resources**: The algorithm requires computational resources for video processing and model training, particularly for the diffusion model.

</details>

### [Data Repetition Beats Data Scaling in Long-CoT Supervised Fine-Tuning](https://arxiv.org/pdf/2602.11149v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Supervised Fine-Tuning

### 2. Motivation & Gaps
- The paper investigates the effectiveness of data repetition compared to data scaling in the context of supervised fine-tuning for language models.

### 3. Core Idea
- The core idea is that data repetition can lead to better performance in fine-tuning language models than simply increasing the amount of data through scaling.

### 4. Method
- **Pipeline**: The method involves training models with repeated data samples and comparing their performance against models trained with scaled data.
- **Architecture / Loss / Training**: Utilizes standard architectures with a focus on loss functions that emphasize accuracy improvements.
- **Complexity / Resources**: The experiments were conducted using various model sizes and configurations, requiring significant computational resources.

</details>

### [Just on Time: Token-Level Early Stopping for Diffusion Language Models](https://arxiv.org/pdf/2602.11133v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Text Generation

### 2. Motivation & Gaps
- The paper addresses the need for efficient text generation models that can reduce computational overhead while maintaining performance.

### 3. Core Idea
- Introducing Jot, a model that utilizes early-exit mechanisms to improve generation speed without significantly sacrificing accuracy.

### 4. Method
- **Pipeline**: The model employs a diffusion-based approach with spatial modulation to optimize generation steps.
- **Architecture / Loss / Training**: The architecture is designed to minimize loss during training by leveraging early stopping techniques.
- **Complexity / Resources**: The model is tested on NVIDIA A100 GPUs, demonstrating significant wallclock speedups.

</details>

## model collapse

### [Mapping reservoir-enhanced superconductivity to near-long-range magnetic order in the undoped 1D Anderson- and Kondo-lattices](https://arxiv.org/pdf/2602.11153v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Study the 1D Anderson-lattice and its connection to Kondo systems using numerical methods.

### 2. Motivation & Gaps
- This work shows that at half-filling neither the simplest 1D version of Kivelsonâ€™s bilayer proposal nor the 1D Anderson lattice can escape having fully gapped insulating ground states in the thermodynamic regime.

### 3. Core Idea
- The study establishes that the RKKY-interaction in these systems is not long-ranged but effectively short-ranged, impacting the ability to achieve long-range order.

### 4. Method
- **Pipeline**: Numerical many-body calculations using DMRG and AFQMC.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Utilizes SyTen and ALF packages for calculations.

</details>

### [Utilitarian Distortion Under Probabilistic Voting](https://arxiv.org/pdf/2602.11152v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Evaluating voting rules and their distortions in AI alignment contexts

### 2. Motivation & Gaps
- Combining insights from different research communities and creating a practically useful and theoretically grounded evaluation framework for voting rules is an interesting and timely problem.

### 3. Core Idea
- The study investigates the distortion of voting rules under KL-constrained policy spaces, comparing Bordas and Maximal Lotteries in terms of their performance and distortion characteristics.

### 4. Method
- **Pipeline**: Construct instances of voting scenarios to analyze the distortion of voting rules.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The complexity of the analysis is primarily driven by the need to evaluate the expected social welfare and the associated probabilities under different voting rules.

</details>
