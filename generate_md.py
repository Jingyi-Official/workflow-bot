import os
import arxiv
from datetime import datetime, timezone
from textwrap import dedent


KEYWORDS = dict()
KEYWORDS["neural rendering"] = ["neural rendering", "radience field", "novel view synthesis", "NeRF", "light field"]
KEYWORDS["3D reconstruction"] = ["3D reconstruction", "surface reconstruction", "neural surface reconstruction"]

MAX_RESULTS = 5

# ========== arXiv Client ==========
client = arxiv.Client(
    page_size=MAX_RESULTS,
    delay_seconds=3,
    num_retries=3,
)

def get_papers(query: str, max_results: int = 100):
    search = arxiv.Search(
        query=query,
        max_results=max_results,
        sort_by=arxiv.SortCriterion.SubmittedDate,
        sort_order=arxiv.SortOrder.Descending,
    )
    return list(client.results(search))

def build_markdown():
    today = datetime.now(timezone.utc).astimezone().strftime("%Y-%m-%d")
    header = dedent(f"""\
    # æ¯æ—¥è®ºæ–‡é€Ÿé€’ Â· {today}

    > è‡ªåŠ¨ç”Ÿæˆï¼šæŒ‰ä¸»é¢˜ä¸å…³é”®è¯ä» arXiv æŠ“å–æœ€è¿‘æŠ•ç¨¿ï¼ˆæ¯ç±»æœ€å¤š {MAX_RESULTS} ç¯‡ï¼‰ã€‚
    """)
    lines = [header]

    for topic, keywords in KEYWORDS.items():
        lines.append(f"\n## {topic}\n")
        for kw in keywords:
            lines.append(f"### ğŸ” {kw}\n")
            results = get_papers(query=kw, max_results=MAX_RESULTS)
            if not results:
                lines.append("- ï¼ˆæ— ç»“æœï¼‰\n")
                continue

            for r in results:
                published = r.published.strftime("%Y-%m-%d") if r.published else "N/A"
                title = r.title.replace("\n", " ").strip()
                pdf = r.pdf_url or r.entry_id
                # å¦‚æœéœ€è¦æ‘˜è¦ï¼Œæ‰“å¼€ä¸‹ä¸€è¡Œï¼ˆæ‘˜è¦è¾ƒé•¿ï¼Œé»˜è®¤å…ˆä¸å±•å¼€ï¼‰
                # summary = (r.summary or "").replace("\n", " ").strip()
                lines.append(f"- **{title}**  \n  å‘å¸ƒï¼š{published}  Â·  [PDF]({pdf})\n")
                # æƒ³å±•å¼€æ‘˜è¦å¯åŠ ï¼š\n  æ‘˜è¦ï¼š{summary}\n

    return "\n".join(lines)

def ensure_dir(path: str):
    os.makedirs(path, exist_ok=True)

def main():
    # ä»¥â€œæ—¥æœŸâ€å‘½åçš„æ–‡ä»¶å¤¹
    today = datetime.now(timezone.utc).astimezone().strftime("%Y-%m-%d")
    out_dir = os.path.join(".", today)
    ensure_dir(out_dir)

    # Markdown æ–‡ä»¶å
    out_md = os.path.join(out_dir, "summary.md")
    content = build_markdown()
    with open(out_md, "w", encoding="utf-8") as f:
        f.write(content)

    # é¢å¤–ï¼šæ›´æ–°ä¸€ä¸ªæ ¹ç›®å½• README æŒ‡å‘ä»Šæ—¥æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
    readme_path = "README.md"
    link_line = f"- [{today} çš„æ±‡æ€»]({today}/summary.md)\n"
    if os.path.exists(readme_path):
        with open(readme_path, "r+", encoding="utf-8") as rf:
            txt = rf.read()
            if link_line not in txt:
                rf.seek(0, os.SEEK_END)
                rf.write("\n" + link_line)
    else:
        with open(readme_path, "w", encoding="utf-8") as rf:
            rf.write("# Daily ArXiv Digest\n\n" + link_line)

    print(f"[OK] å·²ç”Ÿæˆ {out_md}")

if __name__ == "__main__":
    main()