# Daily Paper Digest Â· 2025-12-03
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [YingVideo-MV: Music-Driven Multi-Stage Video Generation](https://arxiv.org/pdf/2512.02492v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation

### 2. Motivation & Gaps
- The framework aims to unify multi-modal inputs for long-sequence music video synthesis, addressing challenges in cinematic language and temporal consistency.

### 3. Core Idea
- The proposed framework integrates a two-stage pipeline for video generation, enhancing audio-visual synchronization and cinematic coherence.

### 4. Method
- **Pipeline**: The pipeline consists of MV-Director for global shot planning followed by DiT-based clip-wise generation.
- **Architecture / Loss / Training**: Incorporates DPO-driven preference alignment and dynamic window inference optimization.
- **Complexity / Resources**: Utilizes meticulously curated datasets and practical training/inference strategies.

</details>

### [FastAnimate: Towards Learnable Template Construction and Pose Deformation for Fast 3D Human Avatar Animation](https://arxiv.org/pdf/2512.01444v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D avatar rendering

### 2. Motivation & Gaps
- The paper addresses the need for expressive and animatable 3D avatars using Gaussian representations.

### 3. Core Idea
- The core idea is to utilize Gaussian representations to create expressive and animatable 3D avatars that can be rendered in real-time.

### 4. Method
- **Pipeline**: The method involves a pipeline that integrates Gaussian modeling with real-time rendering techniques.
- **Architecture / Loss / Training**: The architecture employs a loss function that emphasizes the quality of the Gaussian representation and the realism of the rendered output.
- **Complexity / Resources**: The method is designed to be computationally efficient, allowing for real-time applications on standard hardware.

</details>

### [Magnetic Dipole Portal Vector Dark Matter at Fixed-Targets](https://arxiv.org/pdf/2511.23259v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate light spin-1 dark matter phenomenology and search opportunities

### 2. Motivation & Gaps
- The study extends previous work on light spin-1 dark matter to a reversed mass hierarchy, providing new search opportunities at fixed target experiments.

### 3. Core Idea
- The paper proposes a viable light spin-1 dark matter model that includes an extension to the Standard Model gauge symmetry with a new SU(2) and a Z' mediator, along with new scalars and a higher dimensional portal interaction.

### 4. Method
- **Pipeline**: The study computes the relic abundance of dark matter and analyzes various annihilation processes to derive constraints from fixed target experiments.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The analysis involves complex calculations of decay rates and constraints from multiple experimental setups.

</details>

## video understanding

### [Video2Act: A Dual-System Video Diffusion Policy with Robotic Spatio-Motional Modeling](https://arxiv.org/pdf/2512.03044v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Real-World Manipulation

### 2. Motivation & Gaps
- The model shows robust spatial reasoning, accurately aligning the grasped object with the target placement zone despite variations in object appearance and initial positions.

### 3. Core Idea
- Video2Act learns a generalized representation of manipulation tasks, enabling stable execution across diverse dynamic scenarios.

### 4. Method
- **Pipeline**: The method involves capturing inter-arm temporal dependencies and utilizing Spatial Filtering Operators for geometric reasoning.
- **Architecture / Loss / Training**: The architecture is trained to optimize the balance between depth and performance, particularly focusing on the number of transformer blocks used.
- **Complexity / Resources**: The method balances complexity with performance, showing that a lightweight configuration can achieve high success rates without excessive latency.

</details>

### [OneThinker: All-in-one Reasoning Model for Image and Video](https://arxiv.org/pdf/2512.03043v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Segmentation

### 2. Motivation & Gaps
- The task involves identifying the creature that poses the greatest threat to an unwanted visitor in its domain.

### 3. Core Idea
- To provide segmentation hints by identifying a target object and its spatial characteristics in a video.

### 4. Method
- **Pipeline**: Identify the target object, select a representative time frame, and provide bounding boxes and points for segmentation.
- **Architecture / Loss / Training**: Utilizes a multi-task learning framework with shared and task-specific layers to optimize performance across different tasks.
- **Complexity / Resources**: The model requires significant computational resources, including high-performance GPUs for training and inference.

</details>

### [MultiShotMaster: A Controllable Multi-Shot Video Generation Framework](https://arxiv.org/pdf/2512.03041v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- multi-shot reference-to-video generation

### 2. Motivation & Gaps
- The study aims to improve spatiotemporal consistency in multi-shot video generation.

### 3. Core Idea
- Introducing Multi-Shot Narrative RoPE for enhanced shot transitions and reference injection in video generation.

### 4. Method
- **Pipeline**: Three-stage training paradigm focusing on multi-shot and reference-to-video generation.
- **Architecture / Loss / Training**: Utilizes diffusion loss across frames for global consistency.
- **Complexity / Resources**: High construction cost for multi-shot & multi-reference data.

</details>

## model collapse

### [MagicQuillV2: Precise and Interactive Image Editing with Layered Visual Cues](https://arxiv.org/pdf/2512.03046v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Image Editing

### 2. Motivation & Gaps
- The paper addresses the need for robust image editing techniques that can handle perceptual nuances in image composition.

### 3. Core Idea
- The core idea is to implement a two-stage difference extraction pipeline that generates robust masks for image editing, enhancing the quality of local edits while filtering out insignificant changes.

### 4. Method
- **Pipeline**: A two-stage difference extraction pipeline with pre-screening and mask generation in the CIELAB color space.
- **Architecture / Loss / Training**: Utilizes a diffusion transformer-based model with a heavy backbone and multiple control adapters.
- **Complexity / Resources**: Requires high-end H20 GPU for inference, with a latency of approximately 30-45 seconds per edit.

</details>

### [CAMEO: Correspondence-Attention Alignment for Multi-View Diffusion Models](https://arxiv.org/pdf/2512.03045v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Denoising multi-view diffusion

### 2. Motivation & Gaps
- The paper addresses the challenges in denoising multi-view images using diffusion models.

### 3. Core Idea
- Utilizing a 3D large reconstruction model to enhance the denoising process in multi-view diffusion.

### 4. Method
- **Pipeline**: The proposed method involves a pipeline that integrates 3D reconstruction with diffusion processes.
- **Architecture / Loss / Training**: The architecture employs a loss function tailored for multi-view consistency during training.
- **Complexity / Resources**: The method requires significant computational resources due to the complexity of 3D reconstruction.

</details>
