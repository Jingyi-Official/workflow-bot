# Daily Paper Digest Â· 2025-12-15
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [JoyAvatar: Real-time and Infinite Audio-Driven Avatar Generation with Autoregressive Diffusion](https://arxiv.org/pdf/2512.11423v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Audio-driven video generation

### 2. Motivation & Gaps
- The paper addresses the challenges in generating high-quality video from audio inputs, focusing on improving lip-sync accuracy and identity preservation.

### 3. Core Idea
- The introduction of a bidirectional teacher model that is distilled into a causal generator, enhancing video generation quality and speed.

### 4. Method
- **Pipeline**: The model employs Progressive Step Bootstrapping (PSB) and Motion Condition Injection (MCI) to improve training and inference consistency.
- **Architecture / Loss / Training**: Utilizes Denoising Matching Distillation (DMD) for model distillation and training.
- **Complexity / Resources**: The model achieves real-time performance exceeding 30 FPS with multi-GPU parallelization.

</details>

### [GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting](https://arxiv.org/pdf/2512.10939v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D talking head generation

### 2. Motivation & Gaps
- The paper addresses the challenges of generating realistic 3D talking heads that maintain lip synchronization and visual stability during audio playback.

### 3. Core Idea
- The proposed method generates a lip-sync 3D mesh and uses optimized FLAME parameters to ensure stable and realistic lip movements.

### 4. Method
- **Pipeline**: Audio input is processed to generate a 3D mesh with lip synchronization.
- **Architecture / Loss / Training**: Utilizes a loss function that minimizes artifacts and enhances lip motion accuracy.
- **Complexity / Resources**: Requires moderate computational resources for real-time processing.

</details>

### [Adaptive Optimal Control for Avatar-Guided Motor Rehabilitation in Virtual Reality](https://arxiv.org/pdf/2512.09667v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Motor rehabilitation using adaptive control frameworks

### 2. Motivation & Gaps
- The control frameworkâ€™s primary strength is its inherent adaptability, allowing it to adjust assistance based on the patient's motor capabilities and rehabilitation progress.

### 3. Core Idea
- The framework adapts the level of assistance and guidance to the patientâ€™s current motor capabilities, enhancing rehabilitation outcomes.

### 4. Method
- **Pipeline**: The method involves a parameter adaptation mechanism that updates the weights of the cost function based on a smoothness-based ability index.
- **Architecture / Loss / Training**: The control input is generated by minimizing a cost functional that balances synchronization with the patient's trajectory and guiding them towards an ideal reference motion.
- **Complexity / Resources**: The system requires a virtual reality setup and a mechanism for real-time adaptation based on patient performance.

</details>

## video understanding

### [V-RGBX: Video Editing with Accurate Controls over Intrinsic Properties](https://arxiv.org/pdf/2512.11799v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Image decomposition and synthesis

### 2. Motivation & Gaps
- The paper addresses the need for improved image decomposition and synthesis techniques that consider material and lighting variations.

### 3. Core Idea
- The core idea is to utilize diffusion models that are aware of material properties and lighting conditions to enhance image decomposition and synthesis.

### 4. Method
- **Pipeline**: The method involves a diffusion process that incorporates material and lighting information to generate high-quality images.
- **Architecture / Loss / Training**: The architecture employs a loss function that balances perceptual quality and fidelity to the original image.
- **Complexity / Resources**: The method requires significant computational resources due to the complexity of the diffusion models.

</details>

### [AnchorDream: Repurposing Video Diffusion for Embodiment-Aware Robot Data Synthesis](https://arxiv.org/pdf/2512.11797v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Imitation Learning in Robot Manipulation

### 2. Motivation & Gaps
- The study addresses the challenge of scaling imitation learning for real-robot policies by leveraging video diffusion models to synthesize diverse training data.

### 3. Core Idea
- AnchorDream repurposes pretrained video diffusion models to generate kinematically grounded and visually realistic demonstrations for scalable imitation learning.

### 4. Method
- **Pipeline**: The method involves collecting human demonstrations, segmenting trajectories, perturbing key states, and synthesizing augmented demonstrations using AnchorDream.
- **Architecture / Loss / Training**: The architecture utilizes global trajectory conditioning and long inference windows to enhance coherence and performance.
- **Complexity / Resources**: The method requires a PiPER robot platform and computational resources for video diffusion model training.

</details>

### [Structure From Tracking: Distilling Structure-Preserving Motion for Video Generation](https://arxiv.org/pdf/2512.11792v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation

### 2. Motivation & Gaps
- The paper addresses the challenges in video generation, particularly focusing on structural fidelity and temporal coherence.

### 3. Core Idea
- The proposed method, SAM2VideoX, enhances video generation by incorporating structural metrics and refining the feature fusion process to improve temporal coherence.

### 4. Method
- **Pipeline**: The method utilizes a DiT-based architecture with a focus on Local Gram Feature loss and a forward-only design for temporal consistency.
- **Architecture / Loss / Training**: The architecture employs a Local Gram Feature loss to enhance structural fidelity without introducing backward constraints.
- **Complexity / Resources**: The model operates with 5 billion parameters, demonstrating competitive performance against larger models.

</details>

## model collapse

### [Moment-Based 3D Gaussian Splatting: Resolving Volumetric Occlusion with Order-Independent Transmittance](https://arxiv.org/pdf/2512.11800v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Derivation and evaluation of trigonometric moments using Fourier basis

### 2. Motivation & Gaps
- The paper presents an alternative to polynomial basis moments by deriving trigonometric moments for Gaussian density functions.

### 3. Core Idea
- The core idea is to derive trigonometric moments for Gaussian density functions using a Fourier basis, providing a more accurate representation than traditional polynomial moments.

### 4. Method
- **Pipeline**: The method involves deriving the trigonometric moments through integrals and substitutions, focusing on the Gaussian parameters.
- **Architecture / Loss / Training**: L = (1âˆ’Î±)L + Î±L D-SSIM + Î»L consistency.
- **Complexity / Resources**: The complexity involves evaluating integrals with complex arguments and requires careful handling of Gaussian parameters.

</details>

### [Particulate: Feed-Forward 3D Object Articulation](https://arxiv.org/pdf/2512.11798v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D Object Generation

### 2. Motivation & Gaps
- The study addresses the challenges in generating articulated 3D objects, particularly focusing on the limitations of existing models when faced with diverse articulation configurations.

### 3. Core Idea
- The proposed model, PARTICULATE, aims to enhance the generation of articulated 3D objects by leveraging mesh connectivity and addressing the shortcomings of previous methods.

### 4. Method
- **Pipeline**: The method employs Hungarian matching to establish correspondences between predicted and ground-truth parts, applying penalties for unmatched parts.
- **Architecture / Loss / Training**: Utilizes a simple and scalable architecture with a focus on data efficiency.
- **Complexity / Resources**: The model is designed to be faster and more accurate, requiring fewer resources compared to traditional methods.

</details>
