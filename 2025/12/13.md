# Daily Paper Digest Â· 2025-12-13
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting](https://arxiv.org/pdf/2512.10939v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D talking head generation

### 2. Motivation & Gaps
- The paper addresses the challenges of generating realistic 3D talking heads that maintain lip synchronization and visual stability during audio playback.

### 3. Core Idea
- The proposed method utilizes audio-driven Gaussian splatting to create stable and realistic 3D talking heads.

### 4. Method
- **Pipeline**: The method generates a lip-sync 3D mesh from audio signals and uses optimized FLAME parameters for lip motion transfer.
- **Architecture / Loss / Training**: Incorporates a stability metric to quantify perceptual wobbling in generated videos.
- **Complexity / Resources**: Requires significant computational resources for real-time processing.

</details>

### [Adaptive Optimal Control for Avatar-Guided Motor Rehabilitation in Virtual Reality](https://arxiv.org/pdf/2512.09667v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Motor rehabilitation using adaptive control frameworks

### 2. Motivation & Gaps
- The control frameworkâ€™s primary strength is its inherent adaptability, allowing it to adjust assistance based on the patient's motor capabilities and rehabilitation progress.

### 3. Core Idea
- The framework adapts the level of assistance and guidance to the patientâ€™s current motor capabilities, enhancing rehabilitation outcomes.

### 4. Method
- **Pipeline**: The method involves a parameter adaptation mechanism that updates the weights of the cost function based on a smoothness-based ability index.
- **Architecture / Loss / Training**: The control input is generated by minimizing a cost functional that balances synchronization with the patient's trajectory and guiding them towards an ideal reference motion.
- **Complexity / Resources**: The system requires a virtual reality setup and a mechanism for real-time adaptation based on patient performance.

</details>

### [Relightable and Dynamic Gaussian Avatar Reconstruction from Monocular Video](https://arxiv.org/pdf/2512.09335v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Human avatar reconstruction and rendering

### 2. Motivation & Gaps
- The paper addresses the challenge of reconstructing high-fidelity human avatars and rendering them under arbitrary lighting conditions.

### 3. Core Idea
- The proposed framework reconstructs high-fidelity human avatars and enables rendering under arbitrary lighting conditions using a well-constructed dataset and a well-designed modeling framework.

### 4. Method
- **Pipeline**: The framework uses a combination of dataset construction and modeling techniques to achieve high-quality avatar reconstruction.
- **Architecture / Loss / Training**: Utilizes a rough approximation for PBR due to computational constraints.
- **Complexity / Resources**: The method requires significant computational resources, particularly for ray tracing.

</details>

## video understanding

### [WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World](https://arxiv.org/pdf/2512.10958v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Autonomous driving

### 2. Motivation & Gaps
- The paper discusses the potential of generative AI in enhancing autonomous driving technologies.

### 3. Core Idea
- The core idea is to leverage generative AI techniques to improve the decision-making and predictive capabilities of autonomous driving systems.

### 4. Method
- **Pipeline**: The method involves a generative model that integrates various data sources to simulate driving scenarios.
- **Architecture / Loss / Training**: Utilizes a combination of loss functions tailored for generative tasks in driving contexts.
- **Complexity / Resources**: The approach requires significant computational resources for training and real-time inference.

</details>

### [Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision](https://arxiv.org/pdf/2512.10956v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Visual Navigation

### 2. Motivation & Gaps
- The paper addresses the challenges of reliable navigation learning in urban environments, particularly focusing on filtering out distracting scenes.

### 3. Core Idea
- StereoWalker predicts five future waypoints spanning a five-second horizon to ensure smooth robot motion.

### 4. Method
- **Pipeline**: The method involves a series of steps including data filtering, depth estimation, point tracking, and attention-based feature aggregation.
- **Architecture / Loss / Training**: The model uses a transformer architecture with specific attention layers and a custom loss function to ensure directional consistency.
- **Complexity / Resources**: Requires 2.89 GB of VRAM and 0.2 s per sample on an A100 GPU at inference time.

</details>

### [E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training](https://arxiv.org/pdf/2512.10950v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- downstream supervised pose estimation

### 2. Motivation & Gaps
- The paper analyzes how different training datasets affect model performance, emphasizing the importance of data quality over quantity.

### 3. Core Idea
- Diversity and quality of training data are more critical than the quantity for training self-supervised models.

### 4. Method
- **Pipeline**: Controlled experiments with fixed computation budget and diverse datasets.
- **Architecture / Loss / Training**: Utilizes a photometric loss for Gaussian-based scene reconstruction while training the pose estimation module with ground-truth camera poses.
- **Complexity / Resources**: The model is trained on a mixture of datasets, optimizing for both performance and computational efficiency.

</details>

## model collapse

### [StereoSpace: Depth-Free Synthesis of Stereo Geometry via End-to-End Diffusion in a Canonical Space](https://arxiv.org/pdf/2512.10959v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Stereo Geometry Synthesis

### 2. Motivation & Gaps
- Transparent objects and depth estimation present significant challenges in stereo methods.

### 3. Core Idea
- StereoSpace maintains more faithful geometry and appearance in the presence of transparent objects compared to other methods.

### 4. Method
- **Pipeline**: The method involves training a diffusion model on stereo image pairs to learn the mapping from 2D images to 3D stereo geometry.
- **Architecture / Loss / Training**: The architecture employs a warping loss based on left-right consistency and utilizes PlÃ¼cker coordinates for ray representation.
- **Complexity / Resources**: The training involves 14 publicly available datasets and requires significant computational resources for model training.

</details>

### [SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model](https://arxiv.org/pdf/2512.10957v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Generative modeling

### 2. Motivation & Gaps
- The paper addresses the challenges in generating realistic 3D scenes, particularly in handling occlusions and open-set scenarios.

### 3. Core Idea
- The proposed framework, SceneMaker, utilizes a decoupled de-occlusion model and a unified pose estimation diffusion model to enhance 3D scene generation.

### 4. Method
- **Pipeline**: The framework includes a robust de-occlusion model and a pose estimation model with local and global attention mechanisms.
- **Architecture / Loss / Training**: The model is trained using a curated de-occlusion dataset and a synthesized scene dataset for open-set generalization.
- **Complexity / Resources**: The framework requires significant computational resources for training and evaluation, including a 10K curated dataset and a 200K synthesized scene dataset.

</details>
