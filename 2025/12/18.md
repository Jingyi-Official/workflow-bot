# Daily Paper Digest Â· 2025-12-18
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [Gaussian Pixel Codec Avatars: A Hybrid Representation for Efficient Rendering](https://arxiv.org/pdf/2512.15711v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Neural rendering

### 2. Motivation & Gaps
- The paper addresses the challenge of rendering dynamic scenes from images using neural networks.

### 3. Core Idea
- The core idea is to learn dynamic renderable volumes from images to improve the quality and efficiency of neural rendering.

### 4. Method
- **Pipeline**: The method involves a pipeline that processes images to create dynamic volumetric representations.
- **Architecture / Loss / Training**: Utilizes a neural network architecture with specific loss functions to optimize the rendering process.
- **Complexity / Resources**: The method requires significant computational resources for training and rendering.

</details>

### [FlexAvatar: Learning Complete 3D Head Avatars with Partial Supervision](https://arxiv.org/pdf/2512.15599v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Avatar Creation and Animation

### 2. Motivation & Gaps
- The paper addresses the challenge of creating high-quality avatars from limited input images, focusing on data efficiency during fitting.

### 3. Core Idea
- The proposed method improves avatar quality and identity preservation using fewer input frames by leveraging a novel architecture and data preparation techniques.

### 4. Method
- **Pipeline**: The pipeline includes data preparation, model training, and inference with head-centric coordinates.
- **Architecture / Loss / Training**: Utilizes a ViT-based architecture with specific hyperparameters for cross-attention and expression sequence MLP.
- **Complexity / Resources**: The model requires approximately 58k 3D Gaussians and operates on input images of resolution 512x512.

</details>

### [Towards Seamless Interaction: Causal Turn-Level Modeling of Interactive 3D Conversational Head Dynamics](https://arxiv.org/pdf/2512.15340v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D conversational head generation

### 2. Motivation & Gaps
- The DualTalk benchmark dataset provides a large-scale corpus for studying dual-speaker 3D conversational head generation, addressing the need for high-quality audio-visual recordings in face-to-face interactions.

### 3. Core Idea
- The proposed turn-level causal modeling provides a more general and principled framework for interactive 3D conversational head generation.

### 4. Method
- **Pipeline**: The DualTalk preprocessing pipeline is used for speaker separation, tracking, and 3D reconstruction to obtain aligned 3D head parameters and speech signals.
- **Architecture / Loss / Training**: The architecture includes a Transformer encoder with Turn-Level Causal Attention and employs a diffusion loss computed separately for head components during training.
- **Complexity / Resources**: The scalability of the diffusion head is investigated by varying its hidden dimension and the number of residual blocks.

</details>

## video understanding

### [Spatia: Video Generation with Updatable Spatial Memory](https://arxiv.org/pdf/2512.15716v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation

### 2. Motivation & Gaps
- The paper addresses the challenges in generating high-dynamic videos, which are essential for various applications in computer vision.

### 3. Core Idea
- The core idea is to enhance video generation techniques to produce high-quality dynamic videos efficiently.

### 4. Method
- **Pipeline**: The method involves a novel pipeline that integrates advanced generative techniques with efficient resource management.
- **Architecture / Loss / Training**: Utilizes a loss function tailored for dynamic content generation.
- **Complexity / Resources**: Designed to minimize computational complexity while maximizing output quality.

</details>

### [Artism: AI-Driven Dual-Engine System for Art Generation and Critique](https://arxiv.org/pdf/2512.15710v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Exploration of AI's role in art criticism and creation

### 2. Motivation & Gaps
- The project aims to demonstrate that AI technology is essential for critical art analysis and to address the superficial recombination of existing theoretical resources in contemporary art.

### 3. Core Idea
- The Artism project combines two AI systems, AIDA and Ismism Machine, to create a dynamic, self-evolving critical ecosystem that reflects the complexities of contemporary art criticism.

### 4. Method
- **Pipeline**: Integration of AIDA's evolving virtual art history with Ismism Machine's diagnostics to create a self-reflective loop.
- **Architecture / Loss / Training**: Utilizes a multi-stage processing architecture including a knowledge base, conceptual engine, concept visualizer, and art-critique generator.
- **Complexity / Resources**: Involves a comprehensive database of artists and artworks, along with advanced generative models and LLMs.

</details>

### [GateFusion: Hierarchical Gated Cross-Modal Fusion for Active Speaker Detection](https://arxiv.org/pdf/2512.15707v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Audio-Visual Fusion for Action Recognition

### 2. Motivation & Gaps
- Existing architectures benefit from pre-trained encoders, but the full model demonstrates superior performance, indicating that contributions extend beyond just encoder initialization.

### 3. Core Idea
- The proposed method enhances audio-visual interaction through a robust fusion strategy that leverages auxiliary losses for improved performance under data corruption.

### 4. Method
- **Pipeline**: The model incorporates multiple fusion layers and decoder widths to optimize performance and efficiency.
- **Architecture / Loss / Training**: Utilizes MAL and OPP objectives to enhance robustness against data corruption.
- **Complexity / Resources**: Involves trade-offs between memory cost and inference throughput, with selected configurations balancing efficiency and performance.

</details>

## model collapse

### [In Pursuit of Pixel Supervision for Visual Pre-training](https://arxiv.org/pdf/2512.15715v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Visual Representation Learning from Videos

### 2. Motivation & Gaps
- Static images have inherent limitations for learning visual intelligence, as they do not represent the natural format of visual information. Videos, particularly long ones, capture the temporal progression of events and their causal relationships, offering advantages for predictive modeling.

### 3. Core Idea
- This work validates that pixel supervision alone can produce strong visual representations competitive with more complex pre-training paradigms, aiming to scale this approach to web-scale video data.

### 4. Method
- **Pipeline**: Pre-training of a large encoder followed by distillation to smaller student models, with downstream evaluation on various tasks.
- **Architecture / Loss / Training**: Utilizes a teacher-student model where the teacher processes unmasked images and the student learns from masked inputs, optimizing cosine similarity loss.
- **Complexity / Resources**: Pre-training involves 1.3M iterations with a batch size of 16,384, using a 5.4B parameter encoder and various configurations for student models.

</details>

### [Large Isolated Stripes on Short 18-leg $t$-$J$ Cylinders](https://arxiv.org/pdf/2512.15714v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the formation of isolated stripes in the t-t'-J model

### 2. Motivation & Gaps
- The approach is motivated by thinking of the stripe as a one-dimensional line of dopants traversing a two-dimensional system.

### 3. Core Idea
- The emergence of a spin domain wall and the behavior of dopants in different filling fractions and doping types.

### 4. Method
- **Pipeline**: We use DMRG in the framework of matrix product states (MPS) implemented in the SyTeN toolkit.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The calculations are performed with a maximum bond dimension of m=10,240.

</details>
