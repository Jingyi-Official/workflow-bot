# Daily Paper Digest Â· 2025-12-10
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [Visionary: The World Model Carrier Built on WebGPU-Powered Gaussian Splatting Platform](https://arxiv.org/pdf/2512.08478v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Neural Rendering and World Modeling

### 2. Motivation & Gaps
- Visionary addresses fundamental barriers in neural rendering platforms, including the lack of effective web-native computation, limited extensibility, and heavy system dependencies.

### 3. Core Idea
- Visionary combines a modern graphics API (WebGPU) with a unified ONNX-based integration contract to enable real-time, in-browser rendering of diverse 3DGS variants.

### 4. Method
- **Pipeline**: A single browser-resident pipeline supports fast rendering and per-frame neural updates.
- **Architecture / Loss / Training**: The architecture decouples inference logic from training-specific rasterization operators, ensuring compatibility with standard ONNX runtimes.
- **Complexity / Resources**: WebGPU and ONNX runtimes are evolving, leading to compatibility and stability differences across browsers.

</details>

### [Blur2Sharp: Human Novel Pose and View Synthesis with Generative Prior Refinement](https://arxiv.org/pdf/2512.08215v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Novel Pose and View Synthesis

### 2. Motivation & Gaps
- The paper addresses the challenges of generating novel poses and views while maintaining high fidelity and consistency in visual quality.

### 3. Core Idea
- The proposed method integrates SMPL texture, normal, and semantic priors for comprehensive geometric guidance to achieve high-quality novel pose and view synthesis.

### 4. Method
- **Pipeline**: The method involves rendering SMPL condition maps, applying Human NeRF, and refining with a generative prior.
- **Architecture / Loss / Training**: The architecture includes a Reference Knowledge Transfer Module that enhances feature propagation and appearance consistency.
- **Complexity / Resources**: Memory usage ranges from 2.47 GB to 6.87 GB, with computation times varying from 1.58 seconds to 14.12 seconds.

</details>

### [ViSA: 3D-Aware Video Shading for Real-Time Upper-Body Avatar Creation](https://arxiv.org/pdf/2512.07720v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D avatar generation and video synthesis

### 2. Motivation & Gaps
- The paper addresses the need for high fidelity and real-time performance in 3D avatar generation.

### 3. Core Idea
- The proposed method leverages a 3D-aware reconstruction module to guide a distilled autoregressive video diffusion model for generating high-fidelity, temporally coherent avatars.

### 4. Method
- **Pipeline**: 3D reconstruction module -> Distilled autoregressive video diffusion model.
- **Architecture / Loss / Training**: Utilizes Adversarial Distribution Preservation loss to enhance visualization quality.
- **Complexity / Resources**: Achieves 15 FPS on a single A100 GPU.

</details>

## video understanding

### [Astra: General Interactive World Model with Autoregressive Denoising](https://arxiv.org/pdf/2512.08931v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Interactive Video Prediction

### 2. Motivation & Gaps
- Astra aims to provide a comprehensive solution for long-horizon interactive video prediction across various domains.

### 3. Core Idea
- Astra utilizes a noise-augmented memory and input-packing technique to achieve long-horizon predictions across diverse interactive tasks.

### 4. Method
- **Pipeline**: Astra employs an autoregressive denoising framework with action-aware conditioning.
- **Architecture / Loss / Training**: Utilizes a multi-modal control architecture with a focus on temporal and visual coherence.
- **Complexity / Resources**: Requires multiple denoising steps per frame, impacting real-time deployment.

</details>

### [Strong Mode Coupling via Quasi-Bound States in the Continuum in Bianisotropic Metasurfaces](https://arxiv.org/pdf/2512.08927v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- To develop a theoretical framework for designing optical reciprocal metasurfaces with maximum asymmetric directional absorption.

### 2. Motivation & Gaps
- The study aims to provide a comprehensive understanding of omega-type bianisotropy in dielectric metasurfaces and its implications for light absorption.

### 3. Core Idea
- The introduction of controlled out-of-plane symmetry breaking activates electromagnetic coupling between electric and magnetic dipolar resonances, leading to hybridization and strong coupling effects.

### 4. Method
- **Pipeline**: Utilization of temporal coupled-mode theory (TCMT) to model the behavior of metasurfaces under high-quality resonances.
- **Architecture / Loss / Training**: The design incorporates a dielectric slab acting as a Fabry-PÃ©rot resonator to enhance reflectivity and absorption characteristics.
- **Complexity / Resources**: The approach is straightforward and does not require optimization, yet achieves significant results.

</details>

### [Efficiently Reconstructing Dynamic Scenes One D4RT at a Time](https://arxiv.org/pdf/2512.08924v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Depth Estimation and Camera Pose Estimation

### 2. Motivation & Gaps
- The paper addresses the challenge of accurate depth estimation and camera pose estimation from high-resolution video inputs.

### 3. Core Idea
- The proposed method, D4RT, utilizes high-resolution video inputs to achieve accurate depth and pose estimations while maintaining computational efficiency.

### 4. Method
- **Pipeline**: The method involves feeding RGB patches from high-resolution video into a decoder to enhance depth map fidelity.
- **Architecture / Loss / Training**: The model is trained using a combination of depth estimation and camera pose estimation losses.
- **Complexity / Resources**: The model maintains low computational cost and memory requirements despite high fidelity outputs.

</details>

## model collapse

### [Hot Jupiters are Inflated Primarily by Shallow Heating](https://arxiv.org/pdf/2512.08932v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the heating mechanisms in hot Jupiter interiors

### 2. Motivation & Gaps
- The study aims to resolve the tension between deep heating models and delayed cooling observed in hot Jupiters.

### 3. Core Idea
- The dominant heating mechanism in hot Jupiters is shallow heating, which reconciles previous models of deep heating and delayed cooling.

### 4. Method
- **Pipeline**: Updated giant planet interior structure and thermal evolution model applied to archival photometry and astrometry data.
- **Architecture / Loss / Training**: The model uses a two-step MCMC process to ensure convergence and accuracy in retrieving posterior distributions.
- **Complexity / Resources**: Hierarchical Bayesian framework used for analysis.

</details>

### [Selfi: Self Improving Reconstruction Engine via 3D Geometric Feature Alignment](https://arxiv.org/pdf/2512.08930v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- View Synthesis

### 2. Motivation & Gaps
- The paper addresses the challenges in large view synthesis, particularly focusing on self-supervised methods.

### 3. Core Idea
- The core idea is to develop a self-supervised model that can synthesize large views from limited input data without requiring extensive labeled datasets.

### 4. Method
- **Pipeline**: The method involves a self-supervised learning pipeline that leverages existing views to generate new perspectives.
- **Architecture / Loss / Training**: Utilizes a novel architecture with specific loss functions designed to enhance view synthesis quality.
- **Complexity / Resources**: The model is designed to be computationally efficient, requiring moderate resources for training and inference.

</details>
