# Daily Paper Digest Â· 2025-12-17
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image](https://arxiv.org/pdf/2512.14677v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D talking head generation

### 2. Motivation & Gaps
- Existing methods for 3D talking head avatars lack high-quality rendering and accurate audio-lip synchronization.

### 3. Core Idea
- Our method generates high-quality 3D head renderings with accurate audio-lip sync and vivid facial expressions, outperforming existing methods.

### 4. Method
- **Pipeline**: Collect high-quality talking videos and render training frames using V ASA-1 decoder.
- **Architecture / Loss / Training**: Utilizes V ASA-1 latents extracted from random VoxCeleb2 video clips.
- **Complexity / Resources**: Requires 10 hours of training frames from 1-minute high-quality talking videos.

</details>

### [Towards Interactive Intelligence for Digital Humans](https://arxiv.org/pdf/2512.13674v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Action Segmentation

### 2. Motivation & Gaps
- Existing avatars lack genuine interaction capabilities despite achieving photorealistic visual fidelity.

### 3. Core Idea
- Introducing Interactive Intelligence as a framework for digital humans that integrates cognitive reasoning with real-time embodiment.

### 4. Method
- **Pipeline**: Utilizes a data-free self-training loop to achieve robust fidelity without manual data curation.
- **Architecture / Loss / Training**: Integrates five specialized modules: Talker, Face Animator, Body Animator, DiT Renderer, and Thinker.
- **Complexity / Resources**: Achieves high performance with a score of 76.8 on the Interactive Intelligence Score benchmark.

</details>

### [KlingAvatar 2.0 Technical Report](https://arxiv.org/pdf/2512.13313v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Avatar synthesis and animation

### 2. Motivation & Gaps
- The paper addresses the need for more realistic and interactive avatar synthesis through advanced modeling techniques.

### 3. Core Idea
- The core idea is to enhance avatar synthesis by employing a co-reasoning directed spatio-temporal cascade model that improves the realism and interactivity of avatars.

### 4. Method
- **Pipeline**: The method involves a multi-stage pipeline that integrates cognitive simulation with spatio-temporal modeling.
- **Architecture / Loss / Training**: The architecture utilizes a loss function that emphasizes both spatial coherence and temporal consistency during training.
- **Complexity / Resources**: The model is designed to be resource-efficient while maintaining high-quality output.

</details>

## video understanding

### [MemFlow: Flowing Adaptive Memory for Consistent and Efficient Long Video Narratives](https://arxiv.org/pdf/2512.14699v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Interactive long video generation

### 2. Motivation & Gaps
- The paper addresses the challenge of maintaining long-range consistency in interactive long video generation without severe efficiency degradation.

### 3. Core Idea
- The introduction of Narrative Adaptive Memory (NAM) for dynamic retrieval of semantic-aligned context and Sparse Memory Activation (SMA) for balancing memory-efficiency trade-off.

### 4. Method
- **Pipeline**: The framework utilizes a memory mechanism to enhance interactive long video generation.
- **Architecture / Loss / Training**: The architecture employs a memory mechanism that updates based on relevance-gated selection to mitigate error accumulation.
- **Complexity / Resources**: Achieves 18.7 FPS inference on a single NVIDIA H100 GPU.

</details>

### [TimeLens: Rethinking Video Temporal Grounding with Multimodal LLMs](https://arxiv.org/pdf/2512.14698v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Temporal Localization

### 2. Motivation & Gaps
- Existing video temporal grounding models struggle with data quality and reasoning capabilities, leading to suboptimal performance.

### 3. Core Idea
- TimeLens models improve video temporal grounding by refining existing datasets and enhancing model capabilities without sacrificing general video understanding.

### 4. Method
- **Pipeline**: Automated re-annotation of existing datasets to create TimeLens-100K, followed by training models on this refined dataset.
- **Architecture / Loss / Training**: Utilizes a combination of existing MLLMs and custom prompts for effective training and evaluation.
- **Complexity / Resources**: The model architecture is designed to be efficient, requiring fewer parameters while maintaining high performance.

</details>

### [CRISP: Contact-Guided Real2Sim from Monocular Video with Planar Scene Primitives](https://arxiv.org/pdf/2512.14696v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Scene reconstruction and motion tracking in real-time environments

### 2. Motivation & Gaps
- The paper addresses the need for efficient scene reconstruction and motion tracking in real-time applications, particularly in robotics.

### 3. Core Idea
- The proposed CRISP algorithm integrates real-time RGB-D data for efficient planar fitting and motion tracking.

### 4. Method
- **Pipeline**: The pipeline includes prior preparation, visual SLAM, HMR, and planar fitting, designed to operate in real-time.
- **Architecture / Loss / Training**: The policy architecture uses a transformer encoder with a latent dimension of 256 and a multi-layer perceptron for the critic.
- **Complexity / Resources**: The method is lightweight, allowing for real-time processing with a single NVIDIA RTX A6000.

</details>

## model collapse
