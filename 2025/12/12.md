# Daily Paper Digest Â· 2025-12-12
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting](https://arxiv.org/pdf/2512.10939v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D talking head generation

### 2. Motivation & Gaps
- Existing methods struggle with lip synchronization and stability in 3D talking head generation.

### 3. Core Idea
- GaussianHeadTalk generates a lip-sync 3D mesh and uses optimized FLAME parameters to transfer lip motion, addressing issues of stability and quality.

### 4. Method
- **Pipeline**: Audio input is processed to generate a 3D mesh with lip synchronization.
- **Architecture / Loss / Training**: Utilizes a loss function that minimizes artifacts and maximizes lip motion accuracy.
- **Complexity / Resources**: Requires moderate computational resources for real-time processing.

</details>

### [Adaptive Optimal Control for Avatar-Guided Motor Rehabilitation in Virtual Reality](https://arxiv.org/pdf/2512.09667v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Motor rehabilitation using adaptive control frameworks

### 2. Motivation & Gaps
- The control framework's primary strength is its inherent adaptability, allowing it to adjust assistance based on the patient's motor capabilities and rehabilitation progress.

### 3. Core Idea
- The framework adapts the level of assistance and guidance to the patient's current motor capabilities, enhancing rehabilitation outcomes.

### 4. Method
- **Pipeline**: The method involves a parameter adaptation mechanism that updates the weights of the cost function based on a smoothness-based ability index.
- **Architecture / Loss / Training**: The control input is generated by minimizing a cost functional that synchronizes the avatar's motion with the patient's trajectory.
- **Complexity / Resources**: The system requires a VR platform and a mechanism for real-time adaptation of control parameters.

</details>

### [Relightable and Dynamic Gaussian Avatar Reconstruction from Monocular Video](https://arxiv.org/pdf/2512.09335v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Human avatar reconstruction and rendering

### 2. Motivation & Gaps
- The paper addresses the challenge of reconstructing high-fidelity human avatars and rendering them under arbitrary lighting conditions.

### 3. Core Idea
- The proposed framework reconstructs high-fidelity human avatars and enables rendering under arbitrary lighting conditions using a well-constructed dataset and a well-designed modeling framework.

### 4. Method
- **Pipeline**: Reconstruction of human avatars from monocular video followed by rendering under various lighting conditions.
- **Architecture / Loss / Training**: Utilizes a rough approximation for PBR due to computational constraints.
- **Complexity / Resources**: High computational complexity due to ray tracing.

</details>

## video understanding

### [WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World](https://arxiv.org/pdf/2512.10958v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Autonomous driving

### 2. Motivation & Gaps
- The paper discusses the potential of generative AI in enhancing autonomous driving technologies.

### 3. Core Idea
- Utilizing generative AI to improve the realism and efficiency of simulations in autonomous driving.

### 4. Method
- **Pipeline**: The method involves a generative model that simulates various driving scenarios.
- **Architecture / Loss / Training**: The architecture employs a loss function tailored for driving scene generation.
- **Complexity / Resources**: The model requires significant computational resources for training and inference.

</details>

### [Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision](https://arxiv.org/pdf/2512.10956v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Urban visual navigation

### 2. Motivation & Gaps
- The CityWalker videos include non-navigation content, resulting in noise that undermines reliable navigation learning.

### 3. Core Idea
- StereoWalker predicts five future waypoints spanning a five-second horizon to ensure smooth robot motion.

### 4. Method
- **Pipeline**: The model processes input frames using a combination of depth estimation and point tracking to predict future waypoints.
- **Architecture / Loss / Training**: The architecture includes tracking-guided attention layers and uses a loss function with specific weights for arrival probability and direction consistency.
- **Complexity / Resources**: Requires 2.89 GB of VRAM and 0.2 s per sample on an A100 GPU at inference time.

</details>

### [E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training](https://arxiv.org/pdf/2512.10950v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Downstream Supervised Pose Estimation

### 2. Motivation & Gaps
- The paper analyzes how different training datasets affect model performance, emphasizing the importance of data quality over quantity.

### 3. Core Idea
- Diversity and quality of training data are more critical than the quantity for training self-supervised models.

### 4. Method
- **Pipeline**: Controlled experiments with fixed computation budget and varying dataset sizes.
- **Architecture / Loss / Training**: The Gaussian-based scene reconstruction module is optimized with a photometric loss, while pose estimation is trained using ground-truth camera poses.
- **Complexity / Resources**: 152K iterations with a global batch size of 192.

</details>

## model collapse

### [StereoSpace: Depth-Free Synthesis of Stereo Geometry via End-to-End Diffusion in a Canonical Space](https://arxiv.org/pdf/2512.10959v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Stereo Geometry Synthesis

### 2. Motivation & Gaps
- Transparent objects and depth estimation are significant challenges in stereo methods.

### 3. Core Idea
- StereoSpace maintains more faithful geometry and appearance in the presence of transparent objects compared to other methods.

### 4. Method
- **Pipeline**: The method involves training a diffusion model on stereo image pairs to learn the mapping from 2D images to 3D stereo geometry.
- **Architecture / Loss / Training**: The model employs a warping loss based on left-right consistency and utilizes PlÃ¼cker coordinates for viewpoint conditioning.
- **Complexity / Resources**: The training involves 14 publicly available datasets and is conducted over 3 epochs with approximately 48.6K optimizer steps.

</details>

### [SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model](https://arxiv.org/pdf/2512.10957v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Generative modeling

### 2. Motivation & Gaps
- The paper addresses the challenges in generating 3D scenes from single images, highlighting the need for improved methods in this area.

### 3. Core Idea
- The proposed method utilizes a novel diffusion-based approach to enhance the fidelity of 3D scene generation from single images.

### 4. Method
- **Pipeline**: The method involves a multi-stage pipeline that integrates diffusion models with scene understanding techniques.
- **Architecture / Loss / Training**: The architecture employs a combination of reconstruction loss and adversarial loss to improve output quality.
- **Complexity / Resources**: The method requires significant computational resources, including high-performance GPUs for training.

</details>
