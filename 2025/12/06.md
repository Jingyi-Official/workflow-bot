# Daily Paper Digest Â· 2025-12-06
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length](https://arxiv.org/pdf/2512.04677v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation

### 2. Motivation & Gaps
- The paper addresses the challenge of generating cinematic videos driven by audio inputs.

### 3. Core Idea
- The core idea is to leverage audio signals to drive the generation of cinematic videos, enhancing the realism and coherence of the output.

### 4. Method
- **Pipeline**: The method involves a pipeline that processes audio inputs and generates corresponding video frames in a coherent manner.
- **Architecture / Loss / Training**: The architecture employs a loss function that balances audio-video alignment and visual quality.
- **Complexity / Resources**: The method requires significant computational resources for real-time processing.

</details>

### [Mind-to-Face: Neural-Driven Photorealistic Avatar Synthesis via EEG Decoding](https://arxiv.org/pdf/2512.04313v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- EEG-driven avatar synthesis

### 2. Motivation & Gaps
- The paper addresses the challenge of generating realistic facial expressions in avatars using EEG signals, aiming to enhance the realism and expressiveness of virtual avatars.

### 3. Core Idea
- The core idea is to utilize EEG signals to drive the synthesis of photorealistic avatars that can accurately reflect the emotional states of users in real-time.

### 4. Method
- **Pipeline**: The method involves capturing EEG signals while subjects watch stimulus videos, followed by processing these signals to generate corresponding facial expressions in avatars.
- **Architecture / Loss / Training**: The model employs a reconstruction loss and a smoothness constraint to ensure realistic facial motion and spatial coherence in the generated avatars.
- **Complexity / Resources**: The system requires a light stage with 16 synchronized cameras and an EEG cap, along with significant computational resources for processing high-resolution imagery.

</details>

### [CloseUpAvatar: High-Fidelity Animatable Full-Body Avatars with Mixture of Multi-Scale Textures](https://arxiv.org/pdf/2512.03593v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- High-fidelity avatar generation

### 2. Motivation & Gaps
- The paper addresses the need for high-fidelity, animatable full-body avatars that can be generated efficiently.

### 3. Core Idea
- The proposed method utilizes a mixture of multi-scale textures to enhance the fidelity and animatability of full-body avatars.

### 4. Method
- **Pipeline**: The method involves initializing textured surfels along the SMPL-X mesh surface and aligning them with the mesh's normal vectors.
- **Architecture / Loss / Training**: The training employs convolutional neural networks focusing on LPIPS and FID metrics for perceptual quality.
- **Complexity / Resources**: The method requires significant computational resources for training and rendering high-fidelity avatars.

</details>

## video understanding

### [Light-X: Generative 4D Video Rendering with Camera and Illumination Control](https://arxiv.org/pdf/2512.05115v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- joint cameraâ€“illumination control and video relighting

### 2. Motivation & Gaps
- The study addresses the challenges in maintaining stable lighting behavior under complex illumination changes and the impact of different data sources on the performance of the model.

### 3. Core Idea
- The integration of static, dynamic, and AI-generated data enhances the fidelity, consistency, and stability of the model under diverse lighting conditions.

### 4. Method
- **Pipeline**: Light-X processes video frames to propagate illumination cues over time, allowing for robust performance even under occlusions and depth noise.
- **Architecture / Loss / Training**: The architecture is designed to handle various lighting conditions and occlusions, with a focus on maintaining performance across different reference frames.
- **Complexity / Resources**: The method is computationally efficient, requiring moderate resources for depth estimation and video processing.

</details>

### [Deep infant brain segmentation from multi-contrast MRI](https://arxiv.org/pdf/2512.05114v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Brain segmentation

### 2. Motivation & Gaps
- Existing methods struggle with segmentation accuracy for infants and young children, particularly with varying input modalities and resolutions.

### 3. Core Idea
- Integrate a powerful group convolutional mechanism with a training strategy that incorporates real and synthetic images of tremendous variability.

### 4. Method
- **Pipeline**: Processes all inputs in parallel, allowing for flexible experimentation with various MRI contrasts and resolutions.
- **Architecture / Loss / Training**: Utilizes a single model to achieve state-of-the-art performance across a range of ages from extremely preterm neonates to five years.
- **Complexity / Resources**: Requires sufficient memory for systems processing multiple modalities.

</details>

### [Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting](https://arxiv.org/pdf/2512.05113v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D Gaussian Splatting

### 2. Motivation & Gaps
- The paper addresses the need for efficient 3D rendering techniques that can handle dynamic scenes without the complexity of traditional methods.

### 3. Core Idea
- The core idea is to utilize Gaussian splatting techniques to render 3D scenes dynamically and efficiently, improving upon existing methods by reducing computational overhead.

### 4. Method
- **Pipeline**: The method involves a pipeline that integrates Gaussian splatting with advanced rendering techniques to optimize performance.
- **Architecture / Loss / Training**: The architecture employs a loss function designed to minimize rendering errors while maintaining visual fidelity.
- **Complexity / Resources**: The method is designed to operate with reduced computational resources compared to traditional rendering techniques.

</details>

## model collapse

### [On the treatment of thermal effects in the equation of state on neutron star merger remnants](https://arxiv.org/pdf/2512.05118v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the impact of thermal effects on the rotation profiles and gravitational wave emission of post-merger remnants.

### 2. Motivation & Gaps
- The study aims to understand how different equations of state (EOS) affect the stability and dynamics of post-merger remnants in binary neutron star (BNS) mergers.

### 3. Core Idea
- Incorporating thermal effects in long-term simulations of BNS merger remnants is crucial for accurate predictions of their stability and gravitational wave signatures.

### 4. Method
- **Pipeline**: Simulations of BNS mergers using both tabulated and hybrid EOS models to analyze thermal profiles and their effects on remnant dynamics.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Utilized MareNostrum supercomputing resources and various open-source packages for simulations and analysis.

</details>

### [The Universal Weight Subspace Hypothesis](https://arxiv.org/pdf/2512.05117v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Subspace extraction and analysis across various models

### 2. Motivation & Gaps
- Addressing both the financial and environmental costs associated with training and deploying deep learning systems.

### 3. Core Idea
- Lowering the hardware and energy requirements for adaptation and inference to empower under-resourced researchers and institutions.

### 4. Method
- **Pipeline**: Extraction of universal subspaces from various models using layerwise spectral analysis.
- **Architecture / Loss / Training**: Utilizes a shared subspace model with specific learning rates and epochs for different tasks.
- **Complexity / Resources**: Experiments conducted on a single A5000 GPU and a CPU with 8 workers.

</details>
