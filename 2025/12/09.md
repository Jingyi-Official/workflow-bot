# Daily Paper Digest Â· 2025-12-09
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [ViSA: 3D-Aware Video Shading for Real-Time Upper-Body Avatar Creation](https://arxiv.org/pdf/2512.07720v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D avatar generation and video synthesis

### 2. Motivation & Gaps
- Existing methods for human keypoint inputs produce artifacts in high-frequency regions due to lack of pixel-level guidance.

### 3. Core Idea
- The proposed model leverages a 3D-aware reconstruction module to provide structural and appearance priors, guiding a distilled autoregressive video diffusion model for high-fidelity avatar rendering.

### 4. Method
- **Pipeline**: Feature-based conditioning bypasses the VAE encoder for improved efficiency.
- **Architecture / Loss / Training**: Adversarial Distribution Preservation loss (ADP) improves visualization quality.
- **Complexity / Resources**: The feature-based conditioning results in a 34% acceleration over traditional methods.

</details>

### [Human Geometry Distribution for 3D Animation Generation](https://arxiv.org/pdf/2512.07459v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D Animation Generation

### 2. Motivation & Gaps
- The paper addresses the challenge of generating high-fidelity 3D animations of clothed humans by modeling human geometry distribution.

### 3. Core Idea
- The core idea is to construct a low-cost mapping for 3D human geometry using a supervised model to improve the accuracy of animated human avatars.

### 4. Method
- **Pipeline**: The method involves three steps: coarse mapping, initial transitions, and coverage refinement to ensure uniform transitions across the SMPL mesh.
- **Architecture / Loss / Training**: The architecture employs a U-Net model with attention layers and uses AdamW for optimization with a cosine learning rate scheduler.
- **Complexity / Resources**: The latent model is trained for approximately five days using four NVIDIA A100 GPUs, while the generative animation model is trained for two days on the same hardware configuration. The batch size is set to 16 per GPU.

</details>

### [Size Matters: The Impact of Avatar Size on User Experience in Healthcare Applications](https://arxiv.org/pdf/2512.07357v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Assessing user perception and preferences for avatar sizes in virtual interactions

### 2. Motivation & Gaps
- The findings contribute to research on digital human interaction and avatar design in virtual healthcare settings, focusing on proxemics and perceived realism.

### 3. Core Idea
- Continued exploration of avatar scale, emotional adaptability, and contextual fit will improve the quality of experience in avatar-based applications.

### 4. Method
- **Pipeline**: Participants interacted with Metahuman avatars projected at different sizes and rated their experiences.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: N/A

</details>

## video understanding

### [UnityVideo: Unified Multi-Modal Multi-Task Learning for Enhancing World-Aware Video Generation](https://arxiv.org/pdf/2512.07831v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation and Estimation

### 2. Motivation & Gaps
- The paper addresses the need for improved physical reasoning and world understanding in video generation models.

### 3. Core Idea
- UnityVideo leverages a unified multimodal training paradigm to enhance physical reasoning and world modeling in video generation.

### 4. Method
- **Pipeline**: The method involves a systematic data curation process and a dual-track evaluation strategy for video tasks.
- **Architecture / Loss / Training**: Utilizes joint modal training to improve performance across various video generation tasks.
- **Complexity / Resources**: Requires significant computational resources for training and evaluation due to the multimodal nature of the data.

</details>

### [One Layer Is Enough: Adapting Pretrained Visual Encoders for Image Generation](https://arxiv.org/pdf/2512.07829v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Generative Modeling

### 2. Motivation & Gaps
- FAE provides a simple and general mechanism for leveraging pretrained vision encoders in generative modeling, offering a compelling balance between architectural minimalism, adaptability, and performance.

### 3. Core Idea
- FAE preserves fine-grained, part-level semantics rather than only coarse global information.

### 4. Method
- **Pipeline**: Identify animal-related patches using K-Means clustering and match patches based on cosine similarity.
- **Architecture / Loss / Training**: The model achieves competitive image generation quality while using substantially less training data.
- **Complexity / Resources**: FAE employs a compact architecture with 1.4B parameters, demonstrating efficient performance across benchmarks.

</details>

### [OpenVE-3M: A Large-Scale High-Quality Dataset for Instruction-Guided Video Editing](https://arxiv.org/pdf/2512.07826v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Editing with Style Transfer

### 2. Motivation & Gaps
- The paper addresses the need for a comprehensive benchmark for evaluating video editing methods that utilize style transfer techniques.

### 3. Core Idea
- The proposed OpenVE-Edit framework provides a systematic approach to evaluate and compare various video editing methods based on style transfer, ensuring consistency and quality across different editing tasks.

### 4. Method
- **Pipeline**: The pipeline involves inputting a video, applying style transfer techniques, and evaluating the output against predefined metrics.
- **Architecture / Loss / Training**: Utilizes a combination of perceptual loss and content loss to train the model for better style adherence and content preservation.
- **Complexity / Resources**: The model requires significant computational resources, including high-performance GPUs for training and inference.

</details>

## model collapse

### [Relational Visual Similarity](https://arxiv.org/pdf/2512.07833v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Image Filtering and Caption Generation

### 2. Motivation & Gaps
- The study focuses on developing an image filtering model to classify images as interesting or uninteresting based on their content.

### 3. Core Idea
- To create a model that can effectively filter images and generate anonymous captions based on shared logic among images.

### 4. Method
- **Pipeline**: Training an image filtering model using LoRA on a dataset of labeled images.
- **Architecture / Loss / Training**: The model used was Qwen2.5-VL-7B, trained with LoRA.
- **Complexity / Resources**: The keep rate is around 0.7%, indicating a high level of filtering.

</details>

### [Do Generalisation Results Generalise?](https://arxiv.org/pdf/2512.07832v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Natural Language Inference (NLI)

### 2. Motivation & Gaps
- The study aims to assess the generalization capacity of fine-tuned models in NLI tasks using various datasets.

### 3. Core Idea
- To evaluate the generalization capabilities of fine-tuned models on NLI tasks using diverse datasets and adversarial examples.

### 4. Method
- **Pipeline**: Pattern-based finetuning with specified input patterns and token mappings.
- **Architecture / Loss / Training**: Utilizes various model sizes and architectures for training.
- **Complexity / Resources**: Experiments conducted on multiple GPU setups with a total runtime of 5,500 GPU hours.

</details>
