# Daily Paper Digest Â· 2025-12-14
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting](https://arxiv.org/pdf/2512.10939v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D talking head generation

### 2. Motivation & Gaps
- The paper addresses the challenges of generating realistic 3D talking heads that maintain lip synchronization and visual stability during audio playback.

### 3. Core Idea
- The proposed method, GaussianHeadTalk, utilizes audio-driven Gaussian splatting to create stable and realistic 3D talking heads.

### 4. Method
- **Pipeline**: The method generates a lip-sync 3D mesh from audio signals and uses optimized FLAME parameters for lip motion transfer.
- **Architecture / Loss / Training**: Introduces a stability metric to quantify perceptual wobbling in generated videos.
- **Complexity / Resources**: Requires significant computational resources for real-time processing and high-quality output.

</details>

### [Adaptive Optimal Control for Avatar-Guided Motor Rehabilitation in Virtual Reality](https://arxiv.org/pdf/2512.09667v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Rehabilitation of post-stroke patients using a virtual reality platform

### 2. Motivation & Gaps
- The control frameworkâ€™s primary strength is its inherent adaptability, allowing it to adjust assistance based on the patient's motor capabilities and rehabilitation progress.

### 3. Core Idea
- The platform adapts the level of assistance and guidance to the patientâ€™s current motor capabilities and rehabilitation progress.

### 4. Method
- **Pipeline**: Patients perform motor exercises with an adaptive virtual avatar that adjusts its guidance based on the patient's ability index.
- **Architecture / Loss / Training**: The control input is generated by minimizing a cost functional that synchronizes the avatar's motion with the patient's trajectory.
- **Complexity / Resources**: The system requires a virtual reality setup and computational resources for real-time adaptation of the avatar.

</details>

### [Relightable and Dynamic Gaussian Avatar Reconstruction from Monocular Video](https://arxiv.org/pdf/2512.09335v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Human avatar reconstruction and rendering

### 2. Motivation & Gaps
- The paper addresses the challenge of reconstructing high-fidelity human avatars and rendering them under arbitrary lighting conditions.

### 3. Core Idea
- The proposed framework reconstructs high-fidelity human avatars and enables rendering under arbitrary lighting using a well-constructed dataset and a well-designed modeling framework.

### 4. Method
- **Pipeline**: The framework uses a combination of dataset construction and modeling techniques to achieve high-quality avatar reconstruction.
- **Architecture / Loss / Training**: The training involves optimizing geometric consistency loss and using an Adam optimizer with a learning rate of 1e-3.
- **Complexity / Resources**: The method requires significant computational resources due to the complexity of the rendering process.

</details>

## video understanding

### [WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World](https://arxiv.org/pdf/2512.10958v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Autonomous driving

### 2. Motivation & Gaps
- The paper discusses the potential of generative AI in enhancing autonomous driving technologies.

### 3. Core Idea
- Utilizing generative AI to improve the realism and effectiveness of simulations in autonomous driving.

### 4. Method
- **Pipeline**: The method involves a generative model that simulates various driving scenarios.
- **Architecture / Loss / Training**: The architecture employs a loss function tailored for driving scene generation.
- **Complexity / Resources**: The approach requires significant computational resources for training and inference.

</details>

### [Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision](https://arxiv.org/pdf/2512.10956v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Visual Navigation

### 2. Motivation & Gaps
- The CityWalker videos include non-navigation content, resulting in noise that undermines reliable navigation learning.

### 3. Core Idea
- The proposed model, StereoWalker, predicts five future waypoints for robotic navigation with minimal computation overhead.

### 4. Method
- **Pipeline**: The model processes input frames using a combination of depth estimation and point tracking to predict future waypoints.
- **Architecture / Loss / Training**: The architecture includes tracking-guided attention layers and uses a loss function with specific weights for arrival probability and direction consistency.
- **Complexity / Resources**: Requires 2.89 GB of VRAM and 0.2 s per sample on an A100 GPU.

</details>

### [E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training](https://arxiv.org/pdf/2512.10950v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Downstream Supervised Pose Estimation

### 2. Motivation & Gaps
- The paper analyzes how different training datasets affect model performance, emphasizing the importance of data quality over quantity.

### 3. Core Idea
- Diversity and quality of training data are more critical than the quantity for training self-supervised models.

### 4. Method
- **Pipeline**: Controlled experiments with fixed computation budget and varying dataset sizes.
- **Architecture / Loss / Training**: Utilizes a Gaussian-based scene reconstruction module optimized with a photometric loss.
- **Complexity / Resources**: 152K iterations with a global batch size of 192.

</details>

## model collapse

### [StereoSpace: Depth-Free Synthesis of Stereo Geometry via End-to-End Diffusion in a Canonical Space](https://arxiv.org/pdf/2512.10959v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Stereo Geometry Synthesis

### 2. Motivation & Gaps
- Transparent objects and depth estimation present significant challenges in stereo methods.

### 3. Core Idea
- StereoSpace maintains more faithful geometry and appearance in the presence of transparent objects compared to other methods.

### 4. Method
- **Pipeline**: The method involves training a diffusion model on stereo image pairs to learn the underlying geometry and generate new views.
- **Architecture / Loss / Training**: The architecture employs a warping loss based on left-right consistency masks derived from disparity maps.
- **Complexity / Resources**: The training requires a diverse dataset of stereo pairs and is computationally intensive, involving multiple epochs and optimization steps.

</details>

### [SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model](https://arxiv.org/pdf/2512.10957v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Generative modeling

### 2. Motivation & Gaps
- The paper addresses the challenges in generating 3D scenes from single images, highlighting the need for improved methods in this area.

### 3. Core Idea
- The core idea is to utilize advanced diffusion models to enhance the fidelity and accuracy of 3D scene generation from single images.

### 4. Method
- **Pipeline**: The method involves a diffusion-based approach that iteratively refines the generated 3D scene.
- **Architecture / Loss / Training**: The architecture employs a loss function that balances fidelity and diversity in generated scenes.
- **Complexity / Resources**: The method requires significant computational resources due to the complexity of the diffusion process.

</details>
