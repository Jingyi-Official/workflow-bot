# Daily Paper Digest Â· 2025-12-30
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [LiveTalk: Real-Time Multimodal Interactive Video Diffusion via Improved On-Policy Distillation](https://arxiv.org/pdf/2512.23576v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation

### 2. Motivation & Gaps
- The paper addresses the need for real-time interactive long video generation, which is a significant challenge in the field of video synthesis.

### 3. Core Idea
- The core idea is to develop a method for generating long videos interactively in real-time, leveraging autoregressive models to enhance the quality and coherence of the output.

### 4. Method
- **Pipeline**: The method involves a pipeline that integrates audio inputs and user interactions to guide the video generation process.
- **Architecture / Loss / Training**: The architecture employs a loss function that balances quality and coherence across generated frames.
- **Complexity / Resources**: The method is designed to be computationally efficient, allowing for real-time processing on standard hardware.

</details>

### [SoulX-LiveTalk Technical Report](https://arxiv.org/pdf/2512.23379v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Audio-driven avatar video generation

### 2. Motivation & Gaps
- The paper addresses the challenge of generating audio-driven avatars in real-time with infinite length.

### 3. Core Idea
- The proposed method leverages advanced diffusion techniques to create realistic and responsive avatars driven by audio input.

### 4. Method
- **Pipeline**: The method involves a diffusion model that processes audio signals to generate corresponding avatar animations.
- **Architecture / Loss / Training**: Utilizes a combination of loss functions to optimize the quality of generated video frames.
- **Complexity / Resources**: The model is designed to be resource-efficient, allowing for real-time processing on standard hardware.

</details>

### [StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars](https://arxiv.org/pdf/2512.22065v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- talking avatar generation

### 2. Motivation & Gaps
- This work focuses on talking avatar generation for constructive, human-centered applications.

### 3. Core Idea
- The system supports real-time generation of talking avatars while ensuring ethical considerations are met.

### 4. Method
- **Pipeline**: The method involves a diffusion model architecture that processes audio inputs to generate corresponding video outputs in real-time.
- **Architecture / Loss / Training**: The architecture employs adversarial training with consistency-aware discriminators to enhance video quality and synchronization.
- **Complexity / Resources**: The model is evaluated using two H800 GPUs.

</details>

## video understanding

### [Stream-DiffVSR: Low-Latency Streamable Video Super-Resolution via Auto-Regressive Diffusion](https://arxiv.org/pdf/2512.23709v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Super Resolution (VSR)

### 2. Motivation & Gaps
- Existing VSR methods struggle with temporal consistency and visual fidelity, particularly in challenging real-world sequences.

### 3. Core Idea
- Stream-DiffVSR leverages diffusion-based methods to enhance visual fidelity and temporal consistency in video super resolution.

### 4. Method
- **Pipeline**: The method processes video frames sequentially, utilizing temporal information from previous frames to improve reconstruction quality.
- **Architecture / Loss / Training**: The architecture employs a loss function that emphasizes perceptual quality and temporal stability.
- **Complexity / Resources**: The method is designed to be resource-efficient, although it faces limitations with GPU memory during execution.

</details>

### [Diffusion Knows Transparency: Repurposing Video Diffusion for Transparent Object Depth and Normal Estimation](https://arxiv.org/pdf/2512.23705v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Depth and Normal Estimation

### 2. Motivation & Gaps
- The study introduces DKT, a model finetuned from a video diffusion model using a LoRA training strategy, aiming to improve performance in video depth and normal estimation.

### 3. Core Idea
- DKT sets a new state-of-the-art (SOTA) across comprehensive benchmarks in video depth and normal estimation.

### 4. Method
- **Pipeline**: Finetuning a video diffusion model using LoRA training strategy.
- **Architecture / Loss / Training**: LoRA fine-tuning strategy applied to scale model size and improve performance.
- **Complexity / Resources**: DKT-1.3B achieves high efficiency with an inference time of 167.48ms per frame and peak GPU memory occupancy of 11.19 GB.

</details>

### [Robo-Dopamine: General Process Reward Modeling for High-Precision Robotic Manipulation](https://arxiv.org/pdf/2512.23703v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Robotic Reinforcement Learning

### 2. Motivation & Gaps
- The paper addresses the need for a robust reward model in reinforcement learning that can generalize across diverse tasks and maintain performance under varying conditions.

### 3. Core Idea
- The Generative Reward Model (GRM) provides dense, semantically meaningful rewards that enable agents to recover from unexpected external perturbations and improve task performance.

### 4. Method
- **Pipeline**: The GRM integrates visual and temporal information to assess progress in real-time during reinforcement learning tasks.
- **Architecture / Loss / Training**: Utilizes low-precision quantization techniques to enhance inference speed while maintaining reward accuracy.
- **Complexity / Resources**: The model aims to reduce memory footprint and computational latency, making it suitable for online reinforcement learning.

</details>

## model collapse

### [Training AI Co-Scientists Using Rubric Rewards](https://arxiv.org/pdf/2512.23707v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Define host transcriptomic programs through which Aeromonas sp. H1 promotes coriander growth

### 2. Motivation & Gaps
- The study aims to capture the temporal dynamics of plant-microbe interactions and identify molecular mechanisms underlying probiotic-mediated growth promotion in coriander.

### 3. Core Idea
- Integrate high-resolution transcriptomics with physiological validation to elucidate the mechanisms of growth promotion by Aeromonas sp. H1 in coriander.

### 4. Method
- **Pipeline**: Isolate Aeromonas sp. H1, validate PGP traits, and conduct RNA-seq on treated coriander seedlings.
- **Architecture / Loss / Training**: Use DESeq2 for differential expression analysis and functional enrichment mapping.
- **Complexity / Resources**: Requires high-quality RNA extraction, sequencing, and bioinformatics analysis.

</details>
