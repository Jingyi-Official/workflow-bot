# Daily Paper Digest Â· 2025-12-05
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length](https://arxiv.org/pdf/2512.04677v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation

### 2. Motivation & Gaps
- The paper addresses the challenge of generating cinematic videos driven by audio inputs.

### 3. Core Idea
- The core idea is to leverage audio signals to drive the generation of cinematic videos, enhancing the realism and engagement of the output.

### 4. Method
- **Pipeline**: The method involves a pipeline that processes audio inputs and generates corresponding video frames in a coherent manner.
- **Architecture / Loss / Training**: The architecture employs a loss function that balances fidelity and temporal coherence during training.
- **Complexity / Resources**: The method requires significant computational resources for real-time processing.

</details>

### [Mind-to-Face: Neural-Driven Photorealistic Avatar Synthesis via EEG Decoding](https://arxiv.org/pdf/2512.04313v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- EEG-driven avatar synthesis

### 2. Motivation & Gaps
- The paper addresses the challenge of generating realistic facial expressions in avatars using EEG signals, which has not been extensively explored in prior work.

### 3. Core Idea
- The core idea is to synthesize photorealistic avatars that can express emotions based on EEG signals, leveraging a novel decoding approach to map neural activity to facial expressions.

### 4. Method
- **Pipeline**: The method involves capturing EEG signals while subjects watch stimulus videos, followed by decoding these signals to generate facial expressions in avatars.
- **Architecture / Loss / Training**: The loss function includes reconstruction loss and a Laplacian regularizer to ensure smoothness in the predicted position maps.
- **Complexity / Resources**: The system utilizes 16 high-speed RGB cameras and an EEG cap, requiring significant computational resources for real-time processing.

</details>

### [CloseUpAvatar: High-Fidelity Animatable Full-Body Avatars with Mixture of Multi-Scale Textures](https://arxiv.org/pdf/2512.03593v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- High-Fidelity Avatar Generation

### 2. Motivation & Gaps
- The paper addresses the need for high-fidelity, animatable full-body avatars that can be generated efficiently.

### 3. Core Idea
- The proposed method utilizes a mixture of multi-scale textures to enhance the realism and animatability of full-body avatars.

### 4. Method
- **Pipeline**: The method involves initializing textured surfels along the SMPL-X mesh surface and aligning them with the mesh's normal vectors.
- **Architecture / Loss / Training**: The training employs convolutional neural networks focusing on LPIPS and FID metrics for perceptual quality.
- **Complexity / Resources**: The method requires significant computational resources for training and rendering high-fidelity avatars.

</details>

## video understanding

### [Light-X: Generative 4D Video Rendering with Camera and Illumination Control](https://arxiv.org/pdf/2512.05115v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- joint cameraâ€“illumination control and video relighting

### 2. Motivation & Gaps
- The study addresses the challenges in maintaining stable lighting behavior under complex illumination changes and the impact of different data sources on the performance of the model.

### 3. Core Idea
- The integration of static, dynamic, and AI-generated data enhances the fidelity, consistency, and stability of the model under diverse lighting conditions.

### 4. Method
- **Pipeline**: Light-X processes video frames by relighting the first frame and propagating illumination cues to subsequent frames.
- **Architecture / Loss / Training**: The architecture is designed to handle various lighting conditions and occlusions, with a focus on maintaining aesthetic quality and motion preservation.
- **Complexity / Resources**: The method is computationally efficient, requiring moderate resources for depth estimation and video processing.

</details>

### [Deep infant brain segmentation from multi-contrast MRI](https://arxiv.org/pdf/2512.05114v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Brain segmentation

### 2. Motivation & Gaps
- Existing methods struggle with segmentation accuracy for infants and young children, particularly with varying input modalities and resolutions.

### 3. Core Idea
- Integrate a powerful group convolutional mechanism with a training strategy that incorporates real and synthetic images of tremendous variability.

### 4. Method
- **Pipeline**: Processes all inputs in parallel, allowing for flexible experimentation with various MRI contrasts and resolutions.
- **Architecture / Loss / Training**: Utilizes a single model to achieve state-of-the-art performance across a range of ages from extremely preterm neonates to five years.
- **Complexity / Resources**: Requires sufficient memory for segmentation of subjects with many modalities.

</details>

### [Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting](https://arxiv.org/pdf/2512.05113v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D Gaussian Splatting

### 2. Motivation & Gaps
- The paper addresses the challenges in 3D Gaussian splatting techniques, aiming to improve rendering quality and efficiency.

### 3. Core Idea
- The core idea is to enhance 3D Gaussian splatting techniques to achieve better rendering results without relying on traditional methods like COLMAP.

### 4. Method
- **Pipeline**: The method involves a novel pipeline for 3D Gaussian splatting that integrates uncertainty handling and dynamic scene reconstruction.
- **Architecture / Loss / Training**: Utilizes a loss function tailored for Gaussian splatting to optimize the training process.
- **Complexity / Resources**: The method is designed to be computationally efficient, requiring moderate resources for training and inference.

</details>

## model collapse

### [On the treatment of thermal effects in the equation of state on neutron star merger remnants](https://arxiv.org/pdf/2512.05118v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the impact of thermal effects on the rotation profiles and gravitational wave emission of post-merger remnants.

### 2. Motivation & Gaps
- The study aims to understand how different equations of state (EOS) affect the thermal profiles and stability of neutron star remnants post-merger.

### 3. Core Idea
- Different EOS models (tabulated vs hybrid) significantly influence the thermal profiles and stability of neutron star remnants, affecting gravitational wave emissions.

### 4. Method
- **Pipeline**: Simulations of binary neutron star mergers using different EOS models to analyze thermal effects.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Utilized MareNostrum supercomputing resources and various open-source packages for simulations.

</details>

### [The Universal Weight Subspace Hypothesis](https://arxiv.org/pdf/2512.05117v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Subspace extraction and analysis across various models

### 2. Motivation & Gaps
- Addressing both the financial and environmental costs associated with training and deploying deep learning systems.

### 3. Core Idea
- Lowering the hardware and energy requirements for adaptation and inference to empower under-resourced researchers and institutions.

### 4. Method
- **Pipeline**: Extraction of universal subspaces from various models using layerwise spectral analysis.
- **Architecture / Loss / Training**: Utilizes a shared subspace model with specific learning rates and epochs for different tasks.
- **Complexity / Resources**: Experiments conducted on a single A5000 GPU and a CPU with 8 workers.

</details>
