# Daily Paper Digest Â· 2025-12-16
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [Towards Interactive Intelligence for Digital Humans](https://arxiv.org/pdf/2512.13674v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Action Segmentation

### 2. Motivation & Gaps
- Existing avatars lack genuine interaction capabilities despite achieving photorealistic visual fidelity.

### 3. Core Idea
- Introducing Interactive Intelligence, a framework that integrates multiple modules to create expressive, embodied digital agents capable of meaningful engagement.

### 4. Method
- **Pipeline**: Utilizes a data-free self-training loop to achieve robust fidelity without manual data curation.
- **Architecture / Loss / Training**: Integrates cognitive reasoning with real-time embodiment capabilities.
- **Complexity / Resources**: Achieves significant improvements in perceived intelligence and immersion with a score of 76.8 on the Interactive Intelligence Score (IIS).

</details>

### [KlingAvatar 2.0 Technical Report](https://arxiv.org/pdf/2512.13313v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Avatar synthesis and animation

### 2. Motivation & Gaps
- The paper addresses the need for more realistic and interactive avatar generation through advanced modeling techniques.

### 3. Core Idea
- The core idea is to enhance avatar synthesis by employing a co-reasoning directed spatio-temporal cascade model that improves the realism and interactivity of generated avatars.

### 4. Method
- **Pipeline**: The method involves a multi-stage pipeline that integrates cognitive reasoning with spatio-temporal modeling.
- **Architecture / Loss / Training**: Utilizes a combination of loss functions tailored for both spatial and temporal coherence in avatar animations.
- **Complexity / Resources**: The model is designed to be resource-efficient while maintaining high-quality output.

</details>

### [Towards Unified Co-Speech Gesture Generation via Hierarchical Implicit Periodicity Learning](https://arxiv.org/pdf/2512.13131v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Generating full-body animations that match speech

### 2. Motivation & Gaps
- The paper explores the implicit rules of co-speech human gesture movements and aims to model this learning process, addressing limitations in existing methods.

### 3. Core Idea
- The proposed method introduces a periodicity disentanglement module to model regular periodic phase manifolds and non-periodic individual latents, along with a face animation generator that constructs hierarchical attribute guidance.

### 4. Method
- **Pipeline**: The method involves extracting periodic and non-periodic features from audio to generate corresponding facial and body animations.
- **Architecture / Loss / Training**: The model uses a loss function that encourages the generation of realistic gestures by learning periodic patterns.
- **Complexity / Resources**: Trained on 16 cores CPUs and 32GB memory with a batch size of 256.

</details>

## video understanding

### [DiffusionBrowser: Interactive Diffusion Previews via Multi-Branch Decoders](https://arxiv.org/pdf/2512.13690v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Predicting multiple scene intrinsics simultaneously using video diffusion transformer features

### 2. Motivation & Gaps
- The paper addresses the challenge of generating stable and coherent geometry from diffusion features, highlighting the limitations of pseudo-ground-truth supervision.

### 3. Core Idea
- The multi-branch decoder specializes in different plausible modes, yielding clean and mode-consistent predictions while maintaining diversity through ensemble predictions.

### 4. Method
- **Pipeline**: The method involves training intrinsic decoders on a diverse dataset generated from various scene categories, followed by a multi-branch architecture for decoding.
- **Architecture / Loss / Training**: The training loss combines mode-seeking loss with a standard MSE objective to encourage specialization in plausible modes.
- **Complexity / Resources**: The framework is designed to be resource-efficient while providing actionable insights into the diffusion process.

</details>

### [Towards Scalable Pre-training of Visual Tokenizers for Generation](https://arxiv.org/pdf/2512.13687v1)
  (summary failed: 'utf-8' codec can't encode characters in position 7709-7712: surrogates not allowed)


### [Recurrent Video Masked Autoencoders](https://arxiv.org/pdf/2512.13684v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video representation learning and evaluation

### 2. Motivation & Gaps
- RVM maintains consistency over time and effectively preserves the identity of semantic parts during non-rigid motion.

### 3. Core Idea
- RVM leverages recurrent cues to maintain accurate object boundaries and temporal consistency.

### 4. Method
- **Pipeline**: Utilizes a ViT encoder to process video frames and employs recurrent mechanisms for feature tracking.
- **Architecture / Loss / Training**: Minimizes L2 reconstruction loss on RGB values across all patches with a random masking strategy.
- **Complexity / Resources**: Evaluated on a massive corpus of 170 million web videos with official checkpoints used for training.

</details>

## model collapse

### [Non-parametric exploration of minimally coupled gravity with phantom crossing](https://arxiv.org/pdf/2512.13691v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate KGB theories as alternatives to conformally coupled scenarios in light of current data

### 2. Motivation & Gaps
- The paper aims to establish whether selected KGB models are broadly consistent with key late-time cosmological observables, motivating a more rigorous statistical analysis in future work.

### 3. Core Idea
- KGB models can provide viable alternatives to minimally coupled models in the context of modified gravity and cosmic acceleration.

### 4. Method
- **Pipeline**: Utilization of a manifestly stable EFT basis and the ability to pass arbitrary arrays as input for the EFT functions.
- **Architecture / Loss / Training**: Implement a manifestly stable EFT basis to avoid ghost and gradient instabilities.
- **Complexity / Resources**: Decouple exploration of theory space from specific Lagrangian forms, allowing for efficient model scanning.

</details>

### [Quantum oracles give an advantage for identifying classical counterfactuals](https://arxiv.org/pdf/2512.13692v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Identifying counterfactual distributions using quantum oracles

### 2. Motivation & Gaps
- The paper discusses the limitations of quantum oracles in providing advantages for Deutschâ€“Jozsaâ€™s and Simonâ€™s algorithms compared to classically-explainable theories.

### 3. Core Idea
- The paper discusses the limitations of classical oracles in identifying joint counterfactual distributions and demonstrates how quantum oracles can provide a tighter upper bound on three-way joint counterfactuals.

### 4. Method
- **Pipeline**: The method involves using quantum oracles to query and identify counterfactual distributions.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The complexity involves understanding the dimensionality of the systems being compared and the nature of the queries to the quantum oracle.

</details>
