# Daily Paper Digest Â· 2025-12-07
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length](https://arxiv.org/pdf/2512.04677v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation

### 2. Motivation & Gaps
- The paper addresses the challenge of generating cinematic videos driven by audio inputs.

### 3. Core Idea
- The core idea is to leverage audio signals to drive the generation of cinematic videos, enhancing the realism and coherence of the output.

### 4. Method
- **Pipeline**: The method involves a pipeline that processes audio inputs to generate corresponding video frames in a coherent manner.
- **Architecture / Loss / Training**: The architecture employs a loss function that balances fidelity and temporal coherence during training.
- **Complexity / Resources**: The method requires significant computational resources for real-time processing and high-quality output.

</details>

### [Mind-to-Face: Neural-Driven Photorealistic Avatar Synthesis via EEG Decoding](https://arxiv.org/pdf/2512.04313v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- EEG-driven avatar synthesis

### 2. Motivation & Gaps
- The paper addresses the challenge of generating realistic facial expressions in avatars using EEG signals, aiming to enhance the realism and expressiveness of virtual avatars.

### 3. Core Idea
- The core idea is to utilize EEG signals to drive the synthesis of photorealistic avatars, enabling real-time expression rendering based on neural activity.

### 4. Method
- **Pipeline**: The method involves capturing EEG signals while subjects view stimulus videos, followed by processing these signals to generate corresponding facial expressions in avatars.
- **Architecture / Loss / Training**: The model employs a reconstruction loss and a smoothness constraint to ensure realistic facial motion and spatial coherence in the generated avatars.
- **Complexity / Resources**: The system requires a light stage with 16 synchronized cameras and an EEG cap, along with significant computational resources for real-time processing.

</details>

### [CloseUpAvatar: High-Fidelity Animatable Full-Body Avatars with Mixture of Multi-Scale Textures](https://arxiv.org/pdf/2512.03593v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- High-fidelity avatar generation

### 2. Motivation & Gaps
- The paper addresses the need for high-fidelity, animatable full-body avatars that can be generated efficiently.

### 3. Core Idea
- The proposed method utilizes a mixture of multi-scale textures to enhance the fidelity and animatability of full-body avatars.

### 4. Method
- **Pipeline**: The method involves initializing textured surfels along the SMPL-X mesh surface and aligning them with the mesh's normal vectors.
- **Architecture / Loss / Training**: The training employs convolutional neural networks focusing on perceptual metrics like LPIPS and FID.
- **Complexity / Resources**: The method requires significant computational resources for training and rendering high-fidelity avatars.

</details>

## video understanding

### [Light-X: Generative 4D Video Rendering with Camera and Illumination Control](https://arxiv.org/pdf/2512.05115v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- joint cameraâ€“illumination control and video relighting

### 2. Motivation & Gaps
- The study addresses the challenges in maintaining stable lighting behavior under complex illumination changes and the impact of different data sources on the performance of the model.

### 3. Core Idea
- The integration of static, dynamic, and AI-generated data enhances the fidelity, consistency, and stability of the model under diverse lighting conditions.

### 4. Method
- **Pipeline**: Light-X processes video frames by relighting the first frame and propagating illumination cues to subsequent frames.
- **Architecture / Loss / Training**: The architecture incorporates a global illumination control module and is trained using a combination of static, dynamic, and AI-generated data.
- **Complexity / Resources**: The method is designed to be robust under moderate noise levels and does not require highly accurate depth information.

</details>

### [Deep infant brain segmentation from multi-contrast MRI](https://arxiv.org/pdf/2512.05114v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Brain segmentation

### 2. Motivation & Gaps
- Existing methods struggle with segmentation accuracy for infants and young children, particularly with varying input modalities and resolutions.

### 3. Core Idea
- Integrate a powerful group convolutional mechanism with a training strategy that incorporates real and synthetic images of tremendous variability.

### 4. Method
- **Pipeline**: Processes all inputs in parallel, allowing for flexible experimentation with various MRI contrasts and resolutions.
- **Architecture / Loss / Training**: Utilizes a single model to achieve state-of-the-art performance across a range of ages from extremely preterm neonates to five years.
- **Complexity / Resources**: Requires sufficient memory for segmentation of subjects with many modalities.

</details>

### [Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting](https://arxiv.org/pdf/2512.05113v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D Gaussian Splatting

### 2. Motivation & Gaps
- The paper addresses the challenges in 3D Gaussian splatting techniques, aiming to improve rendering quality and efficiency.

### 3. Core Idea
- The core idea is to enhance 3D Gaussian splatting techniques to improve rendering performance and quality without relying on traditional methods like COLMAP.

### 4. Method
- **Pipeline**: The method involves a novel pipeline for 3D Gaussian splatting that integrates uncertainty handling and dynamic scene rendering.
- **Architecture / Loss / Training**: Utilizes a custom loss function tailored for Gaussian splatting to optimize the rendering process.
- **Complexity / Resources**: The method is designed to be computationally efficient, requiring moderate resources for real-time applications.

</details>

## model collapse

### [On the treatment of thermal effects in the equation of state on neutron star merger remnants](https://arxiv.org/pdf/2512.05118v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the impact of thermal effects on the rotation profiles and gravitational wave emission of post-merger remnants.

### 2. Motivation & Gaps
- The study addresses the significant deviations from spherical symmetry in post-merger remnants and their implications for gravitational wave detection.

### 3. Core Idea
- Accurate temperature modeling in the equation of state (EOS) is crucial for understanding the stability and gravitational wave emission characteristics of neutron star remnants.

### 4. Method
- **Pipeline**: Simulations of binary neutron star mergers using different EOS models to assess thermal effects.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Utilized MareNostrum supercomputing resources and various open-source packages for simulations.

</details>

### [The Universal Weight Subspace Hypothesis](https://arxiv.org/pdf/2512.05117v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Subspace extraction and analysis across various models

### 2. Motivation & Gaps
- Addressing both the financial and environmental costs associated with training and deploying deep learning systems.

### 3. Core Idea
- Lowering the hardware and energy requirements for adaptation and inference to empower under-resourced researchers and institutions.

### 4. Method
- **Pipeline**: Extraction of universal subspaces from various models using layerwise spectral analysis.
- **Architecture / Loss / Training**: Utilizes a shared subspace model with minimal training on coefficients.
- **Complexity / Resources**: Experiments conducted on a single A5000 GPU and a CPU with 8 workers.

</details>
