# Daily Paper Digest Â· 2025-08-21
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## neural rendering
### [Lorentz-Equivariance without Limitations](http://arxiv.org/pdf/2508.14898v1)


<!--break-out-of-list-->
<details>
<summary>ðŸ“„ Paper Summary (click to expand)</summary>

### 1. Task / Problem
- Jet tagging

### 2. Motivation & Gaps
- The study investigates the performance of various neural classifiers in distinguishing between different event generators in particle physics.

- **Related work challenges:**
-- Various Lorentz-equivariant architectures: Task specificity and lack of transferability
-- Symmetry breaking in equivariant networks: Unclear performance comparison with networks equivariant under a subgroup of the Lorentz group
-- LorentzNet: Relies on specialized layers.
-- PELICAN: Relies on specialized layers.
-- L-GATr: Relies on specialized layers.
-- Previous Lorentz-equivariant architectures: Difficulty in achieving optimal performance due to symmetry breaking.
-- MadGraph: Generating sufficient training events while maintaining numerical stability.
-- MLP-I: Struggles with high multiplicity due to lack of permutation equivariance.
-- L-GATr: More expensive in terms of computational resources compared to LLoCa.
-- GNN: Limited performance without the benefits of Lorentz-equivariance.
-- Ref. [26]: The choice of target trajectory is crucial for the performance of CFM phase space generators.
-- Ref. [35]: Previous studies found that permutation-equivariant architectures significantly outperform simple MLPs.
-- N/A: Learning the full phase space density to a precision that renders the network uncertainty negligible.
-- Lorentz-equivariant L-GATr: Performance drop when comparing with E(3)-GATr due to unused translation representations.
-- Standard transformer: Struggles to learn mass distributions of virtual particles.
-- LLoCa-Transformer: Instabilities during training with large boost factors.
-- Ref. [35]: Extending results with additional datasets and design choices in the LLoCa framework.
-- ParticleNet: Limited performance due to non-equivariance.
-- ParT: Requires careful hyperparameter tuning to avoid overfitting.
-- L-GATr: Computational cost and applicability to specialized architectures.
-- N/A: N/A
-- ParT: Reproducing results and optimizing performance without learnable attention bias.
-- ParticleNet: Achieving better results with the ParT training setup compared to the official ParticleNet setup.
-- LLoCa-Transformer: Dealing with limited statistics in the TopTagXL dataset.
-- L-GATr: Cannot distinguish samples from L-GATr and LLoCa-Transformer with sufficient training data.
-- SO(2)-Transformer: Similar performance issues in distinguishing events when sufficient training data is used.
-- DA-Transformer: Performance is overshadowed by uncertainties from the training process in small-data regimes.
-- N/A: N/A
-- N/A: N/A

### 3. Core Idea
- The paper explores the effectiveness of different transformer architectures in jet tagging tasks, particularly focusing on Lorentz-equivariant methods.

### 4. Method
- **Pipeline**: Training multiple transformer architectures and neural classifiers on large datasets with specific hyperparameters.
- **Architecture / Loss / Training**: Using Adam optimizer with learning rate adjustments based on validation loss, and employing dropout for regularization.
- **Complexity / Resources**: Evaluating timings, memory consumption, and FLOPs for different architectures on a H100 GPU.

### 5. Experiments
- **Datasets & Metrics**: JetClass dataset with background rejection rates at fixed signal efficiency.
- **Baselines**: DA-GNN, DA-Transf., Established high-performance taggers, GNN, L-GATr, LLoCa-ParT, LLoCa-ParticleNet, LLoCa-Transformer, LorentzNet, MIParT, MIParT-L, MLP-I, Message passing graph network (GNN), N/A, Non-equivariant neural networks, P-CNN, PFN, ParT, ParticleNet, Standard transformer, Transformer
- **Main Results**: The classifier AUC shows that the LLoCa-Transformer can distinguish events generated by various transformers.
- **Ablations**: Performance improvements observed with pre-training on the JetClass dataset and fine-tuning.
- **Limitations / Stress Tests**: The performance metrics are upper bounds and depend on implementation details.

### 6. Takeaways
- **Pros**: Achieves exact Lorentz-equivariance with minimal computational overhead., Flexible implementation applicable to various neural network architectures., Allows for direct comparison of different equivariant network types.
- **Cons**: Task-specific architectures may limit generalizability., Performance comparison with non-equivariant networks can be complex., Symmetry breaking introduces additional considerations in network design.
- **Future Work**: Explore further applications of LLoCa in other physics domains., Investigate the integration of LLoCa with emerging ML techniques., Develop more generalized frameworks for equivariant neural networks.

</details>
### [Snap-Snap: Taking Two Images to Reconstruct 3D Human Gaussians in Milliseconds](http://arxiv.org/pdf/2508.14892v1)


<!--break-out-of-list-->
<details>
<summary>ðŸ“„ Paper Summary (click to expand)</summary>

### 1. Task / Problem
- Human Reconstruction

### 2. Motivation & Gaps
- Existing methods struggle with high-quality human reconstruction from limited views, often leading to misalignment and uncontrollable textures.

- **Related work challenges:**
-- Previous human reconstruction methods: Require synchronized cameras and multiple views, making them less accessible.
-- Single-view human reconstruction: Often misaligned with real-world coordinates and lacks detail.
-- Dense input view methods: Require expensive data acquisition setups.
-- HumanSplat: Inferring explicit human representation from a single image with semantic cues.
-- NHP: Learning generalizable neural radiance representations with body motion prior under sparse camera settings.
-- GPS-Gaussian: Building upon depth estimation models to extract Gaussian properties for novel view synthesis.
-- GPS-Gaussian: Requires multiple views for accurate reconstruction.
-- GHG: Utilizes ground-truth parameters which may not be available in practical scenarios.
-- GPS-Gaussian [59]: Lower reconstruction quality and missing body parts due to depth estimation limitations.
-- GHG [20]: Relies on ground-truth SMPL-X parameters, limiting its applicability in real scenarios.
-- SiTH [8]: Produces distorted poses and lacks alignment with the world coordinate system.
-- Auto-rectify network for unsupervised indoor depth estimation: Limited depth estimation capabilities in complex environments.
-- Geometry-guided progressive nerf for generalizable and efficient neural human rendering: Challenges in generalizing rendering techniques across different human poses.
-- High-fidelity 3D human digitization from single 2k resolution images: Achieving high fidelity in 3D reconstruction from a single image.
-- N/A: N/A
-- TRELLIS: Requires two images and struggles with clarity and texture consistency.
-- GPS-Gaussian: Relies on dense-view methods which may not generalize well to fewer input views.
-- SiTH: Generative models lead to uncontrollable textures and misalignment.
-- Snap-Snap: Reconstruction results still contain holes, particularly around occluded areas.
-- GHG: Estimating human body parameters using only two views is very challenging.

### 3. Core Idea
- Our method achieves high-quality human reconstruction using only a minimal number of input views, enhancing side-view predictions without relying on generative models.

### 4. Method
- **Pipeline**: Utilizes a side-view enhancement module to improve reconstruction quality from limited input views.
- **Architecture / Loss / Training**: UNet-like network architecture with ResNet blocks for Gaussian attribute regression.
- **Complexity / Resources**: Total inference time around 190 ms.

### 5. Experiments
- **Datasets & Metrics**: Evaluated on various datasets with metrics including PSNR, SSIM, and LPIPS.
- **Baselines**: DUSt3R, Dense input view methods, GHG, GHG [20], GPS-Gaussian, GPS-Gaussian [59], N/A, NHP, Previous human reconstruction methods, SiTH, SiTH [8], Single-view reconstruction methods, TRELLIS
- **Main Results**: Our method achieves good reconstruction quality across different poses while maintaining excellent consistency.
- **Ablations**: Ablation studies show that additional regression networks do not significantly improve reconstruction quality.
- **Limitations / Stress Tests**: The hollows on the human bodies could potentially be reduced with the use of geometric generative priors.

### 6. Takeaways
- **Pros**: Fast reconstruction time of 190 ms., Can work with low-cost mobile device images., Reduces the need for professional data collection.
- **Cons**: Limited detail recovery due to sparse input., Potential inaccuracies in geometry consistency.
- **Future Work**: Explore further generalizability across different human poses., Improve detail recovery from sparse inputs., Investigate applications in virtual/augmented reality.

</details>
### [Deep Reinforcement Learning Based Routing for Heterogeneous Multi-Hop Wireless Networks](http://arxiv.org/pdf/2508.14884v1)


<!--break-out-of-list-->
<details>
<summary>ðŸ“„ Paper Summary (click to expand)</summary>

### 1. Task / Problem
- Covert routing in heterogeneous networks

### 2. Motivation & Gaps
- The paper addresses the challenges of routing in heterogeneous networks, particularly focusing on covert routing techniques.

- **Related work challenges:**
-- Q-learning for routing in multi-hop networks: Scalability and poor generalization due to large Q-table management.
-- Deep Q-Network (DQN) applications in wireless routing: Reliance on distance-based channel models limits applicability in real-world scenarios.
-- Traditional distance-based neighbor node selection: Does not account for channel conditions and available rates, leading to suboptimal performance.
-- Existing routing algorithms: Often fail to adapt to dynamic environments and interference in wireless communication.
-- Existing algorithms for neighbor node selection: Limited efficiency in maximizing communication rates due to reliance on immediate rewards.
-- Various benchmark schemes for routing: Lack of optimal solutions for multi-hop wireless routing considering interference.
-- Dueling-DQN architecture: Complexity in selecting suitable neighbor nodes for data transmission.
-- Reinforcement learning based covert routing with node failure resiliency for heterogeneous networks: Node failure resiliency in routing
-- Deep reinforcement learning for multi-objective routing in wireless sensor networks: Multi-objective optimization in routing
-- Deep learning based routing protocols for wireless ad-hoc networks: A review: Lack of comprehensive reviews on deep learning routing protocols

### 3. Core Idea
- Utilizing reinforcement learning techniques to enhance covert routing strategies in heterogeneous networks.

### 4. Method
- **Pipeline**: The proposed method involves a reinforcement learning framework that adapts to network conditions for optimal routing.
- **Architecture / Loss / Training**: The architecture employs a deep reinforcement learning model with specific loss functions tailored for routing tasks.
- **Complexity / Resources**: The method is designed to be scalable, addressing the complexity of heterogeneous network environments.

### 5. Experiments
- **Datasets & Metrics**: Experiments were conducted using simulated heterogeneous network datasets with metrics focusing on routing efficiency and covert operation success.
- **Baselines**: Best direction to destination, Closest to destination, Destination directly, Distance-based neighbor selection, Distance-based selection methods, Existing node selection algorithms, Existing reinforcement learning approaches, Largest data rate, Least interfered, Strongest neighbor, Traditional Q-learning, Traditional distance-based selection, Traditional routing protocols, Widest path-based algorithm
- **Main Results**: The proposed method outperformed baseline approaches in terms of routing efficiency and covert operation success rates.
- **Ablations**: Ablation studies were performed to assess the impact of various components of the reinforcement learning model.
- **Limitations / Stress Tests**: Limitations include potential scalability issues in extremely large networks and the need for extensive training data.

### 6. Takeaways
- **Pros**: Improved scalability and adaptability in routing decisions., Dynamic adaptation to network conditions., Maximization of end-to-end rate through effective neighbor node selection.
- **Cons**: Dependence on the quality of the DNN training data., Potential challenges in real-world implementation due to environmental factors., Complexity in managing multiple communication technologies.
- **Future Work**: Exploration of additional reinforcement learning techniques for routing., Investigation of real-world deployment scenarios., Development of more robust neighbor node selection strategies.

</details>
