# Daily Paper Digest · 2025-08-28
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## neural rendering

### [Strong Lens Discoveries in DESI Legacy Imaging Surveys DR10 with Two Deep Learning Architectures](http://arxiv.org/pdf/2508.20087v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Identifying strong lens systems

### 2. Motivation & Gaps
- The study aims to enhance the identification of strong lens systems in astronomical surveys, particularly using advanced machine learning techniques.

- **Related work challenges:**
  - Huang et al. 2020: Previous searches have identified a significant number of lens candidates, but there is still a need for more comprehensive catalogs.
  - Huang et al. 2021: The challenge of accurately classifying and identifying lens candidates remains, necessitating improved methodologies.
  - Storfer et al. 2024: The integration of deep learning techniques into lens identification processes is still evolving and presents challenges in model training and validation.
  - Papers I, II, and III: Previous works had limitations in lens classification and sample selection.
  - Zitrin et al. (2012): Earlier methods did not effectively utilize the full potential of the Legacy Surveys data.
  - Paper III: Excluded certain galaxy types from the training sample, limiting the model's effectiveness.
  - Lanusse et al. (2018): Previous models had limitations in classification accuracy and computational efficiency.
  - Tan & Le (2019): EfficientNetV1 lacked the optimization for training speed and model size.
  - N/A: N/A
  - Storfer et al. (2025): Previous searches lacked the use of separate bands for visual inspection.
  - Paper I (Huang et al. 2020): Focused on DR7 with limited candidate types.
  - Paper II (Huang et al. 2021): Expanded to DR8 but still limited in candidate types.
  - Paper III (Storfer et al. 2024): Included more candidate types but still had gaps in the search.
  - N/A: N/A
  - Rojas et al. 2021: Existing methods for identifying strong lenses are often limited in accuracy and efficiency.
  - Rojas et al. 2022: Previous approaches may not leverage the full potential of convolutional neural networks.
  - Sheu et al. 2024: N/A
  - Suyu et al. 2020: N/A
  - Wong et al. 2019: N/A

### 3. Core Idea
- Utilizing convolutional neural networks to improve the detection of strong lens systems in the Dark Energy Survey data.

### 4. Method
- **Pipeline**: The method involves preprocessing the survey data, training a convolutional neural network, and validating the model on test datasets.
- **Architecture / Loss / Training**: The architecture includes multiple convolutional layers followed by fully connected layers, optimized using cross-entropy loss.
- **Complexity / Resources**: The model requires significant computational resources for training, including GPUs and large memory capacity.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize data from the Dark Energy Survey and evaluate performance using metrics such as precision, recall, and F1 score.
- **Baselines**: EfficientNet, Huang et al. 2020, Huang et al. 2021, Jaelani et al. (2020), Manual classification techniques, N/A, O’Donnell et al. (2022), Papers I-III, Previous lens detection methods, Previous machine learning models, Previous papers in the series (I, II, III), ResNet, Stein et al. (2022), Storfer et al. 2024, Traditional lens detection algorithms
- **Main Results**: The proposed method outperforms baseline models in identifying strong lens systems with higher accuracy.
- **Ablations**: Ablation studies indicate that specific architectural choices significantly impact model performance.
- **Limitations / Stress Tests**: The model's performance may degrade in regions with high noise or low signal-to-noise ratios.

### 6. Takeaways
- **Pros**: Significant increase in the number of identified lens candidates., Utilization of advanced deep learning techniques improves identification accuracy., Comprehensive coverage of the extragalactic sky enhances the dataset.
- **Cons**: Dependence on the quality of training data may introduce biases., Computationally intensive, requiring substantial resources., Potential for false positives in lens candidate identification.
- **Future Work**: Further refinement of neural network architectures for better performance., Exploration of additional datasets to enhance training., Integration of spectroscopic follow-up to validate lens candidates.

</details>

### [Smart Contract Intent Detection with Pre-trained Programming Language Model](http://arxiv.org/pdf/2508.20086v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Smart contract intent detection

### 2. Motivation & Gaps
- The paper addresses the need for a model that specifically targets unsafe developer intents in smart contracts, which is a gap in existing research that primarily focuses on vulnerabilities or coding practices.

- **Related work challenges:**
  - SmartIntentNN: Limited focus on detecting developer's intent in smart contracts.
  - SmartIntentNN: Enhancing detection accuracy in smart contracts.
  - CodeBERT: Adapting pre-trained models for specific tasks in code analysis.
  - Previous models for intent detection: Limited effectiveness in handling class imbalance and sequence length variability.
  - SmartIntentNN V1: Limited performance on minority-class intents and class imbalance.
  - General-purpose models (RoBERTa, CodeBERT): Inability to capture domain-specific patterns in smart contract data.
  - Pre-trained models for NLP and PLP: Transforming advances in pre-trained language models to effectively analyze smart contracts.
  - Smart contract vulnerability detection: Focusing on external risks associated with smart contracts.
  - Malicious behaviors and developer intents: Reflecting internal risks in smart contract development.
  - Smart-LLaMA-DPO: Focuses on generic vulnerability detection rather than unsafe developer intents.
  - SCALM: Leverages prompting strategies but does not systematically address unsafe developer intents.
  - SmartIntentNN: Initial work on intent detection but lacks the improvements and broader framework proposed in this paper.
  - N/A: N/A

### 3. Core Idea
- The proposed model, SmartIntentNN2, is a BERT-based pre-trained model specifically designed for smart contracts, generating contextual embeddings for intent-level security analysis.

### 4. Method
- **Pipeline**: The model uses a BERT-based pre-trained model to generate embeddings, which are then classified by a BiLSTM multi-label classifier.
- **Architecture / Loss / Training**: The architecture is lightweight and efficient, allowing integration with neural layers like BiLSTMs for specialized tasks.
- **Complexity / Resources**: The model is designed to be efficient, making it easier to deploy in practical applications.

### 5. Experiments
- **Datasets & Metrics**: Evaluation was conducted on 10,000 smart contracts, measuring performance using the F1 score.
- **Baselines**: BERT, BiLSTM, CNN, CodeBERT, ContractWard, ESCORT, GPT, GPT-3.5-turbo, GPT-4.1, GPT-4o-mini, LSTM, N/A, Previous intent detection models, RoBERTa, SaferSC, SmartIntentNN, SmartIntentNN V1
- **Main Results**: SmartIntentNN2 achieved an F1 score of 0.927, outperforming previous methods and other baselines.
- **Ablations**: Extensive ablation testing conducted with various model configurations and hyperparameters.
- **Limitations / Stress Tests**: Data imbalance and dataset coverage issues identified, particularly with low-frequency intent categories.

### 6. Takeaways
- **Pros**: Enhanced performance with an F1 score of 0.927., Integration of a BERT-based pre-trained model for better contextual understanding., Open-sourced all dataset, code, documentation, and models.
- **Cons**: Limited by maximum sequence length during training., Potential overfitting on the training dataset.
- **Future Work**: Further improvements in intent detection accuracy., Exploration of additional categories of unsafe intents., Potential application of the model to other programming languages.

</details>

### [Seam360GS: Seamless 360° Gaussian Splatting from Real-World Omnidirectional Images](http://arxiv.org/pdf/2508.20080v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Novel view synthesis with calibration adjustments

### 2. Motivation & Gaps
- The paper addresses challenges in dual-fisheye camera systems for omnidirectional novel view synthesis.

- **Related work challenges:**
  - Neural Radiance Fields (NeRF): Fails to produce accurate renderings for omnidirectional data.
  - 3D Gaussian Splatting (3DGS): Primarily designed for perspective images, struggles with calibration inaccuracies in omnidirectional images.
  - Recent 3DGS-based approaches: Neglect inter-camera gap in dual fisheye systems, constraining seamless image synthesis.
  - 360Roam: Manufacturing imperfections and suboptimal factory calibration can introduce noticeable stitching artifacts in the source images.
  - NeRF--: Eliminating the need for pre-calibrated inputs.
  - Omni-NeRF: Does not address the stitching artifacts in omnidirectional images commonly observed in consumer-grade systems.
  - Previous methods of 3D Gaussian splatting: Assumed accurate stitching of input 360° images, leading to geometric inaccuracies.
  - OmniNeRF: High mean absolute error in calibration performance compared to the proposed method.
  - OmniGS: Struggles to capture fine details and accurately reproduce text in 360° images.
  - JaxNeRF: Requires longer training times and does not achieve the same level of calibration accuracy.
  - OmniGS: Requires precise calibration for effective performance.
  - 360Roam: Struggles with camera gap and lens distortion.
  - OmniGS: Outperforms MVG approaches in novel-view synthesis without explicit distortion correction.
  - OP43DGS: Consistently shows worse performance compared to ERP-based rasterization.
  - N/A: N/A

### 3. Core Idea
- The proposed method integrates translation-based adjustments and angular distortion corrections within the Gaussian Splatting paradigm to enhance scene reconstruction accuracy.

### 4. Method
- **Pipeline**: Calibration process using Gaussian splats adjusted via translation and angular distortion.
- **Architecture / Loss / Training**: The architecture employs a total variation loss to enforce smoothness in the estimated rotations and uses a learning rate that decays exponentially.
- **Complexity / Resources**: Requires more than twice the training time and up to 2 GB additional VRAM.

### 5. Experiments
- **Datasets & Metrics**: EgoNeRF-Ricoh360 dataset and 360Roam dataset
- **Baselines**: 3D Gaussian Splatting, EgoNeRF, Existing state-of-the-art algorithms for omnidirectional novel view synthesis, NeRF, ODGS, OP43DGS, OmniGS, OmniNeRF, Other omnidirectional rendering techniques, Standard 3D Gaussian splatting
- **Main Results**: Quantitative evaluation results show improvements in PSNR, SSIM, and LPIPS metrics across various scenes.
- **Ablations**: Ablation studies show the importance of both translation and angular distortion adjustments.
- **Limitations / Stress Tests**: Cross-device transfer remains challenging due to significant inter-device calibration differences.

### 6. Takeaways
- **Pros**: Seamless omnidirectional novel view synthesis., No additional computational overhead during inference., Robust calibration parameters learned from realistic simulations.
- **Cons**: Manufacturing imperfections can introduce noticeable stitching artifacts., Reliance on pre-corrected equirectangular images can be challenging., Some methods do not account for inter-camera gaps.
- **Future Work**: Explore further optimizations for real-time applications., Investigate additional calibration techniques for other camera systems., Enhance robustness against varying environmental conditions.

</details>

## Gaussian Splatting

### [On the Maximal Gaussian Perimeter of Convex Sets, Revisited](http://arxiv.org/pdf/2508.20079v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Revisiting Nazarov’s construction of a convex set with nearly maximal Gaussian surface area

### 2. Motivation & Gaps
- The paper aims to provide an alternate analysis of Nazarov's construction using the concept of convex influence, addressing the gap between the best known upper and lower bounds for the Gaussian surface area of convex sets.

- **Related work challenges:**
  - Nazarov [Naz03]: His proof was considered boring and technical, and he speculated on a simpler proof.
  - Ball [Bal93]: Established a uniform bound on the Gaussian surface area of convex sets.
  - Raič [Rai19]: Provided a refinement of Ball's bound, but gaps remain in the bounds for Γ(n).
  - Nazarov’s original argument [Naz03]: Existence of a convex set with large Gaussian perimeter
  - Recent work [DNS24]: Polyhedral approximation under the Gaussian measure
  - N/A: N/A

### 3. Core Idea
- The paper presents a simpler proof of the existence of a convex set with large Gaussian perimeter by analyzing the concept of convex influence.

### 4. Method
- **Pipeline**: The proof utilizes a probabilistic method to demonstrate the existence of a convex set with large Gaussian perimeter.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The method avoids heavy analytic machinery and technical estimates, focusing instead on easier calculations related to convex influence.

### 5. Experiments
- **Datasets & Metrics**: N/A
- **Baselines**: Ball's uniform bound, N/A, Nazarov's original proof
- **Main Results**: The paper establishes that the Gaussian surface area of convex sets can be large, specifically showing that Γ(n) has a lower bound of Ω(n1/4).
- **Ablations**: N/A
- **Limitations / Stress Tests**: N/A

### 6. Takeaways
- **Pros**: Provides a simpler proof for a complex result., Addresses existing gaps in the literature regarding Gaussian surface area., Utilizes a novel concept of convex influence.
- **Cons**: The proof may still rely on some technical aspects., Gaps between upper and lower bounds for Γ(n) remain., The method may not be applicable to all types of convex sets.
- **Future Work**: Further exploration of the convex influence concept., Investigating other potential proofs for similar results., Addressing the remaining gaps in the bounds for Γ(n).

</details>

### [Neural Conditional Simulation for Complex Spatial Processes](http://arxiv.org/pdf/2508.20067v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Simulation from complex spatial processes

### 2. Motivation & Gaps
- The paper presents NCS in the context of spatial process models, highlighting its flexibility and efficiency in simulating from intractable predictive distributions.

- **Related work challenges:**
  - Walchessen et al. (2024): Efficient evaluation of the likelihood function of a spatial process model.
  - Lenzi et al. (2023): Using neural networks as Bayes estimators for parameter estimation.
  - Gelfand et al. (2010): Markov chain Monte Carlo (MCMC) methods often involve a trade-off between computational efficiency and statistical accuracy.
  - Wang et al. (2024): Not designed for high-dimensional conditioning.
  - Richards et al. (2024): Requires explicit masking for missing data.
  - Sainsbury-Dale et al. (2025): Limited applicability to high-dimensional predictive distributions.
  - Song et al., 2021: The score function is generally analytically or computationally intractable for non-Gaussian target distributions.
  - Gloeckler et al., 2024: Adapting the unconditional score-based diffusion approach for conditional simulation from predictive distributions.
  - Zammit-Mangion et al., 2025: The need for a modified score matching algorithm that does not require knowledge of predictive distributions.
  - Linhart et al. (2023): Difficulty in validating predictive distributions due to high-dimensional settings.
  - Song et al. (2021): Intractability of predictive distributions and variable conditioning sets.
  - Padoan et al. (2010): Computational challenges in sampling predictive distributions.
  - FCS simulations: Negatively biased at unobserved locations far from conditioning sites when the range parameter is small.
  - NCS simulations: Slight inaccuracy in the case of seven observed locations when the range parameter is high.
  - Gibbs sampler in FCS: Difficult to implement using available software and computational complexity increases with the number of observed locations.
  - FCS: Computationally intractable when the number of observed spatial locations exceeds seven.
  - LCS: Inherently restricted in the degree of high-dimensional patterns it can capture.
  - MCMC methods: Computational inefficiency and limitations in practical settings.
  - Vincent (2011): Intractable loss function
  - Ho et al. (2020): Connection between DDPM and VPSDE framework
  - Song et al. (2021): Utilizing a weighting function proportional to the inverse of the expectation of the conditional score function.
  - Chan et al. (2018): Avoiding overfitting and minimizing data storage during training.
  - Castruccio et al. (2016): Setting appropriate parameters for the Gaussian and Brown–Resnick processes.
  - N/A: N/A
  - N/A: N/A
  - FCS: Negative bias for unobserved locations farther from the spatial domain center when the range parameter is small.
  - NCS: Slightly increased graininess as the range parameter increases.

### 3. Core Idea
- The paper explores the application of NCS to Gaussian and Brown–Resnick processes, focusing on the simulation of spatial processes and the training of U-Nets for conditional evaluations.

### 4. Method
- **Pipeline**: Implementation of FCS and LCS using the condrmaxstab function with observed locations or nearest neighbors.
- **Architecture / Loss / Training**: Training involves log-transformation of data and uses U-Net architectures for simulations.
- **Complexity / Resources**: Training data parameters include minimum and maximum observations, full spatial field realizations, and conditioning sets.

### 5. Experiments
- **Datasets & Metrics**: Simulated data from the Brown–Resnick process on the Gumbel scale.
- **Baselines**: Brown–Resnick process unconditional simulator, FCS, Full Conditional Simulation (FCS), Gaussian process case study, Gaussian process model simulations, Gaussian process unconditional simulator, Gibbs Sampler, LCS, Local Conditional Simulation (LCS), MCMC methods, Markov Chain Monte Carlo (MCMC) standard approximation, Markov chain Monte Carlo (MCMC) simulations, N/A, NCS
- **Main Results**: FCS shows negative bias while NCS appears more accurate overall.
- **Ablations**: N/A
- **Limitations / Stress Tests**: FCS is fragile beyond seven observed locations.

### 6. Takeaways
- **Pros**: Efficient conditional simulation from complex spatial predictive distributions., No need for retraining the neural network for different observations., Improved accuracy over traditional MCMC methods.
- **Cons**: Dependence on the quality of unconditional samples for training., Potential limitations in high-dimensional conditioning.
- **Future Work**: Exploration of NCS for non-Gaussian processes., Validation of the method in high-dimensional data settings., Integration with other machine learning techniques for enhanced performance.

</details>

## avatar

### [FastAvatar: Towards Unified Fast High-Fidelity 3D Avatar Reconstruction with Large Gaussian Reconstruction Transformers](http://arxiv.org/pdf/2508.19754v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Avatar creation and representation

### 2. Motivation & Gaps
- The paper addresses the need for creating complete, driveable, and generalizable avatars using paired human captures.

- **Related work challenges:**
  - Contemporary 3D avatar methods: Suffer from drawbacks such as data sensitivity, high time complexity, and low data utilization efficiency.
  - Existing 3D avatar methods: Inability to leverage prior knowledge and inadequate handling of variable-length data.
  - Optimization-based 3D avatar methods: Require input data of a minimum specific length, leading to modeling failure with insufficient data.
  - NeRF-based approaches: Significant issues with head rendering speed limitations and extensive training data.
  - 3DGS: Requires multi-frame data for identity-specific training and lacks flexibility.
  - Feed-forward networks: Application to 3D head avatar reconstruction is still nascent and lacks a unified framework.
  - LAM: Fails to effectively process additional input views beyond single-view conditions.
  - MonoGaussianAvatar: Exhibits significant performance degradation with sparse inputs.
  - GaussianAvatar: Similar performance issues with sparse inputs as MonoGaussianAvatar.
  - LAM: Generative bias introduces pose and expression artifacts that compromise objective measurements.
  - MonoGaussianAvatar: Requires a fixed number of input frames, reducing flexibility.
  - GaussianAvatars: Similar limitations in flexibility and data usage.
  - Rignerf: Fully controllable neural 3D portraits: Limited control over 3D avatar expressions and poses.
  - Flame-in-nerf: Neural control of radiance fields for free view face animation: Challenges in achieving high-quality animations from limited input data.
  - A morphable model for the synthesis of 3D faces: Difficulty in synthesizing diverse facial expressions and poses.
  - Nerf: Representing scenes as neural radiance fields for view synthesis: Limited generalization across different scenes.
  - Instant neural graphics primitives with a multiresolution hash encoding: Challenges in real-time rendering and efficiency.
  - Learning robust visual features without supervision: Dependence on large labeled datasets for training.

### 3. Core Idea
- The core idea is to utilize paired human captures to create avatars that are not only visually accurate but also capable of being driven in virtual environments.

### 4. Method
- **Pipeline**: The method involves capturing paired human data and processing it to generate avatars that can be manipulated in a 3D space.
- **Architecture / Loss / Training**: Incorporates Landmark Tracking Loss and Sliced Fusion Loss to enhance model fidelity and robustness.
- **Complexity / Resources**: The method is designed to operate efficiently, allowing for real-time avatar reconstruction.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize various datasets to evaluate the performance of the avatar generation method.
- **Baselines**: 3DGS, Avat3r, Dinov2, Feed-forward networks, Flame-in-nerf, GaussianAvatar, GaussianAvatars, Instant neural graphics primitives, LAM, MonoGaussianAvatar, Morphable model, NeRF-based approaches, Nerf, Rignerf, VGGT
- **Main Results**: The results demonstrate significant improvements in avatar realism and driveability compared to existing methods.
- **Ablations**: Ablation studies confirmed the effectiveness of the proposed loss functions in improving reconstruction quality.
- **Limitations / Stress Tests**: The framework faces limitations in multi-model fusion, particularly in handling directional inconsistencies.

### 6. Takeaways
- **Pros**: Incremental reconstruction improves quality with more observations., High-quality 3D avatar modeling with flexible input data., Competitive speed in 3D reconstruction.
- **Cons**: Sensitivity to data quality., High time complexity in certain scenarios., Dependence on complete 3D observations.
- **Future Work**: Explore further optimizations for speed., Enhance robustness against data quality variations., Investigate applications in real-time environments.

</details>

### [SAT: Supervisor Regularization and Animation Augmentation for Two-process Monocular Texture 3D Human Reconstruction](http://arxiv.org/pdf/2508.19688v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- 3D Human Reconstruction

### 2. Motivation & Gaps
- The OAA module addresses data scarcity by generating augmented samples online.

- **Related work challenges:**
  - PIFu: Introduces pixel-aligned implicit functions for shape and texture but struggles with geometric ambiguity.
  - ICON: Enhances reconstruction using skinned body models but still faces integration issues with various geometric forms.
  - GTA: Employs a 3D-decoupling transformer for detailed reconstruction but does not fully address the data scarcity issue.
  - GTA: Detailed reconstruction using a 3D-decoupling transformer.
  - VS: Handling large deformations in loose clothing.
  - HiLo: Improving geometry detail and noise robustness.
  - Existing geometric models: Limited accuracy leading to flawed details in 3D reconstructions.
  - Monocular reconstruction methods: Struggles with integrating geometric information effectively.
  - Animation augmentation techniques: Limited availability of 3D human scan datasets restricts reconstruction performance.
  - ICON: Limited accuracy in 3D reconstruction.
  - SiTH: Inability to effectively utilize multi-view data.
  - MultiGO: Challenges in texture representation.
  - LBS method: Samples generated from the LBS method can lead to a decrease in performance due to significant distortion.
  - SCAPE: shape completion and animation of people: Limited data availability for training robust models.
  - ShapeNet: An Information-Rich 3D Model Repository: Need for diverse and high-quality 3D models.
  - Collaborative Regression of Expressive Bodies using Moderation: Challenges in capturing expressive body movements.
  - N/A: N/A

### 3. Core Idea
- Our method demonstrates SOTA performance on public datasets, validating its contribution.

### 4. Method
- **Pipeline**: Two-process framework that incorporates supervisor regularization and animation augmentation.
- **Architecture / Loss / Training**: Utilizes constraints from a trained supervisor model to improve feature extraction in the monocular reconstruction network.
- **Complexity / Resources**: Online learning requires fewer local resources and is more efficient compared to offline augmentation.

### 5. Experiments
- **Datasets & Metrics**: CustomHuman and THuman3.0 datasets with metrics including CD, NC, f-score, LPIPS, SSIM, and PSNR.
- **Baselines**: ECON, Existing monocular reconstruction methods, GTA, ICON, LBS, LBS method, MultiGO, N/A, PIFu, Previous state-of-the-art methods, Separate training approaches
- **Main Results**: The proposed method outperforms existing methods in terms of texture quality and geometric accuracy, achieving lower distortion and better detail reconstruction.
- **Ablations**: Ablation studies show the impact of different geometry prior models, supervisor regularization, and animation augmentation on reconstruction results.
- **Limitations / Stress Tests**: The performance of offline augmentation is limited compared to online learning due to the smaller data size.

### 6. Takeaways
- **Pros**: Achieves state-of-the-art performance in 3D human reconstruction., Effectively integrates various geometric priors., Augments training data online to improve model robustness.
- **Cons**: Increased computational complexity due to multiple networks., Dependency on the quality of existing 3D human data., Potential challenges in real-time applications.
- **Future Work**: Explore further integration of additional geometric modalities., Investigate real-time applications of the proposed framework., Enhance the online augmentation process for more diverse training samples.

</details>

### [Fast Texture Transfer for XR Avatars via Barycentric UV Conversion](http://arxiv.org/pdf/2508.19518v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Texture transfer for full-body avatars

### 2. Motivation & Gaps
- Existing methods for avatar texture transfer are slow and prone to visual artifacts, limiting their practical applicability in immersive XR applications.

- **Related work challenges:**
  - FLAME and SMPL-X models: Integration of detailed facial expression and full-body animation simultaneously faces limitations due to lengthy processing times.
  - Conventional affine-transform methods: High computational cost and visual artifacts during texture transfer.
  - FLAME2SMPLX: Lower quality scores and noticeable visual artifacts along facial boundary seams.

### 3. Core Idea
- The method achieves a significant speedup in texture transfer while maintaining high fidelity to the original texture.

### 4. Method
- **Pipeline**: Generating a UV grid for texture transfer between SMPL-X and FLAME.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The one-time pre-computation stage takes approximately 9.77 seconds for SMPL-X to FLAME and 13.12 seconds for FLAME to SMPL-X.

### 5. Experiments
- **Datasets & Metrics**: Evaluated using FLAME2SMPLX as the baseline method with metrics including L1 distance, SSIM, PSNR, and LPIPS.
- **Baselines**: FLAME2SMPLX
- **Main Results**: Achieves a speedup of over 7000x compared to the baseline while outperforming it across all image similarity metrics.
- **Ablations**: N/A
- **Limitations / Stress Tests**: N/A

### 6. Takeaways
- **Pros**: Significantly faster texture transfer speed., Higher texture quality with fewer visual artifacts., Practical applicability for real-time avatar personalization.
- **Cons**: N/A, N/A, N/A
- **Future Work**: Explore further optimizations for real-time applications., Investigate integration with other avatar features., Expand to different avatar models and textures.

</details>

## video understanding

### [Bridging Domain Gaps for Fine-Grained Moth Classification Through Expert-Informed Adaptation and Foundation Model Priors](http://arxiv.org/pdf/2508.20089v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Fine-Grained Moth Classification

### 2. Motivation & Gaps
- The study addresses the challenges in fine-grained classification of moths, particularly in the context of domain adaptation and the use of foundation models.

- **Related work challenges:**
  - Automated insect camera traps: Raw imagery must be processed before providing actionable ecological insights.
  - Citizen science repositories like GBIF: Domain shift reduces performance when models are trained on source-domain images and evaluated on target-domain insects.
  - Existing domain adaptation methods: Developing lightweight models for insect monitoring remains important due to limited computing infrastructure.
  - N/A: Limited understanding of domain shift effects in species classification.
  - BioCLIP: Weaker overall performance compared to BioCLIP2, but performs well in low target-supervision settings.
  - ConvNeXt: Requires significant target supervision to boost accuracy.
  - A survey on knowledge distillation: Recent advancements: Knowledge distillation techniques may not effectively transfer knowledge across diverse domains.
  - Towards a standardized framework for ai-assisted, image-based monitoring of nocturnal insects: Existing frameworks lack adaptability to different insect species and environments.
  - Learning transferable visual models from natural language supervision: Transferability of visual models is limited when applied to fine-grained classifications.

### 3. Core Idea
- Utilizing expert-informed adaptation techniques alongside foundation model priors to improve classification accuracy in fine-grained moth identification.

### 4. Method
- **Pipeline**: The method involves embedding images using a pretrained ResNet-50, followed by agglomerative hierarchical clustering for train/test splitting.
- **Architecture / Loss / Training**: The architecture employs a ResNet-50 backbone with a focus on minimizing cosine distance in the embedding space.
- **Complexity / Resources**: The method requires significant computational resources for training the ResNet-50 and performing clustering on large datasets.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize a mixed dataset composed of AMI and GBIF images, with various target-domain percentages to evaluate model performance.
- **Baselines**: BioCLIP, BioCLIP2, ConvNeXt, ConvNeXt+KD, ConvNeXt-tiny, ConvNeXt-tiny+KD, Previous domain adaptation methods, Standard ResNet-50 classification
- **Main Results**: The proposed method shows improved classification accuracy compared to baseline models, particularly in low target-domain scenarios.
- **Ablations**: Ablation studies indicate the importance of expert-informed adaptation in enhancing model performance.
- **Limitations / Stress Tests**: The model's performance may degrade with highly imbalanced datasets or when the target domain is underrepresented.

### 6. Takeaways
- **Pros**: Lightweight models are easier to retrain for new species integration., Facilitates edge computing directly on camera trap hardware., Offers practical guidelines for efficient insect monitoring systems.
- **Cons**: Limited expert-labelled data may restrict model performance., Domain shift can still impact accuracy despite adaptations., Dependence on high-quality images for effective training.
- **Future Work**: Explore further integration of expert knowledge in model training., Investigate additional domain adaptation strategies., Develop more robust models for diverse ecological scenarios.

</details>

### [Visio-Verbal Teleimpedance Interface: Enabling Semi-Autonomous Control of Physical Interaction via Eye Tracking and Speech](http://arxiv.org/pdf/2508.20037v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Determining stiffness matrices for groove sections

### 2. Motivation & Gaps
- The study aims to improve the accuracy of stiffness matrix determination in robotic teleoperation tasks.

- **Related work challenges:**
  - Existing teleimpedance command interfaces: Require either manual control or automation, limiting cognitive flexibility and operator input.
  - EMG-based teleimpedance interfaces: Require sensor placement and calibration, limiting generalizability.
  - Automated impedance control systems: Remove operator from the control loop, reducing ability to intervene.
  - GazeGPT: Incorporates mobile eye-tracking to enhance context awareness but lacks integration with teleimpedance control.
  - Previous teleoperation systems: Limited adaptability to operator's gaze and verbal inputs.
  - Existing haptic interfaces: Inability to dynamically adjust stiffness based on real-time feedback.
  - Studies on few-shot prompting: Few-shot prompting significantly improves VLM performance compared to zero-shot prompting.
  - Parameter optimization experiments: Identifying effective combinations of prompt parameters for teleimpedance applications.
  - Previous studies on teleimpedance interfaces: Limited interaction capabilities and reliance on visual context.
  - Manual teleimpedance control methods: Inability to adapt stiffness dynamically based on verbal commands.
  - A review on manipulation skill acquisition through teleoperation-based learning from demonstration: Limited understanding of how to effectively acquire manipulation skills in complex environments.
  - A survey of robot manipulation in contact: Challenges in robot manipulation when interacting with complex structures.
  - Tele-impedance: Teleoperation with impedance regulation using a body–machine interface: Need for better impedance control in teleoperation tasks.
  - Attention is all you need: N/A
  - Scaling laws for neural language models: N/A
  - GazeGPT: Augmenting human capabilities using gaze-contingent contextual AI for smart eyewear: N/A
  - Language models are few-shot learners: N/A
  - Flamingo: a visual language model for few-shot learning: N/A

### 3. Core Idea
- To enhance teleimpedance applications by optimizing camera angles and image resolution for better prediction accuracy.

### 4. Method
- **Pipeline**: Utilizing a mobile eye tracker to capture images and determine stiffness matrices based on visual input.
- **Architecture / Loss / Training**: Utilizes a specialized stiffness matrix generator with varying prompt designs to improve output quality.
- **Complexity / Resources**: The study relies on a mobile eye tracker and requires additional image-processing steps.

### 5. Experiments
- **Datasets & Metrics**: The experiments involved various camera angles and lighting conditions to assess classification accuracy.
- **Baselines**: Automated impedance control, Few-shot prompting without prior examples, High-resolution images, Image priors from different environments, Manual impedance control, Manual teleimpedance control, N/A, Previous robotic control interfaces, Previous teleoperation systems, Single camera angle input, Standard haptic interfaces, Zero-shot prompting
- **Main Results**: Classification accuracy for slant increased to 66.6% with improved camera angle and lighting.
- **Ablations**: Post-experiment tests indicated the impact of camera angle and lighting on performance.
- **Limitations / Stress Tests**: The reliance on a mobile eye tracker introduces challenges in isolating the display screen from the environment.

### 6. Takeaways
- **Pros**: Allows intuitive control of robot stiffness using natural modalities (gaze and speech)., Reduces cognitive workload on the operator., Enhances adaptability in unstructured environments.
- **Cons**: May require initial setup and calibration of gaze tracking and speech recognition systems., Dependence on technology may introduce new points of failure., Limited by the capabilities of the Visual Language Model.
- **Future Work**: Explore integration with additional sensory inputs for improved control., Investigate applications in more complex robotic tasks., Enhance robustness of the system against environmental variations.

</details>

### [Microscopic Origin of Domain Wall Reconfiguration Dynamics in a Quantum Material via Quantum Simulation](http://arxiv.org/pdf/2508.20028v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Investigate microscopic processes in non-equilibrium dynamics using quantum simulations.

### 2. Motivation & Gaps
- The study aims to address the microscopic origin of non-equilibrium reconfiguration in correlated materials, particularly in 1T-TaS2.

- **Related work challenges:**
  - Prior studies using STM on 1T-TaS2: Uncertainty whether domain wall motion arises from coherent multi-particle tunneling or cascades of local spin flips.
  - N/A: N/A
  - Quantum simulations of molecular chemistry: Often focus on idealized models with limited applicability to real-world systems.
  - Lattice gauge theories: Lack of insights into complex, real-world non-equilibrium dynamics.
  - Programmable quantum matter: Does not adequately address metastable state dynamics in solid-state materials.
  - N/A: N/A

### 3. Core Idea
- Utilizing quantum simulations as a microscope to probe complex non-equilibrium dynamics in strongly correlated materials.

### 4. Method
- **Pipeline**: Combining quantum simulations of a transverse-field Ising model with analytical mapping to a hardcore boson model.
- **Architecture / Loss / Training**: Mapping the TFIM to a hardcore boson model using a Schrieffer–Wolff transformation.
- **Complexity / Resources**: Large-scale quantum annealer simulations were employed.

### 5. Experiments
- **Datasets & Metrics**: Simulations of polaronic reconfiguration events across various transverse fields.
- **Baselines**: Hardcore boson model, Idealized quantum models, N/A, Previous quantum simulation studies, Transverse-field Ising model (TFIM)
- **Main Results**: Reconfiguration dynamics dominated by single-polaron tunneling and density-changing events.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The study does not extend to phonon coupling or longer-range interactions.

### 6. Takeaways
- **Pros**: Establishes quantum simulation as a powerful tool for studying non-equilibrium dynamics in quantum materials., Provides a concrete strategy for bridging effective spin models with real-space mechanisms., Offers insights into the microscopic relaxation pathways in strongly correlated systems.
- **Cons**: The study may not fully capture all complexities of real material behavior., Limited to the specific case of 1T-TaS2 and may not generalize to other materials., Minor discrepancies between experimental and simulated results could affect conclusions.
- **Future Work**: Explore the application of quantum simulation to other strongly correlated materials., Investigate the role of disorder and lattice geometry in non-equilibrium dynamics., Develop more comprehensive models that incorporate additional physical effects.

</details>
