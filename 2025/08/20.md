# Daily Paper Digest Â· 2025-08-20
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## neural rendering
### [LongSplat: Robust Unposed 3D Gaussian Splatting for Casual Long Videos](http://arxiv.org/pdf/2508.14041v1)


<!--break-out-of-list-->
<details>
<summary>ðŸ“„ Paper Summary (click to expand)</summary>

### 1. Task / Problem
- Novel view synthesis and camera pose estimation

### 2. Motivation & Gaps
- Existing methods struggle with visual quality and accuracy in complex scenes.

- **Related work challenges:**
-- COLMAP: Fails in casual settings due to incorrect camera pose estimation.
-- CF-3DGS: Suffers from out-of-memory issues.
-- LocalRF: Struggles with complex camera trajectories, resulting in fragmented reconstructions.
-- MASt3R: Provides inaccurate poses leading to degraded rendering quality.
-- NeRF: Implicit global representation struggles with challenging trajectories.
-- LocalRF: Slow training and fragmentation under irregular camera movements.
-- Scaffold-GS: Requires SfM initialization.
-- Scaffold-GS: Relies on a fixed-resolution grid, limiting adaptability to varying scene complexities.
-- CF-3DGS: Frequently encounters out-of-memory issues.
-- NoPe-NeRF: Produces blurred results with inaccurate geometries.
-- LocalRF: Exhibits artifacts or blurry reconstructions.
-- CF-3DGS: Encounters out-of-memory (OOM) issues in all scenes.
-- LocalRF: Produces fragmented geometry and pose drift.
-- MASt3R + Scaffold-GS: Inaccurate global pose estimates lead to blurred renderings.
-- Mip-nerf: A multiscale representation for anti-aliasing neural radiance fields: Dynamic objects and varying focal lengths.
-- Hyperreel: High-fidelity 6-dof video with ray-conditioned sampling: High fidelity rendering in dynamic environments.
-- Garf: Gaussian activated radiance fields for high fidelity reconstruction and pose estimation: Pose estimation in dynamic scenes.
-- CF-3DGS: Limited performance on complex scenes.
-- HT-3DGS: Struggles with pose estimation accuracy.
-- COLMAP: Noisy poses and failure in long trajectories or low-texture regions.
-- HT-3DGS: Out of memory issues and poor performance on diverse datasets.
-- CF-3DGS: Inconsistent results across different scenes.
-- CF-3DGS: Out of memory issues in long sequences.
-- NoPe-NeRF: Produces blurred results with inaccurate geometries.
-- LocalRF: Exhibits artifacts or blurry reconstructions.

### 3. Core Idea
- LongSplat achieves superior rendering quality and accurate camera pose estimation by utilizing adaptive window sizes and optimization techniques.

### 4. Method
- **Pipeline**: The method involves novel view synthesis followed by camera pose estimation using adaptive optimization.
- **Architecture / Loss / Training**: Utilizes a combination of global and local optimization techniques to enhance accuracy.
- **Complexity / Resources**: The method is designed to be resource-efficient, avoiding out-of-memory issues while maintaining high performance.

### 5. Experiments
- **Datasets & Metrics**: Evaluated on the Tanks and Temples and Free datasets using PSNR, SSIM, and LPIPS for quality assessment.
- **Baselines**: CF-3DGS, COLMAP, COLMAP + 3DGS, COLMAP+3DGS, Garf, HT-3DGS, Hyperreel, LocalRF, MASt3R, MASt3R + Scaffold-GS, Mip-nerf, NeRF, NoPe-NeRF, Scaffold-GS
- **Main Results**: LongSplat consistently outperforms existing methods across multiple challenging scenes in both view synthesis and pose estimation.
- **Ablations**: Ablation studies demonstrate the importance of each proposed module in maintaining pose accuracy and reconstruction quality.
- **Limitations / Stress Tests**: The method shows limitations in extremely complex scenes where even state-of-the-art methods struggle.

### 6. Takeaways
- **Pros**: Achieves accurate novel view synthesis without provided camera poses., Improves rendering quality and pose accuracy., Reduces memory usage while preserving reconstruction quality.
- **Cons**: Still requires careful initialization for optimal performance., May struggle with very complex scenes., Performance can degrade with highly erratic camera movements.
- **Future Work**: Explore further optimizations for large-scale scenes., Investigate applications in dynamic environments., Enhance robustness against varying camera motions.

</details>
### [Distilled-3DGS:Distilled 3D Gaussian Splatting](http://arxiv.org/pdf/2508.14037v1)


<!--break-out-of-list-->
<details>
<summary>ðŸ“„ Paper Summary (click to expand)</summary>

### 1. Task / Problem
- Knowledge Distillation in 3D Gaussian Splatting

### 2. Motivation & Gaps
- The paper addresses the challenge of preserving reconstruction quality in 3D Gaussian Splatting (3DGS) while significantly reducing Gaussian counts.

- **Related work challenges:**
-- 3D Gaussian Splatting (3DGS): Requires a large number of 3D Gaussians for high-fidelity rendering, leading to high memory consumption.
-- Knowledge Distillation: Applying it to 3DGS introduces unique challenges such as lack of consistent latent feature spaces and unordered Gaussian primitives.
-- Mini-Splatting: Addresses overlapping and reconstruction artifacts but does not fully resolve rendering efficiency.
-- Radsplatting: Enhances robustness but may not improve overall rendering quality.
-- Taming-3DGS: Utilizes pixel saliency but does not address the issue of redundant Gaussians.
-- 3DGS: Limited robustness and generalization ability of existing models.
-- Dropout Techniques: Inadequate representation learning due to reliance on critical Gaussian primitives.
-- Mip-NeRF 360: Limited ability to capture fine details in complex scenes.
-- 3D-GS: Requires a large number of Gaussian primitives for high-quality rendering.
-- Taming 3DGS: Struggles with maintaining quality while reducing the number of primitives.
-- Hinton et al. (2015): Distilling knowledge in neural networks often requires extensive computational resources.
-- Fang and Wang (2024): Efficient representation of scenes with a constrained number of Gaussians remains a challenge.
-- Kerbl et al. (2023): Real-time rendering with high-quality output is difficult with traditional methods.
-- N/A: N/A
-- EAGLES: Requires significant memory and computation time.
-- Mini-Splatting: N/A
-- 3D-GS: N/A

### 3. Core Idea
- Proposed voxel histogram-based method outperforms existing approaches while requiring less memory and computation time.

### 4. Method
- **Pipeline**: The pipeline involves training multiple teacher models and distilling their knowledge into a compact student model.
- **Architecture / Loss / Training**: The architecture employs a spatial distribution distillation strategy to align the student model's learning with that of the teacher models.
- **Complexity / Resources**: Significantly less memory and computation time.

### 5. Experiments
- **Datasets & Metrics**: Mip-NeRF360, Tanks&Temples, Deep Blending datasets with metrics PSNR, SSIM, LPIPS.
- **Baselines**: 3D-GS, 3DGS, CompactGaussian, EAAGLES, EAGLES, INGP, INGP-Big, LP-3DGS, Mini-Splatting, MiniSplatting, Mip-NeRF 360, N/A, Plenoxels, Radsplatting, Single teacher models, Standard 3D Gaussian Splatting, Taming 3D-GS, Taming 3DGS, Vanilla 3DGS
- **Main Results**: Our method consistently outperforms the baselines across various scenes.
- **Ablations**: Ablation studies showed that increasing grid size improves PSNR but increases GPU memory usage.
- **Limitations / Stress Tests**: The distilled model requires substantial GPU memory for generating distillation soft labels.

### 6. Takeaways
- **Pros**: Achieves better detail preservation with lower storage., First method to leverage multi-teacher knowledge priors to optimize 3DGS., Promising performance in both rendering quality and efficiency.
- **Cons**: Requires careful design of teacher model ensembles., Challenges in designing stable and informative distillation losses.
- **Future Work**: Explore further optimizations in the distillation process., Investigate the application of the framework to other 3D representation tasks.

</details>
### [ASDFormer: A Transformer with Mixtures of Pooling-Classifier Experts for Robust Autism Diagnosis and Biomarker Discovery](http://arxiv.org/pdf/2508.14005v1)


<!--break-out-of-list-->
<details>
<summary>ðŸ“„ Paper Summary (click to expand)</summary>

### 1. Task / Problem
- Early detection of autism spectrum disorders (ASD)

### 2. Motivation & Gaps
- The study aims to improve the diagnostic performance for autism spectrum disorders by uncovering connectivity patterns that align with established ASD biomarkers.

- **Related work challenges:**
-- Graph Neural Networks (GNNs): GNNs primarily rely on local message passing, which restricts their ability to model long-range dependencies across the brain network.
-- Traditional diagnostic practices: Conventional methods rely on subjective behavioral assessments, which are time-consuming and prone to variability.
-- Attention mechanisms in Transformers: Attention weights do not guarantee which Regions of Interest (ROIs) are truly responsible for the modelâ€™s final decision.
-- Deng et al. [14]: Introduced a spatial-temporal attention model combined with data balancing techniques to enhance ASD prediction.
-- Com-BrainTF [12]: Integrates local and global attention but attention maps alone do not guarantee interpretability.
-- Shazeer et al. [16]: Sparsely-gated MoE requires auxiliary regularization to ensure balanced expert utilization.
-- Com-BrainTF: Limited interpretability and expert specialization.
-- BrainNetTF: Inability to effectively model global brain-wide interactions.
-- FBNETGEN: Challenges in dynamic inference of brain networks.
-- FBNETGNN: Lower AUC and accuracy compared to ASDFormer.
-- BrainNetCNN: Lower sensitivity and specificity compared to ASDFormer.
-- BrainNetTF: Lower overall performance metrics compared to ASDFormer.
-- N/A: N/A
-- CLS token approach: Limited performance despite allowing interpretability through attention visualization.
-- OCRead strategy: Significantly improved performance but sacrificed token-level interpretability.
-- Pooling-Classifier design: Preserved interpretability but had notably lower performance.
-- Hasan, S.M., et al. : A machine learning framework for early-stage detection of autism spectrum disorders.: Limited diagnostic performance and lack of interpretability in existing models.
-- Ahmed, I.A., et al. : Eye tracking-based diagnosis and early detection of autism spectrum disorder using machine learning and deep learning techniques.: Challenges in integrating diverse data sources for accurate diagnosis.
-- Kavadi, D.P., et al.: A hybrid machine learning model for accurate autism diagnosis.: Need for improved model performance and interpretability.

### 3. Core Idea
- ASDFormer utilizes advanced machine learning techniques to enhance the diagnostic accuracy for autism spectrum disorders by identifying key biomarkers and connectivity patterns.

### 4. Method
- **Pipeline**: The method involves data preprocessing, model training, and evaluation phases to ensure robust performance.
- **Architecture / Loss / Training**: The architecture employs a transformer-based model with specific loss functions tailored for connectivity pattern analysis.
- **Complexity / Resources**: The model requires significant computational resources for training and inference, leveraging modern GPU capabilities.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize fMRI datasets and evaluate performance using metrics such as accuracy, precision, and recall.
- **Baselines**: BrainNetCNN, BrainNetTF, CLS, CNN-FC, Com-BrainTF, Deep learning models, Dense models, FBNETGEN, FBNETGNN, GNNs, Graph Neural Networks, N/A, OCRead, Pooling-Classifier, Previous MoE variants, Traditional machine learning methods, Traditional machine learning models
- **Main Results**: ASDFormer achieved state-of-the-art diagnostic performance, uncovering connectivity patterns that align with well-established ASD biomarkers.
- **Ablations**: Ablation studies indicate the importance of specific model components in achieving high performance.
- **Limitations / Stress Tests**: The study acknowledges limitations in data availability and the need for further validation across diverse populations.

### 6. Takeaways
- **Pros**: Improved classification performance for ASD diagnosis., Enhanced interpretability in identifying disorder-related biomarkers., State-of-the-art performance on the ABIDE dataset.
- **Cons**: Dependence on the quality of fMRI data., Complexity in model training and interpretation., Potential overfitting due to high model capacity.
- **Future Work**: Exploration of additional datasets for validation., Integration with other neuroimaging modalities., Further development of interpretability strategies.

</details>
