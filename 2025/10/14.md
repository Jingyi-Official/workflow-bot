# Daily Paper Digest Â· 2025-10-14
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## neural rendering

### [Ev4DGS: Novel-view Rendering of Non-Rigid Objects from Monocular Event Streams](http://arxiv.org/pdf/2510.11717v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Novel-view rendering from monocular event streams

### 2. Motivation & Gaps
- The paper addresses the challenge of rendering non-rigid objects using monocular event streams, which provide limited information about changes in luminance.

- **Related work challenges:**
  - Neural Radiance Fields (NeRF): Long training and rendering time.
  - 3D Gaussian Splatting (3DGS): Requires RGB images as input, which can be a practical limitation.
  - EvDNeRF: Requires known event streams and uses D-NeRF as the backbone, limiting its applicability.
  - DE-NeRF: Requires RGB image input in addition to event streams, which is a limitation for monocular event-based methods.
  - NPGs: Focuses on rigid object shapes and does not accommodate non-rigid deformations effectively.
  - 3DGS: Assumes static scenes and fails to restore dynamic parts.
  - Deformable-3DGS (D3DGS): Performs comparably but struggles with details in rapidly moving objects.
  - E2VID: Reconstructed frames often differ in background color, impacting evaluation.
  - E2VID: Often fails to produce high-quality binary masks, affecting the final reconstruction results.
  - Snake: While effective, it still produces inferior results compared to ground-truth binary masks.
  - EventNeRF: Limited ability to estimate absolute luminance values from event data.
  - ESIM: Only simulates greyscale events, complicating the generation of RGB events.
  - D-nerf: Challenges in rendering dynamic scenes accurately from event data.

### 3. Core Idea
- The proposed method utilizes a combination of coarse and fine training stages to optimize parameters in 3D Gaussians for rendering non-rigid objects from monocular event streams.

### 4. Method
- **Pipeline**: The method consists of a coarse stage followed by a fine stage, optimizing the model parameters iteratively.
- **Architecture / Loss / Training**: Uses a cosine annealing scheduler for learning rates and applies color correction to align rendered images with ground truth.
- **Complexity / Resources**: Experiments conducted on NVIDIA Quadro GV100, with full reconstruction taking approximately 4 hours.

### 5. Experiments
- **Datasets & Metrics**: Synthetic dataset created using Blender for RGB frames and real dataset recorded with a DA VIS 346 MONO event camera and GoPro HERO10 Black for evaluation.
- **Baselines**: 3D Gaussian Splatting (3DGS), 3DGS, D-nerf, DE-NeRF, Deformable-3DGS (D3DGS), E2VID, E2VID+SAM, ESIM, EvDNeRF, EventNeRF, Ground-truth binary masks, NPGs, Neural Radiance Fields (NeRF), Snake
- **Main Results**: The proposed method shows improved rendering quality compared to baseline methods, particularly in handling non-rigid objects.
- **Ablations**: Ablation studies were conducted to evaluate the impact of different components of the model on rendering performance.
- **Limitations / Stress Tests**: The method's reliance on event data limits its ability to estimate absolute luminance, which may affect evaluation metrics.

### 6. Takeaways
- **Pros**: First approach for novel-view rendering of non-rigid scenes from monocular event cameras., Enables self-supervised learning with only event streams., Employs a coarse deformation model tailored to the event-based setting.
- **Cons**: The problem remains ill-posed due to non-rigid object shape changes., Requires new synthetic and real sequences for evaluation.
- **Future Work**: Further exploration of event-based methods for dynamic scenes., Development of more robust models for non-rigid reconstruction.

</details>

### [CodePlot-CoT: Mathematical Visual Reasoning by Thinking with Code-Driven Images](http://arxiv.org/pdf/2510.11718v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Dataset Collection and Evaluation

### 2. Motivation & Gaps
- The Math-VR dataset aims to provide a rich resource for evaluating multimodal mathematical reasoning by collecting a diverse set of secondary school-level mathematical problems and their solutions.

- **Related work challenges:**
  - Visual Chain-of-Thought (Visual CoT): Breaks down in the context of mathematics problems that demand high precision.
  - Existing LLMs and VLMs: Constrained to text-only reasoning chains, leading to redundant and incorrect reasoning.
  - Unified multimodal models: Lack the necessary precision and controllability for tasks requiring visual reasoning.
  - Math-500: Primarily evaluates modelsâ€™ textual reasoning abilities.
  - MathVista: Focuses on visual perception without integrating visual thoughts into reasoning.
  - MATH-Vision: Incorporates image-based questions but still relies on text-only reasoning.
  - Existing benchmarks for mathematical reasoning: Lack of multimodal questions that integrate visual and textual reasoning.
  - Visual CoT: Difficulties in satisfying strict geometric constraints in mathematical contexts.
  - Image generation models: Inability to accurately represent structured geometric information.
  - Gemini-2.5-Pro: Fails on approximately one-third of the benchmark problems.
  - Bagel-Zebra-CoT: Provides only modest gains due to poor controllability and low geometric precision.
  - Qwen2.5-VL-72B: Exhibits low answer correctness on Math-VR benchmark.
  - Qwen-2.5VL-3B: Inability to incorporate visual information in text-only reasoning.
  - Bagel: Underperformance in comparison to code-driven reasoning methods.
  - Mathvista: Evaluating mathematical reasoning of foundation models in visual contexts: Limited datasets for multimodal reasoning in mathematics.
  - Visual COT: Advancing multi-modal language models with a comprehensive dataset: Existing datasets lack comprehensive coverage of multimodal reasoning tasks.
  - Mathcoder: Seamless code integration in LLMs for enhanced mathematical reasoning: Challenges in integrating visual and textual reasoning in mathematical contexts.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- To create a dataset that includes approximately 900k secondary school-level mathematical problems with corresponding images and solutions, facilitating the evaluation of multimodal reasoning capabilities in language models.

### 4. Method
- **Pipeline**: The dataset was created by collecting problems, labeling images, extracting text, and standardizing the format using GPT-4.1.
- **Architecture / Loss / Training**: Loss is assigned to the textual reasoning chain and generated code, with no loss applied to rendered images.
- **Complexity / Resources**: The dataset includes 178,150 bilingual question-solution pairs, with a focus on multimodal questions.

### 5. Experiments
- **Datasets & Metrics**: The dataset comprises approximately 90k unique questions covering a wide range of types, including both single-part and multi-part questions.
- **Baselines**: Bagel-Thinking-with-image, Claude-Sonnet-4, CodePlot-CoT, Existing mathematical reasoning benchmarks, G-LLaVA, GPT-4.1, Gemini-2.5-Pro, MA VIS, Math-LLaVA, Mathcoder, Mathvista, Multimodal (MathVista), N/A, Nano Banana, Qwen-2.5VL-3B-Text-Tune, Text-centric (MATH-500), Visual COT, Visual Reasoning (Our Math-VR)
- **Main Results**: The dataset shows a distribution of 29% text questions and 71% multimodal questions, with various question types and lengths.
- **Ablations**: Two sets of ablation experiments were conducted comparing code-driven reasoning to text-only and direct image generation methods.
- **Limitations / Stress Tests**: Due to the limitations of data scale and model size, our MatPlotCode has not yet achieved a 100% fidelity rate on images-to-code conversion.

### 6. Takeaways
- **Pros**: Introduces a new paradigm for multimodal mathematical reasoning., Provides the first large-scale dataset and comprehensive benchmark for visual reasoning in mathematics., Demonstrates significant improvements over existing models.
- **Cons**: Requires high precision in code generation which may be challenging., Existing models struggle with direct image generation.
- **Future Work**: Explore further improvements in code generation accuracy., Investigate additional applications of the CodePlot-CoT paradigm., Enhance the dataset with more complex mathematical problems.

</details>

### [Reinforced sequential Monte Carlo for amortised sampling](http://arxiv.org/pdf/2510.11711v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Biochemical Sequence Design

### 2. Motivation & Gaps
- The proposed importance-weighted experience replay and SMC scheme significantly improve the results, but there is still substantial room for improvement.

- **Related work challenges:**
  - Markov chain Monte Carlo (MCMC) methods: Require a large number of steps to produce low-variance estimators.
  - Amortised sampling with neural networks: May fail to converge to the target distribution due to insufficient model capacity.
  - Diffusion models: Trained to maximise a variational bound, which may not directly address sampling from complex distributions.
  - Richter et al. (2024): N/A
  - Gritsaev et al. (2025): N/A
  - Blessing et al. (2025): N/A
  - Del Moral et al., 2006: Convergence of empirical approximation to target distribution.
  - CappÃ© et al., 2004; Cornuet et al., 2012; Bugallo et al., 2017; Elvira and Chouzenoux, 2022: Refining proposal kernels based on current population of particles.
  - Wu et al., 2025: Training the sampler with off-policy samples from SMC.
  - Martino et al. (2018a): High variance in importance weights leading to instability in training.
  - El-Laham et al. (2018): Bias introduced by adaptive importance weight tempering.
  - Kong (1992): Degeneracy in effective sample size (ESS) affecting sample diversity.
  - Doucet et al., 2022: Existing methods struggle with mode collapse and inefficiencies in sampling.
  - Chen et al., 2025: Previous approaches do not effectively combine amortised sampling with Monte Carlo methods.
  - Albergo and Vanden-Eijnden, 2025: Lack of robust training methods for complex target distributions.
  - Doucet et al., 2022: N/A
  - Chen et al., 2025: N/A
  - Albergo and Vanden-Eijnden, 2025: N/A
  - N/A: N/A
  - N/A: N/A
  - Hinton, 2002: High variance issue in REINFORCE estimator.
  - Bengio et al., 2021, 2023: Double-counting problem when multiple action sequences lead to the same object.
  - Deleu et al., 2022: Need for improved sample efficiency and target approximation in off-policy training.
  - Vargas et al. (2024): Coupling to a specialised training objective.
  - Chen et al. (2025): Coupling to a specialised training objective.
  - Albergo and Vanden-Eijnden (2025): Coupling to a specialised training objective.
  - Lew et al. (2023): Sampling intractable posterior distributions under language model priors.
  - Loula et al. (2025): Sampling intractable posterior distributions under language model priors.
  - Zhang and Chen (2022): The default approach for expressing drift in diffusion samplers is limited.
  - MÃ¡tÃ© and Fleuret (2023): Geometric interpolation methods may not effectively set intermediate targets.
  - Chen et al. (2025): Existing metrics for evaluating sampling methods may not be suitable under certain conditions.
  - Chen et al. (2025): Reported the best performance observed during the training process, which may not reflect the true model performance.
  - Vargas et al. (2023): Existing methods may not effectively handle the time-reversal of diffusion processes.
  - Sendera et al. (2024): Gradient-free settings may lack powerful gradient guidance.
  - Midgley et al. (2023): Previous methods struggled with numerical errors and instability during optimization.
  - Zhang and Chen (2022): Lack of gradient information in training schemes.
  - Kim et al. (2025c): Need for more powerful MCMC algorithms to enhance performance.
  - Shen et al. (2023): Using advanced network architectures and finer discretisation steps.
  - Kim et al. (2024b): Incorporating other learning objectives such as likelihood maximisation.
  - Bengio et al. (2021): Employing more powerful MCMC algorithms.

### 3. Core Idea
- The use of importance-weighted experience replay techniques to improve mode coverage in biochemical sequence design tasks.

### 4. Method
- **Pipeline**: The method involves generating string representations of molecular graphs and DNA/RNA sequences, followed by training using specific reward functions.
- **Architecture / Loss / Training**: MLP as a backbone architecture with specific hidden dimensions and training using Adam and SGD optimizers.
- **Complexity / Resources**: Training for 3,000 to 6,000 epochs with a batch size of 100 and a buffer size of 100,000.

### 5. Experiments
- **Datasets & Metrics**: The experiments were conducted on QM9, sEH, TFbind8, and L14-RNA1 tasks, measuring metrics like ELBO, EUBO, and Pearson correlation.
- **Baselines**: Amortised methods, Buf, CMCD with KL or log-variance losses, DDS, L SubTB-Î», L-Buf, LV, MaxEnt RL algorithms, Monte Carlo methods, N/A, PIS, Previous amortised sampling methods, R-Buf, REINFORCE, SCLD, SMC with Hamiltonian Monte Carlo (SMC-HMC), SMC with random-walk Metropolis (SMC-RWM), SMC-RWM, Standard diffusion samplers, SubTB, TB, TB + Buf, TB + IW-Buf, log-variance (LV), on-policy training algorithms, replay buffers with other prioritisation strategies, Ïµ-exploration
- **Main Results**: IW-Buf improves mode coverage and yields comparable or superior results to baselines in various metrics.
- **Ablations**: Ablation studies indicated that smaller subtrajectory lengths generally yield better results.
- **Limitations / Stress Tests**: The method showed sensitivity to hyperparameters, particularly the off-policy ratio and subtrajectory length.

### 6. Takeaways
- **Pros**: Improved target distribution approximation., Enhanced training stability., Combines strengths of both amortised and Monte Carlo methods.
- **Cons**: Potential failure to converge due to insufficient model capacity., Complexity in training procedures., Dependence on the quality of historical samples.
- **Future Work**: Explore further integration of RL techniques., Investigate scalability to higher dimensions., Develop more robust training methodologies.

</details>

## Gaussian Splatting

### [BayeSN-TD: Time Delay and $H_0$ Estimation for Lensed SN H0pe](http://arxiv.org/pdf/2510.11719v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Time Delay Estimation

### 2. Motivation & Gaps
- The primary motivation for the development of this model was for analysis of glSNe Ia serendipitously discovered by JWST, such as SN H0pe and SN Encore, given the late phase coverage of these observations.

- **Related work challenges:**
  - Refsdal (1964): Measuring the Hubble constant using time delays between multiple images of a gravitationally lensed supernova.
  - Ding et al. (2021): The fading nature of supernovae makes them more difficult to discover compared to lensed quasars.
  - Kelly et al. (2023): Only a small number of gravitationally lensed supernovae have been observed, limiting the data available for analysis.
  - Pierel et al. (2024a): Limited photometric data available significantly after peak for SN H0pe.
  - Hayes et al. (2024): Need for a template-independent method for time-delay inference.
  - Huber et al. (2022): Incorporating the effect of chromatic microlensing in time-delay estimation.
  - Pierel et al. (2024a): Lack of coverage of SN Ia SED models at later phases, especially in NIR wavelengths.
  - Mandel et al. (2022): N/A
  - Thorp et al. (2021): N/A
  - Dobler & Keeton 2006: Understanding the unique light paths and their effects on time-delay measurements.
  - Goldstein et al. 2018: Incorporating microlensing effects into time-delay analysis.
  - Hayes et al. 2024: Modeling the time-varying magnification due to microlensing.
  - Grayling et al. (2024): Previous models did not adequately account for microlensing effects in time-delay estimation.
  - Guy et al. (2007): Existing SED models may not accurately represent the true properties of SNe Ia.
  - Piere et al. (2021): Simulations used for testing may not align with the empirical models applied in real observations.
  - Pierel et al. (2021): Demonstrating well-calibrated uncertainties in time-delay recovery.
  - Arendse et al. (2024): Incorporating chromatic treatment of microlensing in simulations.
  - Kromer & Sim (2009): Combining microlensing maps with SN Ia explosion models.
  - Pierel et al. (2024a): Differences in methodology for fitting observations in color space versus light curve space.
  - Pierel et al. (2024a): Insensitivity to achromatic microlensing due to fitting in colour space rather than photometry.
  - Ward et al. (2023): Utilization of a phase-extended version of the BayeSN model which may not capture the full complexity of the data.
  - N/A: The exact cause of discrepancies in time delay estimates remains uncertain.
  - Pierel et al. (2024a): The previous work adapted the BayeSN model within the SNTD framework, which may not account for residual intrinsic chromatic scatter effectively.
  - Grayling et al. (2024): The challenge lies in marginalizing over the population distribution of residual intrinsic scatter, which was excluded in previous analyses.
  - Pascale et al. (2025): Combining lens models with time delay constraints without bias corrections.
  - Agrawal et al. (2025): Exploring the consistency of lens models with magnification constraints.
  - Chen et al. (2024): Incorporating spectroscopic data to improve precision in H0 estimation.
  - Pascale et al. (2025): Overestimation of absolute magnifications of SN H0pe.
  - Chen et al. (2024): Incorporating spectroscopic analysis to improve constraints.
  - Agrawal et al. (2025): Need for precise constraints on H0 to address the Hubble tension.
  - Pierel et al. (2024a): Inconsistency in inferred time-delays between analyses.
  - Pascale et al. (2025): Combining different lens models to obtain H0 constraints.
  - Chen et al. (2024): Need for more precise photometry and lens modeling.
  - Pierel et al. (2024a): Applied a version of the model which incorporated U-band data and covered phases out to +50 days, relying on linear extrapolation for later phases.
  - Ward et al. (2023): Previous model lacked sufficient phase coverage and reliability at later phases.

### 3. Core Idea
- A new, phase-extended version of the BayeSN model that improves reliability at later phases and maintains wavelength coverage.

### 4. Method
- **Pipeline**: The new BayeSN model was trained to extend phase coverage and improve reliability without relying on extrapolation.
- **Architecture / Loss / Training**: Trained on data out to phases as late as +85 days, though training data becomes scarce at these later phases.
- **Complexity / Resources**: Increased training sample at later phases would be valuable to improve the reliability of SED models.

### 5. Experiments
- **Datasets & Metrics**: Simulations based on an alternative SED model, SALT.
- **Baselines**: Agrawal et al. (2025), BayeSN, BayeSN model, BayeSN-TD, Chen et al. (2024), Mandel et al. (2022), Pascale et al. (2025), Pierel et al. (2024a), Previous microlensing treatments, SALT, SALT SED model, SALT model, SNTD, SNTD framework, Standard BayeSN model, Thorp et al. (2021), W22x model from Ward et al. (2023), Ward et al. (2023)
- **Main Results**: The new model demonstrates much more physical behavior at later times, aligning with expected linear decline in magnitude space.
- **Ablations**: Testing the model's performance with and without the microlensing treatment.
- **Limitations / Stress Tests**: The model likely becomes increasingly less reliable at later phases due to scarce training data.

### 6. Takeaways
- **Pros**: BayeSN-TD provides robust inference of time delays and uncertainties., The model is validated against simulations with different SED models., It will be a valuable tool for future analyses of gravitationally lensed supernovae.
- **Cons**: The fading nature of supernovae makes them harder to discover., Only a limited number of glSNe have been observed., Current estimates of H0 are not precise enough to resolve the Hubble tension.
- **Future Work**: Upcoming analyses with more accurate photometry will strengthen constraints on H0., Further development of the BayeSN-TD model may improve its applicability., Exploration of additional gravitationally lensed supernovae could provide more data.

</details>

### [Simultaneous Frequentist Calibration of Confidence Regions for Multiple Functionals in Constrained Inverse Problems](http://arxiv.org/pdf/2510.11708v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Develop a framework for confidence regions in linear inverse problems with constraints

### 2. Motivation & Gaps
- This work has been motivated by inverse problems in the physical sciences, with potential applications in the general statistical literature on constrained and shape-restricted methods.

- **Related work challenges:**
  - Simultaneous Strict Bounds (SSB) method: This method often yields overly conservative regions that are larger than necessary due to its requirement to be valid for any possible functional.
  - Burrus conjecture: Proposed a less conservative calibration for single-functional intervals under non-negativity constraints, which remained unresolved for a long time.
  - Burrus conjecture: Proposed a less conservative calibration for single-functional intervals, which remained unresolved for decades.
  - Constrained inference literature: Heavily relies on specific hypothesis test frameworks that may not apply to the methods discussed in this work.
  - Universal inference: Relying on data splitting, which is often prohibited in scientific scenarios motivating this work.
  - N/A: N/A
  - N/A: N/A
  - Burrus conjecture: Claimed confidence level not reduced with extra constraints, later disproven.
  - Rust and Oâ€™Leary (1986): Proposed practical algorithm based on the dualization of optimization problems.
  - Tenorio et al. (2007): Provided counterexample to the conjecture, later disproven.
  - [2]: Prior works had limited coverage guarantees only for preconstructed confidence sets.
  - [28]: Computing the necessary quantities for uniform calibration can be computationally challenging.
  - Burrus unconstrained (1964): No optimal coverage
  - Burrus constrained (1964): No optimal coverage
  - Rust and Burrus (1972): Optimal coverage not guaranteed
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Previous TFM reduction methods: Limited to single-functional cases and do not adequately handle multiple functionals or box constraints.
  - N/A: N/A
  - Simultaneous Strict Bounds (SSB) method: Constructing confidence regions that are both accurate and computationally efficient.
  - Bonferroni-corrected product of intervals: Achieving joint coverage while maintaining computational feasibility.
  - Previous studies on likelihood ratio test statistics: Difficulty in solving chance-constrained problems (CCP) and ensuring valid quantiles.
  - Research on convex approximations of CCP: Finding test statistics that yield easily solvable CCPs.
  - Exploration of finite-sample confidence envelopes: Limited understanding of maximizing quantile functions and their calibration.
  - [7] explores finite-sample confidence envelopes for densities that are known to be monotonic or have kmodes relative to a positive weight function.: The confidence envelopes rely on simultaneous confidence sets of the distribution, which may be conservative.
  - [26] approaches Type A and B problems in constrained inference literature.: These approaches may not address scenarios outside of Type A and B problems.

### 3. Core Idea
- The approach could reduce the conservatism inherent in confidence bands constructed in a strict bounds approach.

### 4. Method
- **Pipeline**: The framework includes practical high-dimensional methods such as refined TFM reductions and multi-functional generalizations.
- **Architecture / Loss / Training**: The analysis establishes convexity and recession-monotonicity for specific statistics, improving classical bounds.
- **Complexity / Resources**: The methods developed are computationally intensive but provide optimal global thresholds for nonnegative problems.

### 5. Experiments
- **Datasets & Metrics**: Empirical coverage and area distributions were evaluated using simulations with N=10^5 samples.
- **Baselines**: Bonferroni x, Bonferroni-corrected intervals, Classical SSB methods, Existing optimization-based methods with known coverage guarantees, N/A, QuantileZero mu, QuantileZero x, SSB mu, SSB x, Simultaneous Strict Bounds (SSB), Simultaneous Strict Bounds (SSB) method, Single-functional TFM reduction methods, Standard statistical methods for confidence interval estimation, Î»1, Î»2_c, Î»2_u
- **Main Results**: The proposed methods showed improved coverage probabilities and area distributions compared to traditional methods.
- **Ablations**: Further analysis is needed to explore the impact of different configurations of test statistics.
- **Limitations / Stress Tests**: The study acknowledges the challenges in verifying the validity of quantiles and the complexity of CCPs.

### 6. Takeaways
- **Pros**: Improved calibration constants leading to smaller confidence regions., Ability to capture functional dependence structure in confidence regions., Generalization beyond Gaussian error distributions.
- **Cons**: The method may not achieve global optimality among all conceivable methods., Complexity in implementation due to the need for convex optimization., Potential challenges in extending the method to more complex constraints.
- **Future Work**: Exploration of additional types of constraints beyond those discussed., Investigation of the method's performance in high-dimensional settings., Development of more efficient algorithms for practical applications.

</details>

## avatar

### [InfiniHuman: Infinite 3D Human Creation with Precise Control](http://arxiv.org/pdf/2510.11650v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D human generation and reconstruction

### 2. Motivation & Gaps
- The paper addresses the need for generating high-quality 3D human models using multi-modal inputs, including text, SMPL normal maps, and clothing images.

- **Related work challenges:**
  - Score Distillation Sampling (SDS): Long optimization times, limited visual fidelity, and lack of precise control over attributes.
  - Liao et al. 2025: Limited controllability in generating avatars from images.
  - Cao et al. 2023: Inability to condition on detailed clothing items.
  - Zhuang et al. 2025: View inconsistencies and lack of true 3D geometry in generated images.
  - FLUX: Produces images with dramatic perspective and complex lighting, which are suboptimal for 3D reconstruction tasks.
  - OminiControl: Requires paired image-scan training data for clothing extraction.
  - NLF: Aligning SMPL parameters accurately with both overall pose and pixel-level features.
  - MVDream: Low-resolution constraints leading to blurry detailed features.
  - Gen-Schnell: Fast generation but lacks high fidelity in details.
  - Gen-HRes: Requires longer processing time for high-resolution outputs.
  - MVDream: Limited generation speed and quality compared to optimization-based methods.
  - SPAD: Requires significant time for generation despite achieving higher quality.
  - DreamAvatar: Optimization-based methods suffer from unnatural saturation and alignment issues.
  - Gen-Schnell: Cannot generate faithful details such as face due to low resolution.
  - Existing avatar generation methods: Limited in visual quality and speed compared to the proposed method.
  - Multi-view mesh carving: Can cause texture artifacts in self-occluded parts of the avatar.
  - HumanNorm, CVPR2024: wrong color, unnatural limb, wrong geometry
  - HumanGaussian, CVPR2024: wrong color, degenerating geometry
  - AvatarVerse, AAAI2024: wrong color, unnatural saturation
  - InfiniHuman-GenHRes: Janus Problem, incorrect color, geometry artifacts
  - DreamAvatar, CVPR2024: failed to generate avatar
  - FLUX: Complex lighting degrading multi-view generation
  - OpenPose: Real-time multi-person 2D pose estimation limitations
  - AvatarCLIP: Zero-shot text-driven generation limitations
  - HumanRF: High-Fidelity Neural Radiance Fields for Humans in Motion: Achieving high fidelity in dynamic human representations.
  - 3D Gaussian Splatting for Real-Time Radiance Field Rendering: Real-time rendering of complex 3D scenes.
  - CLIP-Actor: Text-Driven Recommendation and Stylization for Animating Human Meshes: Integrating text-driven methods with 3D human animation.
  - DreamFusion and its variants: SDS-based methods often suffer from slow convergence and visual artifacts such as over-smoothed textures or structural inaccuracies.
  - Chupa: Fails to generalize to complex text prompts and does not support specific clothing images as conditioning input.
  - IDOL dataset: Generated results often exhibit noticeable view inconsistencies and temporal artifacts.
  - IDOL [Zhuang et al. 2025]: Generated results often exhibit noticeable view inconsistencies and temporal artifacts due to the neighbor-only attention mechanism.
  - IDOL Dataset: Achieving better visual realism and multi-view consistency.
  - MVDream: Handling wrong geometry in 3D rendering.
  - MVDream: Originally designed to condition only on text, lacking support for additional modalities like clothing images.
  - PSHuman: Generates single blurry head-view images instead of high-resolution multi-view images.
  - OminiControl2: Difficulty in fusing spatially aligned and non-aligned conditions for image generation.
  - PSHuman: Limited to low-resolution single head view generation.
  - Human-3Diffusion: Inconsistency between orthographic and perspective image generation.

### 3. Core Idea
- The proposed method enhances 3D human generation by fine-tuning a multi-view diffusion model to incorporate additional modalities, improving realism and detail in generated images.

### 4. Method
- **Pipeline**: The pipeline involves fine-tuning a multi-view diffusion model on a dataset of human scans and using a Splat Decoder for 3D Gaussian Splat representations.
- **Architecture / Loss / Training**: The model employs spectral normalization and a combination of perceptual loss (LPIPS) and â„“2 reconstruction loss during training.
- **Complexity / Resources**: The model is trained on 8 NVIDIA A100 GPUs with a batch size of 256 and an initial learning rate of 5 Ã— 10âˆ’4.

### 5. Experiments
- **Datasets & Metrics**: The model is trained on InfiniHumanData and evaluated through user studies for realism assessment.
- **Baselines**: 3D Gaussian Splatting, AvatarCLIP, AvatarVerse, AvatarVerse, AAAI2024, CLIP-Actor, Cao et al. 2023, Chupa, DreamAvatar, Existing state-of-the-art methods, FLUX, Feed-forward approaches, Gen-HRes, Gen-Schnell, Human-3Diffusion, HumanGaussian, HumanGaussian, CVPR2024, HumanNorm, HumanNorm, CVPR2024, HumanRF, IDOL, InfiniHuman-GenHRes, Liao et al. 2025, MVDream, NLF, OminiControl, OminiControl2, OpenPose, PSHuman, SDS-based methods, SPAD, TADA, TADA, 3DV2024, Zhuang et al. 2025
- **Main Results**: The fine-tuned model demonstrates superior realism in generated images, receiving more votes than scan subjects in user studies.
- **Ablations**: Conducted ablation studies to assess the impact of different components in the model.
- **Limitations / Stress Tests**: The model's performance may vary based on the quality of input modalities and the alignment of generated images.

### 6. Takeaways
- **Pros**: Democratizes high-quality avatar generation with fine-grained control., Theoretically unlimited scalability., Affordable solution for generating diverse 3D human avatars.
- **Cons**: Requires significant computational resources., Dependence on quality of training data., Potential inaccuracies in generated outputs.
- **Future Work**: Publicly release the automatic data generation pipeline., Release the comprehensive dataset InfiniHumanData., Release the generative models InfiniHumanGen.

</details>

### [Building and Evaluating a Realistic Virtual World for Large Scale Urban Exploration from 360Â° Videos](http://arxiv.org/pdf/2510.11447v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Evaluation of Virtual Exploration Systems

### 2. Motivation & Gaps
- The study evaluates the effectiveness of different virtual exploration systems, specifically comparing 360RVW, MovieMap, and GSV.

- **Related work challenges:**
  - Deep learning techniques for automatic 3D model generation: Heavily rely on the accuracy of training datasets and face significant challenges in terms of generalization and computational efficiency.
  - Google Street View and MovieMap: Limits interactivity and makes it difficult to create social experiences as users can only passively watch videos or images.
  - GSV and MovieMap: Limited user interaction and exploration capabilities.
  - Geollery: Reduction of realism due to texture changes based on user position.
  - Avatar360: Limited to movements between images rather than smooth transitions through videos.
  - Model-based virtual worlds: Lack of photorealism in visualization.
  - Image- or video-based virtual environments: Limited interaction capabilities.
  - GSV: Limited interaction and navigation capabilities.
  - MovieMap: Lacks avatar-based navigation.
  - Existing 360Â° video systems: Inadequate user experience and immersion.
  - Previous studies on spatial cognition in virtual worlds: Understanding how different interfaces impact memory and navigation.
  - GSV: Users had difficulty navigating due to the need to search for locations of placed 360Â° images.
  - MovieMap: Participants criticized the cumbersome adjustment of video playback speed, which required stopping movement to look around.
  - 360RVW: Operating an avatar with a gamepad was seen as laborious and detracted from the experience.
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The proposed system creates realistic virtual worlds from 360Â° videos, allowing users to explore urban areas with a sense of presence and movement.

### 4. Method
- **Pipeline**: The system builds virtual worlds directly from 360Â° videos without requiring 3D modeling.
- **Architecture / Loss / Training**: Involves deep video completion models optimized for perspective projection, adapted for ERP format frames of 360Â° videos.
- **Complexity / Resources**: The system is scalable and applicable to any area as long as videos are captured.

### 5. Experiments
- **Datasets & Metrics**: User evaluations were conducted to assess the sense of exploration and overall experiences with the systems.
- **Baselines**: 360RVW, Avatar360, GSV, Google Street View, MovieMap, N/A
- **Main Results**: 360RVW and MovieMap significantly outperform GSV across all evaluated criteria.
- **Ablations**: Evaluation of virtual collision detection and video completion techniques comparing with and without rotation.
- **Limitations / Stress Tests**: The study did not assess the system's performance in a multi-user setting and relied on a small number of qualitative feedback.

### 6. Takeaways
- **Pros**: Allows for interactive exploration of large urban environments., Reduces the need for manual creation of complex 3D models., Provides a highly immersive experience using 360Â° videos.
- **Cons**: Still relies on the quality of the 360Â° videos., Potential limitations in areas without sufficient video coverage.
- **Future Work**: Explore further improvements in video completion techniques., Investigate the integration of more interactive elements., Expand the system to cover more diverse urban environments.

</details>

### [ImHead: A Large-scale Implicit Morphable Model for Localized Head Modeling](http://arxiv.org/pdf/2510.10793v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Localized shape editing

### 2. Motivation & Gaps
- The paper addresses the need for effective localized shape editing in 3D models.

- **Related work challenges:**
  - NPHM: Models 3D faces using a global entangled latent space which prohibits localized editing and disentangled manipulations.
  - 3DMMs: Fail to capture complex local variations of the human face, resulting in overly-smooth surfaces.
  - Deep Implicit Functions: Current implicit 3DMMs rely on datasets with small identity variations, limiting their ability to capture real-world distributions.
  - DeepSDF: Limited ability to represent diverse geometries due to small training datasets.
  - SPAGHETTI: Entangled latent space prohibits localized face editing.
  - i3DMM: Trained on low-resolution scans, limiting identity variation.
  - NPHM: Limited expressivity and editing capabilities.
  - monoNPHM: Inability to capture high-frequency details.
  - BFM: Lack of flexibility in editing facial expressions.
  - NPM: Performance drop on in-the-wild data.
  - NPHM: Limited expressivity and performance issues with diverse expressions.
  - imFace: Modeling only the frontal face part limits expressivity.
  - NPHM: Exhibits racial biases and struggles with high-frequency details.
  - Traditional 3D Morphable Models (3DMM): Limited in capturing localized edits without affecting global identity.
  - 3DMMs: Slow inference times and inability to capture fine-grained details.
  - NPHM: Demographic biases and limited diversity in datasets.
  - NPM: Requires a registration step to non-rigidly align the scans.
  - NPHM: Heavily relies on iterative root finding schemes, which can affect robustness.
  - FLAME model: N/A
  - N/A: N/A
  - Wilor: End-to-end 3d hand localization and reconstruction in-the-wild: Challenges in real-world hand localization and reconstruction.
  - High-fidelity facial albedo estimation via texture quantization: Difficulty in achieving high-fidelity texture representation.
  - Generating 3d faces using convolutional mesh autoencoders: Limitations in generating realistic 3D facial structures.

### 3. Core Idea
- The core idea is to utilize a diffusion model for editing localized shapes in 3D space effectively.

### 4. Method
- **Pipeline**: The method involves a diffusion process that refines shape edits iteratively.
- **Architecture / Loss / Training**: The architecture employs a loss function that balances fidelity and editability during training.
- **Complexity / Resources**: The method requires moderate computational resources for training and inference.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize various 3D shape datasets and metrics for evaluation.
- **Baselines**: BFM, DeepSDF, Existing shape editing methods, FLAME, LSFM, Local Lat. (d=1248), Local Lat. (d=312), Local and Global Lat. (d=1344), N/A, NPHM, NPM, PCA, Previous 3DMMs, SPAGHETTI, Traditional 3D modeling techniques, Traditional 3DMMs, i3DMM, imFace, monoNPHM, w/o FusionNet, w/o Local Canonical Space
- **Main Results**: The results demonstrate significant improvements in localized shape editing accuracy and efficiency.
- **Ablations**: Ablation studies indicate the importance of specific components in the diffusion model.
- **Limitations / Stress Tests**: Limitations include challenges in handling highly complex shapes and real-time performance.

### 6. Takeaways
- **Pros**: Generates realistic 3D heads with significant detail compared to traditional 3DMMs., Facilitates localized editing without additional constraints., Captures large shape variations effectively.
- **Cons**: Still relies on a large dataset which may not be readily available for all applications., Potential limitations in capturing extremely fine details compared to other advanced models.
- **Future Work**: Explore further enhancements in localized editing capabilities., Investigate the application of imHead in various domains such as gaming and virtual reality., Expand the dataset to include more diverse identities and expressions.

</details>

## video understanding

### [Point Prompting: Counterfactual Tracking with Video Diffusion Models](http://arxiv.org/pdf/2510.11715v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Point Propagation in Video Generation

### 2. Motivation & Gaps
- The paper addresses challenges in point propagation during video generation, particularly focusing on issues like ambiguity near edges, stationary points, symmetry confusion, and propagation failures.

- **Related work challenges:**
  - Chefer et al., 2025: Using trackers to supervise or control video generators.
  - Burgert et al., 2025: Evaluating temporal consistency of generated videos.
  - Bear et al., 2023: Counterfactual modeling in self-supervised motion estimation.
  - DINOv2 (Oquab et al., 2023): Adaptation for semantic and temporal correspondence
  - DIFT (Tang et al., 2023): Feature extraction suitable for matching
  - SD-DINO (Zhang et al., 2023a): Combining features to solve semantic and geometric tasks
  - Nam et al. (2025): Complex analysis for feature extraction and occlusion handling
  - Visual Jenga (Bhattad et al., 2025): Revealing geometric relationships among scene elements
  - Counterfactual world modeling (Bear et al., 2023; Venkatesh et al., 2023): Keypoint prediction and optical flow estimation
  - Stojanov et al. (2025): Learning RGB perturbations for point tracking
  - N/A: N/A
  - Bear et al., 2023; Stojanov et al., 2025: Previous methods enhance counterfactual signals by directly subtracting generated images, which can lead to artifacts and tracking errors.
  - RAFT (Teed & Deng, 2020): Supervised methods require extensive labeled data.
  - TAP-Net (Doersch et al., 2022): Existing methods struggle with occlusion and require training.
  - Opt-CWM (Stojanov et al., 2025): Self-supervised methods may not generalize well to unseen scenarios.
  - Direct motion models for assessing generated videos: N/A
  - Click to move: Controlling video generation with sparse motion: N/A
  - Exploring visual prompts for adapting large-scale models: N/A
  - Controllable video generation with sparse trajectories: Limited control over video generation processes.
  - Particle video revisited: Tracking through occlusions using point trajectories: Challenges in tracking accuracy during occlusions.
  - Self-supervised autoflow: Dependence on self-supervised methods for flow estimation.
  - Learning transferable visual models from natural language supervision: Transfer learning limitations
  - Exploring the limits of transfer learning with a unified text-to-text transformer: Unified model challenges
  - High-resolution image synthesis with latent diffusion models: Image quality and resolution issues
  - N/A: N/A
  - RAFT (Teed & Deng, 2020): Lower performance in tracking accuracy.
  - TAP-Net (Doersch et al., 2022): Inconsistent results due to synthetic dataset characteristics.
  - DINOv2+NN (Oquab et al., 2023): Zero-shot performance limitations.
  - N/A: N/A

### 3. Core Idea
- The proposed method enhances point propagation accuracy in video generation by addressing specific failure cases and optimizing tracking through various ablation studies.

### 4. Method
- **Pipeline**: The method involves preprocessing videos, detecting red pixels, and applying a tracking algorithm with enhancements like local search windows and position refinement.
- **Architecture / Loss / Training**: The architecture is trained using a loss function that emphasizes consistency across frames.
- **Complexity / Resources**: The method requires significant computational resources for video processing and model training.

### 5. Experiments
- **Datasets & Metrics**: Experiments were conducted on TAP-Vid Kubric and TAP-Vid DA VIS datasets, using metrics like AJ, Î´x avg, and OA.
- **Baselines**: CoTracker3, CogVideoX, DIFT, DINOv2+NN, Exploring the limits of transfer learning with a unified text-to-text transformer, GMRW, High-resolution image synthesis with latent diffusion models, Learning transferable visual models from natural language supervision, N/A, Opt-CWM, Previous zero-shot tracking methods, RAFT, Recent generative models, SD-DINO, Self-supervised models, TAP-Net, TAPIR, TAPNext, Traditional video editing techniques, Wan2.1, Wan2.2, Zero-shot approaches
- **Main Results**: The proposed method outperforms zero-shot baselines but shows lower performance on Kubric due to the synthetic nature of the dataset.
- **Ablations**: Key components of the tracking pipeline were ablated, showing improvements with local search windows and position refinement.
- **Limitations / Stress Tests**: The method's performance is affected by the synthetic nature of the dataset and the choice of marker color.

### 6. Takeaways
- **Pros**: Utilizes off-the-shelf video diffusion models for tracking., Achieves competitive performance without additional training., Demonstrates effective tracking through occlusions.
- **Cons**: Markers may be unnatural in some environments., Dependence on the quality of the initial frame.
- **Future Work**: Explore further applications of counterfactual modeling., Investigate improvements in marker visibility., Develop methods for real-time tracking.

</details>

### [Comparing Symmetrized Determinant Neural Quantum States for the Hubbard Model](http://arxiv.org/pdf/2510.11710v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Quantum state optimization using symmetrized variational inference

### 2. Motivation & Gaps
- The paper investigates the use of symmetrization procedures in variational inference for quantum many-body systems, focusing on the performance of different architectures.

- **Related work challenges:**
  - Neural Quantum States (NQS): A fair comparison among different architectures does not exist.
  - Variational Monte Carlo framework: Reaching a consensus on the phase diagram of the Hubbard model remains a considerable challenge.
  - N/A: N/A
  - Previous studies on variational methods in quantum systems: Limited exploration of symmetrization effects on variational energies.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- Investigating the influence of different patching strategies on model performance in quantum systems.

### 4. Method
- **Pipeline**: Conducted experiments comparing 2Ã—2 and 1Ã—1 patching schemes.
- **Architecture / Loss / Training**: Utilizes kernel reformulation of stochastic reconfiguration with a cosine decay scheduler for learning rate adjustment.
- **Complexity / Resources**: Simulations were performed with NetKet and parallelized with mpi4JAX.

### 5. Experiments
- **Datasets & Metrics**: 8Ã—8 torus lattice with U/t= 8 and n h = 1/8.
- **Baselines**: 1Ã—1 patching, 2Ã—2 patching, HFDS, Hidden Fermion Determinant State, Jastrow-Backflow ansatz, N/A, Symm ViT, Symm ViT-Ti, Unsymmetrized ViT, ViT, ViT-Ti
- **Main Results**: 2Ã—2 patches with concatenated spin channels provide the best trade-off between energy and GPU time.
- **Ablations**: Investigated the impact of varying the number of parameters and Monte Carlo samples on the performance of the wavefunctions.
- **Limitations / Stress Tests**: Results may be impacted by significant finite-size effects.

### 6. Takeaways
- **Pros**: Neural Quantum States achieve high accuracy for ground state properties., Ability to simulate lattices with periodic boundaries., Promising method for studying strongly correlated fermions.
- **Cons**: Costly for larger system sizes due to output averaging., Lack of fair comparison among different architectures., Challenges in reaching consensus on the phase diagram.
- **Future Work**: Further systematic studies on the strengths and weaknesses of different NQS architectures., Exploration of optimization strategies for better performance., Application of findings to other fermionic systems.

</details>

### [Beyond 'Templates': Category-Agnostic Object Pose, Size, and Shape Estimation from a Single View](http://arxiv.org/pdf/2510.11687v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 6D object pose estimation, size, and shape from RGB-D input

### 2. Motivation & Gaps
- The proposed model aims to jointly estimate 6D object pose, size, and shape from a single RGB-D input, addressing the challenges in existing methods.

- **Related work challenges:**
  - LabbÃ© et al. (2022): Reliance on reference images, templates, or object-specific CAD models which are rarely available in open-set environments.
  - Wang et al. (2019b): Poseâ€“shape entanglement due to large intra-class variations and partial observations.
  - Nguyen et al. (2022): Dependence on multi-stage pipelines which restrict efficiency and real-time deployment.
  - NOCS Wang et al. (2019b): Introduced canonical space but limited to seen categories.
  - GenPose Zhang et al. (2023): Requires iterative sampling and auxiliary scoring networks.
  - FoundationPose Wen et al. (2024): Requires additional inputs at inference time.
  - Zhou et al. (2019): Improving training stability and prediction accuracy for rotation estimation.
  - Yu et al. (2021): Supervising point cloud reconstruction using Chamfer Distance.
  - Zhang et al. (2025b): Handling object symmetries in pose estimation.
  - GenPose++: Stronger performance on some VUS thresholds but limited in generalization to novel instances.
  - Any6D: Sensitivity to reconstruction quality affecting pose predictions.
  - FoundationPose: Requires reference images or CAD models, limiting its applicability.
  - Learning 6-dof object poses to grasp category-level objects by language instructions: Dependency on category-level information.
  - Structure-guided prior adaptation for category-level 6d object pose estimation: Limited generalization to unseen object categories.
  - Fast shape-based network for category-level 6d object pose estimation: Inefficiency in real-time applications.
  - Cap-net: A unified network for 6d pose and size estimation of categorical articulated parts from a single rgb-d image: N/A
  - Center-snap: Single-shot multi-object 3d shape reconstruction and categorical 6d pose and size estimation: N/A
  - Shapo: Implicit representations for multi-object shape, appearance, and pose optimization: N/A
  - Foldingnet: Point cloud auto-encoder via deep grid deformation: Limited capability in handling complex object shapes.
  - Pointr: Diverse point cloud completion with geometry-aware transformers: Inadequate performance in diverse point cloud scenarios.
  - Adapointr: Diverse point cloud completion with adaptive geometry-aware transformers: Challenges in adapting to various object categories.
  - GenPose++: N/A

### 3. Core Idea
- The model utilizes a DGCNN-based encoder and a geometry-aware transformer to effectively process RGB-D data for accurate 6D pose estimation.

### 4. Method
- **Pipeline**: The pipeline includes feature extraction from RGB input, point cloud processing, and pose estimation through a transformer architecture.
- **Architecture / Loss / Training**: The model is trained using AdamW optimizer with a learning rate scheduler and BatchNorm momentum adjustments.
- **Complexity / Resources**: Leveraging GPU acceleration in SAPIEN, we render 1M images in 13 hours using 8Ã— RTX 2080 Ti GPUs.

### 5. Experiments
- **Datasets & Metrics**: The dataset used is ObjaversePose, a synthetic RGB-D dataset derived from high-quality CAD models.
- **Baselines**: Adapointr, Any6D, Category-level methods, Depth Only, Foldingnet, FoundationPose, GenPose, GenPose++, N/A, NOCS, Pointr, Reference-based novel object pose estimators, w/o MoE, w/o Shape Completion
- **Main Results**: Performance remains relatively stable across most configurations with varying the number of activated experts.
- **Ablations**: We summarize three sets of experiments: (1) number of activated experts, (2) choice of pre-trained visual backbones, and (3) contributions of the shape reconstruction branch, coarse-to-fine strategy, and selection step.
- **Limitations / Stress Tests**: The model's performance may degrade with non-watertight geometries or poorly textured objects.

### 6. Takeaways
- **Pros**: Unified framework for 6D pose, size, and shape estimation., Real-time inference capability at 28 FPS., Strong zero-shot generalization to unseen categories.
- **Cons**: Dependence on synthetic data for training., Potential limitations in real-world scenarios not covered by training data.
- **Future Work**: Exploration of real-world training datasets., Improvement of generalization techniques., Integration with other perception tasks in robotics.

</details>
