# Daily Paper Digest Â· 2025-10-26
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [CLiVR: Conversational Learning System in Virtual Reality with AI-Powered Patients](http://arxiv.org/pdf/2510.19031v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Medical training simulation using VR and AI

### 2. Motivation & Gaps
- CLiVR is recognized as a supplemental tool for medical training, providing a safe and adaptive environment that complements human interactions.

### 3. Core Idea
- CLiVR integrates symptom-constrained LLM prompting with real-time empathy feedback through sentiment analysis to enhance medical communication training.

### 4. Method
- **Pipeline**: Utilizes RAG, real-time lip-syncing, and sentiment analysis for speech-based clinical training.
- **Architecture / Loss / Training**: Developed in Unity and deployed on the Meta Quest 3 platform.
- **Complexity / Resources**: Supports deployment in both resource-rich and resource-limited institutions.

</details>

### [Foveated Compression for Immersive Telepresence Visualization](http://arxiv.org/pdf/2510.19848v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Compression

### 2. Motivation & Gaps
- The paper addresses the challenge of reducing bandwidth in VR video streams while maintaining immersion and quality.

### 3. Core Idea
- A lightweight method for foveated compression integrated with the HEVC video codec to reduce bandwidth without noticeable artifacts.

### 4. Method
- **Pipeline**: Integration of foveated compression with HEVC codec.
- **Architecture / Loss / Training**: The architecture includes a lightweight hourglass network for eye tracking and a spherical rendering approach to compensate for head movement latency.
- **Complexity / Resources**: Utilizes NVENC for encoding and requires careful parameter tuning for optimal performance.

</details>

### [From Volume Rendering to 3D Gaussian Splatting: Theory and Applications](http://arxiv.org/pdf/2510.18101v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Survey of 3D Gaussian Splatting methods

### 2. Motivation & Gaps
- This survey reviews various methods for avatar generation and 3D reconstruction using Gaussian splatting techniques, highlighting the evolution and challenges in the field.

### 3. Core Idea
- Gaussian Splatting introduces a novel approach to 3D reconstruction, enabling the creation of high-quality representations from various input types.

### 4. Method
- **Pipeline**: The pipeline involves processing inputs through various models including FFNs, MLPs, and transformers to generate 3D Gaussian representations.
- **Architecture / Loss / Training**: Different architectures such as U-Net and transformers are employed, with a focus on optimizing loss functions for better reconstruction quality.
- **Complexity / Resources**: The methods vary in complexity, with some requiring significant computational resources for training and inference.

</details>

## video understanding

### [HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives](http://arxiv.org/pdf/2510.20822v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation

### 2. Motivation & Gaps
- The paper addresses the challenge of generating coherent long video narratives that maintain aesthetic quality and semantic consistency across multiple shots.

### 3. Core Idea
- The proposed method integrates multiple evaluation metrics to holistically assess and improve the generation of cinematic video narratives.

### 4. Method
- **Pipeline**: The method involves a multi-agent framework that generates video sequences based on textual prompts while ensuring aesthetic and semantic coherence.
- **Architecture / Loss / Training**: The architecture employs a combination of loss functions that focus on aesthetic quality, semantic consistency, and shot control.
- **Complexity / Resources**: The model requires significant computational resources for training, including high-performance GPUs and large datasets.

</details>

### [Generative Reasoning Recommendation via LLMs](http://arxiv.org/pdf/2510.20815v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Recommendation of next likely purchase based on user history

### 2. Motivation & Gaps
- The user has a consistent pattern of purchasing compact, affordable home fitness equipment suited for small spaces.

### 3. Core Idea
- To recommend the next likely purchase for the user based on their previous buying patterns and preferences.

### 4. Method
- **Pipeline**: Extraction of behavioral evidence, modeling of latent preferences, inference of user intent.
- **Architecture / Loss / Training**: The architecture employs a generative approach with a focus on maximizing mutual information.
- **Complexity / Resources**: The model's performance is bounded by computational resources, indicating potential for improvement with larger compute budgets.

</details>

### [Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation](http://arxiv.org/pdf/2510.20812v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Analyze the proportion of women researchers in Computer Sciences from 2011-15 across various countries.

### 2. Motivation & Gaps
- The analysis aims to highlight gender disparities in research representation within the field of Computer Sciences.

### 3. Core Idea
- To identify the countries with the highest percentages of women researchers in Computer Sciences during the years 2011-15.

### 4. Method
- **Pipeline**: Data collection from various countries regarding the percentage of women researchers.
- **Architecture / Loss / Training**: The architecture is designed to optimize reasoning paths while minimizing inference costs.
- **Complexity / Resources**: The method balances model complexity with resource efficiency, allowing for effective reasoning even with smaller models.

</details>

## model collapse

### [Efficient analytic approximation for small-scale non-cold relic perturbations](http://arxiv.org/pdf/2510.20821v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Evaluate the performance and accuracy of the small-scale approximation for non-cold dark matter perturbations in CLASSIER.

### 2. Motivation & Gaps
- The study aims to improve the computational efficiency of evaluating NCDM perturbations while maintaining accuracy in cosmological simulations.

### 3. Core Idea
- Implement a small-scale approximation to reduce the runtime of NCDM perturbation evaluations in CLASSIER while preserving accuracy.

### 4. Method
- **Pipeline**: The method involves using quasi-steady-state solutions to the collisionless Boltzmann equation to replace costly late-time convolutions with compact analytic expressions.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The small-scale approximation reduces the total runtime by roughly a factor of two across a broad range of k_max.

</details>

### [LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas](http://arxiv.org/pdf/2510.20820v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Interactive personalization in text-to-image generation

### 2. Motivation & Gaps
- The layered canvas is primarily designed for interactive personalization, enabling users to create images with multiple subjects while maintaining spatial coherence.

### 3. Core Idea
- Our method consistently excels at preserving subject identities, rendering realistic interactions, and maintaining coherence across a wide variety of challenging scenarios.

### 4. Method
- **Pipeline**: An automated canvas creation pipeline is developed to evaluate the model without human intervention, using face detection and segmentation to create personalized images.
- **Architecture / Loss / Training**: Utilizes a diffusion model as the backbone, specifically FLUX Kontext, with a focus on improving robustness through better data quality and model access.
- **Complexity / Resources**: The method requires significant computational resources for image generation and processing, particularly when handling multiple subjects.

</details>
