# Daily Paper Digest Â· 2025-10-21
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [ImaGGen: Zero-Shot Generation of Co-Speech Semantic Gestures Grounded in Language and Image Input](http://arxiv.org/pdf/2510.17617v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Co-Speech Gesture Generation

### 2. Motivation & Gaps
- The paper addresses the challenge of generating co-speech gestures that are semantically aligned with spoken language and visual inputs.

### 3. Core Idea
- The proposed method leverages a zero-shot learning approach to generate gestures based on language and image inputs, enhancing the expressiveness of virtual agents.

### 4. Method
- **Pipeline**: The method involves processing language and image inputs to generate corresponding gestures using a neural network architecture.
- **Architecture / Loss / Training**: Utilizes a combination of loss functions to ensure the generated gestures are semantically and temporally aligned with the input data.
- **Complexity / Resources**: The model is designed to be computationally efficient, allowing for real-time applications in interactive systems.

</details>

### [Capturing Head Avatar with Hand Contacts from a Monocular Video](http://arxiv.org/pdf/2510.17181v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Reconstructing realistic head avatars with hand contact from monocular videos

### 2. Motivation & Gaps
- The method aims to improve the accuracy of hand and facial reconstruction from monocular video input, addressing limitations in existing methods.

### 3. Core Idea
- The proposed method utilizes contact loss and depth order loss to align hand and face meshes, followed by a non-rigid deformation network for realistic avatar reconstruction.

### 4. Method
- **Pipeline**: Preprocessing with contact-aware alignment and depth-aware collision prevention, followed by reconstruction using PCA-based deformation.
- **Architecture / Loss / Training**: Incorporates contact loss and depth order loss during preprocessing and training.
- **Complexity / Resources**: The method requires high-resolution rendered video sequences, segmentation masks, depth maps, and ground-truth mesh tracking.

</details>

### [HGC-Avatar: Hierarchical Gaussian Compression for Streamable Dynamic 3D Avatars](http://arxiv.org/pdf/2510.16463v1)
  (summary failed: 'utf-8' codec can't encode characters in position 2934-2935: surrogates not allowed)


## video understanding

### [ConsistEdit: Highly Consistent and Precise Training-free Visual Editing](http://arxiv.org/pdf/2510.17803v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Visual Editing

### 2. Motivation & Gaps
- The paper addresses the need for consistent and precise visual editing in generative models, particularly in scenarios where users desire a binary behavior in output consistency.

### 3. Core Idea
- The method introduces a simple adjustment in the editing process to enhance consistency and precision in visual editing tasks.

### 4. Method
- **Pipeline**: The method modifies the editing region by transferring vision parts of Q and K tokens along with V tokens.
- **Architecture / Loss / Training**: The architecture is trained using a combination of reconstruction loss and consistency loss to ensure high-quality outputs.
- **Complexity / Resources**: The method is designed to be efficient, requiring minimal computational resources.

</details>

### [Robobench: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models as Embodied Brain](http://arxiv.org/pdf/2510.17801v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Action Extraction and Scene Labeling

### 2. Motivation & Gaps
- The task involves extracting actions from video frames and generating scene labels based on visual inputs.

### 3. Core Idea
- To develop a structured approach for extracting actions and scene labels from visual data using predefined tags and functions.

### 4. Method
- **Pipeline**: Extract actions and scene labels from video frames using a structured prompt-based approach.
- **Architecture / Loss / Training**: Utilizes a combination of supervised and reinforcement learning techniques to optimize model performance.
- **Complexity / Resources**: The benchmark utilizes various datasets and requires significant computational resources for training and evaluation.

</details>

### [Glyph: Scaling Context Windows via Visual-Text Compression](http://arxiv.org/pdf/2510.17800v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Long-context understanding and modeling

### 2. Motivation & Gaps
- The paper presents Glyph, a framework that enhances long-context modeling by rendering long texts into compact images and processing them with vision-language models.

### 3. Core Idea
- Glyph achieves 3â€“4Ã— context compression while maintaining competitive performance with leading LLMs through continual pre-training and targeted post-training.

### 4. Method
- **Pipeline**: Rendering long texts into images, followed by processing with vision-language models.
- **Architecture / Loss / Training**: Utilizes a genetic rendering search and systematic exploration of rendering configurations.
- **Complexity / Resources**: The method demonstrates substantial gains in inference speed and memory efficiency.

</details>

## model collapse

### [Resolving the dusty star-forming galaxy GN20 at z=4.055 with NOEMA and JWST: A similar distribution of stars, gas and dust despite distinct apparent profiles](http://arxiv.org/pdf/2510.17804v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Self-consistent radiative transfer modeling of CO and dust emission

### 2. Motivation & Gaps
- The TUNER model innovates by using a lognormal gas density distribution to describe realistic density distributions with fewer parameters compared to traditional models.

### 3. Core Idea
- The TUNER model utilizes a lognormal probability distribution to represent the volume distribution of H2 gas, allowing for a more efficient and realistic modeling of radiative transfer.

### 4. Method
- **Pipeline**: The model describes the volume distribution of H2 gas using a lognormal probability distribution and incorporates a Bayesian framework for parameter estimation.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The model simplifies the density distribution to only two parameters, reducing the complexity compared to multi-component models.

</details>

### [Unbiased Gradient Low-Rank Projection](http://arxiv.org/pdf/2510.17802v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Distributed optimization

### 2. Motivation & Gaps
- Memory-efficient training techniques are critical for scalable LLM development and for democratizing customized LLMs for broader societal use.

### 3. Core Idea
- The need to derive an unbiased low-rank projection algorithm due to the significant bias between low-rank projected gradients and original gradients.

### 4. Method
- **Pipeline**: The method involves a communication-efficient algorithm that aggregates local estimates to form a global mean.
- **Architecture / Loss / Training**: The architecture is designed to minimize communication loss during training.
- **Complexity / Resources**: The method is computationally efficient, requiring limited resources for communication.

</details>
