# Daily Paper Digest ¬∑ 2025-10-04
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## neural rendering

### [StealthAttack: Robust 3D Gaussian Splatting Poisoning via Density-Guided Illusions](http://arxiv.org/pdf/2510.02314v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Multi-view Attack in 3D Graphics Systems

### 2. Motivation & Gaps
- The paper addresses vulnerabilities in 3D representation models by introducing a density-guided poisoning method that strategically injects illusory objects while maintaining scene consistency.

- **Related work challenges:**
  - IPA-NeRF: Limited applicability to explicit 3D scene representations like 3DGS.
  - Poison-Splat: Focuses on computational cost attacks rather than visible illusion embedding.
  - IPA-NeRF: Pioneered poisoning attacks against NeRF by inserting crafted samples at specific viewing angles.
  - Poison-Splat: Targeted 3DGS efficiency by generating samples that increase memory consumption.
  - Geometry Cloak: Prevents unauthorized 3D reconstruction from copyrighted images.
  - 3D Gaussian Splatting (3DGS): Maintaining multi-view consistency while embedding illusions.
  - Kernel Density Estimation (KDE): Identifying optimal low-density locations for embedding objects.
  - View Consistency Disruption: Weakening multi-view consistency without affecting the poisoned view.
  - IPA-NeRF: Accelerated training and rendering
  - IPA-Splat: Adapting IPA-NeRF for 3D Gaussian Splatting
  - IPA-NeRF: Existing methods struggle with maintaining quality in innocent views while embedding illusory objects.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - IPA-NeRF (Nerfacto): Poor convergence on complex scenes
  - IPA-NeRF (Instant-NGP): Produces heavily distorted illusory objects
  - IPA-Splat: Limited effectiveness in high view overlap environments

### 3. Core Idea
- Our method demonstrates superior robustness and computational efficiency in generating illusory objects for backdoor attacks.

### 4. Method
- **Pipeline**: The method involves injecting illusory objects into multiple viewpoints and evaluating the impact on scene consistency and fidelity.
- **Architecture / Loss / Training**: Utilizes KDE bandwidth and noise scheduling strategies to optimize attack performance.
- **Complexity / Resources**: Reduces GPU memory usage by 41% and Gaussian points by 88%.

### 5. Experiments
- **Datasets & Metrics**: COCO 2017 dataset for illusory objects; Mip-NeRF 360 dataset for computational efficiency.
- **Baselines**: 3D Gaussian Splatting, IPA-NeRF, IPA-NeRF (Instant-NGP), IPA-NeRF (Nerfacto), IPA-NeRF with Instant-NGP, IPA-NeRF with Nerfacto, IPA-Splat, N/A, Naive 3DGS (w/o attack), NeRF, Poison-Splat
- **Main Results**: Our method achieves success rates of 64% to 83% across different threshold combinations, significantly outperforming existing approaches.
- **Ablations**: Combining direct replacement, density-guided poisoning, and multi-view consistency disruption achieves superior illusion embedding.
- **Limitations / Stress Tests**: Our method shows limitations in complex environments with high view overlap.

### 6. Takeaways
- **Pros**: First work addressing data poisoning attacks on 3D Gaussian Splatting., Identifies and analyzes the robustness of 3DGS against prior poisoning techniques., Introduces adaptive noise scheduling to enhance attack efficacy.
- **Cons**: Potential occlusion of illusory objects by existing geometry., Requires careful selection of injection points., May not generalize to all neural rendering architectures.
- **Future Work**: Further exploration of poisoning attacks on other 3D representation methods., Development of more robust defense mechanisms against such attacks., Investigation of the implications of these attacks in real-world applications.

</details>

### [Interactive Training: Feedback-Driven Neural Network Optimization](http://arxiv.org/pdf/2510.02297v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Neural Network Training Optimization

### 2. Motivation & Gaps
- The paper presents a framework that allows for real-time interventions in neural network training, enabling both humans and AI agents to adjust training parameters dynamically.

- **Related work challenges:**
  - Bergstra and Bengio, 2012: Static training paradigms do not allow for real-time adjustments.
  - Takase et al., 2023: Unstable loss dynamics and underperformance on specific tasks require human intervention.
  - Zhang et al., 2022: Prematurely terminating training jobs leads to inefficiencies and wasted computational resources.
  - Traditional static training methods: Lack of adaptability to changing training dynamics.
  - Existing training frameworks: Limited interactivity and real-time feedback mechanisms.
  - Human-in-the-loop training: Difficulty in integrating human interventions seamlessly into the training process.
  - Human-in-the-Loop Machine Learning: Existing methods often rely on predefined schedules rather than real-time interventions.
  - Automated ML and Adaptive Optimization: Traditional methods may not effectively adapt to real-time training dynamics.
  - Population-Based Training (PBT): PBT learns an automatic dynamic schedule of hyperparameters but does not allow real-time human intervention.
  - Reinforcement Learning for Scheduling: While reinforcement learning can optimize scheduling policies, it typically operates in a static manner without real-time adjustments.
  - Interactive Debugging Tools: Current tools provide advisory support but do not integrate directly into the training loop for immediate interventions.
  - Transformers: State-of-the-art natural language processing: N/A
  - Learning an adaptive learning rate schedule: N/A
  - Opt: Open pre-trained transformer language models: N/A

### 3. Core Idea
- The Interactive Training framework reimagines neural network training as an interactive process, allowing for dynamic control and adjustments based on real-time feedback.

### 4. Method
- **Pipeline**: The framework integrates human and AI agent interactions to modify training strategies during the training process.
- **Architecture / Loss / Training**: Utilizes a learning rate schedule that can be adjusted by human experts or an AI agent.
- **Complexity / Resources**: Requires expertise from human trainers or AI agents to identify and implement effective interventions.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilized a large synthetic dataset and real user interaction data for training and evaluation.
- **Baselines**: Fixed learning rate schedule, Human expert intervention, N/A, Static learning rate schedule, Traditional static optimization methods, Traditional static training paradigms
- **Main Results**: The framework shows improved accuracy, reduced sensitivity to initial hyperparameters, and real-time adaptation to evolving application needs.
- **Ablations**: The study included comparisons between human and AI interventions to assess their effectiveness.
- **Limitations / Stress Tests**: Reproducibility issues were noted due to variability in interventions by different experts or agents.

### 6. Takeaways
- **Pros**: Real-time adjustments improve training outcomes., Dynamic intervention reduces the need for job resubmissions., Supports both human and AI-driven optimization.
- **Cons**: Requires a learning curve for effective use., Potential for overfitting if not managed properly., Dependency on real-time feedback may complicate training.
- **Future Work**: Further development of automated AI agents for training., Exploration of fully interactive training paradigms., Integration of more complex feedback mechanisms.

</details>

### [Fine-Grained Urban Traffic Forecasting on Metropolis-Scale Road Networks](http://arxiv.org/pdf/2510.02278v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Traffic Forecasting

### 2. Motivation & Gaps
- The proposed datasets contain important road attributes that strongly affect traffic speed and volume, which are necessary for precise traffic forecasting.

- **Related work challenges:**
  - Jagadish et al., 2014: Existing datasets have a small number of locations (road segments) with available measurements.
  - Li et al., 2018: No graph structure based on road connectivity is available between sensors.
  - Yu et al., 2018: Measurements fail to capture complex urban traffic within cities.
  - ASTGCN (Guo et al., 2019): Complex implementation due to intricate mechanisms.
  - Graph WaveNet (Wu et al., 2019): Difficulty in learning latent spatial structure efficiently.
  - AGCRN (Bai et al., 2020): Decoupling performance from predefined graph structures is challenging.
  - Previous Traffic Forecasting Datasets: Heuristic edge construction based on travel distance rather than actual road connectivity.
  - Existing Neural Spatiotemporal Models: Inability to handle large and complex datasets effectively.
  - Torch Spatiotemporal (Cini & Marisca, 2022): Limited models can be trained on large datasets due to high resource demands.
  - LargeST (Liu et al., 2023): Existing models require long training times and are not scalable.
  - DCRNN: Exhibits significantly longer training times and fails to complete within a 250 hours time limit for larger lookback windows.
  - STGCN: Poor scalability due to the need to maintain and process an explicit temporal state for each input timestamp.
  - GWN: Long training times as lookback window increases.
  - Graph neural network for traffic forecasting: A survey: Limited ability to capture complex spatial-temporal dependencies.
  - Dynamic spatial-temporal aware graph neural network for traffic flow forecasting: Challenges in real-time data processing and prediction accuracy.
  - Diffusion convolutional recurrent neural network: Data-driven traffic forecasting: Inability to generalize across different traffic conditions.
  - city-traffic-M: Higher density and branching structure with a uniform road network.
  - city-traffic-L: Complex structure with bottlenecks and high-traffic corridors due to geographical features.
  - Previous datasets: Do not include important road attributes affecting traffic forecasting.

### 3. Core Idea
- Utilizing learnable node embeddings and additional temporal features for improved traffic forecasting.

### 4. Method
- **Pipeline**: Use of learnable node embeddings for road segments along with static and temporal features.
- **Architecture / Loss / Training**: Trained using the AdamW optimizer with a fixed learning rate of 0.0003 for 5 epochs.
- **Complexity / Resources**: Experiments conducted on a single NVIDIA A100 GPU with 80GB of VRAM.

### 5. Experiments
- **Datasets & Metrics**: Datasets include various road attributes and metrics for traffic speed and volume.
- **Baselines**: ASTGCN, DCRNN, GNN-Mean, GNN-TrfAttn, GRUGCN, GWN, Global mean/median, METR-LA, N/A, Node-wise mean/median, Other machine learning models, PEMS-BAY, Previous 1 day/week ago, Previous strategy, STGCN, Traditional time series forecasting methods, linear model, naive baselines
- **Main Results**: The results indicate that the proposed datasets significantly improve traffic forecasting accuracy.
- **Ablations**: Conducted ablation studies to assess the impact of different model components.
- **Limitations / Stress Tests**: Models exceeding memory limits were reported as OOM after attempts to reduce parameters.

### 6. Takeaways
- **Pros**: Provides a realistic and challenging benchmark for urban traffic forecasting., Datasets contain rich features and fine-grained temporal data., Demonstrates stronger forecasting performance with proposed GNN approach.
- **Cons**: Existing models struggle to scale to the new dataset size., Current benchmarks do not adequately capture urban traffic complexities.
- **Future Work**: Encourage further advancements in traffic forecasting., Support progress in urban computing and smart city development.

</details>

## Gaussian Splatting

### [Robust Tangent Space Estimation via Laplacian Eigenvector Gradient Orthogonalization](http://arxiv.org/pdf/2510.02308v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Tangent space estimation and embedding of noisy data

### 2. Motivation & Gaps
- The paper addresses the challenges of estimating tangent spaces and embedding noisy data while preserving intrinsic geometry.

- **Related work challenges:**
  - Local Principal Component Analysis (LPCA): Struggles with noise and requires prior knowledge of geometric and noise characteristics.
  - Adaptive neighborhood size selection: Hindered by unknown geometric quantities such as curvature and noise level.
  - LPCA: LPCA is not robust to noise, resulting in poor tangent space estimates.
  - Previous methods for tangent space estimation: Struggled with noise and spurious edges in nearest neighbor graphs.
  - Graph Laplacian approaches: May not effectively capture the intrinsic geometry of the data.
  - Eigenvector-based methods: Often require fine-tuning of hyperparameters to achieve stable results.
  - Previous methods for tangent space estimation: Often fail to account for the curvature and topology of the underlying manifold.
  - Davis-Kahan theorem: Establishing the conditions under which Laplacian eigenvectors remain stable under noise perturbations.
  - Previous studies on Laplacian eigenvectors: Limited understanding of the effects of noise on low-frequency eigengaps.
  - LPCA: Highly sensitive to noise, leading to degraded estimates.
  - LEGO: Requires robust performance across varying noise levels.
  - LPCA: Sensitivity to noise and inability to accurately recover local intrinsic geometry.
  - LEGO: Requires effective noise handling to maintain the integrity of the embedding.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Mikhail Belkin and Partha Niyogi. ‚ÄúTowards a theoretical foundation for Laplacian-based manifold methods‚Äù: N/A
  - Amit Singer. ‚ÄúFrom graph to manifold Laplacian: The convergence rate‚Äù: N/A
  - Nicol√°s Garc√≠a Trillos et al. ‚ÄúError estimates for spectral convergence of the graph Laplacian on random geometric graphs toward the Laplace‚ÄìBeltrami operator‚Äù: N/A
  - Xiuyuan Cheng and Boris Landa. ‚ÄúBi-stochastically normalized graph Laplacian: convergence to manifold Laplacian and robustness to outlier noise‚Äù: N/A
  - Yariv Aizenbud and Barak Sober. ‚ÄúNon-parametric estimation of manifolds from noisy data‚Äù: N/A
  - Yariv Aizenbud and Barak Sober. ‚ÄúEstimation of Local Geometric Structure on Manifolds from Noisy Data‚Äù: N/A
  - Anna V Little. ‚ÄúEstimating the intrinsic dimension of high-dimensional data sets: a multiscale, geometric approach‚Äù: N/A
  - Anna V Little, Mauro Maggioni, and Lorenzo Rosasco. ‚ÄúMultiscale geometric methods for data sets I: Multiscale SVD, noise and curvature‚Äù: N/A
  - Christopher R Genovese et al. ‚ÄúMinimax manifold estimation‚Äù: N/A
  - Stefan Haag, Jonas Lampart, and Stefan Teufel. ‚ÄúGeneralised quantum waveguides‚Äù: N/A
  - Daniel Hsu, Sham Kakade, and Tong Zhang. ‚ÄúA tail inequality for quadratic forms of subgaussian random vectors‚Äù: N/A
  - Andrew V Knyazev and Merico E Argentati. ‚ÄúPrincipal angles between subspaces in an A-based scalar product: algorithms and perturbation estimates‚Äù: N/A
  - Roy R Lederman and Ronen Talmon. ‚ÄúLearning the geometry of common latent variables using alternating-diffusion‚Äù: N/A
  - Shuyang Ling. ‚ÄúGeneralized power method for generalized orthogonal Procrustes problem: global convergence and optimization landscape analysis‚Äù: N/A
  - Dhruv Kohli, Gal Mishne, and Alexander Cloninger. ‚ÄúNon-degenerate rigid alignment in a patch framework‚Äù: N/A
  - Shankar Krishnan et al. ‚ÄúGlobal registration of multiple 3D point sets via optimization-on-a-manifold.‚Äù: N/A
  - Boris Landa and Xiuyuan Cheng. ‚ÄúRobust inference of manifold density and geometry by doubly stochastic scaling‚Äù: N/A

### 3. Core Idea
- The proposed method utilizes a tear-enabled alignment framework to produce injective embeddings of data lying on closed manifolds.

### 4. Method
- **Pipeline**: Data dimensionality reduction followed by tangent space estimation and embedding using LEGO.
- **Architecture / Loss / Training**: The architecture involves a Riemannian submersion metric and utilizes eigenfunctions to compute energies.
- **Complexity / Resources**: Computational constraints necessitate dimensionality reduction before processing.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize noisy datasets generated by adding uniformly distributed noise to clean images.
- **Baselines**: LEGO, LPCA, Local Principal Component Analysis (LPCA), N/A, Other eigenvector-based tangent space estimation techniques, Previous eigenfunction-based approaches, Previous methods for Laplacian eigenvector stability, Standard tangent space estimation methods, Traditional PCA-based methods
- **Main Results**: LEGO effectively captures the underlying 2D structure while LPCA fails to maintain the intrinsic geometry.
- **Ablations**: Noise ablation studies confirmed that LPCA estimates degrade rapidly with noise, while LEGO remains stable.
- **Limitations / Stress Tests**: The method's performance is constrained by the noise level and dimensionality reduction steps.

### 6. Takeaways
- **Pros**: LEGO provides more robust tangent space estimates in noisy environments., Utilizes global structure of data for improved local estimation., Theoretical justifications support the effectiveness of the method.
- **Cons**: Requires understanding of graph Laplacian eigenvectors.
- **Future Work**: Explore further applications in manifold learning and boundary detection., Investigate adaptive methods for neighborhood size selection., Enhance the algorithm to handle more complex noise structures.

</details>

### [ALMA Deep Field in SSA22: Reconstructed [CII] Luminosity Function at z = 6](http://arxiv.org/pdf/2510.02303v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Examine completeness and contamination in ALMA data and discuss reasons for false detections.

### 2. Motivation & Gaps
- Our basic motivation is to understand the evolution of galaxy populations by probing the cosmic star-formation history (CSFH).

- **Related work challenges:**
  - ADF22 line survey: Reported detections were shown to be spurious after follow-up observations.
  - Previous source-finding methods: Underestimation of contamination rates due to limited data.
  - Hayatsu et al. (2017): Detection of faint emission-line sources in ALMA data with high sensitivity.
  - Gonz√°lez-L√≥pez et al. (2017): Statistical fluctuations leading to false positives in large ALMA survey datasets.
  - N/A: N/A
  - Hayatsu et al. (2017): Detection reliability and contamination rate evaluation.
  - Carilli and Walter (2013): Calculating luminosity from flux.
  - Williams, de Geus, and Blitz (1994): Source extraction methods.
  - Hatsukade et al. (2016): Approximating Q(x) and C(x) with the error function.
  - Williams, de Geus, and Blitz (1994): Using clumpfind for source detection.
  - Kohandel et al. (2019): Assuming the observed correlation between [Cii] luminosity and FWHM.
  - D√≠az-Santos et al. 2013: N/A
  - Swinbank et al. 2012: N/A
  - Hemmati et al. 2017: N/A
  - Hayatsu et al. 2019: N/A
  - Capak et al. 2015: N/A
  - Aravena et al. 2016: N/A
  - N/A: N/A
  - Hemmati et al. (2017): The original function is a double power law.
  - De Looze et al. (2014): The SFR‚ÄìL[CII] relation may not be accurate for normal (less luminous) [CII] emitters.
  - Farra et al. (2013): SFRD constraints using other FIR lines are still weak.
  - N/A: False detection of high-SN ratio is unavoidable due to existing clump-like structures.
  - N/A: N/A

### 3. Core Idea
- The reconstruction method for line LF can be applied to other blind line surveys using ALMA deep field datacubes.

### 4. Method
- **Pipeline**: We generate luminosity values obeying a Schechter function and calculate the output/input ratio for each parameter of FWHM and peak S/N.
- **Architecture / Loss / Training**: We fit the output line emission assuming a single Gaussian profile.
- **Complexity / Resources**: The process involves 100 realizations and variance calculations.

### 5. Experiments
- **Datasets & Metrics**: ALMA data from various cycles including Cycle-2 and Cycle-5.
- **Baselines**: De Looze et al. (2014), Farra et al. (2013), Hemmati et al. (2017), Mock data, N/A, Previous source-finding methods, Previous studies on [Cii] LF by Matsuda et al. (2015), Capak et al. (2015), and Aravena et al. (2016)., Real data
- **Main Results**: Confirmed that previously detected emitters/candidates are classified as unreliable.
- **Ablations**: Comparison of clump-finding results between TDM and FDM correlator datacubes.
- **Limitations / Stress Tests**: Correction for number count is required up to one order of magnitude at a luminosity range of ‚â•5√ó10^8 L‚äô.

### 6. Takeaways
- **Pros**: Improved understanding of false detection rates in high-SN observations., Method can be applied to future blind line surveys., Confirmed the need for correction in luminosity function estimations.
- **Cons**: Previous methods underestimated contamination rates., Technical issues in original observations may affect results., Limited number of real datacubes used in prior analyses.
- **Future Work**: Further investigation into the effects of observational biases., Exploration of additional line emissions beyond [Cii]., Development of more robust detection algorithms.

</details>

## avatar

### [MPMAvatar: Learning 3D Gaussian Avatars with Accurate and Robust Physics-Based Dynamics](http://arxiv.org/pdf/2510.01619v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Realistic garment dynamics simulation

### 2. Motivation & Gaps
- Existing methods struggle with accurate garment dynamics and rendering quality.

- **Related work challenges:**
  - PhysAvatar: Fails when animation inputs have a small degree of self-penetration, causing simulation failures.
  - Existing methods using piecewise linear transformations: Limited in accurately capturing complex deformations and tend to overfit to motions observed during training.
  - Xiang et al.: Relies on a time-consuming manual parameter search to approximate reasonable cloth behavior.
  - C-IPC: Fails to resolve collisions for noisy colliders during Continuous Collision Detection.
  - Learning-based simulation methods: Limited generalizability beyond training dynamics and cannot guarantee physically plausible deformations.
  - DiffAvatar: Omitted appearance modeling and tailored for scan-based asset preparation rather than dynamic avatar reconstruction.
  - Material Point Method (MPM): Mainly used for modeling the dynamics of general objects, not specifically tailored for garment dynamics.
  - Anisotropic constitutive model: Requires a Lagrangian mesh to track material directions, complicating the modeling of garments.
  - Existing collision handling algorithms: Designed for external objects, not effective for colliders represented as meshes.
  - PhysAvatar [78]: Existing approaches assume ideal conditions, limiting their applicability in real-world scenarios.
  - PhysAvatar [78]: Fails when driving body mesh colliders have self-penetrations.
  - C-IPC [31]: Takes a long time to converge for resolving complex collisions.
  - Learning-based simulators [8, 7]: Less effective in modeling unseen dynamics.
  - N/A: N/A
  - PhysAvatar: Achieving accurate garment dynamics and high rendering quality.
  - PhysAvatar [78]: Inaccurate garment dynamics and rendering quality.
  - Gaussian Garments [55]: Struggles to produce physically accurate deformations.
  - MMLPHuman [74]: Exhibits unnatural surface artifacts or discontinuities under challenging poses.
  - Gaussian Garments [55]: Struggles to capture physical laws under settings where physical parameters must be estimated from only one second of motion, leading to high geometric error.
  - MMLPHuman [74]: Lacks explicit surface modeling and physical understanding, producing unrealistic surface artifacts or broken geometry when encountering unseen poses.
  - Finite-Difference Optimization: Scalability with increasing parameters
  - Relighting-aware extensions for Gaussian avatars: Current framework does not support relightable rendering
  - Generative priors for inpainting unobserved regions: Rendering quality degradation for occluded or unseen parts

### 3. Core Idea
- The paper presents an anisotropic constitutive model for simulating realistic garment behavior, capturing the strain-energy density function to compute stress tensors for accurate dynamics.

### 4. Method
- **Pipeline**: The pipeline includes garment dynamics simulation using MPM and mesh-based collision handling.
- **Architecture / Loss / Training**: Utilizes a constitutive model for anisotropic elastoplasticity and physical parameter learning.
- **Complexity / Resources**: Simulation runs at approximately 1.1 seconds per frame on a single NVIDIA GeForce RTX 4090.

### 5. Experiments
- **Datasets & Metrics**: Evaluated on the ActorsHQ [14] dataset using metrics like penetration depth and physical plausibility scores.
- **Baselines**: ARAH [65], C-IPC, Existing MPM collision handling algorithms, GS-Avatar [12], Gaussian Garments [55], MMLPHuman [74], N/A, PhysAvatar, PhysAvatar [78], TA V A [32], XPBD
- **Main Results**: Our method outperforms both baselines across all geometry and appearance metrics.
- **Ablations**: Ablation studies validate the importance of key components like the constitutive model and physical parameter learning.
- **Limitations / Stress Tests**: Quantitative evaluation of physical plausibility is challenging due to the lack of ground-truth physical annotations.

### 6. Takeaways
- **Pros**: Supports physically realistic and robust animations for loose garments., Achieves high-fidelity rendering from free viewpoints., Demonstrates zero-shot generalizability to novel scene interactions.
- **Cons**: Requires complex setup for accurate simulation., High computational resource demands., Limited by the quality of input multi-view videos.
- **Future Work**: Explore further generalizability to more complex interactions., Enhance the efficiency of the simulation process., Investigate applications in virtual and augmented reality.

</details>

### [When Shared Worlds Break: Demystifying Defects in Multi-User Extended Reality Software Systems](http://arxiv.org/pdf/2510.01182v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Empirical analysis of bug reports in multi-user XR systems

### 2. Motivation & Gaps
- The study aims to understand the unique challenges and characteristics of bugs in multi-user XR systems, which differ from traditional software systems.

- **Related work challenges:**
  - Research on software bugs in various domains: Significant gap in understanding bugs specifically arising from multi-user interactions in XR environments.
  - Traditional distributed systems research: Does not account for the unique social presence issues in multi-user XR environments.
  - Existing bug tracking in software development: Lacks a comprehensive understanding of multi-user XR specific bugs.
  - Previous studies on software bugs: Lack of systematic analysis specific to multi-user XR environments.
  - Asymmetric Interaction Capabilities: Different abilities to interact with the shared environment across platforms.
  - Loss/Hijack of Control: Users losing control or having their camera view taken over by others.
  - Communication & Awareness Impairment: Impairments in social and awareness mechanisms affecting collaborative experiences.
  - Previous studies on software bugs: Traditional software bugs are often tolerable, whereas XR bugs can severely break immersion.
  - Existing QA methodologies: Current methodologies may not effectively address the unique challenges posed by multi-user XR environments.
  - Hubs-Foundation/hubs issue #5586: Orphaned state of objects when both creator and owner leave the session.
  - Hubs-Foundation/hubs issue #1000: Implicit ownership leading to invisibility of objects for new users.
  - Hubs-Foundation/hubs issue #6250: Inadequate access control mechanisms leading to unauthorized object manipulation.
  - Layer demonstrated how game-specific logic failed to account for multiple players: Developers often retrofit single-player logic for multiplayer scenarios without fully considering the implications.
  - Configuration Sensitivity: Many bugs are resolved through configuration adjustments rather than code changes, indicating high sensitivity to deployment configurations.
  - Layered Complexity: Bugs often have multiple contributing root causes, requiring a comprehensive understanding of the entire system stack.
  - Traditional software analysis techniques: Fail to capture the unique characteristics of multi-user XR bugs.
  - Current debugging tools: Ill-equipped to handle the distributed, real-time nature of multi-user XR applications.
  - Existing SDKs and APIs: May not provide sufficiently intuitive or well-documented APIs for multi-user scenarios.
  - Rodriguez and Wang [70]: Analyzed trends and challenges in VR software projects.
  - Adams et al. [45]: Revealed privacy and security threats in VR applications.
  - Miller et al. [65]: Proved personal identifiability with user tracking data in VR software.
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The paper develops comprehensive taxonomies categorizing symptoms, root causes, and consequences of XR defects based on an analysis of 2,649 real-world bug reports.

### 4. Method
- **Pipeline**: Empirical analysis of bug reports to identify and categorize defects.
- **Architecture / Loss / Training**: Rigorous qualitative analysis using iterative open coding to develop taxonomies characterizing multi-user XR bugs.
- **Complexity / Resources**: The study utilizes a hierarchical taxonomy and various analytical methods including frequency analysis and cross-tabulation.

### 5. Experiments
- **Datasets & Metrics**: Analysis of 2,649 real-world bug reports from various XR platforms.
- **Baselines**: Existing debugging tools, Hubs-Foundation/hubs, N/A, Single-user XR applications, Single-user XR bug analysis, Single-user XR systems, Traditional bug tracking methods, Traditional multi-user applications, Traditional online collaboration tools, Traditional software analysis techniques, Traditional software bug analysis methods, Traditional software debugging methods, Unity SDK, Unreal Engine
- **Main Results**: Over 34% of defects cause severe disruptions like crashes and interaction breakdowns.
- **Ablations**: N/A
- **Limitations / Stress Tests**: Findings may not fully reflect emerging technologies or practices due to the rapidly evolving XR landscape.

### 6. Takeaways
- **Pros**: Provides actionable recommendations for developers and platform vendors., Develops a comprehensive taxonomy for multi-user XR bugs., Highlights unique challenges in multi-user XR systems.
- **Cons**: Limited understanding of multi-user XR bugs compared to other domains., Fragmented nature of bug reporting complicates knowledge aggregation., Potential privacy and health implications remain concerning.
- **Future Work**: Further research on automated quality assurance tools for multi-user XR., Exploration of specific privacy and health implications associated with multi-user XR bugs., Development of targeted guidance for bug prevention and mitigation.

</details>

### [Audio Driven Real-Time Facial Animation for Social Telepresence](http://arxiv.org/pdf/2510.01176v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Facial Animation Generation

### 2. Motivation & Gaps
- Existing methods for facial animation often produce spatiotemporally inconsistent results, leading to unnatural avatars.

- **Related work challenges:**
  - Fan et al. 2022; Richard et al. 2021; Xing et al. 2023: Existing methods lack sufficient detail for conveying subtle facial cues and often operate offline, requiring entire audio sequences as input.
  - Li et al. 2024b; Ng et al. 2024: Recent approaches synthesize high-fidelity avatars but do not process audio streams in real-time, leading to computational latency issues.
  - GSTalker: Limited generalization to multiple identities.
  - GaussianTalker: Requires offline computation for audio-based deformations.
  - EmoTalk3D: Computationally expensive and lacks real-time performance.
  - Universal Relightable Prior Model [Li et al. 2024a]: Existing models may not effectively handle real-time performance and the integration of gaze direction.
  - Diffusion models for facial expression generation: Inherent slowness of diffusion models during inference.
  - Graph-based gaze synthesis: Ensuring smooth and consistent gaze transitions.
  - Audio encoders for real-time applications: Maintaining causality in audio processing without future information.
  - GaussianTalker: Generates high-fidelity 3D face animation but is not designed for real-time applications.
  - TalkingGaussian: Focuses on person-specific 3D deformation and rendering, lacking universality.
  - GaussianTalker [Cho et al. 2024]: Generates high-fidelity 3DGS face animation but learns person-specific deformations.
  - TalkingGaussian [Li et al. 2024b]: Similar to GaussianTalker, it does not provide a direct online-based solution.
  - DiffPoseTalk [Sun et al. 2024]: Requires style conditioning which is not available in real-world scenarios.
  - wav2vec 1.0: Limited to non-causal encoding.
  - wav2vec 2.0: Challenges in maintaining accuracy while achieving real-time performance.
  - N/A: N/A
  - FaceFormer: High latency and unsuitability for real-time applications.
  - CodeTalker: High computational overhead and autoregressive nature.
  - AniPortrait: Blurry and distorted artifacts in generated images.
  - Wav2vec 1.0: Employs causal CNNs which may limit the quality of audio processing.
  - Wav2vec 2.0: Utilizes non-causal CNN layers, which can disrupt causality in audio processing.
  - HuBERT: Relies on non-causal CNN layers, failing to ensure full causality.
  - N/A: N/A

### 3. Core Idea
- The proposed method generates high-fidelity avatars with synchronized lip movements by utilizing a gaze graph and a transformer architecture.

### 4. Method
- **Pipeline**: The method involves capturing audio and gaze data, processing it through a transformer architecture, and synthesizing facial animations based on the processed data.
- **Architecture / Loss / Training**: Utilizes a self-attention mechanism with a windowed mask to maintain temporal coherence and reduce boundary issues.
- **Complexity / Resources**: distributed data-parallel (DDP) using two A100 GPUs; Distillation training and emotion-conditioning training are done with a single A100 GPU.

### 5. Experiments
- **Datasets & Metrics**: Out of 265 capture subjects, we use 237 for training and 28 for testing. Data are segmented into sequences of frame length 100 (in 30FPS).
- **Baselines**: AniPortrait, Audio2Photoreal, Audio2Photoreal-Face, CodeTalker, DiffPoseTalk, EmoTalk3D, Existing diffusion models, Existing offline audio-driven facial animation methods, FaceFormer, GSTalker, GaussianTalker, HuBERT, N/A, TalkShow, TalkShow-Face, Traditional regression models for facial expression generation, Wav2vec 1.0, Wav2vec 2.0, wav2vec 1.0, wav2vec 2.0
- **Main Results**: Quantitative comparison experiments on freeform speech and sentence reading data.
- **Ablations**: Ablation studies were conducted to evaluate the impact of different components of the model.
- **Limitations / Stress Tests**: Out of 28 test subjects, two were excluded for excessive frame drops and less than 70 segments can be used for freeform speech; two were excluded for excessive frame drops and less than 30 segments can be used for sentence reading.

### 6. Takeaways
- **Pros**: High fidelity and universal 3D facial avatars in real-time., Significant improvements in animation accuracy., Versatile framework for multimodal applications.
- **Cons**: Limited generalization across diverse identities., Potential computational overhead in complex scenarios., Dependence on the quality of audio input.
- **Future Work**: Explore further multimodal applications., Enhance real-time performance in more complex scenarios., Investigate integration with additional sensory inputs.

</details>

## video understanding

### [Clink! Chop! Thud! -- Learning Object Sounds from Real-World Interactions](http://arxiv.org/pdf/2510.02313v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- sounding object detection

### 2. Motivation & Gaps
- The paper addresses the challenge of aligning audio and visual modalities for sound source localization.

- **Related work challenges:**
  - Existing multimodal techniques: They often rely on global features and predefined sound categories, making it difficult to differentiate subtle sound impacts caused by different materials.
  - Multimodal object-centric representation learning: Previous works have primarily used synthetic or laboratory-collected data, which do not scale well to real-world object interactions.
  - Traditional deep learning models: They analyze entire scenes without distinguishing between individual objects, leading to inefficiencies.
  - Slot Attention Models: Compressing image features into slot vectors for object segmentation.
  - Multimodal Datasets: Data is often synthetically generated or collected in controlled environments.
  - Audiovisual Localization: Requires precise boundary predictions which may not align with the task of identifying involved objects.
  - Previous object-centric learning methods: Directly applying masks to input rather than visual embeddings
  - SoundingActions: Limited to global representations without object awareness.
  - DenseA V: Focuses on audiovisual segmentation but lacks specific object interaction context.
  - SLA VC: Uses a localization framework that may not effectively capture object-specific sound interactions.
  - SoundingActions: Achieving better performance on the task despite using the same training loss and data.
  - ImageBind: Aligning a wide range of modalities into a single embedding space.
  - LanguageBind: Zero-shot evaluation against large-scale pretraining models.
  - N/A: N/A
  - Learning object permanence from video: N/A
  - Understanding human hands in contact at internet scale: N/A
  - Semantic object prediction and spatial sound super-resolution with binaural sounds: N/A
  - N/A: N/A

### 3. Core Idea
- The core idea is to enhance sound source localization by leveraging cross-modal alignment between audio and visual data.

### 4. Method
- **Pipeline**: The method involves a multi-modal approach that integrates audio and visual embeddings for improved localization.
- **Architecture / Loss / Training**: The architecture uses a combination of pretrained models for audio and visual encoding, with specific training strategies to optimize performance.
- **Complexity / Resources**: The model complexity is managed through the use of frozen pretrained models and a common embedding space.

### 5. Experiments
- **Datasets & Metrics**: Epic Kitchens, Ego4D
- **Baselines**: Audiovisual Localization Models, DenseA V, Existing multimodal techniques, ImageBind, InfoNCE loss, LanguageBind, MC3 loss, N/A, Previous Object-Centric Learning Methods, SLA VC, SSLAlign, Slot Attention Models, SoundingActions
- **Main Results**: The results demonstrate significant improvements in sound source localization accuracy compared to previous methods.
- **Ablations**: Ablation studies indicate the importance of cross-modal alignment in achieving high performance.
- **Limitations / Stress Tests**: Limitations include potential challenges in noisy environments and the need for extensive labeled data.

### 6. Takeaways
- **Pros**: Achieves state of the art performance on new tasks., Utilizes a novel multimodal object-aware approach., Scales well to larger datasets with diverse object interactions.
- **Cons**: Relies on the quality of the segmentation masks for training., May not generalize well to unseen object interactions.
- **Future Work**: Explore additional modalities for richer context., Investigate real-time applications of the model., Expand the dataset to include more diverse interactions.

</details>

### [Inferring Dynamic Physical Properties from Video Foundation Models](http://arxiv.org/pdf/2510.02311v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Comparative analysis of elasticity in video frames

### 2. Motivation & Gaps
- The study aims to analyze and compare the elasticity characteristics of different objects as observed in video frames.

- **Related work challenges:**
  - Wu et al., 2015; Ding et al., 2021; Jatavallabhula et al., 2021: Early methods rely heavily on simulation supervision and handcrafted heuristics.
  - Voleti et al., 2022; Lu et al., 2023: Unsupervised learning captures latent dynamics but lacks interpretability in terms of concrete physical quantities.
  - Kawabe et al., 2014; Paulun et al., 2015: Later works infer attributes from task-specific visual cues, which may not generalize well.
  - Bordes et al., 2018: Qualitative and categorical questions in existing benchmarks.
  - Tung et al., 2023: Limited focus on quantitative physical understanding.
  - Bear et al., 2021: Lack of datasets that combine synthetic and real-world video data for physical property estimation.
  - Classical computer vision techniques: Limited accuracy in estimating physical properties due to reliance on heuristics.
  - Video generative models: Need for effective feature extraction and representation learning for physical property estimation.
  - Multimodal large language models (MLLMs): Integrating visual and textual information to infer physical properties remains complex.
  - DynamiCrafter (Xing et al., 2024): Effective feature extraction for 3D physics.
  - V-JEPA-2 (Assran et al., 2025): Utilizing self-supervised learning for video feature representation.
  - Shtedritski et al. (2023): Mitigating the sim-to-real gap in model training.
  - Video Generative Models: Struggle to generalize to real-world scenarios, especially for friction estimation.
  - Self-Supervised Video Models: Performance drops significantly on synthetic splits compared to real-world data.
  - Multimodal Large Language Models (MLLMs): Tend to leverage semantic cues rather than visual motion, affecting their performance.
  - Learning to poke by poking: Experiential learning of intuitive physics: Models fall short of the oracle, particularly in absolute value prediction.
  - V-jepa: Latent video prediction for visual representation learning: Generative and self-supervised models have similar performance but need improvement in physical reasoning.
  - Physion: Evaluating physical prediction from vision in humans and machines: MLLMs perform worse overall but improve with more informative prompting.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: Accurate identification of key points in video frames for restitution coefficient calculation
  - Previous studies on elasticity analysis: Limited accuracy in estimating restitution coefficients from visual data.
  - Comparative analysis of elasticity in materials: Difficulty in determining which material exhibits higher elasticity based solely on visual input.
  - Previous studies on material elasticity: Lack of standardized methods for visual analysis of elasticity.
  - Previous studies on elasticity analysis: Limited interpretability and stability in few-shot examples.
  - DynamiCrafter: Reducing the sim2real gap
  - V-JEPA-2: N/A
  - Qwen2.5VL-max: Limitation of resources
  - GPT-4o: Limitation of resources
  - Gemini-2.5-pro: Limitation of resources

### 3. Core Idea
- Using red circles to improve the performance of models in sim2real tasks.

### 4. Method
- **Pipeline**: Analysis of video frames to assess elasticity characteristics.
- **Architecture / Loss / Training**: MLP networks trained with L1 loss for absolute value prediction and binary cross-entropy for relative value prediction.
- **Complexity / Resources**: Random subset of 100 samples used due to resource limitations.

### 5. Experiments
- **Datasets & Metrics**: Test splits for elasticity, viscosity, and friction properties.
- **Baselines**: Baseline, Baseline model for elasticity analysis, Baseline model for elasticity estimation, Classical estimation methods, Existing machine learning models for physical property estimation, Existing vision-language models, Few-Shot Examples, Frame Index Provided, GPT-4o, GPT-4o (Hurst et al., 2024), Gemini 2.5 Pro (Comanici et al., 2025), Gemini-2.5-pro, Generative models, Multi-modal large language models (MLLMs), N/A, Oracle Estimation Teaching, Oracle Estimator, Oracle estimation teaching model, Previous elasticity analysis methods, Qualitative benchmarks, Qwen2.5-VL-Max (Hui et al., 2024), Qwen2.5VL-max, Self-supervised models, Video Generative Model, Video Self-Supervised Model, With Red circle, Without red circle
- **Main Results**: Performance improved from 0.47 to 0.84 on real test split test-3 with red circle.
- **Ablations**: Ablation study conducted using DynamiCrafter.
- **Limitations / Stress Tests**: Challenges in accurately estimating coefficients due to visual ambiguities and material behaviors.

### 6. Takeaways
- **Pros**: The proposed methods enable explicit estimation of physical properties without task-specific heuristics., The PhysVid dataset facilitates the study of out-of-domain generalization., The approach is lightweight and efficient for training.
- **Cons**: MLLMs currently perform inferiorly compared to other models., The reliance on visual cues may limit generalization to unseen scenarios., Existing datasets lack comprehensive ground-truth annotations for dynamic properties.
- **Future Work**: Explore further improvements in MLLM prompting strategies., Investigate the generalization capabilities of the proposed methods., Develop additional datasets for other dynamic physical properties.

</details>

### [Astrophysical Consequences of an Electroweak $\etaw$ Pseudo-Scalar](http://arxiv.org/pdf/2510.02310v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Investigate the astrophysical implications of the Œ∑w boson and its potential as a dark matter candidate.

### 2. Motivation & Gaps
- The identity of dark matter (DM) remains a mystery, and the paper explores whether Œ∑w can be a viable DM candidate without requiring physics beyond the Standard Model (SM).

- **Related work challenges:**
  - Ref. [1]: Theoretical arguments supporting the presence of Œ∑w within the Standard Model.
  - Ref. [2]: Astrophysical constraints on the couplings of ultralight bosons.
  - Ref. [6]: The idea of Œ∑w being a superposition of hydrogen and anti-hydrogen does not conform with expected mass scaling.
  - Dvali et al. (2025): The bounds on Œ∑w's coupling challenge typical arguments for its necessity and properties.
  - CAST experiment (2017): The null result in the search for solar axions provides stringent constraints on Œ∑w.
  - Baryon nonconservation in standard model and Yukawa interaction: Understanding baryon nonconservation
  - Can electroweak theta term be observable?: Observability of the electroweak theta term
  - Hiding in Plain Sight, the electroweakŒ∑ W: Identifying the electroweakŒ∑ W

### 3. Core Idea
- The paper argues that the ultra-light pseudo-scalar Œ∑w can emerge from non-perturbative electroweak interactions and the B+L anomaly, but its properties are constrained by astrophysical observations.

### 4. Method
- **Pipeline**: Theoretical analysis of the coupling of Œ∑w to photons and electrons, and estimation of bounds based on astrophysical observations.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: N/A

### 5. Experiments
- **Datasets & Metrics**: Astrophysical constraints from Supernova 1987A and the CAST experiment.
- **Baselines**: Astrophysical axion bounds, Astrophysical constraints, Previous theoretical models of axion-like particles, Red giant bound on the axion - electron coupling revisited, Revisiting the SN1987A gamma-ray limit on ultralight axion-like particles, Standard Model predictions, Standard Model predictions for dark matter candidates
- **Main Results**: The strongest bound on Œ∑w's decay constant is fŒ∑w ‚â≥ 1000 TeV, which is significantly higher than previous expectations.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The non-perturbative nature of Œ∑w's dynamics complicates straightforward interpretations of its properties.

### 6. Takeaways
- **Pros**: Potential implications for understanding electroweak interactions., Challenges existing predictions of the Standard Model., Encourages further theoretical and phenomenological investigations.
- **Cons**: Status of Œ∑w as a firm prediction is not well-established., Identifications of Œ∑w as dark matter or dark energy appear unlikely., Theoretical arguments are not definitive.
- **Future Work**: Further investigations into the properties of Œ∑w., Exploration of its role in astrophysical phenomena., Assessment of its implications for fundamental physics.

</details>
