# Daily Paper Digest Â· 2025-11-04
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [Avatar Appearance Beyond Pixels -- User Ratings and Avatar Preferences within Health Applications](http://arxiv.org/pdf/2510.26251v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigating the impact of avatar characteristics on user ratings in healthcare applications

### 2. Motivation & Gaps
- The integration of virtual avatars in mental healthcare has potential benefits, but the effectiveness and design features remain underexplored.

### 3. Core Idea
- The study highlights the influence of avatar characteristics, particularly competence and information sharing, over warmth, attractiveness, and human-likeness in avatar preferences within healthcare applications.

### 4. Method
- **Pipeline**: Repeated measures ANOVA was used to analyze the effects of clothing style and gender on competence ratings.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: N/A

</details>

### [Learning Disentangled Speech- and Expression-Driven Blendshapes for 3D Talking Face Animation](http://arxiv.org/pdf/2510.25234v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D facial animation

### 2. Motivation & Gaps
- The paper addresses the need for improved techniques in 3D facial animation that can effectively disentangle speech and expression.

### 3. Core Idea
- The core idea is to develop a method that disentangles speech and emotional expressions to create more realistic 3D facial animations.

### 4. Method
- **Pipeline**: The method involves a pipeline that processes audio input to generate corresponding facial animations.
- **Architecture / Loss / Training**: Utilizes a novel architecture with specific loss functions to optimize the disentanglement of speech and expressions.
- **Complexity / Resources**: The method requires moderate computational resources for training and inference.

</details>

### [TurboPortrait3D: Single-step diffusion-based fast portrait novel-view synthesis](http://arxiv.org/pdf/2510.23929v1)
  (summary failed: 'utf-8' codec can't encode characters in position 7033-7034: surrogates not allowed)


## video understanding

### [Phased DMD: Few-step Distribution Matching Distillation via Score Matching within Subintervals](http://arxiv.org/pdf/2510.27684v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation

### 2. Motivation & Gaps
- The paper addresses the challenges in video generation, particularly focusing on the effectiveness of Dynamic Movement Distillation (DMD) training.

### 3. Core Idea
- The introduction of Phased DMD, which utilizes reverse nested intervals for noise injection to improve video generation quality.

### 4. Method
- **Pipeline**: The method involves a comparison of video frames generated by different models using DMD techniques.
- **Architecture / Loss / Training**: The architecture focuses on integrating noise injection at various levels to enhance training convergence.
- **Complexity / Resources**: The models require different sampling steps and configurations, impacting the computational resources needed.

</details>

### [PETAR: Localized Findings Generation with Mask-Aware Vision-Language Modeling for PET Automated Reporting](http://arxiv.org/pdf/2510.27680v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Report generation from PET/CT data

### 2. Motivation & Gaps
- The paper introduces PETAR, a framework designed to generate clinically relevant reports from PET/CT imaging data, addressing the need for accurate and coherent report generation in radiology.

### 3. Core Idea
- PETAR combines mask-aware volumetric reasoning and focal prompting to enhance the generation of clinically meaningful reports from PET/CT data.

### 4. Method
- **Pipeline**: The pipeline involves using ROIs generated by AI models or physician input to extract critical measurements and populate reports using LLMs.
- **Architecture / Loss / Training**: The architecture employs a combination of volumetric conditioning and focal prompting, with training focused on improving localization and semantic alignment.
- **Complexity / Resources**: The model requires substantial computational resources for training and evaluation, particularly for processing 3D data.

</details>

### [Dark-Field X-Ray Imaging Significantly Improves Deep-Learning based Detection of Synthetic Early-Stage Lung Tumors in Preclinical Models](http://arxiv.org/pdf/2510.27679v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Tumor segmentation in lung images using dual-channel U-Net architecture

### 2. Motivation & Gaps
- The study aims to improve detection sensitivity in lung cancer screening using dark-field and attenuation radiography.

### 3. Core Idea
- Utilizing a two-channel UNET model combining dark-field imaging (DFI) and attenuation (ATTN) to enhance tumor detection sensitivity.

### 4. Method
- **Pipeline**: Training a UNET model with different imaging modalities (ATTN-only, DFI-only, and ATTN+DFI).
- **Architecture / Loss / Training**: Training stopped early due to oscillations in validation loss, indicating potential overfitting.
- **Complexity / Resources**: The model uses a 3D tensor input of dimension [32 x 32 x 2] and requires data augmentation techniques.

</details>

## model collapse

### [LifWavNet: Lifting Wavelet-based Network for Non-contact ECG Reconstruction from Radar](http://arxiv.org/pdf/2510.27692v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- ECG reconstruction from radar signals

### 2. Motivation & Gaps
- The paper addresses the challenge of reconstructing ECG waveforms from radar signals, which is crucial for non-contact health monitoring.

### 3. Core Idea
- LifWavNet employs learnable lifting wavelet filters to decompose radar signals into scale-specific components for accurate ECG reconstruction.

### 4. Method
- **Pipeline**: The method involves decomposing radar signals, applying lifting wavelet filters, and reconstructing ECG waveforms through an end-to-end learning approach.
- **Architecture / Loss / Training**: Utilizes a multi-resolution STFT loss to ensure high fidelity in both temporal and spectral domains.
- **Complexity / Resources**: The model is designed to be computationally efficient while maintaining high reconstruction accuracy.

</details>

### [WallGo investigates: Theoretical uncertainties in the bubble wall velocity](http://arxiv.org/pdf/2510.27691v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Review of electroweak baryogenesis

### 2. Motivation & Gaps
- This paper reviews the current understanding of electroweak baryogenesis, focusing on the dynamics of phase transitions and bubble wall velocities.

### 3. Core Idea
- The paper synthesizes various models and theories related to electroweak baryogenesis, emphasizing the role of bubble wall dynamics and gravitational wave production.

### 4. Method
- **Pipeline**: The review compiles theoretical models and experimental results to provide a comprehensive overview of electroweak baryogenesis.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The review discusses various computational techniques and theoretical frameworks used in the field.

</details>

### [Continuous Autoregressive Language Models](http://arxiv.org/pdf/2510.27688v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Variational Inference

### 2. Motivation & Gaps
- The paper addresses the need for efficient variational inference methods in Bayesian models.

### 3. Core Idea
- The algorithm is asymptotically unbiased, meaning that as the batch size increases, the probability of sampling a specific outcome converges to the true target distribution.

### 4. Method
- **Pipeline**: The method involves encoding data into a latent space and decoding it back to the original space while optimizing the variational lower bound.
- **Architecture / Loss / Training**: The architecture is trained using a loss function that combines reconstruction loss and Kullback-Leibler divergence.
- **Complexity / Resources**: The method is computationally efficient, requiring less memory and processing power compared to traditional methods.

</details>
