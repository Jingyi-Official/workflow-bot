# Daily Paper Digest Â· 2025-11-13
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [360Â° Volumetric Portrait Avatar](https://arxiv.org/pdf/2312.05311v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 360Â° avatar generation from monocular video inputs

### 2. Motivation & Gaps
- The method addresses the limitations of monocular tracking, particularly in non-frontal views, which affects the reliability of facial expression and jaw pose tracking.

### 3. Core Idea
- The method generates 360Â° avatars using a single camera or smartphone, enabling broad accessibility for immersive telepresence applications.

### 4. Method
- **Pipeline**: Balanced sampling approach to prevent overfitting to frontal views, data preprocessing including cropping, resizing, and background removal, and using multi-resolution hash grids for encoding.
- **Architecture / Loss / Training**: Deformation network with multi-layer perceptron (MLP) architecture, canonical NeRF network with density and color branches, and mapping network for facial expression to deformation field coefficients.
- **Complexity / Resources**: Utilizes a single camera or smartphone for recording, making it accessible for a wide user base.

</details>

### [X-Avatar: Expressive Human Avatars](https://arxiv.org/pdf/2303.04805v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D human avatar reconstruction

### 2. Motivation & Gaps
- The paper addresses the need for a holistic model that captures body pose, hand pose, facial expressions, and appearance in a unified manner.

### 3. Core Idea
- We propose X-Avatar, the first expressive implicit human avatar model that captures body pose, hand pose, facial expressions, and appearance in a holistic fashion.

### 4. Method
- **Pipeline**: The method utilizes a part-aware initialization and sampling strategy to create avatars from multiple input modalities.
- **Architecture / Loss / Training**: Utilizes volumetric IoU, Chamfer distance, and normal consistency metrics for evaluation.
- **Complexity / Resources**: The model is designed to be three times faster than previous methods while maintaining high fidelity.

</details>

### [3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting](https://arxiv.org/pdf/2312.09228v3)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Animatable avatar generation

### 2. Motivation & Gaps
- The paper addresses the challenge of creating animatable avatars using 3D Gaussian splatting techniques.

### 3. Core Idea
- The core idea is to utilize deformable 3D Gaussian splatting to create realistic and animatable avatars from monocular video input.

### 4. Method
- **Pipeline**: The method involves initializing 3D Gaussians, optimizing them through a series of loss functions, and employing a hierarchical softmax layer for skinning weights.
- **Architecture / Loss / Training**: The architecture includes a forward skinning network, a non-rigid deformation network, and a color network, trained with a combination of RGB loss, mask loss, and skinning loss.
- **Complexity / Resources**: The model is trained on a single NVIDIA RTX 3090 GPU, requiring 15k iterations on the ZJU-MoCap dataset and 30k iterations on PeopleSnapshot.

</details>

## video understanding

### [Assessing Visual Quality of Omnidirectional Videos](https://arxiv.org/pdf/1709.06342v4)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Quality Assessment for Omnidirectional Video

### 2. Motivation & Gaps
- The study investigates viewing preferences in omnidirectional video and proposes metrics for quality assessment.

### 3. Core Idea
- Proposing subjective and objective metrics for assessing the quality of omnidirectional video based on viewer preferences.

### 4. Method
- **Pipeline**: Collecting viewing direction data from subjects and developing metrics based on this data.
- **Architecture / Loss / Training**: A random forest classifier is trained using features derived from the viewing direction database and saliency prediction.
- **Complexity / Resources**: The methods are implemented in MATLAB, with some variations in C++ for performance comparison.

</details>

### [InternVideo2: Scaling Foundation Models for Multimodal Video Understanding](https://arxiv.org/pdf/2403.15377v4)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Multimodal Video Understanding

### 2. Motivation & Gaps
- The paper addresses the need for effective multimodal understanding of video content by integrating audio, video, and speech captions.

### 3. Core Idea
- The core idea is to utilize a foundation model to generate and evaluate multiple types of captions for videos, enhancing the understanding of multimodal content.

### 4. Method
- **Pipeline**: The method involves generating uni-modal and multi-modal captions using designed prompt templates and vLLM for inference acceleration.
- **Architecture / Loss / Training**: The architecture is trained to optimize the generation of captions while maintaining a natural human-like style.
- **Complexity / Resources**: The model requires significant computational resources for training and inference, particularly with large datasets.

</details>

### [CoS: Chain-of-Shot Prompting for Long Video Understanding](https://arxiv.org/pdf/2502.06428v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Multi-shot video generation

### 2. Motivation & Gaps
- The paper addresses the challenges in understanding long videos using large language models (LLMs) and proposes a novel approach to enhance their performance.

### 3. Core Idea
- The core idea is to utilize a chain-of-shot prompting mechanism to improve the understanding of long videos by LLMs, allowing them to process and reason over extended contexts effectively.

### 4. Method
- **Pipeline**: The proposed method involves a series of steps that include video segmentation, shot selection, and prompt generation for LLMs.
- **Architecture / Loss / Training**: The architecture is designed to minimize loss during training by focusing on relevant video segments and optimizing the prompt structure.
- **Complexity / Resources**: The method requires moderate computational resources, leveraging existing LLM architectures with some modifications for video processing.

</details>

## model collapse

### [Collapse. What else?](https://arxiv.org/pdf/1701.08300v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the implications of modifying the SchrÃ¶dinger equation to address the quantum measurement problem.

### 2. Motivation & Gaps
- The paper discusses the measurement problem in quantum mechanics and the need for a theory that incorporates spontaneous collapses to explain physical phenomena.

### 3. Core Idea
- The introduction of spontaneous collapses in quantum mechanics is necessary to reconcile the existence of an observer and the measurement problem.

### 4. Method
- **Pipeline**: The proposed method involves deriving a stochastic differential equation that describes the evolution of quantum states.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The method requires understanding stochastic differential equations and their implications in quantum mechanics.

</details>

### [Collapse models and spacetime symmetries](https://arxiv.org/pdf/1612.09470v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the relationship between wave function collapse and the distribution of matter in spacetime.

### 2. Motivation & Gaps
- The paper explores the nature of wave function collapse and its implications for understanding matter distribution in spacetime.

### 3. Core Idea
- The paper argues for an understanding of collapse models where the wave function describes patterns relating matter densities at different points, with the collapse process corresponding to a Bayesian update based on new matter density information.

### 4. Method
- **Pipeline**: The paper outlines a Bayesian updating process for probability distributions based on noisy measurements.
- **Architecture / Loss / Training**: The model does not specify a traditional architecture or loss training as it is more theoretical in nature.
- **Complexity / Resources**: The complexity arises from ensuring Lorentz invariance and independence of spacetime foliation.

</details>

### [Stronger Tests of the Collapse Locality Loophole in Bell Experiments](https://arxiv.org/pdf/1807.08791v3)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Experimental validation of collapse locality hypotheses in quantum mechanics

### 2. Motivation & Gaps
- The paper discusses the need for experiments to test the essential collapse locality loophole, particularly in relation to Wigner's hypothesis and its implications for consciousness and quantum measurement.

### 3. Core Idea
- To test the essential collapse locality loophole, experiments should involve human observers to directly link consciousness with measurement outcomes, thereby providing a strong motivation for the tests.

### 4. Method
- **Pipeline**: Designing experiments that involve human observers at significant distances to test the collapse locality hypothesis.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Utilizing terrestrial and space-based setups to maximize the time intervals for measurements.

</details>
