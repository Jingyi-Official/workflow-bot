# Daily Paper Digest Â· 2025-11-20
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [B2F: End-to-End Body-to-Face Motion Generation with Style Reference](https://arxiv.org/pdf/2511.13988v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Facial Motion Generation

### 2. Motivation & Gaps
- The paper addresses the challenge of generating realistic facial expressions using a model that does not rely on emotion labels.

### 3. Core Idea
- The B2F model generates facial motion by transforming FLAME parameters into ARKit blendshape weights using a parameter-blended Mixture of Experts architecture.

### 4. Method
- **Pipeline**: FLAME parameters are processed through an encoder and a gating network to blend expert networks for generating ARKit weights.
- **Architecture / Loss / Training**: The model uses a loss function combining reconstruction, alignment, KL divergence, consistency, and cross terms, with dynamic scheduling for the KL term.
- **Complexity / Resources**: Trained on a desktop system with an AMD Ryzen 7 7800X3D CPU and an NVIDIA GeForce RTX 4070 GPU, taking approximately 14 hours.

</details>

### [PFAvatar: Pose-Fusion 3D Personalized Avatar Reconstruction from Real-World Outfit-of-the-Day Photos](https://arxiv.org/pdf/2511.12935v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D avatar reconstruction

### 2. Motivation & Gaps
- Existing methods struggle with generating high-quality 3D avatars from real-world images, particularly in terms of fidelity and detail preservation.

### 3. Core Idea
- PFAvatar introduces a novel method for reconstructing high-quality 3D avatars by fine-tuning a Pose-Aware Diffusion Model and distilling a 3D NeRF-based avatar.

### 4. Method
- **Pipeline**: Fine-tuning a Pose-Aware Diffusion Model using few-shot OOTD examples followed by distilling a 3D NeRF-based avatar.
- **Architecture / Loss / Training**: Integrates ControlNet for pose estimation and introduces a Condition Prior Preservation Loss (CPPL).
- **Complexity / Resources**: Optimized through canonical SMPL-X space sampling and Multi-Resolution 3D-SDS.

</details>

### [Hi-Reco: High-Fidelity Real-Time Conversational Digital Humans](https://arxiv.org/pdf/2511.12662v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D Head Avatar Generation

### 2. Motivation & Gaps
- The paper addresses the need for realistic and deformable head avatars that can be generated from video input.

### 3. Core Idea
- The proposed method utilizes deformable point-based representations to create realistic head avatars that can adapt to various facial expressions and movements.

### 4. Method
- **Pipeline**: The pipeline involves video input processing, point cloud generation, and deformation modeling to create the final avatar.
- **Architecture / Loss / Training**: The architecture employs a loss function that balances realism and fidelity to the input video.
- **Complexity / Resources**: The method requires moderate computational resources, primarily for video processing and point cloud manipulation.

</details>

## video understanding

### [GeoVista: Web-Augmented Agentic Visual Reasoning for Geolocalization](https://arxiv.org/pdf/2511.15705v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Multimodal understanding

### 2. Motivation & Gaps
- The study aims to analyze urban layouts and features in satellite images to determine geographic locations.

### 3. Core Idea
- Utilizing visual cues from satellite images and urban features to accurately identify geographic locations.

### 4. Method
- **Pipeline**: Image analysis followed by feature extraction and location identification.
- **Architecture / Loss / Training**: Hierarchical rewards are introduced during RL to provide nuanced supervision.
- **Complexity / Resources**: The model is trained on diverse data types including normal photos, panoramas, and satellite images.

</details>

### [In-N-On: Scaling Egocentric Manipulation with in-the-wild and on-task Data](https://arxiv.org/pdf/2511.15704v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Egocentric manipulation

### 2. Motivation & Gaps
- The paper addresses the challenges of scaling egocentric manipulation tasks using data collected from both human and robot demonstrations.

### 3. Core Idea
- The core idea is to leverage large-scale human demonstration data to improve the performance of robots in egocentric manipulation tasks.

### 4. Method
- **Pipeline**: The method involves collecting demonstrations from both humans and robots, followed by training models on this data.
- **Architecture / Loss / Training**: The architecture is designed to handle both in-distribution and out-of-distribution data, focusing on robust performance across various tasks.
- **Complexity / Resources**: The method requires significant computational resources for training and data collection.

</details>

### [First Frame Is the Place to Go for Video Content Customization](https://arxiv.org/pdf/2511.15700v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Object Extraction and Caption Generation for Video Annotation

### 2. Motivation & Gaps
- The study aims to enhance video annotation by improving object extraction and caption generation processes.

### 3. Core Idea
- Utilizing a prompt-to-prompt workflow to extract objects and generate captions for video annotation.

### 4. Method
- **Pipeline**: Object extraction followed by background cleanup and caption generation using structured prompts.
- **Architecture / Loss / Training**: LoRA modules of rank 128 for high- and low-noise regime transformers.
- **Complexity / Resources**: Training videos resized to 1344 Ã— 768 with a batch size of 4.

</details>

## model collapse

### [Resolving Ratio Redundancy in Chemical Freeze-out Studies with Principal Component Analysis and Bayesian Calibration](https://arxiv.org/pdf/2511.15707v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Determine chemical freeze-out parameters in ultra-relativistic heavy-ion collisions

### 2. Motivation & Gaps
- This work presents a statistically consistent, data-driven framework for determining the chemical freeze-out parameters using a Principal Component Analysis (PCA)â€“based Bayesian calibration of the Hadron Resonance Gas (HRG) model.

### 3. Core Idea
- The PCAâ€“Bayesian framework introduced here provides a statistically consistent method for determining chemical freeze-out conditions by working in a PCA-decorrelated space.

### 4. Method
- **Pipeline**: Construct yield ratios from identified hadron yields at each collision energy and transform into an orthogonal basis using PCA.
- **Architecture / Loss / Training**: Bayesian calibration performed directly in decorrelated principal-component space, ensuring only independent degrees of freedom enter the analysis.
- **Complexity / Resources**: A Gaussian Process (GP) emulator validated against full HRG calculations provided efficient and accurate predictions across the four-dimensional parameter space.

</details>

### [RoMa v2: Harder Better Faster Denser Feature Matching](https://arxiv.org/pdf/2511.15706v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Feature Matching

### 2. Motivation & Gaps
- The paper addresses the challenges in feature matching, aiming to improve the robustness and efficiency of existing methods.

### 3. Core Idea
- The core idea is to utilize a transformer architecture to enhance feature matching by processing features from multiple views jointly.

### 4. Method
- **Pipeline**: The method involves extracting features from images, projecting them into a lower-dimensional space, and using a transformer for similarity computation.
- **Architecture / Loss / Training**: Covariance weighted Sampson error optimization.
- **Complexity / Resources**: The model requires significant computational resources due to the transformer architecture and the dimensionality of the features.

</details>
