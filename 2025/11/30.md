# Daily Paper Digest Â· 2025-11-30
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [VGGTFace: Topologically Consistent Facial Geometry Reconstruction in the Wild](https://arxiv.org/pdf/2511.20366v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Facial Geometry Reconstruction

### 2. Motivation & Gaps
- The method aims to improve facial geometry reconstruction under various capture conditions, including motion blur and hand shake.

### 3. Core Idea
- The proposed method leverages multi-view information and VGGT capabilities for accurate facial geometry reconstruction.

### 4. Method
- **Pipeline**: Geometry reconstruction using captured images and camera parameters.
- **Architecture / Loss / Training**: Minimizes error with respect to predicted point clouds using the Adam optimizer.
- **Complexity / Resources**: The method is designed to be computationally efficient, allowing for real-time processing on standard mobile devices.

</details>

### [The Making of Digital Ghosts: Designing Ethical AI Afterlives](https://arxiv.org/pdf/2511.20094v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Exploration of AI technologies in the context of digital legacies and grief.

### 2. Motivation & Gaps
- The paper investigates the implications of AI technologies on how we perceive and manage digital legacies after death.

### 3. Core Idea
- To analyze how AI technologies can shape our understanding of death and digital legacies.

### 4. Method
- **Pipeline**: Literature review and qualitative analysis of existing studies on AI and grief.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: N/A

</details>

### [STAvatar: Soft Binding and Temporal Density Control for Monocular 3D Head Avatars Reconstruction](https://arxiv.org/pdf/2511.19854v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D head avatar reconstruction

### 2. Motivation & Gaps
- This work addresses the challenges in reconstructing high-fidelity 3D head avatars from monocular videos, focusing on improving the quality and efficiency of the reconstruction process.

### 3. Core Idea
- The proposed method, ST Avatar, improves the reconstruction of 3D head avatars by utilizing Temporal Adaptive Density Control to allocate higher density to transient or frequently occluded regions, enhancing the detail and accuracy of the reconstructed avatars.

### 4. Method
- **Pipeline**: The method involves offset activation, UV sampling, and silhouette coefficient calculations to ensure accurate Gaussian parameter predictions.
- **Architecture / Loss / Training**: The architecture employs nonlinear activation functions to constrain predicted offsets, ensuring stability and physical validity during training.
- **Complexity / Resources**: The method requires moderate computational resources for training and inference, leveraging efficient sampling strategies.

</details>

## video understanding

### [Canvas-to-Image: Compositional Image Generation with Multimodal Controls](https://arxiv.org/pdf/2511.21691v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Evaluate the fidelity of generated scenes based on identity, pose, spatial layout, and realism.

### 2. Motivation & Gaps
- The paper aims to provide a holistic score for Joint Control Fidelity, assessing how well generated scenes meet multiple control criteria.

### 3. Core Idea
- To create a single score that reflects the overall fidelity of generated images based on identity, pose, layout, and realism.

### 4. Method
- **Pipeline**: Evaluation of generated images against control criteria using a scoring rubric.
- **Architecture / Loss / Training**: Utilizes ArcFace for identity evaluation and HPSv3 for visual quality assessment.
- **Complexity / Resources**: Requires internal datasets and models for pose estimation and instance segmentation.

</details>

### [TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos](https://arxiv.org/pdf/2511.21690v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D motion supervision for robot manipulation

### 2. Motivation & Gaps
- TraceForge provides large-scale 3D motion supervision for training TraceGen.

### 3. Core Idea
- TraceForge achieves centimeter-level motion accuracy for reliable supervision in training TraceGen.

### 4. Method
- **Pipeline**: TraceForge extraction pipeline produces 3D trajectories from RGB-D observations.
- **Architecture / Loss / Training**: Multi-encoder architecture with frozen encoders for efficient training.
- **Complexity / Resources**: Reduced trainable parameters and improved generalization to unseen scenarios.

</details>

### [G$^2$VLM: Geometry Grounded Vision Language Model with Unified 3D Reconstruction and Spatial Reasoning](https://arxiv.org/pdf/2511.21688v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D Reconstruction and Spatial Reasoning

### 2. Motivation & Gaps
- The paper addresses the need for improved integration of geometry and language models in visual tasks.

### 3. Core Idea
- The architecture is a lightweight, 5-layer transformer that applies self-attention exclusively to the features of each individual image.

### 4. Method
- **Pipeline**: Utilizes a pretrained DINOv2 encoder with an additional feature alignment step for geometric perception.
- **Architecture / Loss / Training**: The visual geometry loss function is set with specific weights for each component, and training employs AdamW optimizer with a cosine scheduler.
- **Complexity / Resources**: Low-resolution pretraining runs on 32 A800 GPUs over 7 days and high-resolution runs on 64 A800 GPUs over 3 days.

</details>

## model collapse

### [Revisiting Generalization Across Difficulty Levels: It's Not So Easy](https://arxiv.org/pdf/2511.21692v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Cross-difficulty generalization evaluation

### 2. Motivation & Gaps
- The paper addresses the need for a comprehensive evaluation suite to study cross-difficulty generalization in mathematical problem-solving.

### 3. Core Idea
- The study proposes a method to create training samples that better align with the styles of specific models (Qwen and Llama) to improve performance on difficult mathematical problems.

### 4. Method
- **Pipeline**: Fine-tuning models using specially curated datasets that replace original solutions with model-generated responses.
- **Architecture / Loss / Training**: Models were fine-tuned with a learning rate of 5e-6 using the paged_adamw_8bit optimizer and trained for 5 epochs.
- **Complexity / Resources**: Training utilized 8 GPUs per job with a maximum input sequence length of 4096 tokens and mixed precision.

</details>
