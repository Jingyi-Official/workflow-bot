# Daily Paper Digest Â· 2025-11-28
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [VGGTFace: Topologically Consistent Facial Geometry Reconstruction in the Wild](https://arxiv.org/pdf/2511.20366v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Facial Geometry Reconstruction

### 2. Motivation & Gaps
- The method aims to improve facial geometry reconstruction under various capture conditions, including motion blur and hand shake.

### 3. Core Idea
- The proposed method leverages multi-view information and VGGT capabilities for accurate facial geometry reconstruction.

### 4. Method
- **Pipeline**: Geometry reconstruction followed by mesh re-rendering based on captured camera parameters.
- **Architecture / Loss / Training**: Minimizes error with respect to predicted point clouds using an Adam optimizer.
- **Complexity / Resources**: The method is designed to be computationally efficient, allowing for real-time processing on standard mobile devices.

</details>

### [The Making of Digital Ghosts: Designing Ethical AI Afterlives](https://arxiv.org/pdf/2511.20094v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Exploration of AI technologies in the context of digital legacies and grief.

### 2. Motivation & Gaps
- The paper investigates the implications of AI technologies on how we perceive and manage digital legacies after death.

### 3. Core Idea
- The integration of AI technologies into the management of digital legacies raises significant ethical, emotional, and social questions.

### 4. Method
- **Pipeline**: Literature review and analysis of existing research on AI and digital legacies.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Cost and complexity can vary widely, from simple text chat services to sophisticated custom video avatars.

</details>

### [STAvatar: Soft Binding and Temporal Density Control for Monocular 3D Head Avatars Reconstruction](https://arxiv.org/pdf/2511.19854v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D head avatar reconstruction

### 2. Motivation & Gaps
- This work addresses the challenges in reconstructing high-fidelity 3D head avatars from monocular videos, focusing on improving the quality and efficiency of the reconstruction process.

### 3. Core Idea
- The proposed method, ST Avatar, improves the reconstruction of 3D head avatars by utilizing Temporal Adaptive Density Control to allocate higher density to transient or frequently occluded regions, enhancing the detail and accuracy of the reconstructed avatars.

### 4. Method
- **Pipeline**: The method involves offset activation, UV sampling, and silhouette coefficient calculations to ensure accurate Gaussian parameter predictions.
- **Architecture / Loss / Training**: The architecture employs nonlinear activation functions to constrain predicted offsets, ensuring stability and physical validity during training.
- **Complexity / Resources**: The method requires moderate computational resources for training and inference, leveraging efficient sampling strategies.

</details>

## video understanding

### [Canvas-to-Image: Compositional Image Generation with Multimodal Controls](https://arxiv.org/pdf/2511.21691v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Evaluating the fidelity of generated images based on multiple control types

### 2. Motivation & Gaps
- The paper aims to provide a holistic score for Joint Control Fidelity, reflecting how well generated scenes satisfy identity, pose, spatial layout, and realism.

### 3. Core Idea
- To develop a scoring rubric that evaluates generated images based on identity, pose, spatial layout, and realism.

### 4. Method
- **Pipeline**: The evaluation process involves assessing generated images against control inputs and scoring them based on predefined criteria.
- **Architecture / Loss / Training**: Utilizes ArcFace for identity preservation and DINOv2 for object consistency.
- **Complexity / Resources**: Requires substantial computational resources for training and evaluation.

</details>

### [TraceGen: World Modeling in 3D Trace Space Enables Learning from Cross-Embodiment Videos](https://arxiv.org/pdf/2511.21690v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D motion supervision for robot manipulation

### 2. Motivation & Gaps
- TraceForge provides large-scale 3D motion supervision for training TraceGen.

### 3. Core Idea
- TraceForge achieves centimeter-level motion accuracy for reliable supervision in training TraceGen.

### 4. Method
- **Pipeline**: TraceForge extracts 3D traces from robot motion data.
- **Architecture / Loss / Training**: Multi-encoder architecture with frozen encoders for efficient training.
- **Complexity / Resources**: Reduced trainable parameters and improved generalization.

</details>

### [G$^2$VLM: Geometry Grounded Vision Language Model with Unified 3D Reconstruction and Spatial Reasoning](https://arxiv.org/pdf/2511.21688v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D reconstruction and spatial reasoning

### 2. Motivation & Gaps
- The paper addresses the need for improved integration of geometry and language models in visual tasks.

### 3. Core Idea
- The architecture is a lightweight, 5-layer transformer that applies self-attention exclusively to the features of each individual image.

### 4. Method
- **Pipeline**: Utilizes a DINOv2 encoder followed by a lightweight transformer architecture for processing geometric and semantic features.
- **Architecture / Loss / Training**: The visual geometry loss function is set with specific weights for each component, and training employs AdamW optimizer with a cosine scheduler.
- **Complexity / Resources**: Low-resolution pretraining runs on 32 A800 GPUs over 7 days and high-resolution runs on 64 A800 GPUs over 3 days.

</details>

## model collapse

### [Revisiting Generalization Across Difficulty Levels: It's Not So Easy](https://arxiv.org/pdf/2511.21692v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Cross-difficulty generalization evaluation

### 2. Motivation & Gaps
- The paper addresses the need for a comprehensive evaluation suite to study cross-difficulty generalization in mathematical problem-solving.

### 3. Core Idea
- The study proposes a method to create training samples that better align with the styles of specific models (Qwen and Llama) to improve performance on difficult mathematical problems.

### 4. Method
- **Pipeline**: Collect responses from Qwen and Llama models at various temperatures and finetune models with these datasets.
- **Architecture / Loss / Training**: Models were fine-tuned using full-parameter fine-tuning with specific training configurations and optimizers.
- **Complexity / Resources**: Training utilized DeepSpeed ZeRO Stage 3 on heterogeneous clusters with various NVIDIA GPUs.

</details>
