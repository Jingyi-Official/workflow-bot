# Daily Paper Digest Â· 2025-11-07
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [Audience Amplified: Virtual Audiences in Asynchronously Performed AR Theater](http://arxiv.org/pdf/2511.02807v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate user experience in augmented reality performances with virtual audiences

### 2. Motivation & Gaps
- The study explores the impact of virtual audiences on user experience in augmented reality theater, highlighting the balance between audience presence and user engagement.

### 3. Core Idea
- The integration of ML-trained virtual audience avatars enhances user engagement and social interaction in AR performances.

### 4. Method
- **Pipeline**: Conducted pilot studies to optimize audience avatar appearance and behavior, followed by a user study to assess experience differences.
- **Architecture / Loss / Training**: Utilized imitation learning for avatar behavior modeling.
- **Complexity / Resources**: Involves deep neural networks for avatar training and adaptation to user context.

</details>

### [Treat-through OLED Displays: Dosimetry and performance of OLED AVATAR screens for Megavoltage Radiotherapy](http://arxiv.org/pdf/2511.00331v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Evaluate the impact of OLED screens on radiation dose during radiotherapy treatments.

### 2. Motivation & Gaps
- The study investigates the effects of OLED screens on radiation dose and their potential use in radiotherapy.

### 3. Core Idea
- OLED screens minimally impact radiation dose while providing a reliable communication tool during treatments.

### 4. Method
- **Pipeline**: Data collection through parallel plate ion chamber measurements for various setups.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The OLED screen consists of a 0.25 mm thick flexible OLED panel and a custom carbon fiber backing, with electronic components relocated via ribbon cable.

</details>

### [Avatar Appearance Beyond Pixels -- User Ratings and Avatar Preferences within Health Applications](http://arxiv.org/pdf/2510.26251v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigating the impact of avatar characteristics on user ratings in healthcare applications

### 2. Motivation & Gaps
- Virtual avatars are becoming increasingly popular in healthcare applications, influencing user experience and preferences.

### 3. Core Idea
- The perception of virtual avatars varies significantly among users, with competence and information sharing being more influential than warmth and attractiveness in avatar preferences.

### 4. Method
- **Pipeline**: Repeated measures ANOVA was used to analyze the effects of clothing style and gender on competence ratings.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: N/A

</details>

## video understanding

### [Tracking and Understanding Object Transformations](http://arxiv.org/pdf/2511.04678v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Learning from demonstration and object state change annotation

### 2. Motivation & Gaps
- The technology enables automatic annotation of object state changes in recorded manipulation tasks, reducing manual annotation burden.

### 3. Core Idea
- The integration of TubeletGraph with SAM2.1(ft) aims to improve object tracking and transformation detection in video recordings.

### 4. Method
- **Pipeline**: Integration of TubeletGraph with SAM2.1(ft) for object tracking.
- **Architecture / Loss / Training**: The architecture employs a combination of semantic consistency and spatial proximity constraints to enhance tracking performance.
- **Complexity / Resources**: The method requires computational resources for processing video frames and applying the filtering mechanism.

</details>

### [InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual Generation](http://arxiv.org/pdf/2511.04675v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Generation

### 2. Motivation & Gaps
- The paper addresses the discrepancies in training and inference phases of video generation models, particularly focusing on the limitations of traditional teacher-forcing training methods.

### 3. Core Idea
- The introduction of a bitwise self-correction mechanism to enhance the training process and reduce memory costs through a bitwise classifier.

### 4. Method
- **Pipeline**: The method involves a multi-scale bitwise self-correction mechanism during training, utilizing advanced parallelism techniques for efficient training.
- **Architecture / Loss / Training**: The architecture employs a bitwise classifier that predicts d bits instead of 2d indices, significantly optimizing memory usage.
- **Complexity / Resources**: Utilizes FlexAttention, fully sharded data parallelism, and fine-grained activation checkpointing to manage resources effectively.

</details>

### [X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations](http://arxiv.org/pdf/2511.04671v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Imitation Learning

### 2. Motivation & Gaps
- The research aims to train robots using a limited number of demonstrations in a calibrated multi-camera environment.

### 3. Core Idea
- Targeting network to minimize any gap between hand and end-effector keypoints by unifying proprioception into end-effector position and rotation.

### 4. Method
- **Pipeline**: Baseline trained by equally sampling human and robot demonstrations.
- **Architecture / Loss / Training**: Diffusion Policy UNet architecture.
- **Complexity / Resources**: The approach is scalable and designed to work with large-scale human datasets that are not curated.

</details>

## model collapse

### [Dark Energy Survey Year 3 results: Simulation-based $w$CDM inference from weak lensing and galaxy clustering maps with deep learning. I. Analysis design](http://arxiv.org/pdf/2511.04681v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Cosmological inference using weak lensing mass maps

### 2. Motivation & Gaps
- The paper addresses the need for improved methods in cosmological inference using weak lensing data.

### 3. Core Idea
- Utilizing wavelet harmonics and scattering transforms for enhanced cosmological inference from weak lensing mass maps.

### 4. Method
- **Pipeline**: Simulation-based inference pipeline using wavelet harmonics and scattering transforms.
- **Architecture / Loss / Training**: Graph convolutional neural networks trained jointly on all constrained parameters using a theoretically motivated mutual information loss.
- **Complexity / Resources**: Approximately 15 TB of storage required for the generated maps, with 800,000 maps for training and 200,000 for likelihood estimation.

</details>

### [Carousel: A High-Resolution Dataset for Multi-Target Automatic Image Cropping](http://arxiv.org/pdf/2511.04680v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Image Cropping

### 2. Motivation & Gaps
- The paper addresses the limitations of traditional single-target cropping models when applied to images with multiple distinct subjects.

### 3. Core Idea
- Introducing a dataset with a multi-region saliency partitioning algorithm to enhance single-target cropping models for multi-target images.

### 4. Method
- **Pipeline**: Utilizes a multi-region saliency partitioning algorithm to divide images for processing by single-target cropping models.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: N/A

</details>

### [GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction](http://arxiv.org/pdf/2511.04679v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Humanoid robot interaction with compliance control

### 2. Motivation & Gaps
- The study aims to enhance humanoid robot interactions by integrating compliance control to ensure safer and more stable contact forces during tasks such as hugging and object handling.

### 3. Core Idea
- GentleHumanoid employs impedance control to maintain stable and bounded forces during interactions, particularly in scenarios requiring compliance.

### 4. Method
- **Pipeline**: An autonomous, shape-aware pipeline for personalized hugging using motion capture and RGB camera input for human shape estimation.
- **Architecture / Loss / Training**: Unified spring-based formulation for training the policy to generate coordinated responses across multiple links.
- **Complexity / Resources**: Utilizes a motion capture system and RGB camera for human localization and shape estimation.

</details>
