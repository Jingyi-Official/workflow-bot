# Daily Paper Digest Â· 2025-11-14
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [X-Avatar: Expressive Human Avatars](https://arxiv.org/pdf/2303.04805v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D human pose and shape estimation

### 2. Motivation & Gaps
- The paper addresses the need for a holistic model that captures body pose, hand pose, facial expressions, and appearance in a unified manner.

### 3. Core Idea
- We propose X-Avatar, the first expressive implicit human avatar model that captures body pose, hand pose, facial expressions, and appearance in a holistic fashion.

### 4. Method
- **Pipeline**: The method utilizes a part-aware initialization and sampling strategy to create avatars from multiple input modalities.
- **Architecture / Loss / Training**: The architecture incorporates part-aware initialization and regularization techniques to enhance the learning of hand and face geometry.
- **Complexity / Resources**: The method is designed to be efficient, achieving faster training times while maintaining high fidelity in reconstruction.

</details>

### [360Â° Volumetric Portrait Avatar](https://arxiv.org/pdf/2312.05311v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 360Â° avatar generation from monocular video inputs

### 2. Motivation & Gaps
- Existing monocular tracking methods struggle with non-frontal views, leading to unreliable tracking information for facial expressions and jaw poses.

### 3. Core Idea
- To generate 360Â° avatars using a balanced sampling approach that prevents overfitting to frontal views.

### 4. Method
- **Pipeline**: Capture different views, preprocess data, and use a multi-layer perceptron (MLP) for deformation and appearance networks.
- **Architecture / Loss / Training**: Utilizes perceptual loss and beta loss for improved visual quality.
- **Complexity / Resources**: Requires a single camera or smartphone for recording.

</details>

### [3DGS-Avatar: Animatable Avatars via Deformable 3D Gaussian Splatting](https://arxiv.org/pdf/2312.09228v3)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Animatable avatar generation

### 2. Motivation & Gaps
- The paper addresses the need for high-fidelity, animatable avatars that can be generated in real-time.

### 3. Core Idea
- Our method can generate high-quality images with realistic cloth deformations.

### 4. Method
- **Pipeline**: The pipeline involves initializing 3D Gaussians, optimizing them through a series of loss functions, and rendering the avatars using a neural network.
- **Architecture / Loss / Training**: The loss function combines RGB loss, mask loss, skinning loss, and isometric constraints to ensure accurate avatar representation.
- **Complexity / Resources**: Training time does not match fast grid-based methods.

</details>

## video understanding

### [Assessing Visual Quality of Omnidirectional Videos](https://arxiv.org/pdf/1709.06342v4)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Video Quality Assessment for Omnidirectional Video

### 2. Motivation & Gaps
- The study investigates viewing preferences in omnidirectional video and proposes metrics for quality assessment.

### 3. Core Idea
- Propose subjective and objective metrics for assessing the quality of omnidirectional video based on viewer preferences.

### 4. Method
- **Pipeline**: Collect viewing direction data from subjects and analyze it to develop VQA metrics.
- **Architecture / Loss / Training**: A random forest classifier is trained using features derived from the viewing direction database and saliency prediction.
- **Complexity / Resources**: The methods are implemented in MATLAB and C++, with runtime comparisons showing NCP-PSNR runs fast while CP-PSNR achieves the best performance at a higher complexity.

</details>

### [InternVideo2: Scaling Foundation Models for Multimodal Video Understanding](https://arxiv.org/pdf/2403.15377v4)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Multimodal Video Understanding

### 2. Motivation & Gaps
- The paper addresses the need for effective multimodal video understanding by integrating audio, video, and speech captions.

### 3. Core Idea
- The core idea is to utilize a foundation model to enhance the understanding of multimodal video content by generating various types of captions and improving retrieval and QA tasks.

### 4. Method
- **Pipeline**: The method involves generating uni-modal and multi-modal captions, followed by filtering and sampling based on CLIP similarity.
- **Architecture / Loss / Training**: The architecture employs a video encoder with multiple layers, focusing on the last few layers for feature extraction.
- **Complexity / Resources**: The model requires significant computational resources for training and inference, utilizing vLLM for acceleration.

</details>

### [CoS: Chain-of-Shot Prompting for Long Video Understanding](https://arxiv.org/pdf/2502.06428v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Multi-shot video generation

### 2. Motivation & Gaps
- The paper introduces a training-free test-time optimization mechanism called Chain-of-Shot prompting (CoS) that enhances video understanding by dynamically selecting relevant shots based on specific query tasks.

### 3. Core Idea
- CoS dynamically selects task-relevant positive and task-irrelevant negative videos from sparsely distributed useful shots to enhance models' video understanding ability.

### 4. Method
- **Pipeline**: The method involves a dynamic selection of shots based on the specific query task for each video instance.
- **Architecture / Loss / Training**: The architecture employs a training-free, test-time adaptive plug-in approach, maintaining the same inference time complexity as the baseline.
- **Complexity / Resources**: The method runs efficiently on a single 80G A100 GPU, with both time and space complexity remaining O(n).

</details>

## model collapse

### [Collapse. What else?](https://arxiv.org/pdf/1701.08300v2)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the implications of modifying the SchrÃ¶dinger equation to address the quantum measurement problem.

### 2. Motivation & Gaps
- The paper discusses the measurement problem in quantum mechanics and the need for a theory that incorporates spontaneous collapses to explain physical phenomena.

### 3. Core Idea
- The introduction of spontaneous collapses in quantum mechanics is necessary to reconcile the existence of the observer and the measurement problem.

### 4. Method
- **Pipeline**: Develop a stochastic differential equation that describes the evolution of quantum states in a modified framework.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The method relies on stochastic calculus and the properties of operators in quantum mechanics.

</details>

### [Collapse models and spacetime symmetries](https://arxiv.org/pdf/1612.09470v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the relationship between wave function collapse and the distribution of matter in spacetime.

### 2. Motivation & Gaps
- The paper discusses the implications of dynamical collapse models in the context of gravity and quantum mechanics, particularly focusing on the challenges of integrating gravity with quantum theory.

### 3. Core Idea
- The paper argues for an understanding of collapse models where the wave function describes patterns relating matter densities at different points, and the collapse process corresponds to a Bayesian update based on new matter density information.

### 4. Method
- **Pipeline**: The paper outlines a Bayesian updating process for probability distributions based on noisy measurements.
- **Architecture / Loss / Training**: The model does not specify a traditional architecture or loss training as it is more theoretical in nature.
- **Complexity / Resources**: The complexity arises from ensuring Lorentz invariance and independence of spacetime foliation.

</details>

### [Stronger Tests of the Collapse Locality Loophole in Bell Experiments](https://arxiv.org/pdf/1807.08791v3)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Experimental investigation of collapse locality in quantum mechanics

### 2. Motivation & Gaps
- The paper discusses the need for experiments to test the essential collapse locality loophole in quantum mechanics, particularly in relation to Wigner's hypothesis and the implications of consciousness on quantum measurement.

### 3. Core Idea
- The core idea is to conduct experiments that directly involve human observers to test the essential collapse locality loophole, thereby addressing fundamental questions about consciousness and quantum mechanics.

### 4. Method
- **Pipeline**: Designing experiments that utilize both terrestrial and space-based setups to maximize the time intervals for testing collapse locality.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Utilizing piezocrystals, motors, and controlled explosions to create distinct mass distributions in response to signals.

</details>
