# Daily Paper Digest Â· 2025-11-15
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## avatar

### [Dynamic Avatar-Scene Rendering from Human-centric Context](https://arxiv.org/pdf/2511.10539v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Scene Reconstruction

### 2. Motivation & Gaps
- The paper addresses the challenge of effective information exchange between separately modeled human avatars and background scenes in dynamic scene reconstruction.

### 3. Core Idea
- A shared information mapping mechanism that projects separately designed components into a unified representation space for coherent integration.

### 4. Method
- **Pipeline**: Utilizes lightweight residual MLPs to model Gaussian attributes for scene reconstruction.
- **Architecture / Loss / Training**: Utilizes shared-weight mapping architecture to enhance coherence in integration.
- **Complexity / Resources**: Maintains computational efficiency without exhaustive pairwise interactions.

</details>

### [AHA! Animating Human Avatars in Diverse Scenes with Gaussian Splatting](https://arxiv.org/pdf/2511.09827v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Real-time human novel view synthesis

### 2. Motivation & Gaps
- The paper addresses the need for efficient and effective methods for synthesizing novel views of humans in real-time.

### 3. Core Idea
- The core idea is to utilize pixel-wise 3D Gaussian splatting to achieve generalizable and efficient human view synthesis.

### 4. Method
- **Pipeline**: The method involves a pipeline that processes input images to generate novel views using Gaussian splatting techniques.
- **Architecture / Loss / Training**: The architecture employs a loss function that optimizes the quality of the synthesized views during training.
- **Complexity / Resources**: The method is designed to be computationally efficient, allowing for real-time performance on standard hardware.

</details>

### [Deep Inverse Shading: Consistent Albedo and Surface Detail Recovery via Generative Refinement](https://arxiv.org/pdf/2511.08079v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- De-shading and rendering of human avatars

### 2. Motivation & Gaps
- Advanced fitting algorithms offer promising enhancements for finger reconstruction.

### 3. Core Idea
- The normal enhancement network, conditioned on RGB inputs, effectively detects depth boundaries and corrects associated errors during optimization.

### 4. Method
- **Pipeline**: Our training pipeline ensures depth continuity.
- **Architecture / Loss / Training**: Applies Structural Similarity Index (SSIM) loss to ensure structural similarity during training.
- **Complexity / Resources**: Non-connected triangles occur only within individual rasterization cycles to assist geometry optimization but are excluded from the final reconstructed model.

</details>

## video understanding

### [SSR: Socratic Self-Refine for Large Language Model Reasoning](https://arxiv.org/pdf/2511.10621v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Calculate the longest possible distance between exit 47 and exit 48 on a highway

### 2. Motivation & Gaps
- The problem involves determining the maximum distance between two specific exits on a highway given constraints on the minimum distance between exits.

### 3. Core Idea
- To maximize the distance between exit 47 and exit 48, minimize the distances of all other segments while respecting the total distance constraint.

### 4. Method
- **Pipeline**: Calculate the total distance, determine the minimum distances for other segments, and allocate the remaining distance to the target segment.
- **Architecture / Loss / Training**: Utilizes GPT-5-mini in low-reasoning low-verbosity mode for experiments.
- **Complexity / Resources**: Requires computational resources for running multiple iterations of reasoning tasks across various datasets.

</details>

### [Towards Blind and Low-Vision Accessibility of Lightweight VLMs and Custom LLM-Evals](https://arxiv.org/pdf/2511.10615v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Accessibility-focused video description generation

### 2. Motivation & Gaps
- The paper addresses the challenges faced by blind and low-vision (BLV) users in accessing video content through improved video descriptions.

### 3. Core Idea
- The introduction of two novel evaluation frameworks that highlight the strengths of smaller models in generating objective descriptions and environmental adaptability for BLV users.

### 4. Method
- **Pipeline**: The evaluation involves model loading, input processing, and token generation, with a focus on latency and performance metrics.
- **Architecture / Loss / Training**: Utilizes SmolVLM2-500M-Video-Instruct and SmolVLM2-2.2B-Video-Instruct, fine-tuned for video understanding with temporal mechanisms.
- **Complexity / Resources**: Mobile evaluation shows feasibility of edge deployment with 60-83 second inference times for 500M models on consumer hardware.

</details>

### [Classifying Fibers and Bases in Toric Hypersurface Calabi-Yau Threefolds](https://arxiv.org/pdf/2511.10601v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Analyzing fibration structures in the KS database of Calabi-Yau threefolds

### 2. Motivation & Gaps
- The study aims to understand the distribution and complementarity of different fibration structures for Calabi-Yau threefolds, particularly in the context of 6D F-theory.

### 3. Core Idea
- The research investigates how elliptically fibered Calabi-Yau threefolds can be connected through various transitions and how this relates to the broader context of fibration structures.

### 4. Method
- **Pipeline**: Analysis of fibration structures using the KS database and exploring connections between different geometric structures.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The method involves linear algebra and transformations, requiring computational resources for handling polytopes.

</details>

## model collapse

### [Enhancing the Outcome Reward-based RL Training of MLLMs with Self-Consistency Sampling](https://arxiv.org/pdf/2511.10648v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Reinforcement Learning

### 2. Motivation & Gaps
- The paper addresses the limitations of traditional reinforcement learning methods in generating reliable reasoning processes.

### 3. Core Idea
- SCS introduces consistency-based strategies to enhance the reliability of reasoning in reinforcement learning without relying on expensive reward models.

### 4. Method
- **Pipeline**: The pipeline of our SCS method involves generating a response for each question, applying Truncationâ€“Resampling and Visual-Perturbation to generate several resampled trajectories, and calculating the consistency reward.
- **Architecture / Loss / Training**: The architecture incorporates a consistency reward to penalize incoherent reasoning patterns, optimizing for stable outputs.
- **Complexity / Resources**: The method is designed to be efficient and low-cost, making it suitable for broader applications.

</details>

### [Depth Anything 3: Recovering the Visual Space from Any Views](https://arxiv.org/pdf/2511.10647v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- RGB SLAM

### 2. Motivation & Gaps
- Synthetic datasets provide large-scale training data with ground-truth depth annotations but often contain quality issues that can degrade model training.

### 3. Core Idea
- Apply careful preprocessing to filter problematic samples and ensure high-quality supervision for the teacher model.

### 4. Method
- **Pipeline**: Preprocessing of raw training datasets to remove invalid samples and clip unrealistic depth ranges.
- **Architecture / Loss / Training**: Utilizes a novel architecture with specific loss functions tailored for depth estimation.
- **Complexity / Resources**: Designed to be computationally efficient, requiring fewer resources compared to existing methods.

</details>

### [Ordinary lattice defects as probes of topology](https://arxiv.org/pdf/2511.10646v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Experimental validation of theoretical predictions in acoustic lattices

### 2. Motivation & Gaps
- The study aims to experimentally validate theoretical predictions related to the QWZ operator in active acoustic lattices.

### 3. Core Idea
- The study investigates mid-gap modes bound to ordinary lattice defects in topological crystals, demonstrating their robustness against weak random charge impurities.

### 4. Method
- **Pipeline**: Sequentially activate the pump at frequencies ranging from 1000 Hz to 1080 Hz at each cavity site and record the resulting acoustic pressure.
- **Architecture / Loss / Training**: The Hamiltonian is adjusted to account for intrinsic background loss in the system.
- **Complexity / Resources**: The setup allows for flexible and programmable tuning of hopping phases without spatial constraints.

</details>
