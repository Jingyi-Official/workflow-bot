# Daily Paper Digest Â· 2025-09-07
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## neural rendering

### [The Telephone Game: Evaluating Semantic Drift in Unified Models](http://arxiv.org/pdf/2509.04438v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Evaluating cross-modal stability and semantic preservation in multimodal models

### 2. Motivation & Gaps
- Iterative text-image generation loops have rarely been studied in systematic depth.

- **Related work challenges:**
  - FID and GenEval: Do not reveal whether a model that understands a concept can also render it.
  - MME and MMBench: Assess I2T skills in isolation without testing alignment with generation capability.
  - ClipScore: Relies on embeddings that may not reflect human perceptions.
  - BAGEL: Correct reasoning about images but failing to produce faithful T2I images.
  - Vila-U: Rapid degradation in semantic fidelity across multiple generation cycles.
  - Janus: Weak coupling between visual understanding and generation capabilities.
  - Existing metrics for evaluating T2I and I2T models: They often overlook the drift in meaning across multiple generations.
  - N/A: Position Inconsistency
  - N/A: Object Inconsistency
  - N/A: Style Transition
  - N/A: Quantity Inconsistency
  - N/A: Object Hallucinations
  - N/A: Color Inconsistency
  - MME: Assesses basic perception and reasoning but lacks depth in multimodal evaluation.
  - MMBench: Introduces complex queries but does not fully capture semantic drift.
  - MMMU: Focuses on academic problems but may not address practical multimodal applications.
  - [3]: This work only looks at one generation and is limited to VLM models in general and does not consider unified models.
  - N/A: N/A

### 3. Core Idea
- The Unified Consistency Framework (UCF) employs cyclic evaluation to assess how well unified models maintain semantics across repeated modality shifts.

### 4. Method
- **Pipeline**: Alternates between image-to-text (I2T) and text-to-image (T2I) evaluations.
- **Architecture / Loss / Training**: Utilizes a mixture of transformers architecture with specific parameter counts and image resolutions.
- **Complexity / Resources**: Involves a diverse set of filtered multimodal datasets for training.

### 5. Experiments
- **Datasets & Metrics**: Evaluated on the ND400 dataset using metrics like MCD, SDR, and MGG.
- **Baselines**: BAGEL, Blip-3o, CLIP, DINO, Existing T2I and I2T models, Janus, Janus 1.3B, MPNet, N/A, Show-o, VILA-U, Vila-U, Vila-u
- **Main Results**: BAGEL continues to outperform others in both text â†’ text and image â†’ image settings.
- **Ablations**: Further evaluations using CLIP embeddings and fitted parameters for decay functions.
- **Limitations / Stress Tests**: A modelâ€™s proficiency in complex tasks is highly susceptible to generational decay.

### 6. Takeaways
- **Pros**: Provides practical metrics to assess cross-modal stability., Highlights the importance of cyclic consistency in evaluations., Demonstrates that high single-pass scores do not guarantee cross-modal consistency.
- **Cons**: Existing metrics do not capture semantic drift effectively., Evaluation remains fragmented across different tasks., Current benchmarks may overlook important information retention.
- **Future Work**: Develop more comprehensive metrics for evaluating UMs., Explore additional datasets for robust evaluation., Investigate the impact of semantic drift on real-world applications.

</details>

### [Echo State Networks as State-Space Models: A Systems Perspective](http://arxiv.org/pdf/2509.04422v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Analyzing and training recurrent neural networks

### 2. Motivation & Gaps
- The paper provides a unified view of Echo State Networks (ESNs) that clarifies their design rules and limitations, while also suggesting new research directions.

- **Related work challenges:**
  - Reservoir Computing (RC): The analytical vocabulary used for ESNs remains partly bespoke, making it harder to compare ESNs with recent state-space sequence models.
  - Modern sequence models: They dominate long-context learning through structured kernels and dissipative dynamics, which are not well integrated with ESN frameworks.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Kalman filtering and smoothing: Requires well-posed identification methods for effective state estimation.
  - Subspace identification methods: Depend on sufficient excitation and window length for reliable identification.
  - Nonlinear systems modeling: Challenges arise from non-Lipschitz maps and input-dependent switching.
  - Kalman smoothing, EM, and subspace identification: Supply denoised states and principled hyperparameter updates
  - Contractionâ€“metric learning: Addressing nonâ€“Lipschitz regimes and heavy switching
  - Probabilistic ESNs: Calibrating uncertainty under drift
  - N/A: N/A

### 3. Core Idea
- The analysis bridges classical reservoir computing and modern state-space models, providing a common language for stability, identifiability, and efficiency.

### 4. Method
- **Pipeline**: The framework delineates design rules and remedies for ESNs based on structure and probabilistic regularization.
- **Architecture / Loss / Training**: The architecture leverages structured state-space layers to ensure stability and efficiency in training.
- **Complexity / Resources**: The approach requires careful consideration of model structure and data requirements to avoid mis-specification and ensure robust performance.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize various datasets to evaluate the performance of ESNs under different configurations and metrics.
- **Baselines**: Modern state-space sequence models, N/A, Other neural network architectures, Standard inference tools, Traditional Echo State Networks, Traditional LTI models
- **Main Results**: The framework clarifies ESN design and opens new research directions.
- **Ablations**: Ablation studies reveal the impact of different architectural choices on model performance and stability.
- **Limitations / Stress Tests**: Identifies limits such as nonâ€“Lipschitz regimes and longâ€“delay tasks.

### 6. Takeaways
- **Pros**: Provides a unified framework for understanding ESNs and SSMs., Enhances the analytical vocabulary for ESNs, linking them to established systems theory., Offers principled methods for hyperparameter estimation and spectral shaping.
- **Cons**: The approach may require a deeper understanding of systems theory for practitioners., Potentially complex mappings may complicate the implementation of ESNs., The reliance on theoretical constructs may limit immediate practical applications.
- **Future Work**: Further exploration of the connections between ESNs and other modern SSM architectures., Investigation of practical implementations of the proposed methods in real-world applications., Development of tools to facilitate the transition from ESN heuristics to SSM-based approaches.

</details>

### [Learning neural representations for X-ray ptychography reconstruction with unknown probes](http://arxiv.org/pdf/2509.04402v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Ptychographic imaging reconstruction

### 2. Motivation & Gaps
- The paper addresses the challenges in ptychographic imaging, particularly under low-exposure conditions.

- **Related work challenges:**
  - Conventional iterative methods: Often suboptimal under low-signal conditions.
  - Deep learning approaches: Dependence on extensive paired training datasets which are difficult to acquire.
  - ePIE: Exhibits edge ringing and overfits to training artifacts.
  - PINN: Assumes a known probe, which is difficult to obtain accurately.
  - Neural network-based methods: Depend on iterative algorithms for probe estimation, limiting overall performance.
  - ePIE: Notable degradations in reconstruction quality under reduced overlap ratios.
  - AD: Performance declines rapidly as the overlap ratio decreases.
  - RAAR: Fails to recover object amplitude at lower overlap ratios.
  - ePIE: Significantly affected by Gaussian noise, leading to poor reconstruction quality.
  - APG: Designed for noisy data but still underperforms compared to PtyINR in various conditions.
  - DM, RAAR, WASP, AD: Exhibit greater susceptibility to noise and artifacts, particularly at larger scanning step sizes.
  - ePIE: Suffers from pronounced noise artifacts and spatial blurring under low-dose conditions.
  - APG: Produces diffuse and suboptimal probe amplitude distributions.
  - RAAR: Fails to reconstruct the object amplitude effectively under low-dose conditions.
  - Cherukara et al.: Boundary artifacts in conventional algorithms such as ePIE.
  - Instant-NGP: Efficient encoding of spatial coordinates into learnable features.
  - Vincent et al.: Learning high-frequency signals effectively.
  - Grote, L. et al. Imaging Cu2O nanocube hollowing in solution by quantitative in situ X-ray ptychography.: Limited resolution and fidelity in ptychographic reconstructions.
  - Diaz, A. et al. Characterization of carbon fibers using X-ray phase nanotomography.: Challenges in accurately capturing the phase information of complex samples.
  - HÃ©monnot, C. Y. J. & KÃ¶ster, S. Imaging of Biological Materials and Cells by X-ray Scattering and Diffraction.: Difficulty in imaging biological materials with high fidelity.
  - Maiden et al. (2017): Improvements to ptychographical iterative engine.
  - Thibault & Menzel (2013): Reconstructing state mixtures from diffraction measurements.
  - Hoidn et al. (2023): Physics constrained unsupervised deep learning for rapid reconstruction.
  - Prior works on ptychographic reconstruction: Direct application of mean squared error leads to instability and poor performance under certain conditions.
  - Use of different loss functions: Balancing the trade-offs between loss functions to achieve stable convergence and high-quality reconstructions.
  - Neural network architectures for reconstruction: Different characteristics of objects and probes necessitate distinct architectural considerations to ensure effective reconstruction.
  - SIREN: Oscillatory nature of sine activation function leading to instability in gradient propagation.
  - Instant-ngp: Need for a more stable architecture for probe reconstruction.
  - ePIE: Limited accuracy under high noise conditions.
  - DM: Struggles with fine spatial feature resolution.
  - RAAR: Inconsistent results across varying scanning step sizes.
  - Fast R-CNN: Limited performance in low-exposure scenarios.
  - Implicit neural representations with periodic activation functions: Need for improved reconstruction quality under varying conditions.
  - Instant neural graphics primitives with a multiresolution hash encoding: Complexity in handling diverse imaging conditions.

### 3. Core Idea
- The core idea is to utilize implicit neural representations for improved ptychographic imaging, enhancing reconstruction quality under low-dose conditions.

### 4. Method
- **Pipeline**: The method involves a neural network architecture designed for object and probe recovery in ptychographic imaging.
- **Architecture / Loss / Training**: The architecture employs various loss functions, including â„“1, â„“2, and a specific loss function adopted in PtyINR.
- **Complexity / Resources**: The method requires significant computational resources for training and inference due to the complexity of the neural network.

### 5. Experiments
- **Datasets & Metrics**: Experiments were conducted using simulated diffraction patterns and evaluated using PSNR metrics.
- **Baselines**: AD, APG, DM, Deep learning-based reconstruction methods, Matrix-based representation (AD), Mean squared error, N/A, PINN, PtychoDV, PtychoNN, PtychoNet, RAAR, ReLU-based probe neural network, Traditional ptychographic algorithms, WASP, ePIE, â„“1 loss
- **Main Results**: The results demonstrate that the tailored neural network architectures in PtyINR outperform traditional methods, especially under low-overlap conditions.
- **Ablations**: Ablation studies were performed to assess the impact of different probe recovery procedures and loss functions.
- **Limitations / Stress Tests**: The limitations include sensitivity to initialization and the need for careful tuning of regularization parameters.

### 6. Takeaways
- **Pros**: Achieves superior reconstruction quality., Robust under challenging low-signal conditions., Generalizable to a wide range of computational microscopy problems.
- **Cons**: Requires significant computational resources., Performance may still be constrained by iterative probe estimation., Assumes continuous representation which may not fit all scenarios.
- **Future Work**: Explore further applications in computational microscopy., Investigate improvements in robustness against noise., Develop methods to reduce the need for extensive training datasets.

</details>

## Gaussian Splatting

### [Generation of Lognormal Synthetic Lyman-$Î±$ Forest Spectra for $P_{1D}$ Analysis](http://arxiv.org/pdf/2509.04405v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- P1D analysis in large-scale surveys

### 2. Motivation & Gaps
- The framework aims to improve the accuracy of P1D measurements by addressing systematic uncertainties from various sources, particularly damped LyÎ± systems (DLAs).

- **Related work challenges:**
  - Baryon Oscillation Spectroscopic Survey (BOSS): First detection of baryon acoustic oscillations in the LyÎ± forest region at high redshift.
  - Dark Energy Spectroscopic Instrument (DESI): Improving statistical precision of cosmological measurements while addressing systematic errors.
  - Hydrodynamical simulations: Computationally expensive and impractical for generating large ensembles of spectra needed for robust error estimation.
  - McDonald et al. (2006): Earlier methods relied on a fixed analytic form for the power spectrum, limiting precision and flexibility.
  - KaraÃ§aylÄ± et al. (2020): Previous lognormal methods were not adaptable to the evolving requirements of precision cosmology.
  - N/A: N/A
  - KaraÃ§aylÄ± et al. (2020): Previous methods for mock generation did not accurately track the shape and amplitude of the power spectrum across all scales.
  - Turner et al. (2024): Early measurements relied on composite quasar spectra and statistical continuum fitting techniques, which introduced systematic uncertainties.
  - Previous P1D mock generation method: Limited fidelity in reproducing the shape of the power spectrum
  - Previous methods for P1D analysis: Limited performance within restricted k-ranges tailored to specific measurements.
  - Current methods of DLA identification: False positives can exacerbate biases in P1D measurements.
  - Continuum fitting techniques: Errors introduce small biases across all scales, particularly at lower redshifts.
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The proposed framework leverages uncontaminated mocks to systematically evaluate and mitigate systematic effects in P1D analyses, facilitating robust cosmological parameter estimation.

### 4. Method
- **Pipeline**: The framework generates lognormal mocks that replicate transmission fields with accurate statistical properties.
- **Architecture / Loss / Training**: The method fits an underlying Gaussian correlation function to improve the accuracy of the generated mocks.
- **Complexity / Resources**: Utilizes libraries such as NumPy, SciPy, Astropy, and Matplotlib for data manipulation and visualization.

### 5. Experiments
- **Datasets & Metrics**: The framework is validated using the DESI Early Data Release (EDR) redshift range (2.0 â‰¤ z â‰¤ 3.8).
- **Baselines**: Emulator-based approaches, Hydrodynamical simulations, KaraÃ§aylÄ± et al. (2024), N-body simulations, N/A, Previous P1D analysis methods, Previous lognormal mock methods, Previous method, Walther et al. (2018)
- **Main Results**: Mocks recover the mean transmitted flux with a fractional RMS error of 0.003 and match the P1D shape with an average RMS error of 0.02.
- **Ablations**: Future work will focus on incorporating astrophysical contaminants and continuum estimation uncertainties.
- **Limitations / Stress Tests**: The current model assumes a fixed variance for the Gaussian field, which may introduce biases at low redshifts.

### 6. Takeaways
- **Pros**: Fast and analytically tractable alternative for generating synthetic spectra., Captures essential features of the LyÎ± forest efficiently., Well suited for validation testing where speed and control are critical.
- **Cons**: Less detailed than hydrodynamic simulations., Not sufficient for full cosmological inference., Limited by the coverage and granularity of the training grid in emulator-based approaches.
- **Future Work**: Incorporation of more accurate and flexible synthetic datasets for upcoming DESI releases., Expansion of utility in ongoing and upcoming surveys., Broader range of validation efforts and systematic studies for P1D inference.

</details>

### [SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer](http://arxiv.org/pdf/2509.04379v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D scene segmentation and editing

### 2. Motivation & Gaps
- The paper addresses the need for effective segmentation and editing techniques in 3D scenes.

- **Related work challenges:**
  - DreamFusion: Lack of effective methods that integrate diffusion priors into a systematically designed 3D style transfer pipeline.
  - Instruct-NeRF2NeRF: Current methods struggle to maintain coherence across different viewpoints.
  - NeRF and 3DGS based approaches: Stylized results often lack a layered sense of structure.
  - Neural style transfer: Struggles with maintaining consistency across different viewpoints.
  - Text-driven 3D Editing: Often requires iterative updates, which can be inefficient.
  - 3D style transfer methods: Tend to produce artifacts in complex scenes due to geometry and texture imperfections.
  - NeRF: NeRF offers slower rendering speeds compared to 3D Gaussian Splatting.
  - Gaussian Grouping: While it provides instance-level consistency, it does not guarantee pixel-level 3D consistency.
  - ControlNet: ControlNet regulates generation but may not fully ensure multi-view consistency.
  - Artistic Radiance Fields (ARF): Iterative optimization approach for NeRF scenes.
  - StyleGaussian: Feed-forward approach designed for 3DGS scenes.
  - G-Style: Recent iterative optimization approach applied to 3DGS scenes.
  - ARF [20]: NeRF-based rendering at low FPS.
  - StyleGaussian [22]: Long training times and low rendering speeds.
  - G-Style [23]: Inconsistent stylization across views.
  - Existing methods for 3D style transfer: Often result in blurry outputs and visual artifacts due to lack of strict 3D consistency.
  - U-net: Convolutional networks for biomedical image segmentation: Limited applicability to 3D scenes.
  - Neural style palette: A multimodal and interactive style transfer from a single style image: Lacks focus on 3D scene editing.
  - Styleadapter: A unified stylized image generation model: Does not address segmentation in 3D environments.

### 3. Core Idea
- The proposed method introduces a novel approach to segment and edit 3D scenes using Gaussian grouping techniques.

### 4. Method
- **Pipeline**: The method involves a multi-step pipeline that integrates segmentation and editing processes.
- **Architecture / Loss / Training**: Utilizes a combination of loss functions tailored for 3D data.
- **Complexity / Resources**: Requires moderate computational resources for training and inference.

### 5. Experiments
- **Datasets & Metrics**: Evaluated on various 3D datasets with metrics including segmentation accuracy and editing fidelity.
- **Baselines**: ARF, ARF [20], Artistic Radiance Fields (ARF), Existing 3D style transfer methods, G-Style, G-Style [23], NeRF, Neural style palette, State-of-the-art 3D style transfer methods, State-of-the-art methods in 3D style transfer, StyleGaussian, StyleGaussian [22], Styleadapter, U-net
- **Main Results**: Demonstrated superior performance in segmentation accuracy and editing capabilities compared to baseline methods.
- **Ablations**: Conducted ablation studies to assess the impact of different components in the pipeline.
- **Limitations / Stress Tests**: Identified limitations in handling highly complex scenes and real-time processing.

### 6. Takeaways
- **Pros**: Maintains style fidelity and instance-level consistency., Produces visually coherent and artistically enriched stylization., Effectively integrates diffusion priors into 3D style transfer.
- **Cons**: Existing 2D diffusion models struggle with multi-view consistency., Complexity in ensuring coherence across different viewpoints., Potential artifacts in stylization due to imperfections in geometry reconstruction.
- **Future Work**: Explore further integration of advanced diffusion models., Investigate improvements in instance segmentation techniques., Develop methods to enhance pixel-level consistency in 3D style transfer.

</details>

### [Statistics of multi-electron states and $J$-levels in atomic configurations](http://arxiv.org/pdf/2509.04353v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Derive exact formulas for atomic configurations and distributions of quantum numbers.

### 2. Motivation & Gaps
- The paper presents new formulas that simplify the calculation of atomic configurations and quantum numbers, addressing limitations in previous methods.

- **Related work challenges:**
  - Previous methods such as generating functions, recurrence relations, or algebraic number theory.: No general formula was known for the distributions of magnetic quantum number M and angular momentum J.
  - N/A: N/A
  - N/A: N/A
  - Previous methods for calculating atomic configurations: Limited to small numbers of fermions and involved complex piece-wise polynomials.
  - Recursion relations: Less efficient numerically compared to the new formulas for certain calculations.
  - N/A: N/A

### 3. Core Idea
- The new formulas are based on evaluating generating functions as trigonometric polynomials, allowing for exact calculations of atomic configurations.

### 4. Method
- **Pipeline**: Utilize trigonometric polynomials to derive exact formulas for atomic configurations and quantum distributions.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The new expressions are simpler and more compact than previous methods, making them easier to implement.

### 5. Experiments
- **Datasets & Metrics**: The paper does not specify datasets but discusses the application of formulas in atomic structure calculations.
- **Baselines**: Brute-force calculations, N/A, Previous numerical methods for calculating electronic configurations, Recurrence relations
- **Main Results**: The new formulas provide exact counts of atomic configurations and distributions, outperforming previous methods in simplicity.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The new formulas are less efficient numerically than recursion relations for some cases.

### 6. Takeaways
- **Pros**: Provides a general formula for atomic configurations., Addresses a significant gap in atomic spectroscopy calculations., Utilizes effective mathematical methods for complex problems.
- **Cons**: The resulting expressions can be cumbersome., The method may require advanced mathematical understanding., Limited experimental validation of the derived formulas.
- **Future Work**: Further simplification of the derived formulas., Application of the formulas in practical atomic spectroscopy scenarios., Exploration of related problems in nuclear physics.

</details>

## avatar

### [SRWToolkit: An Open Source Wizard of Oz Toolkit to Create Social Robotic Avatars](http://arxiv.org/pdf/2509.04356v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Human-Robot Interaction (HRI) Evaluation

### 2. Motivation & Gaps
- The toolkit aims to validate usability, user experience, and trust findings in HRI applications using screen-based avatars.

- **Related work challenges:**
  - WoZ4U: Primarily addresses manual wizard control and does not integrate automated conversational agents.
  - Fang et al. (LLM Wizards): While reducing manual workload, it still relies on cloud-based LLM inference, raising data privacy concerns.
  - WebWOZ: Offers a generic architecture but does not focus on local execution of LLMs.
  - Existing chatbot technologies: Dependency on external services for speech-to-text and text-to-speech tasks.
  - Current version of the toolkit: Utilizes screen-based avatars, limiting real-world evaluations.
  - User studies in technology: Limited participant diversity and familiarity with chatbot technologies.
  - Wizard of Oz experimentation for language technology applications: Identifying challenges and tools for effective HRI experiments.
  - On LLM wizards: Identifying large language modelsâ€™ behaviors for wizard of oz experiments: Understanding the impact of LLMs on user perceptions in HRI.
  - Foundations for an empirically determined scale of trust in automated systems: Establishing trust metrics in automated interactions.

### 3. Core Idea
- The toolkit facilitates real-world evaluations of HRI by simulating robotic behavior with screen-based avatars, aiming to optimize user interaction and performance.

### 4. Method
- **Pipeline**: The toolkit's pipeline includes real-time performance improvements and local processing capabilities.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The toolkit is designed to be reproducible with complete source code and deployment instructions available.

### 5. Experiments
- **Datasets & Metrics**: The toolkit evaluates user experience and trust through various role types and design variables.
- **Baselines**: LLM Wizards, System Usability Scale (SUS), Trust in Automated Systems (TIA), User Experience Questionnaire (UEQ), User experience questionnaires, WebWOZ, Wizard of Oz techniques, WoZ4U
- **Main Results**: The findings indicate the importance of design variables in shaping user perceptions.
- **Ablations**: N/A
- **Limitations / Stress Tests**: Future research should address the impact of specific role types and variations in LLMs.

### 6. Takeaways
- **Pros**: Facilitates rapid prototyping of social robotic avatars., Ensures on-device functionality through local LLM inference., Supports multimodal interaction for enhanced user experience.
- **Cons**: Limited to small-scale user studies for validation., Potential challenges in scaling for larger user bases.
- **Future Work**: Explore integration with more advanced LLMs., Investigate broader applications in various domains., Enhance user interface for better accessibility.

</details>

### [Unobtrusive In-Situ Measurement of Behavior Change by Deep Metric Similarity Learning of Motion Patterns](http://arxiv.org/pdf/2509.04174v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the effects of photorealism and personalization on embodiment and self-identification in virtual reality.

### 2. Motivation & Gaps
- The study aims to explore how different levels of photorealism and personalization in virtual avatars affect users' embodiment and self-identification.

- **Related work challenges:**
  - Previous studies on the Proteus effect: Relying on subjective questionnaires and explicit behavioral measurements.
  - Existing motion capture methods: Require complex hardware and extensive analysis.
  - Kilteni et al. [13]: Used complex motion capture and analysis of task-specific movement to measure behavior change, requiring additional hardware and intrusive tracking suits.
  - Rogers et al. [34]: Initial application of motion data for user identification was limited to known individuals seen during training.
  - Miller et al. [23]: Scalability issues in identifying users based on classification methods.
  - Questionnaires: Limited in real-time detection of behavioral changes.
  - Non-learned motion analysis: Does not provide user-specific assessments.
  - ML-Based Identification Error: Requires extensive data for accurate identification.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - First person experience of body transfer in virtual reality: Understanding the psychological effects of body transfer in virtual environments.
  - Systematic review and meta-analysis of virtual reality in mental healthcare: Identifying the impact of virtual reality on body image disturbance.
  - The Proteus effect: The effect of transformed self-representation on behavior: Examining how avatar representation influences user behavior in both virtual and real-world contexts.

### 3. Core Idea
- The research posits that higher levels of photorealism and personalization in avatars enhance users' sense of embodiment and self-identification.

### 4. Method
- **Pipeline**: Participants interact with avatars of varying photorealism and personalization levels while their responses are measured.
- **Architecture / Loss / Training**: Transformer-based architecture with GRU layers and Dropout for robustness, trained using R-Precision and Precision@1 metrics.
- **Complexity / Resources**: Implementation in Python using PyTorch Lightning and PyTorch Metric Learning, with hyperparameter optimization via Weights and Biases.

### 5. Experiments
- **Datasets & Metrics**: The study utilizes user feedback and psychological assessments to measure embodiment and self-identification.
- **Baselines**: Behavioral tasks, ML-Based Identification Error, N/A, Non-learned motion analysis, Non-learned motion analysis based on central tendencies, Previous studies on avatar effects, Questionnaires, Standard psychological measures of embodiment, Subjective post-exposure embodiment questionnaires
- **Main Results**: Results indicate that personalized and photorealistic avatars significantly improve users' embodiment and self-identification.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The study acknowledges limitations in sample diversity and the generalizability of results.

### 6. Takeaways
- **Pros**: In-situ measurement without additional user input, User-specific analysis on the individual level, Real-time evaluation of how avatar changes affect behavior
- **Cons**: Requires understanding of study context for non-learned motion analysis., Limited granularity in retrospective analysis of questionnaires., Potential challenges in identifying reliable motion metrics.
- **Future Work**: Explore further applications of the model in different XR contexts, Investigate the impact of other avatar characteristics on behavior, Enhance the model's accuracy with larger datasets

</details>

### [Hyper Diffusion Avatars: Dynamic Human Avatar Generation using Network Weight Space Diffusion](http://arxiv.org/pdf/2509.04145v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D shape representation

### 2. Motivation & Gaps
- The paper addresses the need for effective 3D shape representations that can be utilized in neural fields and generative diffusion models.

- **Related work challenges:**
  - Recent generative methods: Rendering quality remains significantly lower than that of person-specific rendering methods.
  - Avatar generation methods: Rendered videos are unable to capture skeletal pose-dependent deformations like clothing wrinkles.
  - NeRF-based approaches: Inherit limitations resulting in significantly longer rendering times.
  - NeRF-based approaches: Long rendering times and limitations in dynamic human representation.
  - 3DGS methods: Focus on single identities and lack of articulated 3D human generation.
  - Diffusion models for 3D generation: Computational inefficiency and inability to model pose-dependent deformations.
  - Previous person-specific methods: Limited flexibility in representing variations across individuals.
  - Standard Gaussian noise addition in diffusion models: Potential loss of structural information when flattening network weights.
  - Existing dynamic human rendering techniques: Inability to effectively bind Gaussians to a unified template for accurate representation.
  - PrimDiffusion: Can only generate static human avatars.
  - E3Gen: Limited to static generation based on simple skeleton articulation.
  - Hyperdiffusion: Directly learning the complex, high-dimensional distribution of the network weight space poses significant challenges for training.
  - UNet for motion-aware 3D Gaussians: Limited generalization to unseen poses and the need for disentangling geometry and appearance.
  - Gauhuman: Articulated gaussian splatting from monocular human videos: Limited generalization across different poses and environments.
  - Tech: Text-guided reconstruction of lifelike clothed humans: Dependency on textual input which may not always be available.
  - Dreamhuman: Animatable 3D avatars from text: Requires extensive training data and may not perform well with limited input.
  - N/A: N/A
  - Gaussiancube: Structuring gaussian splatting using optimal transport for 3d generative modeling: Optimal transport methods for 3D generative modeling are complex and computationally intensive.
  - Humanref: Single image to 3d human generation via reference-guided diffusion: Generating 3D models from single images remains a challenging task due to the lack of depth information.
  - E 3gen: Efficient, expressive and editable avatars generation: Creating editable and expressive avatars efficiently is a significant challenge in 3D modeling.

### 3. Core Idea
- The core idea is to develop a novel 3D shape representation that enhances the capabilities of neural fields and generative diffusion models.

### 4. Method
- **Pipeline**: The method involves a pipeline that integrates 3D shape representation with neural network architectures for generative tasks.
- **Architecture / Loss / Training**: The architecture employs a loss function tailored for optimizing 3D shape representations during training.
- **Complexity / Resources**: The method requires moderate computational resources, balancing efficiency and output quality.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize various 3D datasets and metrics to evaluate the performance of the proposed method.
- **Baselines**: 3DGS methods, Dreamhuman, E3Gen, Existing 3D shape representation methods, Existing avatar generation methods, Gauhuman, N/A, NeRF-based methods, Previous diffusion models for 3D generation, Previous person-specific dynamic rendering methods, PrimDiffusion, Standard Gaussian noise diffusion models, State-of-the-art human avatar generation methods, Tech, Traditional generative models
- **Main Results**: The proposed method outperforms existing baselines in terms of accuracy and efficiency in 3D shape generation.
- **Ablations**: Ablation studies demonstrate the impact of different components of the model on overall performance.
- **Limitations / Stress Tests**: Limitations include challenges in handling highly complex shapes and the need for extensive training data.

### 6. Takeaways
- **Pros**: Unifies person-specific rendering and diffusion-based generation., Enables dynamic human avatar generation with pose-dependent deformations., Generates network weights for real-time, controllable rendering.
- **Cons**: Rendering quality remains lower than person-specific methods., Requires extensive training data and time.
- **Future Work**: Explore further optimizations in the diffusion model., Investigate scalability to more complex avatars.

</details>

## video understanding

### [Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual Try-On from a Single Image -- Technical Preview](http://arxiv.org/pdf/2509.04450v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Virtual Try-On

### 2. Motivation & Gaps
- The paper addresses the challenge of virtual try-on in uncontrolled environments by leveraging dance videos.

- **Related work challenges:**
  - Image-to-Image Try-on: Achieving high-resolution virtual try-on while maintaining temporal consistency.
  - Conventional auto-regressive video generators: Suffer from temporal inconsistency issues between distant frames.
  - He et al. [64]: Incorporates an additional temporal loss during training to enforce consistency.
  - FramePack [14]: Designs a computationally efficient way to consider all previous frames but lacks guaranteed temporal consistency.
  - DnD [8]: Generates 5s videos with high resolution but is limited by the duration of the generated video.
  - Dress&Dance: Limited to trained datasets and lacks temporal consistency in long video generation.
  - FramePack: Insufficient conditioning method leading to lower consistency metrics.
  - Kling Video 2.0: Degradation of virtual try-on quality despite achieving some consistency.
  - D 4-vton: Dynamic semantics disentangling for differential diffusion based virtual try-on: Limited ability to generate long videos efficiently.
  - Gp-vton: Towards general purpose virtual try-on via collaborative local-flow global-parsing learning: Inadequate garment fidelity in generated videos.
  - Texture-preserving diffusion models for high-fidelity virtual try-on: Lack of temporal consistency in video generation.
  - Style-based global appearance flow for virtual try-on: Limited adaptability to diverse poses and styles.
  - High-resolution virtual try-on with misalignment and occlusion-handled conditions: Struggles with occlusions and misalignments in real-world scenarios.
  - Full-range virtual try-on with recurrent tri-level transform: Inability to handle complex garment interactions.
  - Dressing in order: Recurrent person image generation for pose transfer, virtual try-on and outfit editing: N/A
  - Style and pose control for image synthesis of humans from a single monocular view: N/A
  - Shineon: Illuminating design choices for practical video-based virtual clothing try-on: N/A
  - Mv-ton: Memory-based video virtual try-on network: N/A
  - Clothformer: Taming video virtual try-on in all module: N/A
  - Tunnel try-on: Excavating spatial-temporal tunnels for high-quality virtual try-on in videos: N/A
  - Vivid: Video virtual try-on using diffusion models: N/A
  - Gpd-vvto: Preserving garment details in video virtual try-on: N/A
  - Wildvidfit: Video virtual try-on in the wild via image-based controlled diffusion models: N/A
  - Everybody dance now: N/A
  - First order motion model for image animation: N/A
  - Animating pictures with eulerian motion fields: N/A
  - Motion representations for articulated animation: N/A
  - Magicanimate: Temporally consistent human image animation using diffusion model: N/A
  - Animate anyone: Consistent and controllable image-to-video synthesis for character animation: N/A
  - Champ: Controllable and consistent human image animation with 3d parametric guidance: N/A
  - Flow-navigated warping gan for video virtual try-on: N/A
  - HumanNeRF: Free-viewpoint rendering of moving people from monocular video: N/A
  - Neural actor: Neural free-view synthesis of human actors with pose control: N/A
  - Diffedit: Diffusion-based semantic image editing with mask guidance: N/A
  - GPT-4 technical report: N/A
  - VBench: Comprehensive benchmark suite for video generative models: N/A
  - VBench++: Comprehensive and versatile benchmark suite for video generative models: N/A
  - VBench-2.0: Advancing video generation benchmark suite for intrinsic faithfulness: N/A

### 3. Core Idea
- Utilizing dance videos to enhance the realism and adaptability of virtual try-on systems.

### 4. Method
- **Pipeline**: The proposed method involves a multi-stage pipeline that processes dance videos to extract garment features and apply them to target images.
- **Architecture / Loss / Training**: The architecture employs a combination of generative adversarial networks and diffusion models, with a focus on minimizing appearance loss and maintaining semantic consistency.
- **Complexity / Resources**: The method requires significant computational resources for training, including high-performance GPUs and large datasets of dance videos.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize a dataset of dance videos and standard metrics for evaluating virtual try-on performance, such as visual fidelity and user satisfaction.
- **Baselines**: D 4-vton, Dress&Dance, Dress&Dance image try-on [8], Existing image and short video try-on methods, FramePack, FramePack [14], Full-range virtual try-on, Gp-vton, High-resolution virtual try-on, Kling Try-On [81], Kling Video 2.0, Kling Video 2.0 [81], N/A, Style-based global appearance flow, Texture-preserving diffusion models
- **Main Results**: The proposed method outperforms existing baselines in terms of visual quality and adaptability to different poses.
- **Ablations**: Ablation studies demonstrate the importance of each component in the pipeline, particularly the video-based feature extraction.
- **Limitations / Stress Tests**: The method shows limitations in extreme poses and complex garment interactions, which require further refinement.

### 6. Takeaways
- **Pros**: Generates arbitrarily long virtual try-on videos from a single image., Achieves high-resolution outputs with temporal consistency., Enables free viewpoint rendering and 3D consistency.
- **Cons**: Requires careful selection of anchor videos for consistency., Computationally demanding despite improvements.
- **Future Work**: Explore further improvements in temporal consistency., Investigate the use of additional data sources for training., Develop methods for real-time video generation.

</details>

### [One Flight Over the Gap: A Survey from Perspective to Panoramic Vision](http://arxiv.org/pdf/2509.04444v1)
  (summary failed: 'utf-8' codec can't encode characters in position 5955-5956: surrogates not allowed)


### [Delta Activations: A Representation for Finetuned Large Language Models](http://arxiv.org/pdf/2509.04442v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Model selection and merging in language models

### 2. Motivation & Gaps
- The proposed Delta Activations method facilitates efficient reuse of fine-tuned models by providing an embedding to encode the finetuned modelâ€™s behaviors and capability.

- **Related work challenges:**
  - Existing approaches to represent LLMs: Many methods require access to original training data, which is often proprietary or inaccessible, and cannot differentiate models trained on the same data with different settings.
  - Dimensionality reduction on model weights: Assumes consistent adapter configurations across models, which is unrealistic given the diversity of community-trained LLMs.
  - Evaluation-based embeddings: Reflect only surface-level behavior and are fragile to prompt variations.
  - Ren & Sutherland [53]: Understanding how finetuning on one data point affects responses on others.
  - Previous methods using PCA or matrix factorization: These methods do not differentiate models trained on the same dataset and require metadata.
  - Delta Activations: Traditional methods like flattened weights fail to form effective clusters.
  - Recent works on LLM outputs: Outputs from different LLMs are highly distinguishable, yet existing methods do not leverage this effectively.
  - N/A: N/A
  - Ilharco et al. [23]: Merging task vectors from finetuning to achieve multi-task learning.
  - Ortiz-Jimenez et al. [47]: Model interference identified when similar models are entangled, resulting in poor merging performance.
  - Recent works on embedding models: Existing methods rely on inaccessible data or fail to reflect internal behavior.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: Expanding public model hubs introduces risks, as low-quality or adversarial models could contaminate the pool.

### 3. Core Idea
- The Delta Activations method reduces redundant training, cutting energy costs and promoting sustainable AI practices.

### 4. Method
- **Pipeline**: Delta Activations measure shifts in internal activations to form domain clusters.
- **Architecture / Loss / Training**: Architecture-agnostic approach that successfully forms domain clusters.
- **Complexity / Resources**: Requires access to internal hidden states, which may not be feasible for proprietary models.

### 5. Experiments
- **Datasets & Metrics**: OpenCoder-LLM, GSM8K, HellaSwag, LegalBench, PubMedQA
- **Baselines**: Flattened weights, Gemma, LLAMA-3.1-8B, LLaMA, N/A, Nearest-neighbour selection, Output sentence embeddings, Qwen, Random model selection, Salient mask
- **Main Results**: Silhouette scores for sub-expertise clustering within domains.
- **Ablations**: Further evaluation on other architectures is needed to understand broader applicability.
- **Limitations / Stress Tests**: Delta Activations require access to internal hidden states, limiting evaluation on proprietary models.

### 6. Takeaways
- **Pros**: Delta Activations provide a compact behavioral indicator of model differences., The method is robust across different finetuning settings., It exhibits an additive property when combining finetuning datasets.
- **Cons**: Requires a fixed set of generic prompt templates., May not capture all nuances of model behavior.
- **Future Work**: Explore Delta-X for embedding models finetuned from different base LLMs., Further investigate applications in model selection and merging., Encourage the reuse of publicly available models.

</details>
