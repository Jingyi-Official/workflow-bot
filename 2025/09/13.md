# Daily Paper Digest ¬∑ 2025-09-13
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## neural rendering

### [FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark](http://arxiv.org/pdf/2509.09680v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Text-to-Image Generation

### 2. Motivation & Gaps
- The paper addresses the challenges in text-to-image generation, particularly in complex tasks such as text rendering and long instruction following.

- **Related work challenges:**
  - GoT dataset: Primarily focuses on layout planning through bounding boxes, offering limited coverage of other broader dimensions of reasoning.
  - Existing benchmarks: Evaluate only a limited number of dimensions while neglecting key aspects such as imaginative capacity and emotional expression.
  - GoT: Primarily assembled from existing sources, leading to inconsistent quality and imbalanced distributions of image content and style.
  - Generative models for image synthesis: Producing high-quality images consistently.
  - Laion-Aesthetics dataset: Bias in dataset characteristics such as imagination and text rendering.
  - Quality assurance in image datasets: Ensuring clarity and structural consistency in generated images.
  - Existing T2I benchmarks: Lack of fine granularity and inability to differentiate between state-of-the-art models.
  - Existing evaluation methods for VLMs: Lack of specificity in assessing model performance across different categories.
  - PRISM-Bench: Incorporating high density of details from complex prompts.
  - Unified Aesthetic Evaluation: Ensuring fair comparison of visual quality across different models.
  - Qwen-Image: Performance gap compared to top models.
  - HiDream-I1-Full: Maintaining high fidelity in creative interpretation.
  - FLUX.1-Krea-dev: Text rendering remains a significant challenge.
  - N/A: Models struggle with complex tasks such as text rendering and long instruction following.
  - Hrs-bench: Holistic, reliable and scalable benchmark for text-to-image models: Existing models struggle with complex tasks.
  - Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts: Limited performance in fine-grained human-aligned evaluation.
  - Attend-and-excite: Attention-based semantic guidance for text-to-image diffusion models: Need for improved semantic alignment in generated images.
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- Development of PRISM-Bench, a comprehensive benchmark for evaluating text-to-image models using advanced VLMs.

### 4. Method
- **Pipeline**: Evaluation of models based on quantitative metrics and qualitative assessments.
- **Architecture / Loss / Training**: Utilizes Qwen-VL for generating captions and reasoning processes.
- **Complexity / Resources**: Utilizes advanced VLMs like GPT-4.1 and Qwen2.5-VL-72B for evaluation.

### 5. Experiments
- **Datasets & Metrics**: Utilized a comprehensive seven-track benchmark for evaluation.
- **Baselines**: Bagel, Bagel-CoT, Existing T2I benchmarks, Existing open-source models, FLUX.1-Krea-dev, GPT-4.1, GPT-Image-1, Gemini-2.5-Pro, Gemini2.5-Flash-Image, HiDream-I1-Dev, HiDream-I1-Full, Laion-Aesthetics dataset, Leading closed-source systems, N/A, Qwen-Image, Qwen2.5-VL-72B, Qwen3-32B, SEEDream 3.0, SEEDreeam 3.0, Traditional captioning methods
- **Main Results**: Leading models show impressive performance but struggle with complex tasks.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The Long text track remains the greatest challenge for all models.

### 6. Takeaways
- **Pros**: Provides a large-scale dataset for training reasoning-oriented T2I models., Introduces a comprehensive evaluation benchmark closely aligned with human judgment., Addresses key challenges in existing datasets and benchmarks.
- **Cons**: The dataset creation process is resource-intensive and costly., Existing models may still struggle with complex and detailed prompts.
- **Future Work**: Encourage further research on reasoning capabilities in T2I models., Explore additional dimensions of evaluation beyond current benchmarks., Develop more efficient methods for dataset creation and evaluation.

</details>

### [SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning](http://arxiv.org/pdf/2509.09674v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Scaling Vision-Language-Action (VLA) training using reinforcement learning techniques.

### 2. Motivation & Gaps
- The paper addresses the challenges in scaling VLA training, which is crucial for improving the performance of robotic systems in complex environments.

- **Related work challenges:**
  - DeepSeek-R1: Limited generalization and reliance on expensive human-operated robotic trajectories.
  - SFT: Requires large amounts of high-quality robot trajectories which are scarce.
  - Ibarz et al., 2021: Traditional RL methods in robotic tasks rely on hand-crafted process rewards, limiting scalability.
  - Kroemer et al., 2021: VLA models require multi-round interactions with the environment, making the process slower and more costly.
  - Ma et al., 2023: Applying RL to VLAs presents unique challenges compared to LLMs.
  - DeepSeek-R1: Requires carefully crafted reward functions for RL training.
  - Previous works on RL exploration: VLA models tend to converge on a narrow set of solution patterns due to homogeneity in training trajectories.
  - Dynamic Sampling: Critic-free RL algorithms suffer from vanishing gradients when trajectories are assigned the same rewards.
  - GRPO algorithm [Shao et al., 2024]: The need for a reference model during training limits exploration and increases memory consumption.
  - DAPO [Yu et al., 2025]: KL divergence regularization constrains policy divergence, potentially limiting exploration of new behaviors.
  - Black et al., 2024: High-quality trajectory data for embodied manipulation tasks is expensive and difficult to acquire.
  - Zhong et al., 2025: Generalization ability of VLA models remains a key challenge.
  - Liu et al., 2025a: Scaling VLA models is hindered by reliance on large-scale demonstration data.
  - SFT: SFT suffers from severe overfitting and performance degradation on unseen tasks.
  - RDT: RDT does not utilize RL training, limiting its performance on diverse tasks.
  - DeepSeek-R1: Demonstrates the emergence of novel strategies through RL, highlighting the limitations of supervised fine-tuning (SFT).
  - RLHF: Aligns base models with human preferences but heavily relies on preference modeling, which may limit exploration.
  - DAPO: Introduces a decoupled variant of PPO clipping to enhance exploration but may not address all performance thresholds.
  - E-COT: Improving spatial reasoning ability of VLA models.
  - RDT-1B and VPP: Proposing diffusion-based frameworks for VLA models.
  - Dexmimicgen: Addressing data scarcity in robotics.
  - How to train your robot with deep reinforcement learning: lessons we have learned: Identifying effective strategies for training robots using deep reinforcement learning.
  - A review of robot learning for manipulation: Challenges, representations, and algorithms: Understanding the complexities and limitations in robot learning for manipulation tasks.
  - Eureka: Human-level reward design via coding large language models: Designing rewards that align with human-level understanding in reinforcement learning.
  - Previous approaches to VLA training: Limited scalability and generalization capabilities.
  - Reinforcement learning methods: Inefficiencies in training large models.
  - Existing benchmarks: Lack of comprehensive datasets for evaluating VLA models.

### 3. Core Idea
- The proposed method introduces a scalable framework for VLA training that leverages reinforcement learning to enhance model performance and generalization.

### 4. Method
- **Pipeline**: The training pipeline consists of data collection, model training using reinforcement learning, and evaluation on various benchmarks.
- **Architecture / Loss / Training**: Utilizes a combination of policy optimization and value-based methods to improve learning efficiency.
- **Complexity / Resources**: The method is designed to be resource-efficient, allowing for training on standard hardware setups.

### 5. Experiments
- **Datasets & Metrics**: The experiments are conducted on several benchmark datasets, measuring performance using standard metrics for VLA tasks.
- **Baselines**: DP [Chi et al., 2024], DP3 [Ze et al., 2024], DeepSeek-R1, Existing VLA models, LLM-based generation methods, Model fine-tuned with 100 demonstration trajectories, Model fine-tuned with 1000 demonstration trajectories, Nora [Hung et al., 2025], Octo [Team et al., 2024], OpenVLA [Kim et al., 2024], OpenVLA-OFT, OpenVLA-OFT base model without trajectory fine-tuning, RDT, RDT-1B [Liu et al., 2024], RL, SFT, SFT-tuned models, State-of-the-art robotic manipulation systems, Supervised Fine-Tuning (SFT), Traditional RL approaches, Traditional reinforcement learning approaches, UniVLA [Bu et al., 2025b], ùúã0, ùúã0 [Black et al., 2024], ùúãfast [Pertsch et al., 2025]
- **Main Results**: The proposed method outperforms existing baselines in terms of both efficiency and effectiveness in VLA tasks.
- **Ablations**: Ablation studies demonstrate the impact of various components of the proposed method on overall performance.
- **Limitations / Stress Tests**: The method shows limitations in highly dynamic environments where real-time adaptation is required.

### 6. Takeaways
- **Pros**: Improves long-horizon planning under data scarcity., Surpasses SFT in simulation and real-world tasks., Strengthens spatial/object/goal generalization.
- **Cons**: Requires substantial computational resources., Challenges in data collection for training., Potential limitations in generalization to highly diverse tasks.
- **Future Work**: Explore further enhancements in RL for VLA models., Investigate additional strategies for data efficiency., Develop methods to improve generalization across diverse environments.

</details>

### [Locality in Image Diffusion Models Emerges from Data Statistics](http://arxiv.org/pdf/2509.09672v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Image Generation using Denoising Diffusion Probabilistic Models

### 2. Motivation & Gaps
- The paper addresses the efficiency and effectiveness of various denoising methods in image generation, particularly focusing on the Wiener filter and its application in DDPMs.

- **Related work challenges:**
  - Kamb and Ganguli: Their theory cannot predict the degree of locality from first principles.
  - Recent analytical models: They do not match the performance of deep diffusion models.
  - Yoon et al.: Introduce the memorization-generalization dichotomy, positing that diffusion models generalize when they avoid memorizing training data.
  - Yi et al.: Formalize generalization through mutual information metrics, demonstrating that trained diffusion models can generalize beyond the empirical optimal solutions.
  - Gu et al.: Investigate factors such as dataset size and conditioning that can influence the extent of memorization in diffusion models.
  - N/A: N/A
  - Previous work on learned sensitivity fields in diffusion networks: Understanding the generalization of these fields and their dependence on local data statistics.
  - Kamb and Ganguli [12]: Patch-based locality erasing eyes and blurring out facial features.
  - Niedoba et al. [19]: Limited performance in capturing dataset-dependent locality.
  - Previous diffusion models: Assumption of Gaussian datasets and reliance on architectural inductive biases.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Optimal Denoiser: Produces noisy single-step predictions for high noise levels.
  - Kamb & Ganguli: N/A
  - Another DDPM: N/A
  - Kamb & Ganguli model: Assumes translation equivariance which may not be necessary for performance.
  - Niedoba et al. model: Performance degradation observed with equivariance to translations.

### 3. Core Idea
- The proposed method optimizes image generation by implementing a Wiener filter and analyzing algorithmic complexity while forgoing unnecessary assumptions like translation equivariance.

### 4. Method
- **Pipeline**: The method involves applying a Wiener filter iteratively during the image generation process using DDIM sampling.
- **Architecture / Loss / Training**: Trained for 200 epochs with a batch size of 32 using Adam optimizer and a learning rate of 10^-4.
- **Complexity / Resources**: The method has a complexity of O(nptm) for image generation, with computational resources including a server with 1008GB RAM, 128 CPU cores, and 8 NVIDIA RTX A6000 GPUs.

### 5. Experiments
- **Datasets & Metrics**: The experiments were conducted on datasets such as CIFAR10, CelebA-HQ, AFHQv2, MNIST, and Fashion MNIST, measuring total sampling time over 10 denoising steps.
- **Baselines**: Analytical models based on optimal denoiser, Another DDPM, Another trained diffusion model, Diffusion Transformer, Kamb & Ganguli, Kamb and Ganguli [12], N/A, Niedoba et al., Niedoba et al. [19], Optimal Denoiser, Optimal denoiser, Previous patch-based analytical models, Simple Wiener filter, U-Net, U-Net with self-attention, U-Net without self-attention, Unet, Wiener (linear), Wiener filter
- **Main Results**: The proposed method shows competitive performance in terms of sampling time compared to baselines, with specific times reported for each dataset.
- **Ablations**: Ablation studies on binarization thresholds showed varying effects on image quality.
- **Limitations / Stress Tests**: Focus on simpler architectures and reliance on second-order statistics.

### 6. Takeaways
- **Pros**: Demonstrates locality as a learned property of deep diffusion models., Establishes a quantitative benchmark for analytical diffusion models., Integrates analytically-computed locality into existing models for improved performance.
- **Cons**: The theory cannot predict locality from first principles., Relies on statistical properties of training data, which may not generalize., Prior methods based on optimal denoiser are limited in performance.
- **Future Work**: Explore further implications of locality in other generative models., Investigate the relationship between dataset characteristics and model performance., Develop methods to generalize locality insights across different architectures.

</details>

## Gaussian Splatting

### [Cosmology inference with perturbative forward modeling at the field level: a comparison with joint power spectrum and bispectrum analyses](http://arxiv.org/pdf/2509.09673v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Cosmological inference from galaxy redshift surveys

### 2. Motivation & Gaps
- The paper addresses the challenges in accurately reconstructing the initial conditions of the universe from large-scale structure data.

- **Related work challenges:**
  - Previous studies on field-level cosmological analyses: Most analyses focused on simple examples with limited cosmological parameters.
  - Perturbative forward modeling: Specifying the forward model and likelihood in the nonlinear regime is nontrivial.
  - Ref. [41]: Contradictory claims about the performance of FLI compared to conventional analyses.
  - Ref. [42]: Significant discrepancies in error bars on cosmological parameters between FLI and joint power spectrum analyses.
  - Ref. [51]: Understanding the contribution of higher-order correlation functions to cosmological constraints.
  - Ref. [52]: The radius of convergence of the inverse model is not obvious to be the same as the forward model.
  - Refs. [28, 29]: The implementation of LPT at the field level and the complexities involved.
  - N/A: Degeneracy of linear bias and stochastic noise with cosmological parameters.
  - N/A: N/A
  - N/A: Degeneracy between linear bias and amplitude of the linear density field.
  - N/A: N/A
  - Hybrid Monte Carlo (HMC): The challenge of tuning the mass matrix to balance sampling efficiency across parameters.
  - No-U-Turn Sampler (NUTS): Adapting trajectory length and step size during the warm-up phase for effective sampling.
  - Ref [52]: Direct comparison of posteriors for FLI and standard inference approach.
  - Sec. II: Testing predictions for SNR with varying free parameters.
  - Sec. VI and Sec. VII: Discussing implications of non-Gaussianity in residual field-level noise.
  - N/A: Incorporating higher-order statistics does not automatically lead to improved constraints unless they break parameter degeneracies.
  - N/A: The power spectrum analysis is no longer optimal when varying the noise amplitude.
  - N/A: Shifts in best-fit parameters can be comparable to estimated error bars, leading to biased results.
  - N/A: Degeneracy patterns in cosmological parameter estimation
  - Previous studies on Eulerian perturbation theory: The complexities of real galaxy density fields and their relation to dark matter.
  - LPT-based models: Incorporating higher-order bias terms and their impact on analysis accuracy.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Ref [28]: Demonstrated that the distribution of residuals is non-Gaussian, complicating the use of Gaussian likelihoods.
  - Perturbative forward modeling: While it can account for non-Gaussian noise, it often relies on Gaussian likelihoods, which may not be valid.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Bayesian reconstruction of the cosmological large-scale structure: Methodology and numerical optimization issues.
  - Fast Hamiltonian sampling for large scale structure inference: Efficiency in sampling and parameter estimation.
  - Bayesian physical reconstruction of initial conditions: Handling non-linear and stochastic biases in tracers.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The paper proposes a microcanonical Langevin Monte Carlo method for field-level inference, improving the sampling efficiency of cosmological parameters.

### 4. Method
- **Pipeline**: The method involves a Bayesian framework for reconstructing the initial density field using MCMC techniques.
- **Architecture / Loss / Training**: Involves tuning the mass matrix based on local curvature of the log-posterior during the warm-up phase.
- **Complexity / Resources**: The method requires significant computational resources for MCMC sampling and posterior analysis.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize mock catalogs and real galaxy redshift survey data to validate the proposed method.
- **Baselines**: Bispectrum analysis, Density-dependent likelihood, Field-level analysis, Gaussian likelihood, Gaussian noise case, Gaussian realizations of stochastic fields, Hamiltonian Monte Carlo approaches, Joint power spectrum analysis, Joint power spectrum and bispectrum analysis, N/A, One-loop bispectrum analysis, Power spectrum analysis, Previous HMC implementations, Standard MCMC methods, Standard inference approach, Traditional MCMC methods, joint power spectrum and bispectrum analysis
- **Main Results**: The proposed method shows improved sampling efficiency and accuracy in reconstructing the initial conditions compared to traditional methods.
- **Ablations**: Tested the impact of varying grid sizes and parameter priors on inference results.
- **Limitations / Stress Tests**: The method exhibits slow mixing for certain parameters, indicating potential limitations in sampling efficiency.

### 6. Takeaways
- **Pros**: Optimal use of full information in observed field., Accurate recovery of cosmological parameters., Robustness in performance across different setups.
- **Cons**: Challenges in specifying the correct likelihood., Potential biases with non-Gaussian noise., Limited exploration of complex cosmological scenarios.
- **Future Work**: Explore applications to real data., Investigate effects of non-Gaussian noise further., Extend analyses to more complex cosmological models.

</details>

### [Work statistics of sudden Quantum quenches: A random matrix theory perspective on Gaussianity and its deviations](http://arxiv.org/pdf/2509.09640v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Analyzing the work distribution in sudden quenches using random matrix theory

### 2. Motivation & Gaps
- The study investigates the work distribution in quantum systems undergoing sudden quenches, mapping it onto a random matrix problem to understand its Gaussian core and non-Gaussian tails.

- **Related work challenges:**
  - Previous studies on quantum thermodynamics: Lack of precise characterization of work distributions in sudden quenches
  - Research on Loschmidt amplitude and work statistics: Need for rigorous connections between work distributions and random matrix theory
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Deffner and Campbell, Quantum Thermodynamics: Understanding thermodynamic behavior in quantum systems.
  - Gorin et al., Physics Reports: Explaining the dynamics of quantum systems under various conditions.
  - P√©rez-Garc√≠a et al., Physical Review Research: Identifying the effects of critical points on work distribution.
  - N/A: N/A

### 3. Core Idea
- The multivariate central limit theorem predicts a Gaussian core for the work distribution in large systems, with specific variance determined by quench parameters.

### 4. Method
- **Pipeline**: Mapping work distribution to random matrix theory and analyzing statistical properties.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The method involves complex mathematical constructs including Toeplitz determinants and random matrix theory.

### 5. Experiments
- **Datasets & Metrics**: Data from sudden quenches analyzed through histogram/Q‚ÄìQ pairs and variance/kurtosis trends.
- **Baselines**: Gaussian distribution, Gaussian distribution models, N/A, Non-Gaussian distribution models, Previous empirical studies on work statistics
- **Main Results**: The data aligns with the random-matrix central limit theorem, showing a Gaussian bulk with variance determined by quench parameters.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The results are contingent on the interaction range and the number of harmonics included in the model.

### 6. Takeaways
- **Pros**: Provides a rigorous framework for understanding work statistics in quantum systems., Establishes connections between quantum thermodynamics and random matrix theory., Offers insights into the conditions leading to Gaussian and non-Gaussian distributions.
- **Cons**: Complex mathematical framework may limit accessibility for experimentalists., Results depend on specific model assumptions that may not generalize., Potential for misinterpretation of non-Gaussian features in practical applications.
- **Future Work**: Explore experimental validation of theoretical predictions., Investigate implications for other quantum systems beyond quadratic fermionic chains., Develop simplified models for broader applicability in quantum thermodynamics.

</details>

### [Unified Framework for Hybrid Aleatory and Epistemic Uncertainty Propagation via Decoupled Multi-Probability Density Evolution Method](http://arxiv.org/pdf/2509.09535v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Uncertainty propagation in dynamical systems

### 2. Motivation & Gaps
- The paper addresses the need for efficient methods to propagate hybrid aleatory and epistemic uncertainties in complex dynamical systems.

- **Related work challenges:**
  - Conventional double-loop approaches for uncertainty propagation: High computational costs for large engineering systems
  - Faes et al. (2020, 2021) approach: Limited to linear systems and relies on statistical linearization for weakly nonlinear systems
  - Probability density evolution method (PDEM): Diminished accuracy for large variation in input distributions and lack of universal compatibility
  - Chen & Wan 2019: Diminished accuracy for large variation in input distributions.
  - Jiang et al. 2018: Lack of universal compatibility across diverse epistemic uncertainty representations.
  - Li & Chen (2008): Analytical solutions for joint PDFs are complex and often decoupled.
  - Chen & Li (2009): Existing methods do not effectively handle high-dimensional uncertainties.
  - Bittner et al. (2024): Need for improved efficiency and accuracy in uncertainty quantification.
  - N/A: N/A
  - Previous methods for uncertainty propagation: Limited efficiency and accuracy in handling high-dimensional epistemic uncertainties.
  - Vertex MCS method: Prohibitive computational costs for complex models.
  - Existing PDEM methodologies: Inability to effectively manage distribution-free p-boxes.
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The proposed decoupled multi-probability density evolution method (M-PDEM) provides a unified framework for hybrid uncertainty propagation by transforming the problem into solving conditional probability distributions.

### 4. Method
- **Pipeline**: The method involves generating excitations using spectral representation, followed by uncertainty propagation through the decoupled M-PDEM.
- **Architecture / Loss / Training**: Utilizes path integration for solving equations and various numerical schemes for implementation.
- **Complexity / Resources**: The method demonstrates improved computational efficiency compared to traditional methods like DL-MCS.

### 5. Experiments
- **Datasets & Metrics**: The experiments include numerical examples with various uncertain inputs, focusing on maximum displacement and internal energy outputs.
- **Baselines**: Classical stochastic dynamic analysis methods, DL-MCS, Finite difference scheme, Imprecise probabilistic models, Mesh free scheme, N/A, Non-probabilistic models, Path integration, Probability density evolution method (PDEM), Traditional probabilistic models, Vertex MCS
- **Main Results**: The decoupled M-PDEM shows satisfactory agreement with DL-MCS results while demonstrating improved computational efficiency.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The method's accuracy decreases with increased nonlinearity and dimensionality of random parameters.

### 6. Takeaways
- **Pros**: Provides a comprehensive framework for hybrid uncertainty propagation, Enhances computational efficiency compared to traditional methods, Accommodates various uncertainty representations including p-boxes
- **Cons**: Limited to specific types of dynamical systems, May require further validation in real-world applications
- **Future Work**: Explore extensions to more complex nonlinear systems, Investigate integration with other uncertainty quantification methods, Develop user-friendly software tools for practical applications

</details>

## avatar

### [Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis](http://arxiv.org/pdf/2509.09595v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Long-duration avatar video generation

### 2. Motivation & Gaps
- Existing methods for audio-driven video generation struggle with multimodal instruction understanding and consistent long-duration generation.

- **Related work challenges:**
  - Video Diffusion Transformers (DiT): Insufficient for highly realistic portrait synthesis and often treat each conditional signal independently.
  - Prior work on facial expression and lip synchronization: Leads to semantic conflicts across modalities and affect.
  - Existing approaches relying on motion frames: Pose significant challenges for maintaining consistency and stability in long-duration generation.
  - Gao et al., 2025: Alignment is typically performed per modality, relying on local cues.
  - Fei et al., 2025: Shallow fusion at the generation stage limits effective reproduction of observable details.
  - Wang et al., 2025a: Existing methods do not adequately address the intent behind multimodal instructions.
  - OmniHuman: Identity drift and synchronization issues in long video continuations.
  - HeyGen: Maintaining visual quality and coherence in generated videos.
  - OmniHuman-1: Limited support for prompt input and reliance on fixed resolutions.
  - HeyGen: Produces videos with limited vividness and diversity due to repetitive action patterns.
  - Diffusion Models: Inadequate for speech-driven digital portrait modeling.
  - Jiang et al., 2025: Struggle with multimodal instruction understanding.
  - Gan et al., 2025: Reliance on local cues for alignment within each modality.
  - Huang et al., 2025: Inconsistent long-duration generation.
  - N/A: N/A

### 3. Core Idea
- A cascaded framework that unifies multimodal instruction understanding with long-duration generation of lifelike portrait videos.

### 4. Method
- **Pipeline**: Two-stage pipeline: first employs an MLLM director to produce a blueprint video, then synthesizes long videos through parallel sub-clip generation.
- **Architecture / Loss / Training**: Coupled with carefully curated data and practical training and inference strategies.
- **Complexity / Resources**: Preserves fine-grained details while faithfully realizing global semantics.

### 5. Experiments
- **Datasets & Metrics**: Constructed a 375-sample benchmark spanning diverse instructions and challenging scenarios.
- **Baselines**: Existing audio-driven video generation methods, HeyGen, N/A, OmniHuman, OmniHuman-1, OmniHuman-1 (Lin et al., 2025)
- **Main Results**: Kling-Avatar delivers vivid, fluent videos up to 1080p and 48 fps, with precise lip synchronization and strong controllability.
- **Ablations**: Future work will include additional objective metrics to complement the GSB assessments.
- **Limitations / Stress Tests**: Human preference‚Äìbased metric comparisons confirm superior performance.

### 6. Takeaways
- **Pros**: Generates vivid, fluent, long-duration videos at up to 1080p and 48 fps., Maintains strong generalization to open-domain scenarios., Achieves superior performance across multiple dimensions.
- **Cons**: Potential limitations in handling diverse emotional expressions., Dependence on high-quality training data.
- **Future Work**: Further improve the understanding of multimodal inputs., Enhance the realism and expressiveness of generated avatars., Explore additional applications in virtual assistants and immersive telepresence.

</details>

### [PanoLAM: Large Avatar Model for Gaussian Full-Head Synthesis from One-shot Unposed Image](http://arxiv.org/pdf/2509.07552v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- 3D reconstruction from single-view images

### 2. Motivation & Gaps
- The paper addresses the limitations of existing methods in reconstructing 3D representations from single-view images, particularly focusing on fidelity and generalization to real-world images.

- **Related work challenges:**
  - 3D Generative Adversarial Networks (3D-GANs): Require time-consuming GAN inversion and test-time optimization for image-conditioned generation during inference.
  - Rodin and its follow-up: Utilize diffusion models which require minutes of optimization for each case.
  - 2D super-resolution upsampling: Improves rendering efficiency and quality but compromises 3D consistency.
  - EG3D: Requires time-consuming GAN inversion and test-time optimization for image-conditioned generation.
  - Diffusion models: Multi-step diffusion process is slow and computation-consuming during inference.
  - NeRF-based approaches: Slow rendering speed and low-resolution images lead to view inconsistencies.
  - FLAME model: Inability to model large deformations such as long hairs, glasses, and caps.
  - TriplaneGaussian: Point-based query strategy cannot fully fetch valuable features from the spherical triplane.
  - Previous methods: Require a network trained to upsample sparse points.
  - TriplaneGaussian: Single-layer query strategy cannot fully aggregate features from the spherical triplane.
  - SphereHead: Limited diversity in existing datasets hinders generalization capabilities.
  - Existing 3D head reconstruction methods: Dependence on accurate camera poses and complex optimization processes.
  - Gaussian shell maps for efficient 3d human generation: N/A
  - Panohead: Geometry-aware 3d full-head synthesis in 360¬∞: N/A
  - Rignerf: Fully controllable neural 3d portraits: N/A
  - N/A: N/A
  - Towards unsupervised learning of generative models for 3d controllable image synthesis: Lack of effective unsupervised methods for generating 3D models.
  - Deep learning face attributes in the wild: Challenges in accurately capturing diverse facial attributes.
  - 3d gaussian blendshapes for head avatar animation: Difficulty in achieving realistic head animations.
  - Next3d: Generative neural texture rasterization for 3d-aware head avatars: Limited fidelity in head avatar generation.
  - RODIN: A generative model for sculpting 3d digital avatars using diffusion: Challenges in achieving real-time performance.
  - Gaussian head avatar: Ultra high-fidelity head avatar via dynamic gaussians: Complexity in modeling dynamic facial expressions.
  - EG3D: Limited to rendering near-frontal images.
  - SphereHead: Biases in the dataset leading to poor reconstruction results for certain demographics.

### 3. Core Idea
- The proposed framework combines triplane representation with Gaussian splatting to enhance the quality and generalizability of 3D reconstructions from single-view images.

### 4. Method
- **Pipeline**: The method involves generating a large-scale dataset using trained 3D GANs, followed by training a network on this dataset to reconstruct 3D representations.
- **Architecture / Loss / Training**: The architecture utilizes a triplane representation and Gaussian splatting, with a focus on minimizing reconstruction loss and enhancing fidelity.
- **Complexity / Resources**: The method requires significant computational resources for training on large-scale datasets, including GPU acceleration.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize a large-scale synthesized dataset and real-world images from the VFHQ dataset, measuring fidelity and artifact presence.
- **Baselines**: 3D-GANs, Default configurations of existing 3D head reconstruction methods, Diffusion models, EG3D, Existing 3D avatar generation methods, FLAME model, Gaussian samples (œÉ=1), Gaussian samples (œÉ=10), LGM, LGMHunyuan3D, N/A, NeRF-based approaches, Ours, PH-PTI, PanoHead-PTI, Previous state-of-the-art head avatar generation methods, SH-PTI, SphereHead, SphereHead-PTI, Traditional animation techniques, TriplaneGaussian
- **Main Results**: The proposed framework achieves higher fidelity results with fewer artifacts compared to previous methods.
- **Ablations**: Ablation studies demonstrate the impact of different components of the framework on reconstruction quality.
- **Limitations / Stress Tests**: The framework shows limitations in reconstructing Asian faces and cartoon heads due to biases in the training datasets.

### 6. Takeaways
- **Pros**: Fast reconstruction and rendering of 3D avatars., High-fidelity Gaussian full-head reconstruction., Utilizes a large-scale synthetic dataset for training.
- **Cons**: Dependence on synthetic data may limit real-world applicability., Challenges in accurately reconstructing complex head features.
- **Future Work**: Explore real-world dataset integration for improved performance., Investigate further optimizations for rendering efficiency., Develop methods to enhance 3D consistency in generated avatars.

</details>

### [Reconstruction and Reenactment Separated Method for Realistic Gaussian Head](http://arxiv.org/pdf/2509.05582v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Mapping audio sequences to motion sequences for lip synchronization

### 2. Motivation & Gaps
- The paper addresses the challenge of achieving accurate lip synchronization in 3D models driven by audio input.

- **Related work challenges:**
  - Goodfellow et al. (2014): 2D-based approaches lack explicit 3D structural priors, leading to complex model structures and higher latency.
  - Mildenhall et al. (2020): 3D synthesis technologies require precise estimation of 3D poses, which can introduce errors in texture and expression.
  - Guo et al. (2024): 2D end-to-end approaches struggle to reproduce subtle, natural expressions due to reliance on geometric structures.
  - 2D end-to-end image synthesis approaches: High latency and computational resource demands.
  - 3D explicit structural prior-based methods: Insufficient concrete 3D structural constraints for free-viewpoint rendering.
  - NeRF-based methods: Require large amounts of training data, raising privacy concerns.
  - Deng and others. 2024b: Previous methods did not leverage the advantages of larger scale and extensive training datasets.
  - Chu and others. 2024a: Existing methods may not effectively capture high-frequency details in rendered outputs.
  - He and others. 2025: Prior approaches may struggle with identity consistency in animated outputs.
  - Live Portrait (Guo and others. 2024): Maintaining high-quality texture details while ensuring identity consistency.
  - GFPGAN (Wang and others. 2021b): Achieving accurate expressions and poses aligned with driving images.
  - Previous methods in identity reenactment: Inadequate reconstruction details and alignment with driving images.
  - Wang and others. 2023: Existing methods lack fine-grained control over facial features.
  - Kaplan and others. 2020: Scaling laws indicate potential for performance enhancement, but current methods do not fully utilize this.
  - Wav2Lip: Achieving high lip accuracy scores using sync score as a supervisory loss.
  - HunyuanVideoAvatar: Utilizing large-scale parameters and data for improved performance.
  - MuseTalk: Maintaining competitive results in lip synchronization tasks.
  - N/A: N/A

### 3. Core Idea
- The technique synthesizes high-fidelity, real-time talking head video using a single portrait image, capturing intricate facial expressions and subtle nuances in movement.

### 4. Method
- **Pipeline**: The Gaussian Generator produces static and dynamic Gaussians for controllable 3D Gaussian generation.
- **Architecture / Loss / Training**: Mean square error (MSE) loss is used to train the model, constraining predictions to ground-truth mouth features.
- **Complexity / Resources**: The model is trained on a dataset of 1,000 professional single-speaker lecture videos.

### 5. Experiments
- **Datasets & Metrics**: The method is evaluated on the HDTF and VFHQ datasets.
- **Baselines**: 2D end-to-end image synthesis, 2D end-to-end models, 3D explicit structural prior-based methods, 3D synthesis technologies, FLAME, GAGAvatar, GAGavatar, GPAvatar, HunyuanVideoAvatar, LAM, LivePortrait, MuseTalk, N/A, NeRF-based methods, P4D, P4D-v2, RAR, Real3D, Real3DPortrait, StyleHEAT, StyleHeat, Wav2Lip
- **Main Results**: The generated videos exhibit lifelike clarity and realism.
- **Ablations**: Ablation studies showed that increasing the scale of the pre-trained backbone improves performance.
- **Limitations / Stress Tests**: The method's performance is contingent on the quality of the pre-trained backbone and the effectiveness of the texture restoration module.

### 6. Takeaways
- **Pros**: High frame-rate rendering at 90 FPS., Decoupled architecture allows for precise control over facial features., Improved generalization and accuracy in reconstruction.
- **Cons**: Dependence on the quality of the input image., Potential limitations in reproducing extremely subtle expressions., Complexity in training the texture restoration module.
- **Future Work**: Explore further enhancements in expression control mechanisms., Investigate the integration of additional input modalities for avatar control., Develop methods to reduce dependency on high-quality input images.

</details>

## video understanding

### [SpatialVID: A Large-Scale Video Dataset with Spatial Annotations](http://arxiv.org/pdf/2509.09676v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- 3D perception

### 2. Motivation & Gaps
- The paper addresses the need for continuous 3D perception in dynamic environments.

- **Related work challenges:**
  - Structure-from-Motion (SfM): Limited in scale, diversity, and annotation richness for real-world dynamic scenes.
  - Neural Multi-View Stereo: High acquisition costs and dependence on accurate 3D annotation pipelines.
  - Large language models: Contrast with the progress of large language models due to the scarcity of 3D ground-truth datasets.
  - MotionSight (Du et al., 2025): Lacks direct geometric ground truth, forcing models to learn spatial relationships implicitly from pixels.
  - CO3D (Reizenstein et al., 2021): Limited in scale, diversity, and dynamic richness.
  - Tartanair (Wang et al., 2020): Fails to capture the complexity of real-world scenes.
  - Sora (OpenAI, 2024): Limited fidelity and scalability in video generation.
  - DragNUW A (Yin et al., 2023): Challenges in fine-grained manipulation of object movements.
  - CameraCtrl (He et al., 2024): Need for explicit guidance over camera trajectories.
  - DROID-SLAM: Requires significant time to achieve accuracy.
  - COLMAP: N/A
  - Fast3R: N/A
  - MonST3R: Struggles in scenarios with limited feature points.
  - VGGT: Excels in inference speed but struggles with limited feature points.
  - DROID-SLAM (Teed and Deng, 2021): Previous systems struggled with initialization and handling dynamic content.
  - Depth Anything (Yang et al., 2024a): Existing models may not provide sufficient depth accuracy in challenging scenarios.
  - UniDepth (Piccinelli et al., 2024): Variable focal lengths and significant radial distortion are not well managed.
  - CameraBench (Lin et al., 2025): Addressing the challenge of spatial reasoning in video captioning.
  - VLM4D (Zhou et al., 2025): Improving spatial consistency in generated captions.
  - 3D LLM-Mem (Hu et al., 2025): Incorporating depth maps and camera parameters for better spatial understanding.
  - Panda-70M: Suffers from quality issues such as static videos, flicker-prone content, and underspecified captions.
  - N/A: N/A
  - Droid-slam: Deep visual slam for monocular, stereo, and rgb-d cameras: Existing methods struggle with dynamic scenes.
  - Scaling laws for neural language models: Limited scalability in current models.
  - Structure-from-motion revisited: Challenges in accurate motion estimation.
  - N/A: N/A

### 3. Core Idea
- The proposed model integrates persistent state mechanisms to enhance 3D perception in real-time.

### 4. Method
- **Pipeline**: The model employs a continuous feedback loop for real-time updates.
- **Architecture / Loss / Training**: Utilizes a combination of reconstruction loss and motion consistency loss.
- **Complexity / Resources**: Requires moderate computational resources for training and inference.

### 5. Experiments
- **Datasets & Metrics**: Evaluated on several large-scale datasets including Princeton365 and Openvid-1m.
- **Baselines**: 3D LLM-Mem, COLMAP, CameraBench, DROID-SLAM, Droid-slam, Existing datasets with camera pose information, Fast3R, MiraData (Ju et al., 2024), MonST3R, Multi-Cam Video (Bai et al., 2025), N/A, Panda-70M, Panda70M (Chen et al., 2024), Scaling laws for neural language models, Structure-from-motion, VGGT, VLM4D
- **Main Results**: Achieved state-of-the-art performance in 3D perception tasks.
- **Ablations**: Ablation studies indicate the importance of persistent state in improving accuracy.
- **Limitations / Stress Tests**: Limited testing on highly dynamic environments.

### 6. Takeaways
- **Pros**: Richness and diversity of data foster improved model generalization., Provides explicit spatial annotations including camera poses and depth maps., Supports advancements in high-fidelity 3D reconstruction.
- **Cons**: Limited existing datasets for comparison., High acquisition costs for large-scale 3D data., Dependence on accurate annotation pipelines.
- **Future Work**: Enhance spatial awareness in video generation pipelines., Develop more robust world models using video data., Explore further applications in artificial general intelligence.

</details>

### [Can Understanding and Generation Truly Benefit Together -- or Just Coexist?](http://arxiv.org/pdf/2509.09666v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Unified visual understanding and generation

### 2. Motivation & Gaps
- The paper addresses the need for high-resolution semantic encoders that can effectively unify visual understanding and generation tasks.

- **Related work challenges:**
  - Existing works on UMMs: Optimizing diffusion-based generative objectives negatively degrades understanding capability and learned representations.
  - Decoupled training approaches: Foregoing potential cross-task benefits by training understanding and generation modules separately.
  - Current approaches: Failing to deliver explicit, bidirectional gains between understanding and generation.
  - Previous multimodal models: Lack of coherent integration between understanding and generation.
  - Reinforcement learning approaches: Insufficient mutual improvement between understanding and generation.
  - Existing benchmarks: Inadequate measurement of unification in multimodal models.
  - Existing benchmarks for image realism and caption fidelity: They do not reveal whether a system is truly unified.
  - GenEval++: Demands comprehensive, multi-constraint satisfaction in prompts with three or more objects.
  - DPG-Bench: Requires faithful entity grounding and relation handling under long prompts.
  - Unified-Bench: Involves optimizing captioning for reconstructability to enhance generation quality.
  - X-Omni: OCR-based rewards during RL improve typography fidelity.
  - Qwen-Image: Recent results underscore the importance of supervision for text rendering.
  - UniWorld-V1: Initial designs lacked a clear separation between understanding and generation.
  - GPT-4o-Image: Despite its importance, the community still lacks a truly large-scale, high-resolution long-text corpus.
  - Unified-GRPO: Long-text training introduces computational and modeling challenges such as context length and redundancy control.
  - Dinov2: Learning robust visual features without supervision: Lack of supervision in learning robust visual features.
  - Learning transferable visual models from natural language supervision: Challenges in transferring visual models across different tasks.
  - High-resolution image synthesis with latent diffusion models: Difficulty in achieving high-resolution image synthesis.

### 3. Core Idea
- The core idea is to develop high-resolution semantic encoders that can seamlessly integrate visual understanding and generation capabilities.

### 4. Method
- **Pipeline**: The method involves a pipeline that integrates semantic encoding with visual generation processes.
- **Architecture / Loss / Training**: The architecture employs a loss function designed to optimize both understanding and generation tasks simultaneously.
- **Complexity / Resources**: The method requires significant computational resources due to the high-resolution nature of the tasks.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize a variety of datasets to evaluate performance metrics related to visual understanding and generation.
- **Baselines**: BAGEL, BLIP3-o 4B, BLIP3-o 8B, CLIP, DALLE3, DINO-v2, DINO-v3, Dall¬∑e 3, Dinov2, EMU3, Existing UMM approaches, FLUX.1-dev, Gpt-4o, Hunyuan-DiT, ImgEdit-E1, Janus Pro, LongCLIP, N/A, OmniGen, OmniGen2, Qwen-Image, SDXL, Show-o, TokenFlow-XL, UAE, UniWorld-V1, X-Omni
- **Main Results**: The results demonstrate significant improvements in both understanding and generation tasks compared to existing methods.
- **Ablations**: Ablation studies indicate the importance of specific components in the architecture for achieving high performance.
- **Limitations / Stress Tests**: Limitations include the need for extensive computational resources and potential biases in training data.

### 6. Takeaways
- **Pros**: Demonstrates a novel approach to unify understanding and generation., Provides compelling evidence of mutual gains in multimodal learning., Introduces a measurable signal of cross-modal information coherence.
- **Cons**: Existing methods may still struggle with joint training., The complexity of the model may require significant computational resources., Potential limitations in generalization to unseen data.
- **Future Work**: Explore further optimizations in the reinforcement learning approach., Investigate the application of the framework to other multimodal tasks., Develop more robust benchmarks for evaluating UMMs.

</details>

### [AskDoc -- Identifying Hidden Healthcare Disparities](http://arxiv.org/pdf/2509.09622v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Investigate the interaction between patients and physicians on the online platform, AskDoc.

### 2. Motivation & Gaps
- The study explores disparities among different demographic groups in online health forums, particularly focusing on gender, race, and age.

- **Related work challenges:**
  - Nobles et al.: Limited analysis on self-reported demographics for gender and race without including age.
  - Nobles et al. [2]: Limited analysis on self-reported demographics for gender and race on Reddit, lacking age inclusion.
  - Nobles et al. study on peer-to-peer interactions: Low participation of physicians in online health forums.
  - Study on healthcare discrimination against non-binary individuals: Non-binary individuals receive low average comments despite higher engagement.
  - Research on internet access disparities among racial groups: Lower participation of Black and Hispanic individuals due to lack of access to technology.
  - Structural racism and supporting black lives - the role of health professionals: Addressing health inequities
  - What difference does difference make? the persistence of inequalities in healthcare delivery: Understanding healthcare disparities
  - Stigma, and help seeking for mental health among college students: Overcoming mental health stigma

### 3. Core Idea
- The study provides insights into the engagement levels and comment averages of different demographic groups on AskDoc, highlighting disparities in online health interactions.

### 4. Method
- **Pipeline**: Data collection from AskDoc posts and analysis of demographic engagement.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: N/A

### 5. Experiments
- **Datasets & Metrics**: Descriptive statistics about r/AskDocs (January 2020 ‚Äì May 2022)
- **Baselines**: N/A
- **Main Results**: Count of Unique Users: 157538, Total Count of Posts: 177850
- **Ablations**: N/A
- **Limitations / Stress Tests**: Responses from peers can be false and misleading.

### 6. Takeaways
- **Pros**: Social media can bridge communication gaps in healthcare., Free access to medical advice through platforms like Reddit., Anonymity allows users to seek help without stigma.
- **Cons**: Low participation from physicians compared to posters., Potential biases in responses based on demographics., Limited disclosure of race among users.
- **Future Work**: Further research on engagement patterns across different demographics., Exploration of physician participation strategies., Analysis of the impact of anonymity on health advice seeking.

</details>
