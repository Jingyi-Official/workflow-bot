# Daily Paper Digest Â· 2025-09-06
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## neural rendering

### [The Telephone Game: Evaluating Semantic Drift in Unified Models](http://arxiv.org/pdf/2509.04438v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Evaluating semantic preservation in multimodal models across generations

### 2. Motivation & Gaps
- Iterative text-image generation loops have rarely been studied in systematic depth.

- **Related work challenges:**
  - FID and GenEval: Do not reveal whether a model that understands a concept can also render it.
  - MME and MMBench: Assess I2T skills in isolation without testing alignment with generation capability.
  - ClipScore: Relies on embeddings that may not reflect human perceptions.
  - BAGEL: Correct reasoning about images but failing to produce faithful T2I images.
  - Vila-U and Janus: Rapid degradation in semantic fidelity across multiple generation cycles.
  - Existing single-pass metrics for T2I and I2T: Overlook cross-modal concept drift
  - GenEval benchmark: Limited to single generation fidelity assessments
  - N/A: Position Inconsistency
  - N/A: Object Inconsistency
  - N/A: Style Transition
  - N/A: Quantity Inconsistency
  - N/A: Object Hallucinations
  - N/A: Color Inconsistency
  - MME: Assesses basic perception and reasoning but lacks depth in evaluating semantic drift.
  - MMBench: Introduces complex queries but does not focus on multi-generation evaluation.
  - FID: Provides metric-based evaluation but does not account for semantic consistency across generations.
  - [3]: This work only looks at one generation and is limited to VLM models in general and does not consider unified models.
  - N/A: N/A

### 3. Core Idea
- The Unified Consistency Framework (UCF) evaluates how well multimodal models maintain semantic meaning through cyclic evaluations of image-to-text and text-to-image transformations.

### 4. Method
- **Pipeline**: Cyclic evaluation alternating between image-to-text (I2T) and text-to-image (T2I) transformations.
- **Architecture / Loss / Training**: BAGEL employs a mixture of transformers architecture with a focus on cross-modal stability.
- **Complexity / Resources**: Utilizes a diverse set of filtered multimodal datasets for training.

### 5. Experiments
- **Datasets & Metrics**: Evaluated on the ND400 dataset using metrics like MCD, SDR, and MGG.
- **Baselines**: BAGEL, Blip-3o, CLIP, DINO, GenEval benchmark, Janus, Janus 1.3B, MPNet, N/A, Show-o, Single-pass metrics, VILA-U, Vila-U, Vila-u
- **Main Results**: BAGEL continues to outperform others despite CLIP similarities being consistently lower than those produced with MPNet.
- **Ablations**: Further evaluations reveal that initial scores do not guarantee long-term stability.
- **Limitations / Stress Tests**: A modelâ€™s proficiency in complex tasks is highly susceptible to generational decay.

### 6. Takeaways
- **Pros**: Provides practical metrics to assess unified model's cross-modal stability., Highlights the importance of cyclic consistency in evaluations., Demonstrates that high single-pass scores do not guarantee cross-modal consistency.
- **Cons**: Existing metrics do not capture semantic drift effectively., Current evaluations are fragmented and do not assess overall model performance., Reliance on single-pass metrics can be misleading.
- **Future Work**: Develop more comprehensive metrics for evaluating UMs., Explore additional benchmarks beyond COCO., Investigate the impact of semantic drift on real-world applications.

</details>

### [Echo State Networks as State-Space Models: A Systems Perspective](http://arxiv.org/pdf/2509.04422v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Analyzing and training recurrent neural networks

### 2. Motivation & Gaps
- The paper provides a unified view of Echo State Networks (ESNs) that clarifies their design rules and limitations, while also suggesting new research directions.

- **Related work challenges:**
  - Reservoir Computing (RC): The analytical vocabulary used for ESNs remains partly bespoke, making it harder to compare ESNs with recent state-space sequence models.
  - Modern sequence models: They dominate long-context learning through structured kernels and dissipative dynamics, which are not fully integrated with ESN frameworks.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Kalman filtering/smoothing: Effective identification and denoising of latent states in nonlinear systems.
  - Subspace identification methods: Reliability of identification under varying excitation and data requirements.
  - Neural ODEs and CDEs: Connecting deep models to continuous-time dynamical systems.
  - Kalman smoothing, EM, and subspace identification: Supply denoised states and principled hyperparameter updates
  - Contractionâ€“metric learning: Addressing nonâ€“Lipschitz regimes and heavy switching
  - Probabilistic ESNs: Calibrating uncertainty under drift
  - Bayesian Filtering and Smoothing: N/A
  - An approach to time series smoothing and forecasting using the EM algorithm: N/A
  - Input to state stability: Basic concepts and results: N/A
  - The unscented Kalman filter for nonlinear estimation: N/A
  - A data-driven approximation of the Koopman operator: Extended dynamic mode decomposition: N/A

### 3. Core Idea
- The analysis bridges classical reservoir computing and modern state-space models, providing a common language for stability, identifiability, and efficiency in reservoir designs.

### 4. Method
- **Pipeline**: The framework delineates design rules and remedies for ESNs based on structure, margin, and probabilistic regularization.
- **Architecture / Loss / Training**: The paper discusses the transformation of ESN heuristics into certified design rules.
- **Complexity / Resources**: The framework suggests structured reservoirs with fast kernels and end-to-end guarantees.

### 5. Experiments
- **Datasets & Metrics**: Evaluation of ESNs on various tasks with metrics related to stability and performance.
- **Baselines**: Modern state-space sequence models, N/A, Other neural network architectures, Traditional Echo State Networks, Traditional LTI models
- **Main Results**: The framework clarifies the practice of ESNs and opens new research directions.
- **Ablations**: Analysis of the impact of different structural choices on model performance.
- **Limitations / Stress Tests**: The framework identifies limits such as nonâ€“Lipschitz regimes and longâ€“delay tasks.

### 6. Takeaways
- **Pros**: Provides a unified framework for understanding ESNs and SSMs., Enhances the analytical vocabulary for ESNs, linking them to established systems theory., Offers principled methods for hyperparameter estimation and model design.
- **Cons**: The complexity of the SSM framework may be challenging for practitioners familiar only with traditional ESNs., Potentially requires more computational resources for the proposed methods., The theoretical results may not directly translate to all practical applications.
- **Future Work**: Further exploration of the connections between ESNs and other modern SSM architectures., Investigation of the practical implications of the proposed methods in real-world applications., Development of tools to facilitate the transition from traditional ESNs to the SSM framework.

</details>

### [Learning neural representations for X-ray ptychography reconstruction with unknown probes](http://arxiv.org/pdf/2509.04402v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Ptychographic imaging reconstruction

### 2. Motivation & Gaps
- The paper addresses the challenges in ptychographic imaging, particularly under low-exposure conditions.

- **Related work challenges:**
  - PtychoNN: Dependence on extensive paired training datasets that are difficult to acquire.
  - PtychoNet: Sensitivity to experimental noise and strong dependence on careful initialization.
  - ePIE: Need for sufficient overlap rates between scan positions.
  - ePIE: Exhibits edge ringing and overfits to training-specific artifacts.
  - PINN: Assumes a known probe, which is difficult to obtain accurately.
  - Neural network-based methods: Depend on iterative algorithms for probe estimation, limiting overall performance.
  - ePIE: Notable degradations in reconstruction quality under reduced overlap ratios.
  - AD: Performance declines rapidly as the overlap ratio decreases.
  - RAAR: Fails to recover object amplitude at lower overlap ratios.
  - ePIE: Significantly affected by Gaussian noise.
  - APG: Designed for noisy data but still underperforms compared to PtyINR.
  - DM, RAAR, WASP, AD: Exhibit greater susceptibility to noise and artifacts in reconstructions.
  - ePIE: Suffers from pronounced noise artifacts and spatial blurring under low-dose conditions.
  - APG: Produces diffuse and suboptimal probe amplitude distributions.
  - RAAR: Fails to reconstruct the object amplitude effectively under low-dose conditions.
  - ePIE algorithm: Boundary artifacts in conventional algorithms
  - Instant-NGP: Efficient encoding of spatial coordinates
  - Grote, L. et al. (2022): Imaging Cu2O nanocube hollowing in solution by quantitative in situ X-ray ptychography.
  - Diaz, A. et al. (2014): Characterization of carbon fibers using X-ray phase nanotomography.
  - HÃ©monnot, C. Y. J. & KÃ¶ster, S. (2017): Imaging of Biological Materials and Cells by X-ray Scattering and Diffraction.
  - Maiden, A. M. & Rodenburg, J. M. An improved ptychographical phase retrieval algorithm for diffractive imaging.: Improving phase retrieval algorithms for better imaging results.
  - Hoidn, O., Mishra, A. A. & Mehta, A. Physics constrained unsupervised deep learning for rapid, high resolution scanning coherent diffraction reconstruction.: Integrating physics with deep learning for enhanced reconstruction speed and quality.
  - Zhai, Q., Buzzard, G. T., Mertes, K., Wohlberg, B. & Bouman, C. A. Projected Multi-Agent Consensus Equilibrium (PMACE) With Application to Ptychography.: Addressing consensus in multi-agent systems for improved ptychographic imaging.
  - Prior works on ptychographic reconstruction: Direct application of mean squared error leading to instability and poor performance under certain conditions.
  - Use of different loss functions: Balancing the trade-offs between stability and detail preservation during probe recovery.
  - Neural network architectures: The inherent differences between object and probe characteristics complicate the reconstruction process.
  - SIREN: Oscillatory nature of sine activation function leading to instability in gradient propagation.
  - Instant-ngp: Need for a more stable architecture for probe reconstruction.
  - ePIE: Limited accuracy under high noise conditions.
  - DM: Struggles with fine spatial feature resolution.
  - RAAR: Inconsistent results across different scanning step sizes.
  - Fast R-CNN: Limited performance in low-exposure scenarios.
  - Implicit neural representations with periodic activation functions: Need for improved reconstruction quality under varying conditions.
  - Instant neural graphics primitives: Inadequate handling of complex probe recovery.

### 3. Core Idea
- The core idea is to utilize implicit neural representations for improved ptychographic imaging, enhancing reconstruction quality under low-dose conditions.

### 4. Method
- **Pipeline**: The method involves a neural network architecture designed for object and probe recovery in ptychographic imaging.
- **Architecture / Loss / Training**: The architecture employs various loss functions, including â„“1, â„“2, and a specific loss function adopted in PtyINR.
- **Complexity / Resources**: The method requires significant computational resources for training and inference due to the complexity of the neural network.

### 5. Experiments
- **Datasets & Metrics**: Experiments were conducted using simulated diffraction patterns and evaluated using PSNR metrics.
- **Baselines**: AD, APG, DM, Deep learning-based reconstruction techniques, Mean squared error, Other prior reconstruction methods, PINN, PtychoNN, PtychoNet, RAAR, Recent deep learning-based methods, Traditional ptychographic methods, Traditional ptychographic reconstruction algorithms, Traditional ptychographic reconstruction methods, WASP, ePIE, ePIE algorithm
- **Main Results**: The results demonstrate that PtyINR outperforms traditional methods in reconstruction quality, especially under low-exposure conditions.
- **Ablations**: Ablation studies highlight the sensitivity of probe recovery to normalization and regularization choices.
- **Limitations / Stress Tests**: Tests reveal limitations in reconstruction quality under extreme noise conditions and varying data acquisition parameters.

### 6. Takeaways
- **Pros**: Achieves superior reconstruction quality., Robust under challenging low-signal conditions., Generalizable to a wide range of computational microscopy problems.
- **Cons**: Requires significant computational resources., Performance may still be constrained by iterative probe estimation., Assumes continuous representation which may not fit all scenarios.
- **Future Work**: Explore further applications in computational microscopy., Investigate improvements in training efficiency., Develop methods to handle more complex probe variations.

</details>

## Gaussian Splatting

### [Generation of Lognormal Synthetic Lyman-$Î±$ Forest Spectra for $P_{1D}$ Analysis](http://arxiv.org/pdf/2509.04405v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- P1D analysis in large-scale surveys

### 2. Motivation & Gaps
- The framework aims to improve the accuracy of P1D measurements by addressing systematic uncertainties and enhancing contaminant identification.

- **Related work challenges:**
  - Baryon Oscillation Spectroscopic Survey (BOSS): First detection of baryon acoustic oscillations in the LyÎ± forest region at high redshift.
  - Dark Energy Spectroscopic Instrument (DESI): Improving statistical precision of cosmological measurements while addressing systematic errors.
  - Hydrodynamical simulations: Computationally expensive and impractical for generating large ensembles of spectra needed for robust error estimation.
  - McDonald et al. (2006): Earlier methods relied on a fixed analytic form for the power spectrum, limiting precision and flexibility.
  - KaraÃ§aylÄ± et al. (2020): Previous methods did not account for redshift-dependent Gaussian power spectra.
  - Turner et al. (2024): Existing models struggled to match observational data across varying redshifts and scales.
  - N/A: N/A
  - KaraÃ§aylÄ± et al. (2024): Previous methods did not accurately capture the mean flux evolution across a broad range of redshifts.
  - Turner et al. (2024): Existing models lacked precision in predicting the mean optical depth and its redshift evolution.
  - Previous P1D mock generation method: Limited fidelity in reproducing the shape of the power spectrum
  - Previous methods for P1D analysis: Limited to specific k-ranges and do not generalize well across broader scales.
  - Damped LyÎ± systems (DLAs) identification: False positives can exacerbate bias in P1D measurements.
  - Continuum fitting methods: Introduce small biases that affect measurements, especially at lower redshifts.
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The proposed framework generates lognormal mocks that accurately replicate the mean transmitted flux and P1D shape across a wide range of scales and redshifts.

### 4. Method
- **Pipeline**: Utilizes uncontaminated mocks to evaluate effects and improve contaminant identification.
- **Architecture / Loss / Training**: Involves fitting an underlying Gaussian correlation function to improve accuracy.
- **Complexity / Resources**: Employs libraries such as NumPy, SciPy, Astropy, and Matplotlib for implementation.

### 5. Experiments
- **Datasets & Metrics**: Evaluated using DESI EDR data across redshift range 2.0 â‰¤ z â‰¤ 3.8.
- **Baselines**: DESI EDR measurements, Emulator-based approaches, Hydrodynamical simulations, KaraÃ§aylÄ± et al. (2020), N-body simulations, N/A, Previous P1D analysis methods, Previous lognormal mock methods, Previous method, Static analytic power spectrum models
- **Main Results**: Achieved a fractional RMS error of 0.003 for mean transmitted flux and 0.02 for P1D shape and amplitude.
- **Ablations**: Future work will include incorporating astrophysical contaminants and continuum estimation uncertainties.
- **Limitations / Stress Tests**: Current model assumes a fixed variance for the Gaussian field, which may introduce bias.

### 6. Takeaways
- **Pros**: Fast and analytically tractable alternative for generating synthetic spectra., Captures essential features of the LyÎ± forest efficiently., Well suited for validation testing in cosmological analyses.
- **Cons**: Not as detailed or physically motivated as hydrodynamic simulations., Insufficient for full cosmological inference., Limited by the coverage and granularity of the training grid in emulator-based approaches.
- **Future Work**: Incorporate more astrophysical effects for improved accuracy., Expand utility in ongoing and upcoming surveys., Enable broader range of validation efforts and systematic studies.

</details>

### [SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer](http://arxiv.org/pdf/2509.04379v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D scene segmentation and editing

### 2. Motivation & Gaps
- The paper addresses the need for effective segmentation and editing techniques in 3D scenes, which are crucial for various applications in computer vision and graphics.

- **Related work challenges:**
  - DreamFusion: Lack of effective methods that integrate diffusion priors into a systematically designed 3D style transfer pipeline.
  - Instruct-NeRF2NeRF: Current methods struggle to maintain multi-view consistency across different viewpoints.
  - NeRF and 3DGS based methods: Stylized results often lack a layered sense of structure, making it difficult to distinguish between different instances or objects.
  - Neural style transfer: Struggles with transferring fine style patterns and maintaining consistency across different viewpoints.
  - Text-driven 3D Editing: Existing methods often require iterative updates and may not ensure consistent edits across views.
  - 3D style transfer using point cloud and mesh representations: These approaches produce noticeable artifacts in complex scenes due to geometry and texture imperfections.
  - NeRF: NeRF offers slower rendering speeds compared to 3D Gaussian Splatting.
  - Gaussian Grouping: While it provides instance-level consistency, it does not guarantee pixel-level 3D consistency.
  - Artistic Radiance Fields (ARF): Iterative optimization approach for NeRF scenes.
  - StyleGaussian: Feed-forward approach designed for 3DGS scenes.
  - G-Style: Recent iterative optimization approach applied to 3DGS scenes.
  - ARF [20]: NeRF-based rendering speed is limited to 10 FPS.
  - StyleGaussian [22]: Requires extensive training time of approximately 5 hours per scene.
  - G-Style [23]: Inconsistent stylization quality across different views.
  - Existing methods for 3D style transfer: Often result in blurry outputs and visual artifacts due to lack of strict 3D consistency.
  - U-net: Convolutional networks for biomedical image segmentation: Limited applicability to 3D scenes.
  - Neural style palette: A multimodal and interactive style transfer from a single style image: Focuses on 2D images rather than 3D environments.
  - Styleadapter: A unified stylized image generation model: Does not address the complexities of 3D scene editing.

### 3. Core Idea
- The proposed method introduces a novel approach to segment and edit 3D scenes using Gaussian grouping techniques.

### 4. Method
- **Pipeline**: The method involves a multi-step pipeline that integrates segmentation and editing processes for 3D scenes.
- **Architecture / Loss / Training**: Utilizes a combination of loss functions tailored for 3D data to optimize the segmentation and editing tasks.
- **Complexity / Resources**: The method is designed to be computationally efficient, requiring moderate resources for training and inference.

### 5. Experiments
- **Datasets & Metrics**: Experiments are conducted on various 3D datasets, using metrics such as segmentation accuracy and editing fidelity.
- **Baselines**: ARF, ARF [20], Artistic Radiance Fields (ARF), Existing 3D style transfer methods, G-Style, G-Style [23], NeRF, Neural style palette, State-of-the-art methods in 3D style transfer, State-of-the-art neural style transfer methods, StyleGaussian, StyleGaussian [22], Styleadapter, U-net
- **Main Results**: The proposed method outperforms existing baselines in both segmentation accuracy and editing quality.
- **Ablations**: Ablation studies demonstrate the effectiveness of each component in the proposed pipeline.
- **Limitations / Stress Tests**: The method shows limitations in handling highly complex scenes with occlusions.

### 6. Takeaways
- **Pros**: Maintains style fidelity and instance-level consistency., Produces visually coherent and artistically enriched stylization., Effectively integrates diffusion priors into 3D style transfer.
- **Cons**: Struggles with ensuring multi-view consistency., May produce artifacts in complex real-world scenes.
- **Future Work**: Explore further integration of advanced diffusion models., Investigate improvements in instance segmentation techniques., Develop methods to enhance pixel-level consistency.

</details>

### [Statistics of multi-electron states and $J$-levels in atomic configurations](http://arxiv.org/pdf/2509.04353v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Deriving exact formulas for atomic configurations and distributions of quantum numbers

### 2. Motivation & Gaps
- The paper presents new explicit formulas for the number of atomic configurations and distributions of total magnetic quantum number M and total angular momentum J, addressing limitations in previous methods.

- **Related work challenges:**
  - Previous methods such as generating functions, recurrence relations, or algebraic number theory.: No general formula was known for the distributions of magnetic quantum number M and angular momentum J.
  - N/A: N/A
  - N/A: N/A
  - Previous methods for calculating atomic configurations: Limited to small numbers of fermions and involved complex piece-wise polynomials.
  - Recursion relations: Less efficient numerically compared to the new formulas for certain calculations.
  - N/A: N/A

### 3. Core Idea
- The new formulas are based on the evaluation of generating functions as trigonometric polynomials, allowing for exact calculations of atomic configurations.

### 4. Method
- **Pipeline**: Integration of trigonometric polynomials evaluated at specific points to derive configurations.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The new expressions are simpler and more compact than previous methods, allowing for easier implementation.

### 5. Experiments
- **Datasets & Metrics**: The paper does not specify datasets but discusses the number of operations needed for various configurations.
- **Baselines**: Brute-force calculations, N/A, Previous numerical methods for calculating electronic configurations, Recurrence relations
- **Main Results**: The new formulas provide a more efficient way to calculate the number of atomic configurations compared to previous methods.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The new formulas are less efficient numerically than recursion relations for some cases.

### 6. Takeaways
- **Pros**: Provides a general formula for atomic configurations., Addresses a significant gap in atomic spectroscopy., Utilizes effective mathematical methods for complex problems.
- **Cons**: The resulting expressions can be cumbersome., The method may require advanced mathematical understanding., Limited experimental validation of the formulas.
- **Future Work**: Further simplification of the derived formulas., Application of the formulas to real-world atomic spectroscopy problems., Exploration of the implications in nuclear physics.

</details>

## avatar

### [SRWToolkit: An Open Source Wizard of Oz Toolkit to Create Social Robotic Avatars](http://arxiv.org/pdf/2509.04356v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Human-Robot Interaction (HRI) Evaluation

### 2. Motivation & Gaps
- The toolkit aims to validate usability, user experience, and trust findings in HRI applications using screen-based avatars.

- **Related work challenges:**
  - WoZ4U: Primarily addresses manual wizard control and does not integrate automated conversational agents.
  - Fang et al. (LLM Wizards): While reducing manual workload, it does not focus on local LLM integration.
  - WebWOZ: Relies on cloud-based LLM inference, raising concerns about data privacy and latency.
  - Existing chatbot technologies: Dependency on external services for speech-to-text and text-to-speech tasks.
  - Current version of the toolkit: Utilizes screen-based avatars, limiting real-world evaluations.
  - User study: Limited number of participants and lack of diversity in technological familiarity.
  - Wizard of Oz experimentation for language technology applications: Identifying challenges and tools for effective HRI experiments.
  - On LLM wizards: Identifying large language modelsâ€™ behaviors for wizard of oz experiments: Understanding the impact of LLMs on user perceptions in HRI.
  - Foundations for an empirically determined scale of trust in automated systems: Establishing trust metrics in automated systems.

### 3. Core Idea
- The toolkit facilitates real-world evaluations of HRI by simulating robotic behavior with screen-based avatars and aims to optimize real-time performance.

### 4. Method
- **Pipeline**: The toolkit includes a pipeline for simulating interactions and evaluating user experiences.
- **Architecture / Loss / Training**: The backend processes inputs and manages configurations, while the frontend provides a dynamic interface for user interaction.
- **Complexity / Resources**: The toolkit is designed to be reproducible with complete source code and deployment instructions available.

### 5. Experiments
- **Datasets & Metrics**: The toolkit evaluates user perceptions based on various design variables.
- **Baselines**: LLM Wizards, System Usability Scale (SUS), Trust in Automated Systems (TIA), User Experience Questionnaire (UEQ), User experience questionnaires, WebWOZ, Wizard of Oz technique, WoZ4U
- **Main Results**: The toolkit's findings will inform optimal configurations for various application contexts.
- **Ablations**: N/A
- **Limitations / Stress Tests**: Future research should investigate the impact of specific role types and variations in LLMs.

### 6. Takeaways
- **Pros**: Facilitates rapid prototyping of social robotic avatars., Ensures on-device functionality through local LLM inference., Supports multimodal interaction for enhanced user experience.
- **Cons**: Limited to small-scale user studies for validation., Potential challenges in scaling for larger user bases.
- **Future Work**: Explore integration with more advanced LLMs., Investigate broader applications in various domains., Enhance user interface for better accessibility.

</details>

### [Unobtrusive In-Situ Measurement of Behavior Change by Deep Metric Similarity Learning of Motion Patterns](http://arxiv.org/pdf/2509.04174v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the effects of photorealism and personalization on embodiment and self-identification in virtual reality.

### 2. Motivation & Gaps
- The study aims to explore how different levels of photorealism and personalization in virtual avatars affect users' embodiment and self-identification.

- **Related work challenges:**
  - Previous studies on the Proteus effect: Relying on subjective measures or complex hardware for behavior change assessment.
  - Existing motion analysis methods: Require extensive analysis and do not operate in real-time.
  - Kilteni et al. [13]: Used complex motion capture and analysis of task-specific movement to measure behavior change, requiring additional hardware and intrusive tracking suits.
  - Rogers et al. [34]: First to apply motion data for user identification but limited to recognizing only individuals seen during training.
  - Miller et al. [23]: Demonstrated scalability but primarily used classification methods, limiting recognition to previously observed users.
  - Questionnaires: Limited in real-time detection of behavioral changes.
  - Non-learned motion analysis: Does not provide user-specific effect assessment.
  - ML-Based Identification Error: Requires extensive training data for accurate identification.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - The impact of avatar personalization and immersion on virtual body ownership, presence, and emotional response.: Understanding the nuances of how avatar characteristics influence user experience.
  - Systematic review and meta-analysis of virtual reality in mental healthcare.: Identifying the effects of full body illusions on body image disturbance.
  - The Proteus effect: The effect of transformed self-representation on behavior.: Examining how digital self-representation impacts both online and offline behavior.

### 3. Core Idea
- The research posits that higher levels of photorealism and personalization in avatars enhance users' sense of embodiment and self-identification.

### 4. Method
- **Pipeline**: Participants interact with various avatars that differ in photorealism and personalization levels, followed by assessments of their embodiment and self-identification.
- **Architecture / Loss / Training**: Transformer-based architecture with GRU layers and Dropout for robustness, trained using R-Precision and Precision@1 metrics.
- **Complexity / Resources**: Our approach of a motion-based similarity learning model holds a distinct advantage as it does not require predefined movement features and instead captures generalized behavioral shifts.

### 5. Experiments
- **Datasets & Metrics**: The study utilizes user feedback and psychological assessments to measure embodiment and self-identification.
- **Baselines**: Behavioral tasks, ML-Based Identification Error, N/A, Non-learned motion analysis, Non-learned motion analysis based on central tendencies, Previous studies on avatar personalization, Questionnaires, Research on virtual body ownership, Subjective post-exposure embodiment questionnaires
- **Main Results**: Findings indicate that increased photorealism and personalization significantly enhance users' embodiment and self-identification.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The study's limitations include a small sample size and short exposure time in VR.

### 6. Takeaways
- **Pros**: In-situ measurement without additional user input, Generalizable and scalable motion analysis for various use cases, User-specific analysis on the individual level
- **Cons**: Requires understanding of study context for non-learned motion analysis., Limited granularity in questionnaires and behavioral tasks., Potentially complex analysis of sub-movements.
- **Future Work**: Explore further applications of the model in different XR scenarios, Investigate the impact of other avatar characteristics on behavior, Enhance the model's accuracy with larger datasets

</details>

### [Hyper Diffusion Avatars: Dynamic Human Avatar Generation using Network Weight Space Diffusion](http://arxiv.org/pdf/2509.04145v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D shape representation

### 2. Motivation & Gaps
- The paper addresses the need for effective 3D shape representations in neural fields and generative diffusion models.

- **Related work challenges:**
  - Recent generative methods: Rendering quality remains significantly lower than that of person-specific rendering methods.
  - Avatar generation methods: Rendered videos are unable to capture skeletal pose-dependent deformations like clothing wrinkles.
  - NeRF-based approaches: Inherit limitations resulting in significantly longer rendering times.
  - NeRF: Long rendering times
  - 3DGS: Limited to single personalized human renderings
  - Diffusion models for 3D generation: Inability to model articulated 3D humans
  - Previous person-specific dynamic human rendering methods: Limited flexibility in representing variations across different individuals.
  - Standard Gaussian noise addition in network weight training: Potential loss of structural information when flattening network weights.
  - PrimDiffusion: Can only generate static human avatars based on simple skeleton-based articulation.
  - E3Gen: Limited to generating static human avatars without complex deformations.
  - Hyperdiffusion: Directly learning the complex, high-dimensional distribution of the network weight space poses significant challenges for training.
  - UNet for motion-aware 3D Gaussians: Limited generalization to unseen poses and entanglement between geometry and appearance.
  - Gauhuman: Articulated gaussian splatting from monocular human videos: Limited generalization across different poses and environments.
  - Tech: Text-guided reconstruction of lifelike clothed humans: Dependency on textual input which may not always be available.
  - Dreamhuman: Animatable 3D avatars from text: Requires extensive training data for diverse avatar generation.
  - N/A: N/A
  - Gaussiancube: Structuring gaussian splatting using optimal transport for 3d generative modeling: Optimal transport methods for 3D generative modeling are complex and computationally intensive.
  - Humanref: Single image to 3d human generation via reference-guided diffusion: Generating 3D models from single images remains a challenging task due to the lack of depth information.
  - Diffgs: Functional gaussian splatting diffusion: Functional approaches to Gaussian splatting can be difficult to implement in real-time applications.

### 3. Core Idea
- The core idea is to develop a novel 3D shape representation that enhances the performance of neural fields and generative models.

### 4. Method
- **Pipeline**: The method involves a pipeline that integrates 3D shape representation with neural fields and generative diffusion techniques.
- **Architecture / Loss / Training**: The architecture employs a loss function tailored for 3D shape representation, optimizing for both fidelity and generative quality.
- **Complexity / Resources**: The method requires significant computational resources, particularly for training on large datasets.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize various 3D shape datasets and evaluate performance using standard metrics for generative models.
- **Baselines**: 3DGS, Diffusion models, Dreamhuman, E3Gen, Existing 3D shape representation methods, Existing approaches in human avatar generation, Gauhuman, N/A, NeRF, Previous person-specific dynamic human rendering methods, PrimDiffusion, State-of-the-art human avatar generation methods, Tech, Traditional generative models
- **Main Results**: The proposed method outperforms existing techniques in terms of both quality and efficiency of 3D shape generation.
- **Ablations**: Ablation studies demonstrate the impact of different components of the architecture on overall performance.
- **Limitations / Stress Tests**: Limitations include challenges in scalability and the need for extensive training data.

### 6. Takeaways
- **Pros**: Unifies person-specific rendering and diffusion-based generation., Enables dynamic human avatar generation with pose-dependent deformations., Achieves high photorealism in real-time rendering.
- **Cons**: Still requires extensive data for training., Rendering times may vary based on complexity.
- **Future Work**: Explore further generalization across diverse identities., Improve efficiency of the training process., Investigate additional applications in virtual reality.

</details>

## video understanding

### [Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual Try-On from a Single Image -- Technical Preview](http://arxiv.org/pdf/2509.04450v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Virtual Try-On

### 2. Motivation & Gaps
- The paper addresses the challenge of virtual try-on in uncontrolled environments, leveraging dance videos to enhance garment fitting and appearance.

- **Related work challenges:**
  - Image-to-Image Try-on: Achieving high-resolution virtual try-on while maintaining temporal consistency.
  - Conventional auto-regressive video generators: Suffering from temporal inconsistency issues between distant frames.
  - He et al. [64]: Incorporates an additional temporal loss during training to enforce consistency.
  - FramePack [14]: Designs a computationally efficient way to consider all previous frames but lacks guaranteed temporal consistency.
  - DnD [8]: Generates 5s videos but is limited by the duration of the generated video.
  - Dress&Dance: Limited to trained datasets and lacks temporal consistency.
  - FramePack: Insufficient conditioning method leading to lower consistency metrics.
  - Kling Video 2.0: Quality of virtual try-on degrades despite achieving some consistency.
  - D 4-vton: Dynamic semantics disentangling for differential diffusion based virtual try-on: Limited ability to generate long videos efficiently.
  - Gp-vton: Towards general purpose virtual try-on via collaborative local-flow global-parsing learning: Inadequate garment fidelity in generated videos.
  - Texture-preserving diffusion models for high-fidelity virtual try-on: Lack of temporal consistency in video generation.
  - Style-based global appearance flow for virtual try-on: Limited adaptability to diverse poses and environments.
  - High-resolution virtual try-on with misalignment and occlusion-handled conditions: Struggles with occlusions and misalignments in real-world scenarios.
  - Full-range virtual try-on with recurrent tri-level transform: Inability to handle dynamic movements effectively.
  - Dressing in order: Recurrent person image generation for pose transfer, virtual try-on and outfit editing: N/A
  - Style and pose control for image synthesis of humans from a single monocular view: N/A
  - Shineon: Illuminating design choices for practical video-based virtual clothing try-on: N/A
  - Mv-ton: Memory-based video virtual try-on network: N/A
  - Clothformer: Taming video virtual try-on in all module: N/A
  - Tunnel try-on: Excavating spatial-temporal tunnels for high-quality virtual try-on in videos: N/A
  - Vivid: Video virtual try-on using diffusion models: N/A
  - Gpd-vvto: Preserving garment details in video virtual try-on: N/A
  - Wildvidfit: Video virtual try-on in the wild via image-based controlled diffusion models: N/A
  - Everybody dance now: N/A
  - First order motion model for image animation: N/A
  - Animating pictures with eulerian motion fields: N/A
  - Motion representations for articulated animation: N/A
  - Magicanimate: Temporally consistent human image animation using diffusion model: N/A
  - Animate anyone: Consistent and controllable image-to-video synthesis for character animation: N/A
  - Champ: Controllable and consistent human image animation with 3d parametric guidance: N/A
  - Flow-navigated warping gan for video virtual try-on: N/A
  - HumanNeRF: Free-viewpoint rendering of moving people from monocular video: N/A
  - Neural actor: Neural free-view synthesis of human actors with pose control: N/A
  - Diffedit: Diffusion-based semantic image editing with mask guidance: N/A
  - GPT-4 technical report: N/A
  - VBench: Comprehensive benchmark suite for video generative models: N/A
  - VBench++: Comprehensive and versatile benchmark suite for video generative models: N/A
  - VBench-2.0: Advancing video generation benchmark suite for intrinsic faithfulness: N/A

### 3. Core Idea
- Utilizing dance videos to improve the realism and adaptability of virtual try-on systems in diverse and uncontrolled settings.

### 4. Method
- **Pipeline**: The proposed method involves a multi-stage pipeline that processes dance videos to extract garment features and apply them to target images.
- **Architecture / Loss / Training**: The architecture employs a combination of generative models and loss functions tailored for garment fitting and appearance consistency.
- **Complexity / Resources**: The method requires significant computational resources for video processing and model training, leveraging advanced GPUs.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize a dataset of dance videos and standard metrics for evaluating virtual try-on performance, including visual fidelity and garment fitting accuracy.
- **Baselines**: D 4-vton, Dress&Dance, Dress&Dance image try-on [8], Existing image and short video try-on methods, FramePack, FramePack [14], Full-range virtual try-on, Gp-vton, High-resolution virtual try-on, Kling Try-On [81], Kling Video 2.0, Kling Video 2.0 [81], N/A, Style-based global appearance flow, Texture-preserving diffusion models
- **Main Results**: The proposed method outperforms existing baselines in terms of visual quality and fitting accuracy in various scenarios.
- **Ablations**: Ablation studies demonstrate the importance of each component in the pipeline, particularly the video-based feature extraction.
- **Limitations / Stress Tests**: The method shows limitations in extreme poses and fast movements, where garment fitting may degrade.

### 6. Takeaways
- **Pros**: Generates arbitrarily long virtual try-on videos from a single image., Maintains both local smoothness and global temporal consistency., Enables free viewpoint rendering and 3D consistency.
- **Cons**: Requires careful selection of anchor videos for consistency., Computationally demanding despite improvements.
- **Future Work**: Explore further improvements in temporal consistency., Investigate the application of VFR in different garment types., Develop more efficient training methods to reduce resource requirements.

</details>

### [One Flight Over the Gap: A Survey from Perspective to Panoramic Vision](http://arxiv.org/pdf/2509.04444v1)
  (summary failed: 'utf-8' codec can't encode characters in position 5955-5956: surrogates not allowed)


### [Delta Activations: A Representation for Finetuned Large Language Models](http://arxiv.org/pdf/2509.04442v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Model selection and merging in model hubs

### 2. Motivation & Gaps
- The proposed Delta Activations method facilitates efficient reuse of fine-tuned models by providing an embedding to encode the finetuned modelâ€™s behaviors and capability.

- **Related work challenges:**
  - Existing approaches to represent LLMs: Many methods require access to original training data or assume consistent configurations, which is unrealistic.
  - Ren & Sutherland [53]: Understanding how finetuning on one data point affects responses on others.
  - Previous methods using PCA or matrix factorization: These methods do not differentiate models trained on the same dataset and require metadata.
  - Delta Activations: Traditional methods like flattened weights fail to form effective clusters.
  - Recent works on LLM outputs: Outputs from different LLMs are highly distinguishable, yet clustering performance varies.
  - Previous studies on model clustering: Limited robustness to variations in training settings.
  - Clustering techniques in NLP: Inability to handle diverse output structures and instruction formats.
  - Ilharco et al. [23]: Attempts to represent LLMs using adapter weights or evaluation profiles rely on inaccessible data.
  - Ortiz-Jimenez et al. [47]: Model interference identified where similar models entangle, resulting in poor merging performance.
  - Recent works on model hubs: Creating larger model hubs while achieving true diversity may require further development.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: Expanding public model hubs introduces risks, as low-quality or adversarial models could contaminate the pool.

### 3. Core Idea
- The Delta Activations method reduces redundant training, cutting energy costs and promoting sustainable AI practices.

### 4. Method
- **Pipeline**: Delta Activations are used to identify the most-related LoRA model and sample remaining models for merging.
- **Architecture / Loss / Training**: Token-level cross entropy loss and preference optimization techniques are used.
- **Complexity / Resources**: The study utilizes a model pool organized into domain clusters with varying training settings.

### 5. Experiments
- **Datasets & Metrics**: OpenCoder-LLM, GSM8K, HellaSwag, LegalBench, PubMedQA
- **Baselines**: 20 most similar models using Delta Activations, Flattened weights, Gemma, LLAMA-3.1-8B, LLaMA, N/A, Output sentence embeddings, Qwen, Random model selection, Salient mask
- **Main Results**: Silhouette scores for sub-expertise clustering within domains.
- **Ablations**: The impact of varying training examples, learning rates, and epochs on clustering quality was systematically evaluated.
- **Limitations / Stress Tests**: Further evaluation on other architectures is needed to understand broader applicability.

### 6. Takeaways
- **Pros**: Delta Activations provide a compact behavioral indicator of model differences., The method is robust across different finetuning settings., It exhibits an additive property when combining finetuning datasets.
- **Cons**: The method may not differentiate models trained on the same data with different settings., Requires a fixed set of prompt templates which may limit flexibility.
- **Future Work**: Explore Delta-X for embedding models finetuned from different base LLMs., Encourage the reuse of publicly available models., Investigate further applications in model selection and merging.

</details>
