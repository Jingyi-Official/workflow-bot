# Daily Paper Digest Â· 2025-09-05
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## neural rendering

### [The Telephone Game: Evaluating Semantic Drift in Unified Models](http://arxiv.org/pdf/2509.04438v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Evaluating cross-modal stability and semantic preservation in multimodal models

### 2. Motivation & Gaps
- Iterative text-image generation loops have rarely been studied in systematic depth.

- **Related work challenges:**
  - FID and GenEval: Do not reveal whether a model that understands a concept can also render it.
  - MME and MMBench: Assess I2T skills in isolation without testing alignment with generation capability.
  - ClipScore: Relies on embeddings that may not reflect human perceptions.
  - BAGEL: Correctly reasons about images but fails in faithful image generation.
  - Vila-U: Degrades rapidly in semantic fidelity across generations.
  - Janus: Exposes weaker coupling between visual understanding and generation.
  - Existing T2I and I2T models: They fail to maintain semantic consistency across multiple generations.
  - Single-pass evaluation metrics: They do not capture the gradual drift of concepts across generations.
  - N/A: N/A
  - MME: Assesses basic perception and reasoning but lacks depth in multimodal evaluation.
  - MMBench: Introduces complex queries but does not fully capture semantic drift.
  - MMMU: Focuses on academic problems but may not address practical multimodal applications.
  - Cycle consistency as reward: Learning image-text alignment without human preferences: This work only looks at one generation and is limited to VLM models in general and does not consider unified models.
  - N/A: N/A

### 3. Core Idea
- The paper presents a cyclic evaluation framework that alternates between image-to-text and text-to-image tasks to assess how well models maintain semantic consistency across generations.

### 4. Method
- **Pipeline**: Cyclic evaluation alternating between image-to-text (I2T) and text-to-image (T2I) tasks.
- **Architecture / Loss / Training**: Utilizes a mixture of transformers architecture with specific parameter counts and image resolutions.
- **Complexity / Resources**: BAGEL model has 14B parameters with 7B active during inference, trained on diverse multimodal datasets.

### 5. Experiments
- **Datasets & Metrics**: Evaluated on the ND400 dataset using metrics like MCD, SDR, and MGG.
- **Baselines**: BAGEL, Blip-3o, CLIP, DINO, Existing T2I and I2T models, Janus, Janus 1.3B, LLaV A+SDXL, MPNet, N/A, Show-o, Single-pass metrics, VILA-U, Vila-U, Vila-u
- **Main Results**: BAGEL continues to outperform others in text â†’ text and image â†’ image settings.
- **Ablations**: Further evaluations using CLIP embeddings and fitted parameters for decay functions.
- **Limitations / Stress Tests**: A modelâ€™s proficiency in complex tasks is highly susceptible to generational decay.

### 6. Takeaways
- **Pros**: UCF-UM provides practical metrics for assessing cross-modal stability., Highlights the importance of cyclic consistency in evaluations., Reveals substantial variation in model performance across generations.
- **Cons**: Current metrics do not capture retention of entities and attributes., Single-pass evaluations may misrepresent model capabilities., Existing benchmarks are fragmented and do not assess cross-modal tasks.
- **Future Work**: Develop more comprehensive metrics for evaluating UMs., Explore additional datasets for robust evaluation., Investigate the impact of semantic drift on real-world applications.

</details>

### [Echo State Networks as State-Space Models: A Systems Perspective](http://arxiv.org/pdf/2509.04422v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Analyzing and training recurrent neural networks

### 2. Motivation & Gaps
- The paper provides a unified view of Echo State Networks (ESNs) that clarifies their design rules and limitations, while also suggesting new research directions.

- **Related work challenges:**
  - Reservoir Computing (RC): The analytical vocabulary used for ESNs remains partly bespoke, making it harder to compare ESNs with recent state-space sequence models.
  - Modern sequence models: They dominate long-context learning through structured kernels and dissipative dynamics, which are not well connected to ESNs.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Kalman filtering/smoothing: Requires well-posed identification methods for effective state estimation.
  - Subspace identification methods: Depend on sufficient excitation and window length for reliable identification.
  - Nonlinear systems modeling: Challenges arise from non-Lipschitz maps and input-dependent switching.
  - Kalman smoothing, EM, and subspace identification: Supply denoised states and principled hyperparameter updates
  - Contractionâ€“metric learning: Addressing nonâ€“Lipschitz regimes and heavy switching
  - Probabilistic ESNs: Calibrating uncertainty under drift
  - N/A: N/A

### 3. Core Idea
- The analysis bridges classical Reservoir Computing and modern State Space Models, providing a common language for stability, identifiability, and efficiency in reservoir designs.

### 4. Method
- **Pipeline**: The framework delineates design rules and suggests remedies for various challenges in ESNs.
- **Architecture / Loss / Training**: The paper discusses the transformation of ESN heuristics into certified design rules.
- **Complexity / Resources**: The framework suggests structured reservoirs with fast kernels and end-to-end guarantees.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize various datasets to evaluate the performance of ESNs in different tasks, focusing on stability and identification accuracy.
- **Baselines**: EM, Kalman smoothing, Modern state-space sequence models, N/A, Other neural network architectures, Standard inference tools, Traditional Echo State Networks, Traditional LTI models
- **Main Results**: The unified view clarifies ESN design and opens new research directions.
- **Ablations**: Ablation studies highlight the importance of structured designs and stability certificates in improving model performance.
- **Limitations / Stress Tests**: The framework identifies limits such as nonâ€“Lipschitz regimes and longâ€“delay tasks.

### 6. Takeaways
- **Pros**: Provides a unified framework for understanding ESNs and SSMs., Enhances the analytical vocabulary for ESNs, linking them to established systems theory., Offers principled methods for hyperparameter estimation and model design.
- **Cons**: The approach may require a deeper understanding of systems theory for practitioners., Potentially complex mappings may not be easily interpretable for all users., The reliance on theoretical constructs may limit immediate practical applications.
- **Future Work**: Further exploration of the connections between ESNs and other modern SSM architectures., Investigation of practical implementations of the proposed methods in real-world applications., Development of user-friendly tools to facilitate the application of these theoretical insights.

</details>

### [Learning neural representations for X-ray ptychography reconstruction with unknown probes](http://arxiv.org/pdf/2509.04402v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Ptychographic imaging reconstruction

### 2. Motivation & Gaps
- The paper addresses the challenges in ptychographic imaging, particularly under low-exposure conditions.

- **Related work challenges:**
  - PtychoNN: Dependence on extensive paired training datasets that are difficult to acquire.
  - PtychoNet: Sensitivity to experimental noise and strong dependence on careful initialization.
  - ePIE: Need for sufficient overlap rates between scan positions.
  - ePIE: Exhibits edge ringing and overfits to training artifacts.
  - PINN: Assumes a known probe, which is difficult to obtain accurately.
  - Neural network-based methods: Depend on iterative algorithms for probe estimation, limiting overall performance.
  - ePIE: Notable degradations in reconstruction quality under low overlap ratios.
  - AD: Performance declines rapidly as overlap ratio decreases.
  - RAAR: Fails to recover object amplitude under low overlap conditions.
  - ePIE: Significantly affected by Gaussian noise, leading to poor reconstruction quality.
  - APG: Designed for noisy data but still underperforms compared to PtyINR in various conditions.
  - DM, RAAR, WASP, AD: Exhibit greater susceptibility to noise and artifacts, particularly at larger scanning step sizes.
  - ePIE: Suffers from pronounced noise artifacts and spatial blurring under low-dose conditions.
  - APG: Produces diffuse and suboptimal probe amplitude distributions.
  - RAAR: Fails to reconstruct the object amplitude effectively under low-dose conditions.
  - Cherukara et al.: Reconstruction using conventional algorithms like ePIE can lead to boundary artifacts.
  - Instant-NGP: Efficient encoding of spatial coordinates into learnable features for high-frequency detail representation.
  - Grote, L. et al. (2022): Imaging Cu2O nanocube hollowing in solution by quantitative in situ X-ray ptychography.
  - Diaz, A. et al. (2014): Characterization of carbon fibers using X-ray phase nanotomography.
  - HÃ©monnot, C. Y. J. & KÃ¶ster, S. (2017): Imaging of Biological Materials and Cells by X-ray Scattering and Diffraction.
  - Maiden, A. M. & Rodenburg, J. M. An improved ptychographical phase retrieval algorithm for diffractive imaging.: Improving phase retrieval algorithms for better imaging results.
  - Babu, A. V. et al. Deep learning at the edge enables real-time streaming ptychographic imaging.: Real-time processing and streaming of ptychographic images.
  - Hoidn, O., Mishra, A. A. & Mehta, A. Physics constrained unsupervised deep learning for rapid, high resolution scanning coherent diffraction reconstruction.: Balancing speed and resolution in ptychographic reconstruction.
  - Prior works on ptychographic reconstruction: Instabilities and convergence failures during training, especially with complex probes.
  - SIREN: Instabilities in gradient propagation and convergence challenges during optimization.
  - Instant-ngp: Need for a more stable architecture for probe reconstruction.
  - Auto-differentiation (AD) approach: Inferior performance compared to the proposed architecture.
  - ePIE: Limited performance under high noise conditions.
  - DM: Struggles with fine spatial resolution.
  - RAAR: Inconsistent results across different noise types.
  - Fast R-CNN: Limited performance in low-exposure scenarios.
  - Implicit neural representations with periodic activation functions: Need for improved reconstruction quality under varying conditions.
  - Instant neural graphics primitives: Complexity in handling diverse imaging conditions.

### 3. Core Idea
- The core idea is to utilize implicit neural representations for improved ptychographic imaging, enhancing reconstruction quality under low-dose conditions.

### 4. Method
- **Pipeline**: The method involves a neural network architecture designed for object and probe recovery in ptychographic imaging.
- **Architecture / Loss / Training**: The architecture employs various loss functions, including â„“1, â„“2, and a specific loss function adopted in PtyINR.
- **Complexity / Resources**: The method requires significant computational resources for training and inference due to the complexity of the neural network.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize synthetic datasets and real diffraction patterns to evaluate reconstruction performance.
- **Baselines**: AD, APG, DM, Deep learning-based reconstruction methods, Matrix-based representation (AD), Mean squared error, Other neural network-based approaches, PINN, PtychoNN, RAAR, Traditional ptychographic methods, Traditional ptychographic reconstruction algorithms, Traditional ptychographic reconstruction methods, WASP, ePIE, â„“1 loss
- **Main Results**: The results demonstrate that PtyINR outperforms traditional methods in terms of PSNR and reconstruction quality under low-exposure conditions.
- **Ablations**: Ablation studies highlight the importance of probe normalization and regularization in the recovery process.
- **Limitations / Stress Tests**: Tests reveal limitations in reconstruction quality under extreme noise conditions and varying data acquisition parameters.

### 6. Takeaways
- **Pros**: Achieves superior reconstruction quality., Robust under challenging low-signal conditions., Generalizable framework for various computational microscopy problems.
- **Cons**: Assumes a known probe which can be difficult to obtain., Relies on complex neural network architectures.
- **Future Work**: Explore further applications in computational microscopy., Investigate improvements in training datasets., Develop methods to reduce computational complexity.

</details>

## Gaussian Splatting

### [Generation of Lognormal Synthetic Lyman-$Î±$ Forest Spectra for $P_{1D}$ Analysis](http://arxiv.org/pdf/2509.04405v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- P1D analysis in large-scale surveys

### 2. Motivation & Gaps
- The framework aims to improve the accuracy of P1D measurements by addressing systematic uncertainties and enhancing contaminant identification.

- **Related work challenges:**
  - Baryon Oscillation Spectroscopic Survey (BOSS): First detection of baryon acoustic oscillations in the LyÎ± forest region at high redshift.
  - Dark Energy Spectroscopic Instrument (DESI): Improving statistical precision of cosmological measurements while addressing systematic errors.
  - Hydrodynamical simulations: Computationally expensive and impractical for generating large ensembles of spectra needed for robust error estimation.
  - McDonald et al. (2006): Initial lognormal framework lacked flexibility and precision across varying redshifts.
  - KaraÃ§aylÄ± et al. (2020): Previous methods relied on fixed analytic forms for power spectra, limiting their applicability.
  - DESI Early Data Release and Data Release 1: Need for more accurate synthetic datasets to match the increased statistical precision of upcoming data releases.
  - N/A: N/A
  - KaraÃ§aylÄ± et al. (2020): Previous methods for mock generation did not accurately track the shape and amplitude of the DESI EDR target model.
  - Turner et al. (2024): The effective optical depth model requires precise fitting of parameters to match observed mean flux evolution.
  - Previous P1D mock generation method: Limited fidelity in reproducing the shape of the power spectrum
  - Previous methods for P1D analysis: Limited performance within restricted k-ranges tailored to specific measurements.
  - Damped LyÎ± systems (DLAs) studies: Significant bias on large scales due to extended damping wings.
  - BAL contamination studies: Inflation of P1D through correlated metal absorption features.
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The proposed framework generates lognormal mocks that accurately reproduce the mean transmitted flux and the shape and amplitude of P1D across various scales and redshifts.

### 4. Method
- **Pipeline**: Utilizes uncontaminated mocks to evaluate effects and improve contaminant identification.
- **Architecture / Loss / Training**: Directly fits an underlying Gaussian correlation function.
- **Complexity / Resources**: Employs libraries such as NumPy, SciPy, Astropy, and Matplotlib for computation and visualization.

### 5. Experiments
- **Datasets & Metrics**: Evaluated using DESI EDR redshift range (2.0 â‰¤ z â‰¤ 3.8) and corresponding P1D metrics.
- **Baselines**: Emulator-based approaches, Gaussian correlation function models, Hydrodynamical simulations, KaraÃ§aylÄ± et al. (2024), N-body simulations, N/A, Previous P1D analysis methods, Previous lognormal mock methods, Previous method, Static analytic power spectrum models, Walther et al. (2018)
- **Main Results**: Mocks recover mean transmitted flux with a fractional RMS error of 0.003 and match P1D shape with an average RMS error of 0.02.
- **Ablations**: Future work will incorporate astrophysical contaminants and continuum estimation uncertainties.
- **Limitations / Stress Tests**: Current model assumes fixed variance for Gaussian field, which may introduce bias at low redshifts.

### 6. Takeaways
- **Pros**: Fast and analytically tractable alternative for generating synthetic spectra., Captures essential features of the LyÎ± forest efficiently., Well suited for validation testing in cosmological analyses.
- **Cons**: Not as detailed or physically motivated as hydrodynamic simulations., Insufficient for full cosmological inference., Limited by the coverage and granularity of the training grid in emulator-based approaches.
- **Future Work**: Incorporation of more accurate and flexible synthetic datasets for upcoming DESI releases., Expansion of utility in ongoing and upcoming surveys., Broader range of validation efforts and systematic studies for P1D inference.

</details>

### [SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer](http://arxiv.org/pdf/2509.04379v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D scene segmentation and editing

### 2. Motivation & Gaps
- The paper addresses the need for effective segmentation and editing techniques in 3D scenes, which are crucial for various applications in computer vision and graphics.

- **Related work challenges:**
  - DreamFusion and related works: Lack of effective methods that integrate diffusion priors into a systematically designed 3D style transfer pipeline.
  - Early 3D style transfer methods: Produce noticeable artifacts when applied to complex real-world scenes.
  - Current 3D style transfer methods based on NeRF and 3DGS: Struggle to effectively extract and transfer style semantics from the reference image.
  - Neural style transfer: Struggles with transferring fine style patterns and maintaining consistency across different viewpoints.
  - Text-driven 3D Editing: Existing methods often require iterative updates, which can be inefficient and lead to inconsistencies.
  - 3D style transfer using point clouds and meshes: These approaches produce noticeable artifacts in complex scenes due to geometry and texture imperfections.
  - NeRF: Offers remarkable reconstruction quality but lacks efficient rendering speeds.
  - Gaussian Grouping: Introduces new Identity Encoding parameters but does not guarantee pixel-level 3D consistency.
  - Pretrained diffusion models: While they can transfer style semantics, they do not ensure instance-level consistency across different views.
  - Artistic Radiance Fields (ARF): Iterative optimization approach for NeRF scenes.
  - StyleGaussian: Feed-forward approach designed for 3DGS scenes.
  - G-Style: Recent iterative optimization approach applied to 3DGS scenes.
  - ARF [20]: Low rendering speed and inconsistency in stylization.
  - StyleGaussian [22]: Requires extensive training time and lacks real-time performance.
  - G-Style [23]: Inconsistent results across different views.
  - Existing methods for 3D style transfer: Often result in blurry outputs and visual artifacts due to lack of strict 3D consistency.
  - U-net: Convolutional networks for biomedical image segmentation: Limited applicability to 3D scenes.
  - Neural style transfer: A review: Challenges in maintaining consistency across 3D edits.
  - Layer normalization: Not specifically designed for 3D scene manipulation.

### 3. Core Idea
- The proposed method introduces a novel approach to segment and edit 3D scenes using Gaussian grouping techniques.

### 4. Method
- **Pipeline**: The method involves a multi-step pipeline that integrates segmentation and editing processes.
- **Architecture / Loss / Training**: Utilizes a combination of loss functions tailored for 3D data to optimize the model.
- **Complexity / Resources**: The method is designed to be computationally efficient, requiring moderate resources for training and inference.

### 5. Experiments
- **Datasets & Metrics**: Experiments are conducted on various 3D datasets, evaluating performance using standard metrics for segmentation and editing.
- **Baselines**: ARF [20], Artistic Radiance Fields (ARF), Existing 3D style transfer methods, G-Style, G-Style [23], Gaussian Splatting, InstantStyle, NeRF, Neural style transfer models, Other state-of-the-art stylization methods, State-of-the-art methods in 3D style transfer, Style-Adapter, StyleAlign, StyleGaussian, StyleGaussian [22], Traditional 3D editing tools, U-net
- **Main Results**: The proposed method outperforms existing techniques in terms of segmentation accuracy and editing quality.
- **Ablations**: Ablation studies demonstrate the effectiveness of each component in the proposed pipeline.
- **Limitations / Stress Tests**: The method shows limitations in handling highly complex scenes with occlusions.

### 6. Takeaways
- **Pros**: Maintains style fidelity and instance-level consistency., Produces visually coherent and artistically enriched stylization., Significantly outperforms existing methods.
- **Cons**: May produce blurry results in novel views due to lack of pixel-level consistency., Complexity in training and implementation., Dependence on pretrained models may limit accessibility.
- **Future Work**: Explore further integration of diffusion models in 3D style transfer., Investigate improvements in multi-view consistency., Develop methods to reduce artifacts in complex scenes.

</details>

### [Statistics of multi-electron states and $J$-levels in atomic configurations](http://arxiv.org/pdf/2509.04353v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Derive exact formulas for atomic configurations and distributions of quantum numbers.

### 2. Motivation & Gaps
- The paper presents exact explicit formulas for the number of atomic configurations and distributions of total magnetic quantum number M and total angular momentum J.

- **Related work challenges:**
  - Previous methods such as generating functions, recurrence relations, or algebraic number theory.: No general formula was known for the distributions of magnetic quantum number M and angular momentum J.
  - N/A: N/A
  - N/A: N/A
  - Previous studies on atomic configurations: Limited to small numbers of fermions and involved complex piece-wise polynomials.
  - Recursion relations: Less efficient numerically compared to the new formulas.
  - N/A: N/A

### 3. Core Idea
- The generating functions of the quantities are trigonometric polynomials, allowing for exact evaluation as finite sums at specific points.

### 4. Method
- **Pipeline**: Utilization of trigonometric polynomials for generating functions to derive exact formulas.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The new expressions are simpler and more compact than previous methods.

### 5. Experiments
- **Datasets & Metrics**: N/A
- **Baselines**: Brute-force calculations, N/A, Previous numerical methods for calculating electronic configurations, Recurrence relations
- **Main Results**: The new formulas are much more compact and easier to implement than previous methods.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The new expressions are less efficient numerically than recursion relations for some cases.

### 6. Takeaways
- **Pros**: Provides a general analytical formula for atomic configurations., Addresses a significant gap in atomic spectroscopy calculations., Utilizes generating functions for effective computation.
- **Cons**: The resulting expressions can be cumbersome., The method may require advanced mathematical understanding., Limited experimental validation of the derived formulas.
- **Future Work**: Further simplification of the derived formulas., Application of the formulas to real-world atomic spectroscopy problems., Exploration of the implications for nuclear physics.

</details>

## avatar

### [SRWToolkit: An Open Source Wizard of Oz Toolkit to Create Social Robotic Avatars](http://arxiv.org/pdf/2509.04356v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Human-Robot Interaction (HRI) Evaluation

### 2. Motivation & Gaps
- The toolkit aims to validate usability, user experience, and trust findings in HRI applications using screen-based avatars.

- **Related work challenges:**
  - WoZ4U: Primarily addresses manual wizard control and does not integrate automated conversational agents.
  - Fang et al. (LLM Wizards): While reducing manual workload, it does not focus on local LLM execution.
  - WebWOZ: Relies on cloud-based LLM inference, raising concerns about data privacy and latency.
  - Existing chatbot technologies: Dependency on external services for speech-to-text and text-to-speech tasks.
  - Current user studies: Limited participant diversity and familiarity with chatbot technologies.
  - Screen-based avatars: Need for real-world evaluations with physically embodied robots.
  - Wizard of Oz technique in multimodal human-robot dialogue: Identifying behaviors of large language models for effective HRI experiments.
  - WOZ4U: An open-source wizard-of-oz interface: Creating efficient and robust HRI experiments.
  - Challenges in wizard of oz experimentation for language technology applications: Addressing usability and trust in automated systems.

### 3. Core Idea
- To provide a reproducible toolkit for evaluating HRI through real-time performance improvements and local processing capabilities.

### 4. Method
- **Pipeline**: Utilizes screen-based avatars to simulate robotic behavior and evaluates user interactions.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Complete source code, required packages, and deployment instructions available online.

### 5. Experiments
- **Datasets & Metrics**: Evaluated user perceptions based on various design variables.
- **Baselines**: Existing HRI evaluation methods, LLM Wizards, Previous wizard-of-oz techniques, System Usability Scale (SUS), Trust in Automated Systems (TIA), User Experience Questionnaire (UEQ), WebWOZ, WoZ4U
- **Main Results**: Insights into embodied interaction and perceived presence in HRI.
- **Ablations**: N/A
- **Limitations / Stress Tests**: Investigate the impact of role types and variations in LLMs.

### 6. Takeaways
- **Pros**: Facilitates rapid prototyping of social robotic avatars., Supports multimodal interaction through text and voice., Ensures on-device functionality with local LLM inference.
- **Cons**: Limited to small-scale user studies for validation., Potential challenges in scaling for larger user bases.
- **Future Work**: Explore integration with more advanced LLMs., Expand toolkit features for broader applications., Investigate user feedback for continuous improvement.

</details>

### [Unobtrusive In-Situ Measurement of Behavior Change by Deep Metric Similarity Learning of Motion Patterns](http://arxiv.org/pdf/2509.04174v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the effects of photorealism and personalization on embodiment and self-identification in virtual reality.

### 2. Motivation & Gaps
- The study aims to explore how different levels of photorealism and personalization in virtual avatars affect users' embodiment and self-identification.

- **Related work challenges:**
  - Previous methods for measuring behavior change: Rely on subjective questionnaires or require complex hardware for motion capture.
  - Existing motion analysis techniques: Often operate after exposure and do not provide real-time feedback.
  - Kilteni et al. [13]: Used complex motion capture and analysis of task-specific movement to measure behavior change, requiring additional hardware and making measurement intrusive.
  - Rogers et al. [34]: First to apply motion data for user identification but limited to recognizing only individuals seen during training.
  - Miller et al. [23]: Demonstrated scalability but primarily used classification methods, limiting recognition to previously observed users.
  - Questionnaires: Limited in real-time detection of behavioral changes.
  - Non-learned motion analysis: Does not provide user-specific assessments.
  - ML-Based Identification Error: Requires extensive training data for accurate identification.
  - Capturyâ€™s markerless system: Accurate body motion tracking in a virtual environment.
  - Unityâ€™s avatar animation system: Retargeting body pose accurately to avatars.
  - Machine learning for behavioral changes: Identifying user behavior changes based on avatar height.
  - N/A: N/A
  - N/A: N/A
  - Prior studies on user behavior in VR: Typically rely on larger datasets and subjective input, which may not accurately capture individual user behavior changes.
  - N/A: N/A
  - The Proteus effect: The effect of transformed self-representation on behavior: Understanding how digital self-representation influences behavior in both virtual and real-world contexts.
  - Systematic review and meta-analysis of virtual reality in mental healthcare: Identifying the effects of full body illusions on body image disturbance.
  - The impact of avatar personalization and immersion on virtual body ownership: Examining the relationship between avatar characteristics and emotional responses.

### 3. Core Idea
- The research investigates how varying degrees of avatar photorealism and personalization impact users' sense of self and embodiment in virtual environments.

### 4. Method
- **Pipeline**: Participants engage with avatars of varying photorealism and personalization levels, followed by assessments of embodiment and self-identification.
- **Architecture / Loss / Training**: Utilized a machine learning model to calculate identification error rates based on motion data.
- **Complexity / Resources**: The approach is designed to be scalable and adaptable, allowing for real-time user addition without retraining the model.

### 5. Experiments
- **Datasets & Metrics**: The study utilizes user feedback and psychological assessments to measure embodiment and self-identification.
- **Baselines**: Behavioral tasks, ML-Based Identification Error, N/A, Non-learned motion analysis, Non-learned motion analysis based on central tendencies, Previous motion analysis methods, Previous studies on avatar effects, Previous studies on avatar embodiment, Questionnaire-based assessments, Questionnaires, Standard VR interaction methods, Standard psychological measures of embodiment, Subjective post-exposure embodiment questionnaires
- **Main Results**: Findings indicate that higher levels of photorealism and personalization significantly enhance users' embodiment and self-identification.
- **Ablations**: Analysis of motion data without machine learning to identify differences in user behavior.
- **Limitations / Stress Tests**: The study acknowledges limitations due to the small sample size and short exposure time in VR, suggesting the need for larger and more diverse datasets.

### 6. Takeaways
- **Pros**: In-situ measurement without additional user input, Generalizable and scalable motion analysis for various use cases, User-specific analysis on the individual level
- **Cons**: Requires thorough understanding of study context., May need multiple metrics to identify reliable behavioral changes.
- **Future Work**: Explore further applications of the model in different XR scenarios, Investigate the impact of other avatar characteristics on behavior, Enhance real-time evaluation capabilities

</details>

### [Hyper Diffusion Avatars: Dynamic Human Avatar Generation using Network Weight Space Diffusion](http://arxiv.org/pdf/2509.04145v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D shape representation

### 2. Motivation & Gaps
- The paper addresses the need for effective 3D shape representations in neural fields and generative diffusion models.

- **Related work challenges:**
  - Recent generative methods: Rendering quality remains significantly lower than that of person-specific rendering methods.
  - Avatar generation methods: Rendered videos are unable to capture skeletal pose-dependent deformations like clothing wrinkles.
  - NeRF and 3DGS: Inherit the limitations of NeRF-based approaches, resulting in significantly longer rendering times.
  - NeRF-based approaches: Significantly longer rendering times.
  - 3DGS methods: Primarily focus on single personalized humans.
  - Diffusion models for 3D generation: Suffer from computational inefficiency and fail to model pose-dependent deformations.
  - Person-specific dynamic human rendering: Previous methods relied on person-specific templates, limiting the flexibility and generalization of the model.
  - Diffusion models in neural networks: Existing approaches often flatten all network weights into a single vector, potentially losing important structural information.
  - PrimDiffusion: Can only generate static human avatars.
  - E3Gen: Limited to simple skeleton-based articulation.
  - UNet for motion-aware 3D Gaussians: Limited generalization to unseen poses.
  - Current method for hyper diffusion: Directly learning complex, high-dimensional distribution poses significant training challenges.
  - Gauhuman: Articulated gaussian splatting from monocular human videos: Limited generalization from monocular video inputs.
  - Tech: Text-guided reconstruction of lifelike clothed humans: Dependency on textual input for reconstruction.
  - Dreamhuman: Animatable 3D avatars from text: Challenges in animating avatars without extensive input data.
  - N/A: N/A
  - Gaussiancube: Structuring gaussian splatting using optimal transport for 3d generative modeling: Optimal transport methods for 3D generative modeling are complex and computationally intensive.
  - Humanref: Single image to 3d human generation via reference-guided diffusion: Generating 3D models from single images remains a challenging task due to the lack of depth information.
  - E 3gen: Efficient, expressive and editable avatars generation: Creating editable and expressive avatars efficiently is a significant challenge in 3D modeling.

### 3. Core Idea
- The core idea is to develop a novel representation for 3D shapes that enhances the performance of neural fields and generative models.

### 4. Method
- **Pipeline**: The method involves a pipeline that integrates 3D shape representation with neural networks for generative tasks.
- **Architecture / Loss / Training**: The architecture employs a loss function tailored for 3D shape representation and generative modeling.
- **Complexity / Resources**: The method requires moderate computational resources, balancing efficiency and output quality.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize various 3D datasets and metrics to evaluate the performance of the proposed method.
- **Baselines**: 3DGS methods, Diffusion models for 3D generation, Dreamhuman, E3Gen, Existing 3D shape representation methods, Existing avatar generation methods, Gauhuman, N/A, NeRF-based methods, Previous person-specific dynamic rendering methods, PrimDiffusion, Standard UNet architectures, State-of-the-art human avatar generation methods, Tech, Traditional generative models
- **Main Results**: The proposed method outperforms existing baselines in terms of accuracy and efficiency.
- **Ablations**: Ablation studies demonstrate the impact of different components of the proposed method on performance.
- **Limitations / Stress Tests**: Limitations include potential overfitting on specific datasets and challenges in generalization.

### 6. Takeaways
- **Pros**: Unifies person-specific rendering and diffusion-based generation., Enables dynamic human avatar generation with pose-dependent deformations., Achieves high photorealism in real-time rendering.
- **Cons**: Still limited by the need for multi-view video data., Complexity in training the hyper diffusion model., Potential challenges in generalization across diverse identities.
- **Future Work**: Explore further generalization techniques for different identities., Investigate improvements in rendering speed., Enhance the model's ability to capture more complex deformations.

</details>

## video understanding

### [Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual Try-On from a Single Image -- Technical Preview](http://arxiv.org/pdf/2509.04450v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Virtual Try-On

### 2. Motivation & Gaps
- The paper addresses the challenge of virtual try-on in uncontrolled environments by leveraging dance videos.

- **Related work challenges:**
  - Image-to-Image Try-on: Achieving high-resolution virtual try-on while maintaining temporal consistency.
  - Conventional auto-regressive video generators: Suffering from temporal inconsistency issues between distant frames.
  - He et al. [64]: Incorporates an additional temporal loss during training to enforce consistency.
  - DnD [8]: Generates 5s videos with high resolution but is limited by the duration of the generated video.
  - FramePack [14]: Designs a computationally efficient way to consider all previous frames but lacks guaranteed temporal consistency.
  - Dress&Dance: Limited to trained datasets and lacks temporal consistency.
  - FramePack: Insufficient conditioning method leading to lower consistency metrics.
  - Kling Video 2.0: Quality degradation in virtual try-on despite better consistency.
  - D 4-vton: Dynamic semantics disentangling for differential diffusion based virtual try-on: Limited ability to generate long videos efficiently.
  - Gp-vton: Towards general purpose virtual try-on via collaborative local-flow global-parsing learning: Inadequate garment fidelity and user appearance in generated videos.
  - Texture-preserving diffusion models for high-fidelity virtual try-on: Challenges in achieving smooth and temporally consistent results.
  - Style-based global appearance flow for virtual try-on: Limited adaptability to diverse poses and styles.
  - High-resolution virtual try-on with misalignment and occlusion-handled conditions: Struggles with high-resolution outputs in real-world scenarios.
  - Full-range virtual try-on with recurrent tri-level transform: Inability to handle complex garment interactions.
  - Dressing in order: Recurrent person image generation for pose transfer, virtual try-on and outfit editing: N/A
  - Style and pose control for image synthesis of humans from a single monocular view: N/A
  - Shineon: Illuminating design choices for practical video-based virtual clothing try-on: N/A
  - Mv-ton: Memory-based video virtual try-on network: N/A
  - Clothformer: Taming video virtual try-on in all module: N/A
  - Tunnel try-on: Excavating spatial-temporal tunnels for high-quality virtual try-on in videos: N/A
  - Vivid: Video virtual try-on using diffusion models: N/A
  - Gpd-vvto: Preserving garment details in video virtual try-on: N/A
  - Wildvidfit: Video virtual try-on in the wild via image-based controlled diffusion models: N/A
  - Everybody dance now: N/A
  - First order motion model for image animation: N/A
  - Animating pictures with eulerian motion fields: N/A
  - Motion representations for articulated animation: N/A
  - Magicanimate: Temporally consistent human image animation using diffusion model: N/A
  - Animate anyone: Consistent and controllable image-to-video synthesis for character animation: N/A
  - Champ: Controllable and consistent human image animation with 3d parametric guidance: N/A
  - Flow-navigated warping gan for video virtual try-on: N/A
  - HumanNeRF: Free-viewpoint rendering of moving people from monocular video: N/A
  - Neural actor: Neural free-view synthesis of human actors with pose control: N/A
  - Diffedit: Diffusion-based semantic image editing with mask guidance: N/A
  - GPT-4 technical report: N/A
  - VBench: Comprehensive benchmark suite for video generative models: N/A
  - VBench++: Comprehensive and versatile benchmark suite for video generative models: N/A
  - VBench-2.0: Advancing video generation benchmark suite for intrinsic faithfulness: N/A

### 3. Core Idea
- Utilizing dance videos to enhance the realism and adaptability of virtual try-on systems.

### 4. Method
- **Pipeline**: The proposed method involves a multi-stage process that integrates pose estimation and garment fitting based on video data.
- **Architecture / Loss / Training**: The architecture employs a combination of adversarial loss and perceptual loss to ensure high-quality outputs.
- **Complexity / Resources**: The method requires significant computational resources due to the complexity of video processing and model training.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize a dataset of dance videos and standard metrics for evaluating virtual try-on performance.
- **Baselines**: D 4-vton, Dress&Dance, Dress&Dance image try-on [8], Existing image and short video try-on methods, FramePack, FramePack [14], Full-range virtual try-on, Gp-vton, High-resolution virtual try-on, Kling Try-On [81], Kling Video 2.0, Kling Video 2.0 [81], N/A, Style-based global appearance flow, Texture-preserving diffusion models
- **Main Results**: The proposed method outperforms existing approaches in terms of realism and adaptability.
- **Ablations**: Ablation studies demonstrate the importance of each component in the proposed pipeline.
- **Limitations / Stress Tests**: The method shows limitations in extreme poses and fast movements.

### 6. Takeaways
- **Pros**: Generates high-resolution videos from a single image., Achieves temporal consistency without requiring long videos for training., Enables free viewpoint rendering and 3D consistency.
- **Cons**: Requires computational resources for video generation., Limited by the quality of the input image and reference video.
- **Future Work**: Explore further improvements in video quality and consistency., Investigate the application of VFR in different domains., Develop methods to reduce computational resource requirements.

</details>

### [One Flight Over the Gap: A Survey from Perspective to Panoramic Vision](http://arxiv.org/pdf/2509.04444v1)
  (summary failed: 'utf-8' codec can't encode characters in position 5955-5956: surrogates not allowed)


### [Delta Activations: A Representation for Finetuned Large Language Models](http://arxiv.org/pdf/2509.04442v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Model selection and merging in model hubs

### 2. Motivation & Gaps
- The proposed Delta Activations method facilitates efficient reuse of fine-tuned models by providing an embedding to encode the finetuned modelâ€™s behaviors and capability.

- **Related work challenges:**
  - Existing methods for representing LLMs: Many methods require access to original training data, which is often proprietary or inaccessible, and cannot differentiate models trained on the same data with different settings.
  - Dimensionality reduction techniques: These assume consistent adapter configurations across models, which is unrealistic given the diversity of community-trained LLMs.
  - Evaluation-based embeddings: These reflect only surface-level behavior and are fragile to prompt variations.
  - Ren & Sutherland [53]: Understanding how finetuning on one data point affects LLM responses on others.
  - Previous methods using PCA or matrix factorization: These methods do not differentiate between models trained on the same dataset.
  - Existing embedding methods: They require model metadata and can alter embeddings of existing models.
  - Delta Activations: Existing methods like flattened weights and output sentence embeddings fail to form effective clusters.
  - Recent works on LLM outputs: Outputs from different LLMs are highly distinguishable, indicating a need for better clustering techniques.
  - Previous studies on model clustering: Limited robustness to variations in training settings.
  - Clustering techniques in NLP: Inability to capture nuanced differences in model performance.
  - Ilharco et al. [23]: Merging task vectors from finetuning to achieve multi-task learning.
  - Ortiz-Jimenez et al. [47]: Model interference identified when selecting similar models.
  - Recent works on embedding models: Reliance on potentially inaccessible data or failure to reflect internal behavior.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: Expanding public model hubs introduces risks, as low-quality or adversarial models could contaminate the pool.

### 3. Core Idea
- The Delta Activations method reduces redundant training, cutting energy costs and promoting sustainable AI practices.

### 4. Method
- **Pipeline**: Delta Activations are used to identify the most-related LoRA model and sample remaining models for merging.
- **Architecture / Loss / Training**: Token-level cross entropy loss for supervised finetuning and preference optimization techniques.
- **Complexity / Resources**: Utilizes multiple models across different training settings with varying hyperparameters.

### 5. Experiments
- **Datasets & Metrics**: OpenCoder-LLM, GSM8K, HellaSwag, LegalBench, PubMedQA
- **Baselines**: Delta Activations, Flattened weights, LLAMA-3.1-8B, N/A, Nearest-neighbour selection, Output sentence embeddings, Random model selection, Salient mask
- **Main Results**: Average performance improvement of 2.0% from 34.3% to 36.3% accuracy.
- **Ablations**: Investigated the impact of training settings on clustering quality.
- **Limitations / Stress Tests**: Further evaluation on other architectures is needed.

### 6. Takeaways
- **Pros**: Provides a compact behavioral indicator for model differences., Facilitates model selection and merging., Encourages the reuse of publicly available models.
- **Cons**: Requires a fixed set of prompt templates for evaluation., May not capture all nuances of model behavior.
- **Future Work**: Explore Delta-X for other types of representations., Investigate further applications in model selection., Develop standardized metadata for model repositories.

</details>
