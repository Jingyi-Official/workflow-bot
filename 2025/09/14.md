# Daily Paper Digest ¬∑ 2025-09-14
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## neural rendering

### [FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark](http://arxiv.org/pdf/2509.09680v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Text-to-Image Generation

### 2. Motivation & Gaps
- The paper addresses the challenges in text-to-image generation, particularly in complex tasks such as text rendering and long instruction following.

- **Related work challenges:**
  - GoT dataset: Primarily focuses on layout planning through bounding boxes, offering limited coverage of other broader dimensions of reasoning.
  - Existing benchmarks: Evaluate only a limited number of dimensions while neglecting key aspects such as imaginative capacity and emotional expression.
  - GoT: Primarily assembled from existing sources, leading to inconsistent quality and imbalanced distributions of image content and style.
  - Generative models for image synthesis: Producing high-quality images consistently.
  - Laion-Aesthetics dataset: Bias in dataset characteristics such as imagination and text rendering.
  - Quality assurance in image datasets: Ensuring clarity and structural consistency in generated images.
  - Traditional captioning paradigms: Limited to simple descriptive text without reasoning.
  - Existing T2I benchmarks: Inability to provide multidimensional evaluation.
  - Existing evaluation methods for VLMs: Lack of specificity in assessing model performance across diverse prompt categories.
  - PRISM-Bench: Incorporating high density of details from complex, multi-sentence prompts.
  - VLM Aesthetic Evaluation: Ensuring fair comparison of visual quality across different models.
  - Qwen-Image: Performance gap compared to top models.
  - HiDream-I1-Full: Maintaining high fidelity in creative interpretation.
  - FLUX.1-Krea-dev: Text rendering remains a significant challenge.
  - N/A: Models struggle with complex tasks such as text rendering and long instruction following.
  - Hrs-bench: Holistic, reliable and scalable benchmark for text-to-image models: Existing models struggle with complex tasks.
  - Conceptual 12m: Pushing web-scale image-text pre-training to recognize long-tail visual concepts: Limited performance in fine-grained human-aligned evaluation.
  - Attend-and-excite: Attention-based semantic guidance for text-to-image diffusion models: Need for improved semantic alignment in generated images.
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- Development of PRISM-Bench, a comprehensive benchmark for evaluating text-to-image models using advanced VLMs.

### 4. Method
- **Pipeline**: Evaluation of models based on quantitative results from PRISM-Bench.
- **Architecture / Loss / Training**: Utilizes Qwen-VL for generating captions and reasoning chains.
- **Complexity / Resources**: The method utilizes advanced VLMs like GPT-4.1 and Qwen2.5-VL-72B for evaluation, requiring significant computational resources.

### 5. Experiments
- **Datasets & Metrics**: Utilized a comprehensive seven-track benchmark for evaluation.
- **Baselines**: Bagel, Bagel-CoT, Existing T2I benchmarks, Existing open-source models, FLUX series, FLUX.1-Krea-dev, FLUX.1-dev, GPT-4.1, GPT-Image-1, Gemini-2.5-Pro, Gemini2.5-Flash-Image, HiDream series, HiDream-I1-Dev, HiDream-I1-Full, JanusPro, Leading closed-source systems, N/A, Playground, Qwen-Image, Qwen2.5-VL-72B, Qwen3-32B, SEEDream 3.0, SEEDreeam 3.0, Stable Diffusion series, Traditional captioning models
- **Main Results**: Leading models show impressive performance but struggle with complex tasks.
- **Ablations**: Evaluated the impact of category-specific captions on model performance.
- **Limitations / Stress Tests**: All models struggle with complex tasks such as text rendering and long instruction following.

### 6. Takeaways
- **Pros**: Provides a large-scale dataset for training reasoning-oriented T2I models., Introduces a comprehensive evaluation benchmark closely aligned with human judgment., Addresses critical gaps in existing datasets and benchmarks.
- **Cons**: The dataset creation process is resource-intensive and costly., Existing models may still struggle with complex prompts despite the new dataset.
- **Future Work**: Encourage further research on reasoning capabilities in T2I models., Explore additional dimensions of evaluation beyond current benchmarks., Develop more efficient methods for dataset creation and model training.

</details>

### [SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning](http://arxiv.org/pdf/2509.09674v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Reinforcement Learning for Vision-Language-Action Models

### 2. Motivation & Gaps
- The paper addresses the challenges in scaling Vision-Language-Action (VLA) training through reinforcement learning.

- **Related work challenges:**
  - DeepSeek-R1: Demonstrates RL can enhance reasoning but applying it to VLA models presents unique challenges.
  - SFT of VLAs: Relies on limited, scene- and task-specific data, leading to poor generalization.
  - Robotic trajectory collection: Scarcity and high cost of human-operated trajectories limit scalability.
  - Ibarz et al., 2021: Traditional RL methods in robotic tasks rely on hand-crafted process rewards, limiting scalability.
  - Kroemer et al., 2021: VLA models require multi-round interactions with the environment, making the process slower and more costly.
  - Ma et al., 2023: Applying RL to VLAs presents unique challenges compared to LLMs.
  - DeepSeek-R1: Requires carefully crafted reward functions for RL training.
  - Previous works on RL exploration: VLA models tend to converge on a narrow set of solution patterns due to homogeneity in training trajectories.
  - Dynamic Sampling: Critic-free RL algorithms suffer from vanishing gradients when trajectories are assigned the same rewards.
  - GRPO algorithm [Shao et al., 2024]: The need for a reference model during training limits exploration and increases memory consumption.
  - DAPO [Yu et al., 2025]: KL divergence regularization constrains policy divergence, potentially limiting the exploration of new behaviors.
  - Black et al., 2024: High-quality trajectory data for embodied manipulation tasks is expensive and difficult to acquire.
  - Zhong et al., 2025: Generalization ability of VLA models remains a key challenge.
  - Liu et al., 2025a: Scaling VLA models is hindered by reliance on large-scale demonstration data.
  - SFT: SFT suffers from severe overfitting and catastrophic forgetting, leading to performance degradation on unseen tasks.
  - RDT: RDT does not utilize reinforcement learning, limiting its effectiveness in real-world scenarios.
  - DeepSeek-R1: Demonstrates the emergence of novel strategies through RL, contrasting with traditional supervised fine-tuning (SFT).
  - RLHF: Aligns models with human preferences but heavily relies on preference modeling, limiting exploration.
  - DAPO: Introduces a decoupled variant of PPO clipping to enhance exploration but faces challenges in maintaining effective training.
  - E-COT: Improving spatial reasoning ability of VLA models.
  - RDT-1B and VPP: Proposing diffusion-based frameworks for VLA models.
  - Dexmimicgen: Addressing data scarcity in robotics.
  - How to train your robot with deep reinforcement learning: lessons we have learned: Identifying effective training strategies for robots.
  - A review of robot learning for manipulation: Challenges, representations, and algorithms: Understanding the complexities in robot manipulation learning.
  - Eureka: Human-level reward design via coding large language models: Designing rewards that align with human-level performance.
  - Back to basics: Revisiting reinforce style optimization for learning from human feedback in llms: Inefficiencies in current optimization methods for learning from human feedback.
  - Training language models to follow instructions with human feedback: Difficulty in aligning model outputs with human expectations.
  - Interactive post-training for vision-language-action models: Challenges in effectively integrating interactive learning mechanisms.

### 3. Core Idea
- The paper proposes a novel approach to enhance the training of VLA models using scalable reinforcement learning techniques.

### 4. Method
- **Pipeline**: The proposed method involves a structured pipeline that integrates reinforcement learning with existing VLA training frameworks.
- **Architecture / Loss / Training**: Utilizes a combination of loss functions tailored for VLA tasks to optimize model performance.
- **Complexity / Resources**: The method is designed to be resource-efficient, allowing for scalability in training large models.

### 5. Experiments
- **Datasets & Metrics**: The experiments are conducted on various benchmark datasets with metrics focusing on VLA performance.
- **Baselines**: DP [Chi et al., 2024], DP3 [Ze et al., 2024], DeepSeek-R1, LLM-based generation methods, Model fine-tuned with 100 demonstration trajectories, Model fine-tuned with 1000 demonstration trajectories, Nora [Hung et al., 2025], Octo [Team et al., 2024], OpenVLA [Kim et al., 2024], OpenVLA-OFT, OpenVLA-OFT base model without trajectory fine-tuning, Previous VLA training methods, Previous reinforcement learning approaches, RDT, RDT-1B [Liu et al., 2024], RL, SFT, SFT-only, SFT-tuned models, Standard VLA models, Standard reinforcement learning models, Supervised Fine-Tuning (SFT), Traditional RL approaches, UniVLA [Bu et al., 2025b], veRL, ùúã0 [Black et al., 2024], ùúãfast [Pertsch et al., 2025]
- **Main Results**: The proposed method shows significant improvements in VLA task performance compared to baseline models.
- **Ablations**: Ablation studies demonstrate the effectiveness of each component in the proposed method.
- **Limitations / Stress Tests**: The paper discusses limitations related to the generalizability of the approach across different VLA tasks.

### 6. Takeaways
- **Pros**: Reduces dependence on large-scale data., Enables robust generalization to unseen tasks., Surpasses SFT in real-world tasks.
- **Cons**: Requires significant computational resources., Challenges in data collection remain., RL training can introduce complexity in policy learning.
- **Future Work**: Explore further enhancements in RL for VLA models., Investigate the scalability of the framework., Develop methods to improve data collection efficiency.

</details>

### [Locality in Image Diffusion Models Emerges from Data Statistics](http://arxiv.org/pdf/2509.09672v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Image Generation using Denoising Diffusion Probabilistic Models

### 2. Motivation & Gaps
- The paper addresses the efficiency and effectiveness of various denoising methods in image generation, particularly focusing on the Wiener filter and its application in DDPMs.

- **Related work challenges:**
  - Kamb and Ganguli: Their theory cannot predict the degree of locality from first principles and relies on measuring the receptive field of a trained UNet.
  - Prior optimal denoiser-based methods: They are outperformed by a simple optimal linear filter.
  - Recent analytical models: They fail to capture pixel correlations effectively.
  - Yoon et al. [34]: Introduce the memorization-generalization dichotomy, positing that diffusion models generalize when they avoid memorizing training data.
  - Yi et al. [33]: Formalize generalization through mutual information metrics, demonstrating that trained diffusion models can generalize beyond the empirical optimal solutions.
  - Gu et al. [7]: Investigate factors such as dataset size and conditioning that can influence the extent of memorization in diffusion models.
  - Kamb and Ganguli [12]: Assumed locality patterns in diffusion models are isotropic and constant, which may not hold for specialized datasets.
  - Previous works [17, 29]: Trained diffusion models exhibit linear behavior that can be approximated by a Wiener filter, but this may not generalize across all datasets.
  - N/A: N/A
  - Previous work on learned sensitivity fields in diffusion networks: Understanding the generalization of these fields and their dependence on local data statistics.
  - Kamb and Ganguli [12]: Patch-based locality erasing eyes and blurring out facial features.
  - Niedoba et al. [19]: Limited performance in capturing dataset-dependent locality.
  - Previous diffusion models: Assumption of Gaussian datasets and reliance on architectural inductive biases.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Optimal Denoiser: Produces noisy single-step predictions for high noise levels.
  - Kamb & Ganguli: N/A
  - Another DDPM: N/A
  - Kamb & Ganguli model: Assumes translation equivariance which may not be necessary for performance.
  - Niedoba et al. model: Performance degradation observed with equivariance to translations.

### 3. Core Idea
- The implementation of various models and their analysis in terms of algorithmic complexity and computational efficiency for image generation tasks.

### 4. Method
- **Pipeline**: The method involves using Wiener filters for denoising and applying DDIM sampling for image generation.
- **Architecture / Loss / Training**: Trained for 200 epochs with a batch size of 32 using Adam optimizer and a learning rate of 10^-4.
- **Complexity / Resources**: The method has a complexity of O(nptm) for the proposed model and O(nptm2/k) for Kamb & Ganguli's approximate method.

### 5. Experiments
- **Datasets & Metrics**: The experiments were conducted on datasets such as CIFAR10, CelebA-HQ, AFHQ, MNIST, and Fashion MNIST, measuring total sampling time over 10 denoising steps.
- **Baselines**: Analytical models based on optimal denoiser, Another DDPM, Another trained DDPM, Kamb & Ganguli, Kamb and Ganguli [12], N/A, Niedoba et al., Niedoba et al. [19], Optimal Denoiser, Optimal denoiser, Other denoising architectures, Previous patch-based analytical models, Simple UNet diffusion model, U-Net with self-attention, U-Net without self-attention, Unet, Wiener (linear), Wiener filter
- **Main Results**: The results show that the proposed method has competitive performance in terms of sampling time compared to the baselines.
- **Ablations**: Effect of different binarization thresholds on model performance.
- **Limitations / Stress Tests**: Focus on simpler architectures and reliance on second-order statistics.

### 6. Takeaways
- **Pros**: Demonstrates locality is a learned property of deep diffusion models., Establishes a quantitative benchmark for analytical diffusion models., Improves performance of analytical models by incorporating statistical insights.
- **Cons**: Relies on the quality of the training dataset for locality properties., May not generalize well to datasets with low self-similarity., Analytical models still have limitations in capturing all aspects of deep diffusion models.
- **Future Work**: Explore locality in other generative models beyond diffusion models., Investigate the impact of different training datasets on locality properties., Develop more robust analytical models that can generalize better across diverse datasets.

</details>

## Gaussian Splatting

### [Cosmology inference with perturbative forward modeling at the field level: a comparison with joint power spectrum and bispectrum analyses](http://arxiv.org/pdf/2509.09673v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Cosmological inference from galaxy redshift surveys

### 2. Motivation & Gaps
- The paper addresses the challenges in accurately reconstructing the initial conditions of the universe from large-scale structure data.

- **Related work challenges:**
  - Previous studies on field-level inference: Most analyses focused on simple examples with limited cosmological parameters.
  - Perturbative forward modeling: Specifying the likelihood and forward model in the nonlinear regime is nontrivial.
  - Ref. [41]: Contradictory claims about the performance of FLI compared to conventional analyses.
  - Ref. [42]: Significant differences in error bars on cosmological parameters between FLI and joint power spectrum analysis.
  - Ref. [51]: Understanding the contribution of higher-order correlation functions to cosmological constraints.
  - Ref. [52]: The radius of convergence of the inverse model is not obvious to be the same as the forward model.
  - Refs. [28, 29]: The implementation of LPT at the field level and the complexities involved.
  - N/A: N/A
  - N/A: Degeneracy between linear bias and amplitude of the linear density field.
  - N/A: N/A
  - Hybrid Monte Carlo in lattice QCD: Adapting HMC for cosmological parameter inference while managing the complexity of posterior correlations.
  - CosmoPower-JAX: Balancing the exploration of global parameters and initial conditions in a computationally efficient manner.
  - Ref [52]: Comparison of posteriors for FLI and standard inference approach.
  - Sec. II: Testing predictions for the SNR with varying free parameters.
  - Sec. VI and Sec. VII: Discussing implications of non-Gaussianity in residual field-level noise.
  - N/A: Incorporating higher-order statistics does not automatically lead to improved constraints unless they break parameter degeneracies.
  - N/A: Degeneracy patterns in cosmological parameter estimation
  - Previous studies on Eulerian perturbation theory: The complexities of real galaxy density fields and their relation to dark matter.
  - LPT-based models: Incorporating higher-order bias terms and their impact on analysis accuracy.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Ref [28]: Demonstrated that the distribution of residuals is non-Gaussian, complicating the use of Gaussian likelihoods.
  - Perturbative forward modeling: While it can account for non-Gaussian noise, the assumption of Gaussian likelihoods may not hold.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Bayesian reconstruction of the cosmological large-scale structure: Methodology and numerical optimization issues.
  - Fast Hamiltonian sampling for large scale structure inference: Efficiency in sampling and parameter estimation.
  - Bayesian physical reconstruction of initial conditions: Handling non-linear and stochastic biases in tracers.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The paper proposes a microcanonical Langevin Monte Carlo method for field-level inference, improving the sampling efficiency of cosmological parameters.

### 4. Method
- **Pipeline**: The method involves a Bayesian framework for reconstructing the initial density field using MCMC techniques.
- **Architecture / Loss / Training**: LPT-based model with linear bias.
- **Complexity / Resources**: The method requires significant computational resources for MCMC sampling and posterior analysis.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize mock catalogs and real galaxy redshift survey data to validate the proposed method.
- **Baselines**: Bispectrum analysis, Field-level analysis, Gaussian likelihood with Gaussian noise, Gaussian likelihood with density-dependent noise, Gaussian noise case, Hamiltonian Monte Carlo approaches, Joint power spectrum analysis, Joint power spectrum and bispectrum analysis, N/A, Power spectrum analysis, Standard inference approach, Traditional MCMC methods, joint power spectrum and bispectrum analysis
- **Main Results**: The proposed method shows improved sampling efficiency and accuracy in reconstructing the initial conditions compared to traditional methods.
- **Ablations**: Comparison of results with and without density-dependent variance.
- **Limitations / Stress Tests**: The method exhibits slow mixing for certain parameters, indicating potential limitations in sampling efficiency.

### 6. Takeaways
- **Pros**: Optimal use of full information from observed fluctuations., Accurate recovery of cosmological parameters., Potential for application to real data.
- **Cons**: Dependence on correct likelihood choice., Challenges in nonlinear regime., Limited exploration of complex cosmological scenarios.
- **Future Work**: Explore applications to real observational data., Investigate effects of non-Gaussian noise further., Extend to more complex cosmological models.

</details>

### [Work statistics of sudden Quantum quenches: A random matrix theory perspective on Gaussianity and its deviations](http://arxiv.org/pdf/2509.09640v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Analyze the work distribution in sudden quantum quenches using random matrix theory.

### 2. Motivation & Gaps
- Understanding the statistics of work performed during rapid nonequilibrium protocols is crucial in quantum thermodynamics.

- **Related work challenges:**
  - Previous studies on quantum thermodynamics: Lack of precise characterization of work distributions in sudden quenches.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The work distribution in a sudden quench is mapped onto a random matrix problem, predicting a Gaussian core for large system sizes with variance determined by quench parameters.

### 4. Method
- **Pipeline**: Utilize multivariate central limit theorems for vectors of traces of unitaries to derive the work distribution.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The method involves complex mathematical constructs including Toeplitz determinants and random matrix theory.

### 5. Experiments
- **Datasets & Metrics**: Numerical diagnostics were used to support analytical results.
- **Baselines**: Classical central limit theorem results, N/A, Previous quantum thermodynamics models
- **Main Results**: The data agrees with the random-matrix central limit theorem for traces, showing a Gaussian bulk with variance set by the quadratic form.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The results are contingent on the interaction range and the number of harmonics included.

### 6. Takeaways
- **Pros**: Provides a rigorous framework for understanding work distributions in quantum systems., Establishes connections between random matrix theory and quantum thermodynamics., Offers insights into the conditions leading to Gaussian and non-Gaussian distributions.
- **Cons**: Complex mathematical framework may limit accessibility for broader audiences., Results depend on specific conditions that may not be universally applicable., Numerical checks may not cover all possible scenarios in quantum systems.
- **Future Work**: Explore implications of non-Gaussian corrections in various quantum systems., Investigate the effects of different interaction ranges on work distributions., Develop experimental protocols to test theoretical predictions.

</details>

### [Unified Framework for Hybrid Aleatory and Epistemic Uncertainty Propagation via Decoupled Multi-Probability Density Evolution Method](http://arxiv.org/pdf/2509.09535v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Uncertainty propagation in dynamical systems

### 2. Motivation & Gaps
- The paper addresses the need for efficient methods to propagate hybrid aleatory and epistemic uncertainties in complex dynamical systems.

- **Related work challenges:**
  - Conventional double-loop approaches for uncertainty propagation: Prohibitively high computational costs for large engineering systems.
  - Recent developments in decoupling uncertainties: Unsuitable for distribution-free p-box inputs.
  - Probability density evolution method (PDEM): Accuracy diminishes for large variation in input distributions.
  - Chen & Wan 2019: Diminished accuracy for large variation in input distributions.
  - Jiang et al. 2018: Lack of universal compatibility across diverse epistemic uncertainty representations.
  - Li & Chen (2008): Limited to one-dimensional Li-Chen equations.
  - Chen & Li (2009): Does not address the coupling of multiple dimensions in joint PDFs.
  - Lyu et al. (2024d): Challenges in analytical treatment of multi-dimensional equations.
  - N/A: N/A
  - Previous methods for uncertainty propagation: Limited efficiency and accuracy in high-dimensional epistemic uncertainty scenarios.
  - Existing PDEM methodologies: Challenges in extending to higher-dimensional epistemic uncertainties.
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The proposed decoupled multi-probability density evolution method (M-PDEM) provides a unified framework for handling hybrid uncertainties in dynamical systems.

### 4. Method
- **Pipeline**: The method involves an augmented random space representation to decouple various forms of epistemic uncertainty.
- **Architecture / Loss / Training**: The method decomposes high-dimensional joint PDF solutions into manageable one-dimensional partial differential equations.
- **Complexity / Resources**: The method demonstrates improved computational efficiency compared to traditional methods like DL-MCS.

### 5. Experiments
- **Datasets & Metrics**: Numerical examples involving diverse types of uncertain inputs were used to validate the framework.
- **Baselines**: Classical stochastic dynamic analysis methods, DL-MCS, Finite difference scheme, Imprecise probabilistic models, Mesh free scheme, N/A, Non-probabilistic models, Path integration, Probability density evolution method (PDEM), Traditional probabilistic models, Vertex MCS
- **Main Results**: The decoupled M-PDEM shows satisfactory agreement with DL-MCS results while improving computational efficiency.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The method faces challenges in higher-dimensional epistemic uncertainty and capturing tail behavior in reliability analysis.

### 6. Takeaways
- **Pros**: Accommodates various uncertainty representations., Improves computational efficiency for large systems., Enhances understanding of hybrid uncertainties.
- **Cons**: Limited to specific types of systems., May require complex transformations., Accuracy issues for large variations in input distributions.
- **Future Work**: Extend framework to more complex nonlinear systems., Improve compatibility with diverse epistemic uncertainty representations., Explore real-world applications in engineering.

</details>

## avatar

### [Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis](http://arxiv.org/pdf/2509.09595v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Long-duration avatar video generation

### 2. Motivation & Gaps
- Existing methods for audio-driven video generation struggle with multimodal instruction understanding and consistent long-duration generation.

- **Related work challenges:**
  - Video Diffusion Transformers (DiT): Insufficient for highly realistic portrait synthesis; current approaches treat each conditional signal independently, leading to semantic conflicts.
  - Prior work on facial expression and lip synchronization: Often results in visually polished outputs that are inconsistent with human expectations.
  - Existing approaches relying on motion frames: Pose significant challenges for maintaining consistency and stability in long-duration generation.
  - Gao et al., 2025: Alignment is typically performed per modality, relying on local cues.
  - Fei et al., 2025: Shallow fusion at the generation stage limits expressive capabilities.
  - Wang et al., 2025a: Existing methods do not effectively manage emotional consistency across modalities.
  - OmniHuman: Identity drift and texture distortions in generated videos.
  - HeyGen: Maintaining visual quality and lip synchronization.
  - Diffusion models for image synthesis: Early video generation approaches face limitations in scalability in terms of resolution and sequence length.
  - Audio-driven digital human synthesis: Existing methods are typically limited to facial animation and cannot produce natural upper-body motion or hand gestures.
  - Jiang et al., 2025: Struggle with multimodal instruction understanding.
  - Gan et al., 2025: Reliance on local cues for alignment within each modality.
  - Huang et al., 2025: Inconsistent long-duration generation.
  - N/A: N/A

### 3. Core Idea
- A cascaded framework that unifies multimodal instruction understanding with long-duration generation of lifelike portrait videos.

### 4. Method
- **Pipeline**: Two-stage pipeline: first employs an MLLM director to produce a blueprint video, then synthesizes long videos through parallel sub-clip generation.
- **Architecture / Loss / Training**: Guided by blueprint keyframes to refine local dynamics.
- **Complexity / Resources**: Coupled with carefully curated data and practical training and inference strategies.

### 5. Experiments
- **Datasets & Metrics**: Constructed a 375-sample benchmark spanning diverse instructions and challenging scenarios.
- **Baselines**: Existing audio-driven video generation methods, HeyGen, N/A, OmniHuman, OmniHuman-1
- **Main Results**: Kling-Avatar delivers vivid, fluent videos up to 1080p and 48 fps, with precise lip synchronization and strong controllability.
- **Ablations**: The paper plans to incorporate additional objective metrics in future assessments to complement the GSB evaluations.
- **Limitations / Stress Tests**: The method's performance on Japanese and Korean samples is less reliable due to their small numbers.

### 6. Takeaways
- **Pros**: Generates vivid, fluent, long-duration videos at up to 1080p and 48 fps., Maintains strong generalization to open-domain scenarios., Achieves superior performance across multiple evaluation metrics.
- **Cons**: Dependency on high-quality data for optimal performance., Complexity in managing multiple input modalities., Potential limitations in emotional expression under certain conditions.
- **Future Work**: Further improve the understanding of multimodal inputs., Explore additional applications in virtual assistants and education., Enhance the robustness of the framework for diverse scenarios.

</details>

### [PanoLAM: Large Avatar Model for Gaussian Full-Head Synthesis from One-shot Unposed Image](http://arxiv.org/pdf/2509.07552v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- 3D reconstruction from single-view images

### 2. Motivation & Gaps
- The paper addresses the limitations of existing methods in reconstructing 3D representations from single-view images, particularly focusing on fidelity and generalization to real-world images.

- **Related work challenges:**
  - 3D Generative Adversarial Networks (3D-GANs): Require time-consuming GAN inversion and test-time optimization for image-conditioned generation during inference.
  - Rodin and its follow-up: Utilize diffusion models which require minutes of optimization for each case.
  - 2D super-resolution upsampling: Improves rendering efficiency and quality but compromises 3D consistency.
  - EG3D: Requires time-consuming GAN inversion and test-time optimization for image-conditioned generation.
  - Diffusion models: Multi-step diffusion process is slow and computation-consuming during inference.
  - NeRF-based approaches: Slow rendering speed and low-resolution images lead to view inconsistencies.
  - FLAME model: Inability to model large deformations such as long hairs, glasses, and caps.
  - TriplaneGaussian: Point-based query strategy cannot fully fetch valuable features from the spherical triplane.
  - Previous methods: Require a network trained to upsample sparse points.
  - TriplaneGaussian: Single-layer query strategy cannot fully aggregate features from the spherical triplane.
  - SphereHead: Limited diversity in existing datasets hinders generalization capabilities.
  - Existing 3D head reconstruction methods: Dependence on accurate camera poses and complex optimization processes.
  - Gaussian shell maps for efficient 3d human generation: N/A
  - Panohead: Geometry-aware 3d full-head synthesis in 360¬∞: N/A
  - Rignerf: Fully controllable neural 3d portraits: N/A
  - N/A: N/A
  - N/A: N/A
  - Next3d: Generative neural texture rasterization for 3d-aware head avatars: Limited fidelity in head avatar generation.
  - RODIN: A generative model for sculpting 3d digital avatars using diffusion: Challenges in achieving real-time performance.
  - Gaussian head avatar: Ultra high-fidelity head avatar via dynamic gaussians: Complexity in modeling dynamic facial expressions.
  - EG3D: Limited to rendering near-frontal images.
  - SphereHead: Biases in the dataset leading to poor reconstruction results for certain demographics.

### 3. Core Idea
- The proposed framework combines triplane representation with Gaussian splatting to enhance the quality and generalizability of 3D reconstructions from single-view images.

### 4. Method
- **Pipeline**: The method involves generating a large-scale dataset using trained 3D GANs, followed by training a network on this dataset to reconstruct 3D representations.
- **Architecture / Loss / Training**: The architecture employs a loss function that emphasizes fidelity and consistency in novel view synthesis.
- **Complexity / Resources**: The method requires significant computational resources for training on large-scale datasets.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize a large-scale synthesized dataset and real-world images from the VFHQ dataset, measuring fidelity and artifact presence.
- **Baselines**: 3D-GANs, Default configuration of existing 3D head reconstruction methods, Diffusion models, EG3D, FLAME model, Gaussian samples (ùúé=1), Gaussian samples (ùúé=10), LGM, LGMHunyuan3D, N/A, NeRF-based approaches, NeRF-based frameworks, Ours, PH-PTI, PanoHead-PTI, Previous state-of-the-art methods in head avatar generation., SH-PTI, SphereHead, SphereHead-PTI, TriplaneGaussian
- **Main Results**: The proposed framework achieves higher fidelity results with fewer artifacts compared to previous methods.
- **Ablations**: Ablation studies demonstrate the impact of different components of the framework on reconstruction quality.
- **Limitations / Stress Tests**: The framework shows limitations in reconstructing Asian faces and cartoon heads due to biases in the training datasets.

### 6. Takeaways
- **Pros**: Fast reconstruction and rendering of 3D avatars., High-fidelity Gaussian head reconstruction., Utilizes a large-scale synthetic dataset for training.
- **Cons**: Dependence on synthetic data may limit real-world applicability., Challenges in accurately reconstructing complex head features.
- **Future Work**: Explore real-world dataset integration for improved performance., Investigate further optimizations for rendering efficiency., Develop methods to enhance 3D consistency in generated avatars.

</details>

### [Reconstruction and Reenactment Separated Method for Realistic Gaussian Head](http://arxiv.org/pdf/2509.05582v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Mapping audio sequences to motion sequences for lip synchronization

### 2. Motivation & Gaps
- The paper addresses the challenge of achieving accurate lip synchronization in 3D models driven by audio input.

- **Related work challenges:**
  - Goodfellow et al. (2014): 2D-based approaches rely on deep convolutional networks and generative adversarial models, which lack explicit 3D structural priors.
  - Mildenhall et al. (2020): Cutting-edge 3D synthesis technologies require precise estimation of the 3D pose from a single image, introducing estimation errors.
  - Guo et al. (2024): 2D end-to-end approaches generate pseudo-3D motions that are easier to learn but do not accurately represent true 3D motion.
  - 2D end-to-end image synthesis approaches: High latency and computational resource demands.
  - 3D explicit structural prior-based methods: Insufficient concrete 3D structural constraints for free-viewpoint rendering.
  - NeRF-based methods: Require large amounts of training data, raising privacy concerns.
  - Deng and others. 2024b: Previous methods lacked effective feature extraction for downstream tasks.
  - Chu and others. 2024a: Existing methods did not leverage larger training datasets for better feature representation.
  - He and others. 2025: Prior approaches did not effectively integrate static and dynamic attributes in 3D Gaussian representations.
  - Live Portrait (Guo and others. 2024): Maintaining high-quality texture details while ensuring identity consistency.
  - GFPGAN (Wang and others. 2021b): Achieving accurate expressions and poses aligned with driving images.
  - LAM (He and others. 2025): Balancing inference speed with visual quality.
  - Wang and others. 2023: Existing methods lack fine-grained control over facial features during synthesis.
  - Kaplan and others. 2020: Scaling laws indicate potential for performance enhancement, but current methods do not fully leverage this.
  - Wav2Lip: Achieving high lip accuracy scores using sync score as supervisory loss.
  - HunyuanVideoAvatar: Utilizing large-scale parameters and data for improved performance.
  - MuseTalk: Maintaining competitive results in lip synchronization tasks.
  - N/A: N/A

### 3. Core Idea
- The technique synthesizes high-fidelity, real-time talking head video using a single portrait image, capturing intricate facial expressions and subtle nuances in movement.

### 4. Method
- **Pipeline**: The Gaussian Generator produces static and dynamic Gaussians for controllable 3D Gaussian generation.
- **Architecture / Loss / Training**: The model employs a mean square error (MSE) loss during training to align predictions with ground-truth mouth features.
- **Complexity / Resources**: The model is trained on a dataset of 1,000 professional single-speaker lecture videos, requiring significant computational resources for training and evaluation.

### 5. Experiments
- **Datasets & Metrics**: The method is evaluated on the HDTF and VFHQ datasets.
- **Baselines**: 2D end-to-end image synthesis, 2D end-to-end models, 3D explicit structural prior-based methods, 3D synthesis technologies, FLAME, GAGAvatar, GAGavatar, GPAvatar, HunyuanVideoAvatar, LAM, LivePortrait, MuseTalk, N/A, NeRF-based methods, P4D, P4D-v2, PDFGC, RAR, Real3D, Real3DPortrait, StyleHEAT, StyleHeat, Wav2Lip
- **Main Results**: The generated videos exhibit lifelike clarity and realism.
- **Ablations**: Ablation studies showed that increasing the scale of the pre-trained backbone improves performance.
- **Limitations / Stress Tests**: The method's performance is contingent on the quality of the pre-trained backbone and the effectiveness of the texture restoration module.

### 6. Takeaways
- **Pros**: Decoupled architecture enhances reconstruction accuracy and reenactment speed., High frame-rate rendering capability at 90 FPS., Effective control over facial features and expressions.
- **Cons**: Dependence on the quality of the input portrait image., Potential for estimation errors affecting texture accuracy., Complexity in training the texture restoration module.
- **Future Work**: Exploration of additional control schemes for more nuanced expressions., Integration of more diverse datasets for training., Further optimization of the model for real-time applications.

</details>

## video understanding

### [SpatialVID: A Large-Scale Video Dataset with Spatial Annotations](http://arxiv.org/pdf/2509.09676v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- 3D perception

### 2. Motivation & Gaps
- The paper addresses the need for continuous 3D perception models that can maintain a persistent state over time.

- **Related work challenges:**
  - Structure-from-Motion (SfM): Limited scale, diversity, and annotation richness in existing datasets.
  - Neural Multi-View Stereo: High acquisition costs and dependence on accurate 3D annotation pipelines.
  - Large language models: Contrast in data availability between text and 3D datasets.
  - MotionSight (Du et al., 2025): Infers spatial cues from 2D videos but lacks direct geometric ground truth.
  - CO3D (Reizenstein et al., 2021): Provides precise camera parameters but is limited in scale and dynamic richness.
  - Tartanair (Wang et al., 2020): Based on synthetic data, failing to capture the complexity of real-world scenes.
  - Sora (OpenAI, 2024): Limited fidelity and scalability in model capacity and video duration.
  - DragNUW A (Yin et al., 2023): Need for fine-grained manipulation of object movements.
  - CameraCtrl (He et al., 2024): Explicit guidance over camera trajectories is crucial for dynamic exploration.
  - DROID-SLAM: Requires significant time to achieve accuracy.
  - COLMAP: N/A
  - Fast3R: N/A
  - MonST3R: Struggles in scenarios with limited feature points.
  - VGGT: Excels in inference speed but struggles with limited feature points.
  - DROID-SLAM (Teed and Deng, 2021): Previous systems struggled with initialization and handling dynamic content.
  - Depth Anything (Yang et al., 2024a): Existing models may not provide sufficient depth accuracy in challenging scenarios.
  - UniDepth (Piccinelli et al., 2024): Variable focal lengths and significant radial distortion are not well managed.
  - CameraBench (Lin et al., 2025): Addressing the misrepresentation of geometric details in video captions.
  - VLM4D (Zhou et al., 2025): Enhancing spatial reasoning capabilities in video captioning.
  - 3D LLM-Mem (Hu et al., 2025): Incorporating depth maps and camera parameters for better spatial understanding.
  - Panda-70M: Quality issues such as static videos, flicker-prone content, and underspecified captions.
  - N/A: N/A
  - Droid-slam: Deep visual slam for monocular, stereo, and rgb-d cameras: Existing models struggle with maintaining state across dynamic environments.
  - Scaling laws for neural language models: Challenges in scaling perception models to handle complex 3D environments.
  - Structure-from-motion revisited: Limitations in current structure-from-motion techniques in dynamic scenarios.
  - N/A: N/A

### 3. Core Idea
- The core idea is to develop a model that integrates continuous perception with a persistent state to enhance 3D understanding in dynamic environments.

### 4. Method
- **Pipeline**: The proposed method involves a novel architecture that processes input data continuously and updates the 3D state in real-time.
- **Architecture / Loss / Training**: The architecture employs a combination of loss functions tailored for 3D perception tasks, focusing on accuracy and robustness.
- **Complexity / Resources**: The model is designed to be computationally efficient, requiring moderate resources for training and inference.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize various datasets, including large-scale video datasets, and evaluate performance using standard 3D perception metrics.
- **Baselines**: 3D LLM-Mem, CO3D, COLMAP, CameraBench, DROID-SLAM, Droid-slam, Existing 3D perception models, Existing datasets with camera pose information, Fast3R, MiraData (Ju et al., 2024), MonST3R, MotionSight, Multi-Cam Video (Bai et al., 2025), N/A, Panda-70M, Panda70M (Chen et al., 2024), Structure-from-motion, Tartanair, VGGT, VLM4D
- **Main Results**: The proposed model outperforms existing baselines in terms of accuracy and robustness in dynamic environments.
- **Ablations**: Ablation studies demonstrate the importance of the persistent state mechanism in improving performance.
- **Limitations / Stress Tests**: The model shows limitations in highly chaotic environments where rapid changes occur.

### 6. Takeaways
- **Pros**: Large-scale dataset with diverse scenes and camera movements., Rich annotations including camera poses, depth maps, and structured captions., Potential to advance high-fidelity 3D reconstruction.
- **Cons**: High acquisition costs for large-scale 3D data., Dependence on accurate 3D annotation pipelines., Existing datasets are limited in scale and diversity.
- **Future Work**: Enhance spatial awareness in video generation pipelines., Develop more effective world-modeling tools., Explore further applications in 3D vision research.

</details>

### [Can Understanding and Generation Truly Benefit Together -- or Just Coexist?](http://arxiv.org/pdf/2509.09666v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Unified visual understanding and generation

### 2. Motivation & Gaps
- The paper addresses the need for high-resolution semantic encoders that can effectively unify visual understanding and generation tasks.

- **Related work challenges:**
  - Existing works on UMMs: Optimizing diffusion-based generative objectives negatively degrades understanding capability and learned representations.
  - Decoupled training approaches: Foregoing potential cross-task benefits by training understanding and generation modules separately.
  - Joint training methods: Lack of demonstrable mutual gains leading to skepticism about truly unified systems.
  - Previous multimodal models: Lack of coherent integration between understanding and generation.
  - Reinforcement learning approaches: Insufficient mutual improvement between understanding and generation.
  - Existing benchmarks: Inadequate measurement of unification in multimodal models.
  - Existing benchmarks for image realism and caption fidelity: They do not reveal whether a system is truly unified.
  - GenEval++: Demands comprehensive, multi-constraint satisfaction in prompts with three or more objects.
  - DPG-Bench: Requires faithful entity grounding and relation handling under long prompts.
  - Unified-Bench: Needs a stronger captioner that can optimize for reconstructability.
  - X-Omni: OCR-based rewards during RL improve typography fidelity.
  - Qwen-Image: Recent results underscore the importance of supervision for text rendering.
  - UniWorld-V1: Initial designs lacked complexity in encoder-decoder architecture.
  - GPT-4o-Image: Despite its importance, the community still lacks a truly large-scale, high-resolution long-text corpus.
  - Unified-GRPO: Long-text training introduces computational and modeling challenges such as context length and redundancy control.
  - Dinov2: Learning robust visual features without supervision: Lack of supervision in learning robust visual features.
  - Learning transferable visual models from natural language supervision: Challenges in transferring visual models effectively across different tasks.
  - High-resolution image synthesis with latent diffusion models: Difficulty in achieving high-resolution outputs in image synthesis.

### 3. Core Idea
- The core idea is to develop high-resolution semantic encoders that can seamlessly integrate visual understanding and generation capabilities.

### 4. Method
- **Pipeline**: The method involves a pipeline that integrates semantic encoding with visual generation processes.
- **Architecture / Loss / Training**: The architecture employs a loss function that optimizes both understanding and generation tasks simultaneously.
- **Complexity / Resources**: The method requires significant computational resources due to the high-resolution nature of the tasks.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize a variety of datasets to evaluate performance metrics related to visual understanding and generation.
- **Baselines**: BAGEL, BLIP3-o 4B, BLIP3-o 8B, CLIP, DALLE3, DINO-v2, DINO-v3, Dall¬∑e 3, Dinov2, EMU3, Existing UMM approaches, FLUX.1-dev, GPT-4o, Hunyuan-DiT, ImgEdit-E1, Janus Pro, LongCLIP, N/A, OmniGen, OmniGen2, Qwen-Image, SD3-medium, SDXL, Show-o, TokenFlow-XL, UAE, UniWorld-V1, X-Omni
- **Main Results**: The results demonstrate significant improvements in both understanding and generation tasks compared to existing methods.
- **Ablations**: Ablation studies indicate the importance of specific components in the architecture for achieving high performance.
- **Limitations / Stress Tests**: Limitations include challenges in scaling the model for even higher resolutions and the need for extensive training data.

### 6. Takeaways
- **Pros**: Demonstrates mutual gains between understanding and generation., Introduces a novel framework that effectively links the two tasks., Provides a measurable signal of cross-modal information coherence.
- **Cons**: Joint training can be brittle due to the complexity of optimizing both tasks simultaneously., Existing methods may still struggle with the schism between understanding and generation., Requires substantial computational resources for training.
- **Future Work**: Explore further enhancements in the reinforcement learning approach., Investigate additional datasets for broader evaluation., Develop more robust methods to ensure stability in joint training.

</details>

### [AskDoc -- Identifying Hidden Healthcare Disparities](http://arxiv.org/pdf/2509.09622v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- To study online Ask the Doctor services and analyze healthcare disparities across demographic groups.

### 2. Motivation & Gaps
- This study investigates the interaction between patients and physicians on the online platform AskDoc, highlighting disparities among different demographic groups in health and medical care.

- **Related work challenges:**
  - Nobles et al. (2013-2018): Limited analysis on self-reported demographics for gender and race without including age.
  - Nobles et al. [2]: Performed an analysis on self-reported demographics for gender and race on Reddit but did not include age.
  - N/A: Inequalities between demographic groups in health and medical care.
  - Structural racism and supporting black lives - the role of health professionals: Addressing health inequities
  - What difference does difference make? the persistence of inequalities in healthcare delivery: Understanding healthcare disparities
  - Stigma, and help seeking for mental health among college students: Overcoming mental health stigma

### 3. Core Idea
- The study provides insights into the engagement levels of different demographic groups on AskDoc, revealing that adult white males dominate the platform while gender and racial/ethnic minorities participate at lower rates.

### 4. Method
- **Pipeline**: We extracted self-reported demographics in posts using regex patterns to identify gender, race, and age.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Statistical analysis performed to understand interactions between peers and physicians.

### 5. Experiments
- **Datasets & Metrics**: Descriptive statistics about r/AskDocs (January 2020 ‚Äì May 2022)
- **Baselines**: N/A
- **Main Results**: Count of Unique Users: 157538, Total Count of Posts: 177850
- **Ablations**: N/A
- **Limitations / Stress Tests**: Responses from peers in online health groups can be false and misleading.

### 6. Takeaways
- **Pros**: Social media can bridge communication gaps in healthcare., Free and anonymous access to medical advice., Increased engagement during the COVID-19 pandemic.
- **Cons**: Low participation from healthcare professionals., Potential biases in responses based on demographics., Limited disclosure of race among users.
- **Future Work**: Further research on demographic engagement in online health forums., Exploration of strategies to increase physician participation., Analysis of long-term trends in online health consultations.

</details>
