# Daily Paper Digest ¬∑ 2025-09-12
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## neural rendering

### [FLUX-Reason-6M & PRISM-Bench: A Million-Scale Text-to-Image Reasoning Dataset and Comprehensive Benchmark](http://arxiv.org/pdf/2509.09680v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Text-to-Image Generation

### 2. Motivation & Gaps
- The paper addresses the challenges in text-to-image generation, particularly in complex tasks like text rendering and long instruction following.

- **Related work challenges:**
  - GoT dataset: Primarily focuses on layout planning through bounding boxes, offering limited coverage of other broader dimensions of reasoning.
  - Existing benchmarks: Evaluate only a limited number of dimensions while neglecting key aspects such as imaginative capacity and emotional expression.
  - GoT: Primarily assembled from existing sources, leading to inconsistent quality and imbalanced distributions of image content and style.
  - Recent generative models: Producing high-quality images consistently.
  - Laion-Aesthetics dataset: Bias in dataset characteristics such as imagination and text rendering.
  - Qwen-VL: Ensuring clarity and structural consistency in generated images.
  - Traditional captioning methods: Produce generic descriptions that do not capture the complexity of visual scenes.
  - Existing T2I benchmarks: Rely on coarse metrics and narrowly defined tasks.
  - Existing evaluation methods for VLMs: Lack of specificity in assessing model performance across different categories.
  - PRISM-Bench: Evaluating models on multiple distinct categories of image generation.
  - GCoT prompts: Incorporating high density of details from complex, multi-sentence prompts.
  - Qwen-Image: Performance gap compared to top models.
  - HiDream-I1-Full: Achieving excellent results but still behind leading models.
  - FLUX.1-Krea-dev: Demonstrating rapid progress but facing limitations in certain tasks.
  - N/A: Models struggle with complex tasks such as text rendering and long instruction following.
  - PRISM-Bench: Existing models struggle with complex tasks despite impressive performance.
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- Development of PRISM-Bench, a comprehensive benchmark for evaluating text-to-image models using advanced VLMs.

### 4. Method
- **Pipeline**: Evaluation of models based on quantitative results across multiple tasks.
- **Architecture / Loss / Training**: Utilizes Qwen-VL for generating captions and reasoning processes.
- **Complexity / Resources**: The method utilizes advanced VLMs like GPT-4.1 and Qwen2.5-VL-72B for evaluation.

### 5. Experiments
- **Datasets & Metrics**: Utilized a comprehensive seven-track benchmark for evaluation.
- **Baselines**: Bagel, Bagel-CoT, Existing T2I benchmarks, FLUX series, FLUX.1-Krea-dev, GPT-4.1, GPT-Image-1, Gemini-2.5-Pro, Gemini2.5-Flash-Image, HiDream series, HiDream-I1-Dev, HiDream-I1-Full, JanusPro, Laion-Aesthetics dataset, Leading closed-source systems, N/A, Playground, Qwen-Image, Qwen2.5-VL-72B, Qwen3-32B, SEEDream 3.0, Stable Diffusion series, Traditional captioning methods
- **Main Results**: Extensive experimentation across 19 models revealed performance gaps in complex tasks.
- **Ablations**: N/A
- **Limitations / Stress Tests**: All models struggle with complex tasks such as text rendering and long instruction following.

### 6. Takeaways
- **Pros**: Provides a large-scale dataset for training reasoning-oriented T2I models., Introduces a comprehensive evaluation benchmark aligned with human judgment., Facilitates the next wave of reasoning-oriented T2I generation.
- **Cons**: The dataset creation process is resource-intensive., Existing models may still struggle with complex prompts despite the new dataset.
- **Future Work**: Further research on enhancing reasoning capabilities in T2I models., Exploration of additional characteristics for T2I generation., Development of more nuanced evaluation metrics.

</details>

### [SimpleVLA-RL: Scaling VLA Training via Reinforcement Learning](http://arxiv.org/pdf/2509.09674v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Reinforcement Learning for Vision-Language-Action Models

### 2. Motivation & Gaps
- The paper addresses the challenges in scaling Vision-Language-Action (VLA) training through reinforcement learning techniques.

- **Related work challenges:**
  - DeepSeek-R1: Limited scalability of traditional RL methods relying on hand-crafted process rewards.
  - SFT of VLAs: Dependence on scarce and expensive human-operated robot trajectories.
  - Current VLA models: Poor generalization on compositional, long-horizon, or real-world tasks.
  - Ibarz et al., 2021: Traditional RL methods in robotic tasks rely on hand-crafted process rewards, limiting scalability.
  - Kroemer et al., 2021: VLA models require multi-round interactions with the environment, making them slower and more costly.
  - Ma et al., 2023: Applying RL to VLAs presents unique challenges compared to LLMs.
  - DeepSeek-R1: Requires carefully crafted reward functions.
  - Previous works on RL exploration: VLA models tend to converge on a narrow set of solution patterns.
  - Dynamic Sampling: Critic-free RL algorithms suffer from vanishing gradients when trajectories are assigned the same rewards.
  - DAPO [Yu et al., 2025]: KL divergence regularization limits exploration of new behaviors.
  - GRPO algorithm [Shao et al., 2024]: Existing methods require a reference model, increasing memory consumption.
  - Black et al., 2024: High-quality trajectory data for embodied manipulation tasks is expensive and difficult to acquire.
  - Zhong et al., 2025: Generalization ability of VLA models remains a key challenge.
  - Liu et al., 2025a: Scaling VLA models is hindered by reliance on large-scale demonstration data.
  - SFT: SFT suffers from severe overfitting and catastrophic forgetting on unseen tasks.
  - RDT: RDT does not utilize RL and has lower success rates compared to the proposed method.
  - DeepSeek-R1: Demonstrates the emergence of novel strategies through RL, contrasting with traditional supervised fine-tuning (SFT).
  - RLHF: Aligns models with human preferences but heavily relies on preference modeling, limiting exploration.
  - E-COT: Introduces methods to improve spatial reasoning in VLA models but does not address the fundamental RL challenges.
  - E-COT: Improving spatial reasoning ability of VLA models.
  - RDT-1B and VPP: Proposing diffusion-based frameworks for VLA models.
  - Dexmimicgen: Addressing data scarcity in robotics.
  - How to train your robot with deep reinforcement learning: lessons we have learned: Identifying effective training strategies for robots.
  - A review of robot learning for manipulation: Challenges, representations, and algorithms: Understanding the complexities in robot manipulation learning.
  - Eureka: Human-level reward design via coding large language models: Designing rewards that align with human-level performance.
  - Back to basics: Revisiting reinforce style optimization for learning from human feedback in llms: Existing methods may not effectively leverage human feedback for optimization.
  - Training language models to follow instructions with human feedback: Incorporating human feedback in a scalable manner remains a challenge.
  - Interactive post-training for vision-language-action models: Post-training methods often lack robustness in diverse environments.

### 3. Core Idea
- The core idea is to enhance the training of VLA models by integrating scalable reinforcement learning techniques that improve generalization and performance.

### 4. Method
- **Pipeline**: The proposed method involves a structured pipeline that integrates reinforcement learning with existing VLA training frameworks.
- **Architecture / Loss / Training**: Utilizes a combination of policy optimization and loss functions tailored for VLA tasks.
- **Complexity / Resources**: The method is designed to be resource-efficient, allowing for training on standard computational setups.

### 5. Experiments
- **Datasets & Metrics**: The experiments are conducted on various benchmark datasets for VLA tasks, using metrics such as accuracy and generalization performance.
- **Baselines**: 100 trajectories SFT model, 1000 trajectories SFT model, DeepSeek-R1, Existing VLA models, LLM-based generation methods, Nora, Octo, OpenVLA, OpenVLA-OFT, OpenVLA-OFT base model, Previous VLA training methods, RDT, RDT-1B, RL, SFT, SFT-only, SFT-tuned models, Standard reinforcement learning models, Supervised Fine-Tuning (SFT), Traditional RL approaches, Traditional reinforcement learning approaches, UniVLA, ùúã0
- **Main Results**: The results demonstrate significant improvements in both training efficiency and model performance compared to baseline methods.
- **Ablations**: Ablation studies indicate the importance of specific components in the proposed method for achieving optimal results.
- **Limitations / Stress Tests**: The paper acknowledges limitations in the scalability of the method under extreme conditions and suggests areas for future research.

### 6. Takeaways
- **Pros**: Improves long-horizon planning under data scarcity., Surpasses SFT in simulation and real-world tasks., Enhances generalization capabilities.
- **Cons**: Dependence on complex experimental setups for data collection., Challenges in generalization to unseen tasks., Scalability issues with traditional RL methods.
- **Future Work**: Explore further enhancements in RL for VLA models., Investigate additional strategies for data efficiency., Develop methods to improve generalization across diverse tasks.

</details>

### [Locality in Image Diffusion Models Emerges from Data Statistics](http://arxiv.org/pdf/2509.09672v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Image Generation using Denoising Diffusion Probabilistic Models

### 2. Motivation & Gaps
- The paper addresses the efficiency and effectiveness of denoising diffusion probabilistic models (DDPM) in image generation, particularly focusing on algorithmic complexity and computational resources.

- **Related work challenges:**
  - Kamb and Ganguli: Their theory cannot predict the degree of locality from first principles and relies on measuring the receptive field of a trained UNet.
  - Prior optimal denoiser-based methods: They are outperformed by a simple optimal linear filter.
  - Recent analytical models: They fail to capture pixel correlations effectively.
  - Yoon et al.: Introduce the memorization-generalization dichotomy, positing that diffusion models generalize when they avoid memorizing training data.
  - Yi et al.: Formalize generalization through mutual information metrics, demonstrating that trained diffusion models can generalize beyond the empirical optimal solutions.
  - Gu et al.: Investigate factors such as dataset size and conditioning that can influence the extent of memorization in diffusion models.
  - Previous works on denoising diffusion models: Assumed locality patterns in denoisers are isotropic and constant, which is not universally applicable.
  - Classical image processing literature: The assumptions about the covariance matrix and its implications for denoising may not hold for all datasets.
  - Studies on learned sensitivity fields: Sensitivity fields may not be compact or isotropic for specialized datasets.
  - Previous work on learned sensitivity fields in diffusion networks: Understanding the locality properties and their dependence on data statistics.
  - Analytical models for sensitivity fields: Limited interpretability and flexibility in representing sensitivity fields for specialized datasets.
  - Kamb and Ganguli [12]: Qualitatively performs worse on CelebA-HQ due to patch-based locality erasing eyes and blurring out facial features.
  - Niedoba et al. [19]: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Optimal Denoiser: Produces noisy single-step predictions for high noise levels.
  - Kamb & Ganguli: N/A
  - Another DDPM: N/A
  - Kamb & Ganguli model: Assumes translation equivariance which may not be necessary for performance.
  - Niedoba et al. model: Performance degradation observed with equivariance.

### 3. Core Idea
- The proposed method optimizes the denoising process by implementing a distinct per-pixel mask pattern and forgoing translation equivariance, leading to improved algorithmic complexity.

### 4. Method
- **Pipeline**: The method involves using a Wiener filter as a denoiser and applying a 10-step DDIM sampling process.
- **Architecture / Loss / Training**: U-Net architecture with specific configurations for different datasets, trained for 200 epochs with a batch size of 32.
- **Complexity / Resources**: The method has a complexity of O(nptm) for the proposed model and O(nptm2/k) for approximate nearest-neighbor search.

### 5. Experiments
- **Datasets & Metrics**: The experiments were conducted on CIFAR10, CelebA-HQ, AFHQv2, MNIST, and Fashion MNIST datasets, measuring total sampling time over 10 denoising steps.
- **Baselines**: Another DDPM, Diffusion Transformer (DiT), Kamb & Ganguli, Kamb and Ganguli [12], Kamb and Ganguli's model, N/A, Niedoba et al., Niedoba et al. [19], Optimal Denoiser, Optimal denoiser, Previous patch-based analytical models, Prior expert-crafted alternatives, Simple Wiener filter, U-Net, U-Net with self-attention, U-Net without self-attention, Unet, Wiener (linear), Wiener filter
- **Main Results**: The proposed method shows competitive performance in terms of sampling time compared to baselines, with specific times provided for each dataset.
- **Ablations**: Ablation studies on binarization thresholds show varying r2 and MSE metrics.
- **Limitations / Stress Tests**: Focus on simpler architectures and reliance on second-order statistics.

### 6. Takeaways
- **Pros**: Demonstrates locality is a learned property of deep diffusion models., Establishes a quantitative benchmark for analytical diffusion models., Integrates locality into existing models to improve performance.
- **Cons**: Relies on the statistical properties of the training dataset., May not generalize well to datasets with different characteristics., Prior methods are still relevant in certain contexts despite being outperformed.
- **Future Work**: Explore locality in other generative models beyond diffusion., Investigate the implications of locality on model generalization., Develop methods to better predict locality from first principles.

</details>

## Gaussian Splatting

### [Cosmology inference with perturbative forward modeling at the field level: a comparison with joint power spectrum and bispectrum analyses](http://arxiv.org/pdf/2509.09673v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Bayesian inference of cosmic density fields

### 2. Motivation & Gaps
- The paper addresses the challenges in accurately reconstructing the initial conditions of the universe from large-scale structure surveys using advanced Bayesian methods.

- **Related work challenges:**
  - Previous studies on field-level cosmological analyses: Most analyses focused on simple examples with limited cosmological parameters.
  - Perturbative forward modeling: Specifying the forward model and likelihood in the nonlinear regime is nontrivial.
  - Ref. [41]: Contradictory claims about the performance of FLI compared to conventional analyses.
  - Ref. [42]: Significant discrepancies in error bars on cosmological parameters between FLI and joint power spectrum analyses.
  - Ref. [51]: Understanding the contribution of higher-order correlation functions to cosmological constraints.
  - Ref. [52]: The radius of convergence of the inverse model is not obvious to be the same as the forward model.
  - Refs. [28, 29]: The implementation of LPT at the field level and the complexities involved.
  - N/A: Degeneracy of linear bias and stochastic noise with cosmological parameters.
  - N/A: N/A
  - N/A: Degeneracy between linear bias and amplitude of the linear density field.
  - N/A: N/A
  - Hybrid Monte Carlo in lattice QCD: Adapting the method for cosmological parameter inference.
  - CosmoPower-JAX: Constrained parameter ranges for cosmological parameters.
  - N/A: N/A
  - N/A: Incorporating higher-order statistics does not automatically lead to improved constraints unless they break parameter degeneracies.
  - N/A: The simple tree-level bispectrum leads to biased results compared to the one-loop bispectrum.
  - N/A: The power spectrum analysis is no longer optimal when varying the noise amplitude.
  - N/A: N/A
  - Previous studies on Eulerian perturbation theory: The complexity of real galaxy density fields and their relation to dark matter.
  - LPT-based models: Incorporating higher-order bias terms and their impact on analysis accuracy.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Ref [28]: Demonstrated that the distribution of residuals is non-Gaussian, complicating the inference process.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Bayesian reconstruction of the cosmological large-scale structure: methodology, inverse algorithms and numerical optimization: Need for efficient sampling methods to explore the joint posterior.
  - Fast Hamiltonian sampling for large scale structure inference: Slow mixing of MCMC chains for certain parameters.
  - Bayesian physical reconstruction of initial conditions from large scale structure surveys: Parameter degeneracies complicating the inference process.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The paper proposes a microcanonical Langevin Monte Carlo method to improve the efficiency of sampling in Bayesian inference for cosmological models.

### 4. Method
- **Pipeline**: The method involves a field-level inference pipeline that samples initial conditions and reconstructs the density field.
- **Architecture / Loss / Training**: The No-U-Turn Sampler (NUTS) is employed to adaptively adjust trajectory length, step size, and mass matrix during warm-up.
- **Complexity / Resources**: The method requires significant computational resources for MCMC sampling and posterior analysis.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize mock catalogs and real data from galaxy redshift surveys to validate the proposed method.
- **Baselines**: Bispectrum analysis, Gaussian likelihood with Gaussian noise, Gaussian likelihood with density-dependent noise, Gaussian realizations of stochastic fields, Hamiltonian Monte Carlo, Joint power spectrum analysis, N/A, Traditional MCMC methods
- **Main Results**: The proposed method shows improved sampling efficiency and better reconstruction of initial conditions compared to traditional methods.
- **Ablations**: The impact of resolution mismatch between mock data and inference is examined.
- **Limitations / Stress Tests**: The method exhibits slow mixing for certain parameters, indicating areas for further improvement.

### 6. Takeaways
- **Pros**: Optimal use of full information in observed field., Accurate recovery of cosmological parameters., Robustness in performance across different setups.
- **Cons**: Challenges in specifying likelihood and forward model., Potential biases with incorrect noise models., Limited to perturbative regime for accuracy.
- **Future Work**: Explore applications to real data., Investigate effects of non-Gaussian noise in more detail., Extend analyses to include more complex cosmological scenarios.

</details>

### [Work statistics of sudden Quantum quenches: A random matrix theory perspective on Gaussianity and its deviations](http://arxiv.org/pdf/2509.09640v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Analyzing the work distribution in sudden quenches using random matrix theory

### 2. Motivation & Gaps
- The study investigates the work distribution in quantum systems undergoing sudden quenches, mapping it onto a random matrix problem to understand its Gaussian core and non-Gaussian tails.

- **Related work challenges:**
  - Previous studies on quantum thermodynamics: Lack of precise characterization of work distributions in sudden quenches.
  - Previous studies on Gaussian distributions in random matrices.: Lack of clarity on the conditions that guarantee a Gaussian core.
  - Research on non-Gaussian tails in fermionic models.: Understanding the mechanisms that lead to non-Gaussian behavior.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Deffner and Campbell, Quantum Thermodynamics: Understanding thermodynamic behavior in quantum systems.
  - Gorin et al., Physics Reports: Characterizing the dynamics of quantum systems.
  - P√©rez-Garc√≠a et al., Physical Review Research: Exploring phase transitions in unitary matrix models.
  - N/A: N/A

### 3. Core Idea
- The multivariate central limit theorem predicts a Gaussian core for the work distribution in large systems, with specific non-Gaussian features arising under certain conditions.

### 4. Method
- **Pipeline**: Mapping the work distribution to a random matrix problem and analyzing the resulting statistical properties.
- **Architecture / Loss / Training**: Utilizing the central limit theorem and random matrix theory to derive predictions about the work distribution.
- **Complexity / Resources**: The analysis involves both analytic results and numerical simulations to confirm theoretical predictions.

### 5. Experiments
- **Datasets & Metrics**: Data from sudden quenches in quantum systems analyzed through various statistical measures.
- **Baselines**: Gaussian distribution, N/A, Non-Gaussian distribution models, Non-Gaussian models in random matrix theory, Previous quantum thermodynamics models, Standard Gaussian models
- **Main Results**: The work distribution exhibits a Gaussian core with identifiable non-Gaussian tails under specific conditions.
- **Ablations**: Testing the robustness of the Gaussian core against variations in system parameters and conditions.
- **Limitations / Stress Tests**: Identifying conditions under which the central limit theorem may not hold, leading to non-Gaussian features.

### 6. Takeaways
- **Pros**: Provides a rigorous framework for understanding work distributions in quantum systems., Clarifies the conditions under which Gaussianity holds., Offers insights into the effects of interaction range on work statistics.
- **Cons**: The model may not apply to all types of quantum systems., Assumes specific conditions that may not be universally valid., Complexity of the mathematical framework may limit accessibility.
- **Future Work**: Explore applications of the framework to more complex quantum systems., Investigate the effects of different types of interactions on work distributions., Develop experimental protocols to test the theoretical predictions.

</details>

### [Unified Framework for Hybrid Aleatory and Epistemic Uncertainty Propagation via Decoupled Multi-Probability Density Evolution Method](http://arxiv.org/pdf/2509.09535v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Uncertainty propagation in dynamical systems

### 2. Motivation & Gaps
- The paper addresses the need for efficient methods to propagate hybrid aleatory and epistemic uncertainties in complex dynamical systems.

- **Related work challenges:**
  - Faes et al. (2020, 2021): Limited to linear systems and relies on statistical linearization for weakly nonlinear systems.
  - Xiu et al. (2010), Sankararaman & Mahadevan (2011), Liu et al. (2018): Conventional double-loop approaches suffer from prohibitively high computational costs.
  - Chen & Li (2007), Wan et al. (2020, 2023): Accuracy diminishes for large variation in input distributions and lacks universal compatibility.
  - Chen & Wan 2019: Accuracy diminishes for large variation in input distributions.
  - Jiang et al. 2018: Lacks universal compatibility across diverse epistemic uncertainty representations.
  - Li & Chen (2008): Analytical solutions for joint PDFs are complex and often not feasible.
  - Chen & Li (2009): Existing methods do not effectively handle high-dimensional uncertainties.
  - Bittner et al. (2024): Integration with variance reduction techniques is not fully explored.
  - N/A: N/A
  - Previous methods for uncertainty propagation: Limited efficiency and accuracy when dealing with high-dimensional epistemic uncertainties.
  - DL-MCS approach: Prohibitive computational cost for complex models.
  - Vertex MCS method: Inability to capture tail behavior accurately in reliability analysis.
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The proposed decoupled multi-probability density evolution method (M-PDEM) provides a unified framework for hybrid uncertainty propagation by treating various forms of epistemic uncertainty.

### 4. Method
- **Pipeline**: The method involves an augmented random space representation and decoupled treatment of uncertainties.
- **Architecture / Loss / Training**: Utilizes path integration for solving the Li-Chen equations.
- **Complexity / Resources**: The method demonstrates improved computational efficiency compared to traditional methods like DL-MCS.

### 5. Experiments
- **Datasets & Metrics**: Numerical examples involving diverse types of uncertain inputs were used to validate the framework.
- **Baselines**: DL-MCS, Finite difference schemes, Imprecise probabilistic models, N/A, Non-probabilistic models, Probability density evolution method (PDEM), Traditional PDEM methods, Traditional probabilistic models, Vertex MCS
- **Main Results**: The decoupled M-PDEM shows satisfactory agreement with DL-MCS results while demonstrating improved computational efficiency.
- **Ablations**: Comparison of decoupled M-PDEM with traditional methods shows reduced computational load.
- **Limitations / Stress Tests**: The method's accuracy decreases with higher-dimensional epistemic uncertainties and in reliability analysis of rare events.

### 6. Takeaways
- **Pros**: Provides a unified treatment of hybrid uncertainties., Enhances computational efficiency compared to traditional methods., Accommodates various uncertainty representations.
- **Cons**: Limited to specific types of systems., May require extensive computational resources for large systems., Accuracy may decrease with large variations in input distributions.
- **Future Work**: Explore extensions to nonlinear systems., Investigate compatibility with more uncertainty representations., Develop more efficient computational techniques.

</details>

## avatar

### [Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis](http://arxiv.org/pdf/2509.09595v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Long-duration avatar video generation

### 2. Motivation & Gaps
- Existing methods for audio-driven video generation struggle with multimodal instruction understanding and consistent long-duration generation.

- **Related work challenges:**
  - Video Diffusion Transformers (DiT): Insufficient for highly realistic portrait synthesis; current approaches treat each conditional signal independently, leading to semantic conflicts.
  - Prior work on facial expression and lip synchronization: Often results in visually polished outputs that are inconsistent with human expectations.
  - Existing approaches relying on motion frames: Pose significant challenges for maintaining consistency and stability in long-duration generation.
  - Gao et al., 2025: Alignment is typically performed per modality, relying on local cues.
  - Fei et al., 2025: Shallow fusion at the generation stage limits expressive capabilities.
  - Wang et al., 2025a: Existing methods do not effectively handle emotional conflicts in outputs.
  - OmniHuman: Identity drift and texture distortion in generated videos.
  - HeyGen: Maintaining visual quality and coherence in long video sequences.
  - OmniHuman-1: Limited support for prompt input and reliance on fixed resolutions.
  - HeyGen: Produces videos with looping action patterns that harm vividness and diversity.
  - Diffusion Transformers: Primarily designed for general video generation, inadequate for speech-driven digital portrait modeling.
  - Jiang et al., 2025: Struggle with multimodal instruction understanding.
  - Gan et al., 2025: Reliance on local cues for alignment.
  - Huang et al., 2025: Inconsistent long-duration generation.
  - N/A: N/A

### 3. Core Idea
- We propose Kling-Avatar, a cascaded framework that unifies multimodal instruction understanding with long-duration generation of lifelike portrait videos.

### 4. Method
- **Pipeline**: A two-stage pipeline that first employs an MLLM director to produce a blueprint video and then synthesizes long videos through parallel sub-clip generation.
- **Architecture / Loss / Training**: Coupled with carefully curated data and practical training and inference strategies.
- **Complexity / Resources**: Preserves fine-grained details while faithfully realizing global semantics.

### 5. Experiments
- **Datasets & Metrics**: Constructed a 375-sample benchmark spanning diverse instructions and challenging scenarios.
- **Baselines**: Existing audio-driven video generation methods, HeyGen, N/A, OmniHuman, OmniHuman-1
- **Main Results**: Kling-Avatar delivers vivid, fluent videos up to 1080p and 48 fps, with precise lip synchronization and strong controllability.
- **Ablations**: Future work will include additional objective metrics to complement the GSB assessments.
- **Limitations / Stress Tests**: Human preference‚Äìbased metric comparisons confirm superior performance.

### 6. Takeaways
- **Pros**: Generates vivid, fluent, long-duration videos at up to 1080p and 48 fps., Maintains strong generalization to open-domain scenarios., Achieves high fidelity in audio-driven avatar synthesis.
- **Cons**: Current methods may still struggle with complex narratives., Dependence on high-quality input data for optimal performance., Potential challenges in real-time applications.
- **Future Work**: Explore further improvements in narrative coherence., Investigate real-time processing capabilities., Expand the dataset to include more diverse scenarios.

</details>

### [PanoLAM: Large Avatar Model for Gaussian Full-Head Synthesis from One-shot Unposed Image](http://arxiv.org/pdf/2509.07552v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- 3D reconstruction from single-view images

### 2. Motivation & Gaps
- The paper addresses the limitations of existing methods in reconstructing 3D representations from single-view images, particularly focusing on fidelity and generalization to real-world images.

- **Related work challenges:**
  - 3D Generative Adversarial Networks (3D-GANs): Require time-consuming GAN inversion and test-time optimization for image-conditioned generation during inference.
  - Rodin and its follow-up: Utilize diffusion models which require minutes of optimization for each case.
  - 2D super-resolution upsampling: Compromises 3D consistency while trying to improve rendering efficiency and quality.
  - EG3D: Requires time-consuming GAN inversion and test-time optimization for image-conditioned generation.
  - Diffusion models: Multi-step diffusion process is slow and computation-consuming during inference.
  - NeRF-based approaches: Slow rendering speed and low-resolution images lead to view inconsistencies.
  - TriplaneGaussian: Inefficient feature aggregation from unstructured point clouds.
  - FLAME model: Inability to model large deformations such as long hairs and accessories.
  - Previous methods: Require a network trained to upsample sparse points, leading to inefficiencies.
  - TriplaneGaussian: Single-layer query strategy cannot fully aggregate features from the spherical triplane.
  - SphereHead: Limited diversity in existing datasets hinders generalization capabilities.
  - Existing 3D head reconstruction methods: Dependence on accurate camera poses and optimization processes
  - Gaussian shell maps for efficient 3d human generation: N/A
  - Panohead: Geometry-aware 3d full-head synthesis in 360¬∞: N/A
  - Rignerf: Fully controllable neural 3d portraits: N/A
  - N/A: N/A
  - N/A: N/A
  - Next3d: Generative neural texture rasterization for 3d-aware head avatars: Limited fidelity in head avatar generation.
  - RODIN: A generative model for sculpting 3d digital avatars using diffusion: Challenges in achieving real-time performance.
  - Gaussian head avatar: Ultra high-fidelity head avatar via dynamic gaussians: Complexity in modeling dynamic facial expressions.
  - EG3D: Limited to rendering near-frontal images.
  - SphereHead: Biases in the dataset leading to poor reconstruction results for certain demographics.

### 3. Core Idea
- The proposed framework combines triplane representation with Gaussian splatting to enhance the quality and generalizability of 3D reconstructions from single-view images.

### 4. Method
- **Pipeline**: The method involves generating a large-scale dataset from trained 3D GANs, followed by training a network to reconstruct 3D representations.
- **Architecture / Loss / Training**: The architecture utilizes a triplane representation and Gaussian splatting, with a focus on minimizing reconstruction loss.
- **Complexity / Resources**: The method requires significant computational resources for training on large-scale datasets.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize the VFHQ dataset and various metrics to evaluate reconstruction fidelity and generalization.
- **Baselines**: 3D-GANs, Default configuration of existing 3D head reconstruction methods, Diffusion models, EG3D, LGM, N/A, NeRF-based approaches, PanoHead-PTI, PanoLAM, Previous state-of-the-art methods in head avatar generation., Rodin, SphereHead, SphereHead-PTI
- **Main Results**: The proposed framework achieves higher fidelity results with fewer artifacts compared to previous methods.
- **Ablations**: Ablation studies demonstrate the impact of different components of the framework on reconstruction quality.
- **Limitations / Stress Tests**: The framework shows limitations in reconstructing Asian faces and cartoon heads due to biases in the training datasets.

### 6. Takeaways
- **Pros**: Fast reconstruction and rendering of 3D avatars., High-fidelity Gaussian full-head reconstruction., Utilizes a large-scale synthetic dataset for training.
- **Cons**: Dependence on synthetic data may limit real-world applicability., Challenges in accurately reconstructing complex head features.
- **Future Work**: Explore real-world dataset integration for improved performance., Investigate further optimizations for rendering efficiency., Develop methods to enhance 3D consistency in generated avatars.

</details>

### [Reconstruction and Reenactment Separated Method for Realistic Gaussian Head](http://arxiv.org/pdf/2509.05582v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Mapping audio to 3D motion for lip synchronization

### 2. Motivation & Gaps
- The paper addresses the challenge of achieving accurate lip synchronization in 3D models driven by audio input.

- **Related work challenges:**
  - Goodfellow et al. (2014): 2D-based approaches rely on deep convolutional networks and generative adversarial models, which struggle with 3D structural guidance.
  - Mildenhall et al. (2020): 3D synthesis technologies require precise estimation of 3D poses, introducing errors that affect texture accuracy.
  - Guo et al. (2024): 2D end-to-end approaches generate pseudo-3D motions that are easier to learn but do not capture true 3D motion patterns.
  - 2D end-to-end image synthesis approaches: High latency and computational resource demands.
  - 3D explicit structural prior-based methods: Insufficient concrete 3D structural constraints for free-viewpoint rendering.
  - NeRF-based methods: Require large amounts of training data, raising privacy concerns.
  - Deng and others. 2024b: Previous methods did not leverage the advantages of larger scale datasets for feature extraction.
  - Chu and others. 2024a: Existing methods struggle with high-frequency texture artifacts and camera pose errors.
  - He and others. 2025: Prior approaches lack efficient synthesis and rendering capabilities.
  - Live Portrait (Guo and others. 2024): Maintaining high-quality texture details in synthesized images.
  - GFPGAN (Wang and others. 2021b): Achieving accurate expressions and poses consistent with driving images.
  - Previous methods in identity reenactment: Insufficient identity consistency and texture detail preservation.
  - PDFGC: Limited performance compared to other control priors like FLAME.
  - Webssl-dino7b-full8b-518: Scalability issues with pre-trained backbones.
  - Texture Restoration Module: Incorporating texture restoration effectively.
  - Wav2Lip: Achieving the highest lip accuracy score using sync score as supervisory loss.
  - HunyuanVideoAvatar: Attaining high sync scores through large-scale parameters and data.
  - MuseTalk: Achieving competitive results but lower than Wav2Lip and HunyuanVideoAvatar.
  - N/A: N/A

### 3. Core Idea
- Our innovative technique can synthesize high-fidelity, real-time talking head video using a single portrait image, leveraging advanced algorithms that capture intricate facial expressions and subtle nuances in movement.

### 4. Method
- **Pipeline**: The Gaussian Generator produces two parts: the static and dynamic Gaussians.
- **Architecture / Loss / Training**: The static Gaussian uses 3DMM vertices for positions, while its appearance is predicted by concatenating a global feature with a mesh embedding of those vertices and processing them through MLP layers. The dynamic Gaussian‚Äôs appearance is predicted from the canonicalized feature after Conv2D processing, and its positions are derived from the drive motion using MLPs, reshaping, and Conv2D operations.
- **Complexity / Resources**: Merging both produces a controllable 3D Gaussian for the source portrait.

### 5. Experiments
- **Datasets & Metrics**: The dataset includes 1,000 lecture videos with mouth features extracted through PDFGC, and accuracy is measured using sync score and CSIM metric.
- **Baselines**: 2D end-to-end image synthesis, 2D end-to-end models, 3D explicit structural prior-based methods, 3DGS, FLAME, GAGAvatar, GAGavatar, GPAvatar, HunyuanVideoAvatar, LAM, LivePortrait, MuseTalk, N/A, NeRF, NeRF-based methods, P4D, P4D-v2, RAR, Real3D, Real3DPortrait, StyleHEAT, StyleHeat, Wav2Lip
- **Main Results**: The audio2motion model achieved competitive sync scores, slightly better than MuseTalk but lower than Wav2Lip and HunyuanVideoAvatar.
- **Ablations**: Ablation studies showed that increasing the scale of the pre-trained backbone improves performance.
- **Limitations / Stress Tests**: The method's performance is still dependent on the quality of the pre-trained models used.

### 6. Takeaways
- **Pros**: Decoupled architecture enhances reconstruction accuracy and reenactment speed., High frame-rate rendering at 90 FPS is achieved., Independent control over facial features allows for natural expression reproduction.
- **Cons**: Performance may vary with input image quality., Complex facial expressions may still pose challenges., Dependence on synthetic data for training the texture restoration module.
- **Future Work**: Explore further improvements in 3D pose estimation accuracy., Investigate additional applications in real-time video conferencing., Enhance the model's ability to handle diverse facial expressions.

</details>

## video understanding

### [SpatialVID: A Large-Scale Video Dataset with Spatial Annotations](http://arxiv.org/pdf/2509.09676v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- 3D perception

### 2. Motivation & Gaps
- The paper addresses the need for continuous 3D perception models that maintain a persistent state.

- **Related work challenges:**
  - Structure-from-Motion (SfM): Limited in scale, diversity, and annotation richness for real-world dynamic scenes.
  - Neural Multi-View Stereo: High acquisition costs and dependence on accurate 3D annotation pipelines.
  - MotionSight (Du et al., 2025): Infers spatial cues from 2D videos but lacks direct geometric ground truth.
  - CO3D (Reizenstein et al., 2021): Provides precise camera parameters but is limited in scale and dynamic richness.
  - Tartanair (Wang et al., 2020): Based on synthetic data, failing to capture the complexity of real-world scenes.
  - Panda70M (Chen et al., 2024): Limited camera perspectives and lack of diverse motion types.
  - CO3DV2 (Reizenstein et al., 2021): Sparse camera trajectories and reduced robustness in dynamic environments.
  - CameraBench (Lin et al., 2025): Limited by geometric annotation and motion instruction.
  - DROID-SLAM: Requires significant time to achieve accuracy.
  - COLMAP: N/A
  - Fast3R: N/A
  - DROID-SLAM (Teed and Deng, 2021): Struggles with dynamic content and unconstrained camera motion.
  - Depth Anything (Yang et al., 2024a): Insufficient performance in extreme cases with moving objects.
  - UniDepth (Piccinelli et al., 2024): Reliance on external monocular depth models may be inadequate.
  - CameraBench (Lin et al., 2025): Emphasizes the need for improved spatial reasoning in video captioning.
  - VLM4D (Zhou et al., 2025): Presents early efforts to address spatial reasoning challenges.
  - 3D LLM-Mem (Hu et al., 2025): Incorporates depth maps and camera parameters but still lacks comprehensive spatial understanding.
  - Panda-70M: Suffers from quality issues such as static videos, flicker-prone content, and underspecified captions.
  - N/A: N/A
  - Droid-slam: Deep visual slam for monocular, stereo, and rgb-d cameras: Existing models struggle with maintaining state over time.
  - Scaling laws for neural language models: Challenges in scaling perception models effectively.
  - Structure-from-motion revisited: Limitations in current structure-from-motion techniques.
  - N/A: N/A

### 3. Core Idea
- The proposed model integrates continuous perception with a persistent state to enhance 3D understanding.

### 4. Method
- **Pipeline**: The model employs a pipeline that processes video input to maintain a continuous state.
- **Architecture / Loss / Training**: Utilizes a novel architecture with specific loss functions tailored for 3D perception.
- **Complexity / Resources**: The model is designed to be resource-efficient while maintaining high accuracy.

### 5. Experiments
- **Datasets & Metrics**: Evaluated on various datasets including large-scale video datasets with structured captions.
- **Baselines**: 3D LLM-Mem, CO3D, COLMAP, CamVid-30K (Zhao et al., 2024), CameraBench, DROID-SLAM, Droid-slam, Existing datasets with camera pose information, Fast3R, MonST3R, MotionSight, Multi-Cam Video (Bai et al., 2025), N/A, Panda-70M, Panda70M (Chen et al., 2024), Scaling laws for neural language models, Structure-from-motion, Tartanair, VGGT, VLM4D
- **Main Results**: Demonstrated significant improvements in 3D perception accuracy over baseline models.
- **Ablations**: Conducted ablation studies to assess the impact of different components of the model.
- **Limitations / Stress Tests**: Identified limitations in dynamic environments and proposed future work to address these.

### 6. Takeaways
- **Pros**: Large-scale dataset with diverse scenes and camera movements., Rich spatial and semantic annotations., Key asset for video and 3D vision research community.
- **Cons**: High acquisition costs for large-scale 3D data., Dependence on accurate 3D annotation pipelines., Limited existing datasets in terms of scale and diversity.
- **Future Work**: Enhance spatial awareness in video generation pipelines., Develop more effective world-modeling tools., Address gaps in semantic annotations and spatial metadata.

</details>

### [Can Understanding and Generation Truly Benefit Together -- or Just Coexist?](http://arxiv.org/pdf/2509.09666v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Unified multimodal understanding and generation

### 2. Motivation & Gaps
- The paper addresses the need for a unified approach to multimodal understanding and generation using a single transformer model.

- **Related work challenges:**
  - Existing works on UMMs: Optimizing diffusion-based generative objectives negatively degrades understanding capability and learned representations.
  - Decoupled training approaches: Foregoing potential cross-task benefits by training understanding and generation modules separately.
  - Current approaches: Failing to deliver explicit, bidirectional gains between understanding and generation tasks.
  - Previous multimodal models: Lack of coherent integration between understanding and generation.
  - Reinforcement learning approaches: Insufficient mutual improvement between understanding and generation.
  - Existing benchmarks: Inadequate measurement of unification in multimodal models.
  - CLIP: Judging image realism or caption fidelity alone does not reveal whether a system is truly unified.
  - DINO: Existing benchmarks do not effectively assess the completeness of understanding in relation to generation.
  - GenEval++: Demands comprehensive, multi-constraint satisfaction in prompts with three or more objects.
  - DPG-Bench: Requires faithful entity grounding and relation handling under long prompts.
  - Unified-Bench: Needs optimization for reconstructability in caption generation.
  - X-Omni: Lack of OCR-based rewards during RL leading to poor typography fidelity.
  - Qwen-Image: Struggles with semantic conditioning without explicit VAE latents.
  - UniWorld-V1: Minimal encoder‚Äìconnector‚Äìdecoder design limiting the system's capabilities.
  - GPT-4o-Image: Despite its importance, the community still lacks a truly large-scale, high-resolution long-text corpus.
  - Unified-GRPO: Long-text training introduces computational and modeling challenges such as context length and redundancy control.
  - Uniworld: High-resolution semantic encoders for unified visual understanding and generation: High-resolution semantic encoding for visual tasks.
  - Dinov2: Learning robust visual features without supervision: Lack of supervision in learning visual features.
  - Learning transferable visual models from natural language supervision: Transferability of visual models across different tasks.

### 3. Core Idea
- The core idea is to utilize a single transformer architecture to handle both understanding and generation tasks in a unified manner.

### 4. Method
- **Pipeline**: The method involves a transformer-based architecture that processes multimodal inputs and generates corresponding outputs.
- **Architecture / Loss / Training**: The architecture employs a loss function that balances understanding and generation tasks during training.
- **Complexity / Resources**: The model is designed to be resource-efficient while maintaining high performance across tasks.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize a variety of datasets for multimodal tasks and employ standard metrics for evaluation.
- **Baselines**: BAGEL, BLIP-3o, BLIP3-o 4B, BLIP3-o 8B, CLIP, DALLE3, EMU3, Existing UMM approaches, FLUX.1-dev, GPT-4o-Image, Hunyuan-DiT, ImgEdit-E1, Janus Pro, Janus-Pro, LongCLIP, N/A, OmniGen, OmniGen2, Previous state-of-the-art multimodal models, Qwen-Image, SD3-medium, SDXL, Separate training methods, Show-o, Single-task models for comparison, TokenFlow-XL, UAE, UniWorld-V1, X-Omni
- **Main Results**: The results demonstrate significant improvements in both understanding and generation tasks compared to existing models.
- **Ablations**: Ablation studies indicate the importance of specific components in the transformer architecture.
- **Limitations / Stress Tests**: The model shows limitations in handling highly complex multimodal inputs.

### 6. Takeaways
- **Pros**: Establishes a unified framework for multimodal learning., Demonstrates mutual benefits between understanding and generation tasks., Introduces a novel benchmark for evaluating UMMs.
- **Cons**: Requires significant computational resources for training., Challenges in optimizing the joint objective effectively., Potential limitations in scalability to larger datasets.
- **Future Work**: Explore further enhancements in the reinforcement learning approach., Investigate scalability to more complex multimodal tasks., Develop additional benchmarks for comprehensive evaluation.

</details>

### [AskDoc -- Identifying Hidden Healthcare Disparities](http://arxiv.org/pdf/2509.09622v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>üìÑ Paper Summary </summary>

### 1. Task / Problem
- Analysis of online health community interactions

### 2. Motivation & Gaps
- The study aims to understand the dynamics of health-related inquiries and responses in online platforms, particularly focusing on the Ask the Doctor service.

- **Related work challenges:**
  - Nobles et al. (2013-2018): Limited analysis on self-reported demographics for gender and race without including age.
  - Nobles et al. [2]: Limited analysis on self-reported demographics for gender and race on Reddit.
  - N/A: Inequalities between demographic groups in health and medical care.
  - Hardeman et al. 2016: Addressing structural racism in healthcare delivery.
  - Gengler and Jarrell 2015: Persistence of inequalities in healthcare delivery.
  - Eisenberg et al. 2009: Stigma surrounding mental health help-seeking among college students.

### 3. Core Idea
- The paper investigates the engagement patterns and demographic characteristics of users in the Ask the Doctor online platform.

### 4. Method
- **Pipeline**: Data collection from the AskDocs subreddit, followed by statistical analysis of user interactions.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Utilized descriptive statistics to analyze user engagement and demographics.

### 5. Experiments
- **Datasets & Metrics**: Data from the AskDocs subreddit from January 2020 to May 2022, including user posts and comments.
- **Baselines**: N/A
- **Main Results**: The analysis revealed significant engagement from various demographic groups, with notable differences in interaction rates.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The study acknowledges limitations in self-reported data and potential biases in user engagement.

### 6. Takeaways
- **Pros**: Social media can bridge communication gaps in healthcare., Free and anonymous access to medical advice., Increased engagement during the COVID-19 pandemic.
- **Cons**: Low participation from healthcare professionals., Potential biases in responses based on demographics., Limited disclosure of race among users.
- **Future Work**: Further research on demographic engagement in online health forums., Exploration of strategies to increase physician participation., Analysis of long-term trends in online health consultations.

</details>
