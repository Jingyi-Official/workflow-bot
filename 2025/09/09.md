# Daily Paper Digest · 2025-09-09
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## neural rendering

### [Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments](http://arxiv.org/pdf/2509.06953v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- DRPBench simulation comprising five tasks

### 2. Motivation & Gaps
- The paper presents DRPBench, a simulation framework designed to evaluate robot learning policies in various challenging scenarios.

- **Related work challenges:**
  - Classical motion planners: Require full environment knowledge and are too slow for dynamic scenes.
  - Reactive controller-based approaches: Lack global scene awareness and often become trapped in local minima in complex environments.
  - Prior methods like M πNet: Demonstrated limited success in simple settings and often fail to generalize to unseen environments.
  - MπNets: Struggles to generalize due to limited training diversity.
  - NeuralMP: Relies on slow test-time optimization, limiting real-time performance.
  - Geometric Fabrics: Requires privileged obstacle information, which is not always available.
  - IMPACT: Frequent minor collisions at deployment due to compounding errors over long horizons.
  - Geometric Fabrics: Requires ground-truth obstacle models, limiting its real-world deployability.
  - Riemannian Motion Policy (RMP): Performance degrades in dynamic environments due to lack of dynamic interaction in training.
  - cuRobo: Significantly degrades in dynamic environments, achieving only 3.00% success on Dynamic Goal Blocking.
  - NeuralMP: Relies on test-time optimization, which is ineffective in reactive contexts.
  - IMPACT: While it performs well, it still struggles in highly dynamic tasks without reactive modules.
  - N/A: N/A
  - AIT*: Requires pre-computation and precise object models of the obstacles.
  - cuRobo: Used as the expert policy for generating pretraining dataset.
  - NeuralMP: Trained on a less diverse dataset and requires test-time optimization.
  - MπNets: High cold-start time
  - MπFormer: Low success rates in goal-reaching
  - NeuralMP: N/A

### 3. Core Idea
- The core idea is to evaluate robot learning policies in dynamic environments with various obstacle scenarios using a physics simulation framework.

### 4. Method
- **Pipeline**: The method involves combining goal-attracting and dynamic obstacle-avoiding policies into a single Riemannian Motion Policy (RMP).
- **Architecture / Loss / Training**: The architecture is compared against LSTM-GMM, showing improvements in performance with the proposed design.
- **Complexity / Resources**: 4090 GPU and AMD 7950X CPU

### 5. Experiments
- **Datasets & Metrics**: DRPBench
- **Baselines**: AIT*, Classical motion planners, Geometric Fabrics, IMPACT, MπFormer, MπNets, N/A, Neural motion policies, NeuralMP, RMP, cuRobo, cuRobo-Vox
- **Main Results**: DRP (Ours) achieved 91.34/10.16, 95.67/12.33, 96.00/23.00, 95.00/31.64, 95.50/32.75 on DRPBench.
- **Ablations**: Architecture ablation shows a 9% gain when replacing LSTM-GMM with IMPACT.
- **Limitations / Stress Tests**: The method requires precise obstacle information for traditional implementations.

### 6. Takeaways
- **Pros**: Strong generalization in dynamic environments., Effective collision-free motion generation., Improved obstacle avoidance through iterative finetuning.
- **Cons**: May struggle in environments with limited sensor data., Initial pretraining can lead to minor collisions., Complexity of the architecture may require significant computational resources.
- **Future Work**: Explore further enhancements in dynamic obstacle avoidance., Investigate applications in more complex real-world scenarios., Develop methods for better generalization to unseen environments.

</details>

### [Ultrafast electronic coherence from slow phonons](http://arxiv.org/pdf/2509.06939v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Investigate the dynamics of a 1D metal with nonlinear electron-phonon coupling subjected to an impulsive optical pump.

### 2. Motivation & Gaps
- The study explores the mechanisms behind light-enhanced superconductivity and non-equilibrium ordering, focusing on the role of phonon energy scales.

- **Related work challenges:**
  - Previous studies on light-induced superconductivity: Lack of unambiguous evidence for long-range superconducting coherence and understanding of the underlying dynamical mechanisms.
  - Theoretical treatments of light-driven superconductivity: Most focus on local observables, failing to capture the collective reorganization necessary for true superconductivity.
  - Matrix product state simulations: Limited to fast-phonon regimes, leaving the role of slow phonons unexplored.
  - Previous studies on electron-phonon interactions: Limited understanding of non-equilibrium dynamics in driven systems.
  - Research on phase coherence in materials: Difficulty in achieving controlled, non-perturbative confirmation of coherence enhancement.
  - Previous studies on charge-density wave order: Understanding the dominance of charge-density wave order over superconductivity in 1D half-filled systems.
  - Eﬀective models of electronic dynamics: Capturing the competition between phonon-induced disorder and long-range coherence.
  - Previous studies on optical phonon excitations: Understanding how these excitations enhance superconducting correlations.
  - Theoretical proposals on driven 1D correlated systems: Testing the hypothesis of exotic non-equilibrium orders.
  - Experimental observations in materials like YBa2Cu3Ox and K3C60: Establishing a clear connection between phonon modes and superconductivity.
  - Possible light-induced superconductivity in K3C60 at high temperature: N/A
  - Light-induced charge density wave in LaTe3: N/A
  - The spontaneous symmetry breaking in Ta2NiSe5 is structural in nature: N/A
  - Light-induced superconductivity in a stripe-ordered cuprate: N/A
  - Pump frequency resonances for light-induced incipient superconductivity in YBa2Cu3O6.5: N/A
  - Evidence for metastable photo-induced superconductivity in K3C60: N/A
  - Photomolecular high-temperature superconductivity: N/A
  - Dynamical cooper pairing in nonequilibrium electron-phonon systems: N/A
  - Transient superconductivity from electronic squeezing of optically pumped phonons: N/A
  - Cooling quasiparticles in A3C60 fullerides by excitonic mid-infrared absorption: N/A
  - Previous studies on two-site models: Limited to restricted local Hilbert spaces
  - Conventional MPS methods: Inability to access regimes with slow phonons and long evolution times
  - Kennes et al.: N/A
  - Sous et al.: N/A
  - Kennes et al.: N/A
  - Sous et al.: N/A
  - N/A: N/A

### 3. Core Idea
- The main idea is to rotate the exact Hamiltonian into the squeezed phonon basis, allowing the dynamics of electrons and phonons to decouple.

### 4. Method
- **Pipeline**: Evolve the initial metallic state in time under the full Hamiltonian and the effective model.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: All simulations use a chain length L = 32, a maximum bond dimension χmax = 2000, and a phonon cutoff dmaxν = 40.

### 5. Experiments
- **Datasets & Metrics**: Simulated global phonon distributions and charge correlations in a 1D metal.
- **Baselines**: Conventional MPS methods, Exact model, Experimental data from pump-probe techniques, Experimental reports on transient superconductivity, Eﬀective model, Full microscopic Hamiltonian, Linear models of electron-phonon interactions, N/A, Previous non-equilibrium correlation dynamics studies, Previous theoretical models, Previous theoretical models of light-induced superconductivity, Two-site models
- **Main Results**: The eﬀective Hamiltonian captures the qualitative features of the exact model.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The model is constrained by the stability condition of the electron-phonon coupling and the range of phonon frequencies explored.

### 6. Takeaways
- **Pros**: Provides direct evidence that light can mediate enhancement of long-range order., Highlights the crucial role of phonon energy scale in stabilizing coherence., Suggests future experimental strategies for designing transient superconducting states.
- **Cons**: Unambiguous evidence for long-range superconducting coherence remains elusive., Current methods may not fully capture the complexity of non-equilibrium dynamics., Dependence on specific phonon distributions may limit generalizability.
- **Future Work**: Explore selective excitations of narrow phonon distributions to limit dephasing., Investigate the role of different phonon frequencies in various materials., Develop new theoretical frameworks to better understand light-induced order.

</details>

### [Learning words in groups: fusion algebras, tensor ranks and grokking](http://arxiv.org/pdf/2509.06931v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Understanding grokking in neural networks and its relation to group representations

### 2. Motivation & Gaps
- The paper explores the phenomenon of grokking in neural networks, particularly in the context of learning group operations and representations.

- **Related work challenges:**
  - Power et al.: Demonstrated that a simple decoder-only transformer can learn group operations with limited examples.
  - Gromov: Showed that a Two Layer Perceptron exhibits Grokking for addition modulo p.
  - General group studies: Explored learning and generalization for non-cyclic and non-abelian groups.
  - Gromov [13]: Understanding the phenomenology of the original model.
  - Nanda [5]: Deriving theoretical bounds on the rank of the word tensor.
  - Strassen [30]: Bounding the tensor rank of matrix multiplication.
  - Previous studies on neural networks and group theory.: Limited understanding of how neural networks can generalize across different algebraic structures.
  - Previous studies on irreducible representations: Lack of focus on the specific properties and applications of basic self conjugate representations.
  - Previous studies on group multiplication operations: Limited understanding of the sparsity of bsc3-support in word tensors.
  - Previous studies on tensor ranks in group theory.: Lack of accessible methods for bounding tensor ranks.
  - TLP Model and its variants.: Complexity in implementation and understanding of activation functions.
  - Gromov [13]: Studied group operations with addition modulo p.
  - Nanda et al [24]: Extended results to general groups.
  - Previous studies on weight configurations in neural networks.: Lack of understanding on how different configurations affect loss minimization.
  - Power et al.: Some polynomials could be learned using the same transformer based architecture, while others could not.
  - Gromov et al.: Using more layers allows for learning general biivariate polynomials, provided depth and width are tuned correctly.
  - AlphaZero: Discovering efficient matrix multiplication for various matrix sizes and underlying fields.
  - Hidden progress in deep learning: SGD learns parities near the computational limit: Understanding the limits of generalization in deep learning.
  - Grokking as a first order phase transition in two layer networks: Identifying the conditions under which grokking occurs.
  - Discovering faster matrix multiplication algorithms with reinforcement learning: Optimizing computational efficiency in learning algorithms.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The paper proposes a method to numerically find bsc representations of finite groups using neural networks, leveraging the Hadamard model for convergence.

### 4. Method
- **Pipeline**: Run the Hadamard model until it converges to a terminal configuration that is mono-bsc-aligned.
- **Architecture / Loss / Training**: Utilizes a complex-valued version of the problem to recover irreducible representations.
- **Complexity / Resources**: Assumes sufficient width to reduce computing power while maintaining accuracy.

### 5. Experiments
- **Datasets & Metrics**: Evaluates the performance of the proposed method on various group representations and their corresponding metrics.
- **Baselines**: Complex representations, Decoder-only transformer, HD model, Hadamard Model, Hadamard model, Irreducible representations, N/A, Previous methods for learning group representations, Previous models for learning polynomials, Previous models of word tensors, Previous neural network models, Simple Two Layer Perceptron, Single-bsc supported weight configurations, Standard activation functions, Standard neural network architectures, Standard random initialization, TLP Model, TLP model, Trivial bounds on rank, Two-Layer Pe
- **Main Results**: Demonstrates that the proposed method can effectively recover bsc representations with reduced computational resources.
- **Ablations**: Tests the impact of varying network width and architecture on the recovery of representations.
- **Limitations / Stress Tests**: Identifies scenarios where the method may fail to converge or recover representations accurately.

### 6. Takeaways
- **Pros**: The model can learn complex operations with limited examples., Exhibits Grokking, leading to sharp transitions in accuracy., Utilizes low-rank tensor representations for efficient learning.
- **Cons**: Performance may vary significantly based on the underlying group and word., Limited exploration of more complex architectures., Potential overfitting if the model width is not managed properly.
- **Future Work**: Explore more complex group operations and their representations., Investigate the implications of Grokking in other neural architectures., Develop methods to further reduce the complexity of learning tasks.

</details>

## Gaussian Splatting

### [Stochastic modelling of cosmic-ray sources for Galactic diffuse emissions](http://arxiv.org/pdf/2509.06857v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Calculate the intensity of hadronic diffuse gamma-ray emissions from cosmic rays interacting with Galactic gas

### 2. Motivation & Gaps
- The study investigates the stochastic effects of discrete cosmic ray (CR) sources on gamma-ray diffuse emissions (GDE) spectra and intensity profiles.

- **Related work challenges:**
  - Previous studies on cosmic-ray transport and source modeling: Limited understanding of the exact source coordinates and their influence on predictions.
  - Previous studies on gamma-ray emissions from cosmic rays: Limited understanding of the influence of discrete sources on gamma-ray emissions.
  - Research on cosmic ray intensity distributions: Need for a comprehensive overview of the influence of source stochasticity.
  - N/A: N/A
  - Previous studies on cosmic ray interactions: Incorporating heavier components of the interstellar medium and their spatial correlations with hydrogen.
  - Gamma-ray emission models: Accurately modeling the distribution of Galactic gas and cosmic rays.
  - N/A: N/A
  - Ref. [16]: Distributions of CR intensities in a burst-like discrete source model have been studied.
  - Monte Carlo simulations of GDE predictions: Understanding the morphology of GDEs and linking fluctuations to individual sources.
  - Analysis of GDEs in selected sky windows: Quantifying systematic modeling uncertainties from discrete sources.
  - Investigation of different source injection scenarios: Determining the influence of discrete CR sources on GDEs.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - LHAASO measurements: The spectra in burst-like and energy-dependent escape scenarios undershoot the data, necessitating the invocation of other GDE model uncertainties.
  - CR source models: Popular models do not consider discrete sources, leading to potential inaccuracies in predictions.
  - N/A: N/A
  - N/A: Limited knowledge of the coordinates of current and past cosmic ray sources.
  - N/A: Model uncertainty due to discrete sources and their influence on GDEs.
  - N/A: Correlation of GDEs at different energies and its dependence on CR source models.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The study compares the emissivity contributions of cosmic ray sources under burst-like and energy-dependent escape scenarios, focusing on how source age and distance affect gamma-ray emissions at 100 TeV.

### 4. Method
- **Pipeline**: Stochastic modeling of cosmic ray sources and their impact on GDE predictions.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The study utilizes extensive Monte Carlo simulations and quantile estimation methods implemented in SciPy.

### 5. Experiments
- **Datasets & Metrics**: The study utilizes LHAASO WCDA-KM2A measurements and correlates GDE intensities at different energies.
- **Baselines**: Burst-like scenario, Energy-dependent escape scenario, N/A, Normal distributions, Previous cosmic ray emission models, Previous cosmic-ray emission models, Previous discrete source models, Smooth CR source distribution models, Smooth source distribution models, Smooth source model, Smooth source model predictions, Stable laws with α=4/3, Stable laws with α=5/3, Standard gamma-ray emission calculations, burst-like model, energy-dependent escape model
- **Main Results**: The burst-like model shows higher emissivity contributions for younger sources compared to the energy-dependent escape model, particularly at 100 TeV.
- **Ablations**: N/A
- **Limitations / Stress Tests**: Uncertainties due to CR source stochasticity are subdominant in some scenarios but relevant in others.

### 6. Takeaways
- **Pros**: Increased spatial resolution can constrain source models., Stochastic modeling provides insights into the influence of discrete sources., The study helps reconcile model predictions with observational data.
- **Cons**: Limited knowledge of exact source coordinates complicates predictions., Model uncertainty can lead to significant deviations in high-energy scenarios., Dependence on stochastic modeling may introduce variability in results.
- **Future Work**: Further studies on the influence of other cosmic-ray sources., Exploration of different stochastic modeling techniques., Integration of high-precision measurements from upcoming experiments.

</details>

### [Heavy Field Effects on Inflationary Models in Light of ACT Data](http://arxiv.org/pdf/2509.06739v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Examine the effects of an additional field with a Hubble-scale mass and a mixing coupling to the inflaton on inflationary observables.

### 2. Motivation & Gaps
- The paper explores the reconciliation of Starobinsky-type inflation models with recent ACT data, particularly in the context of large mixing couplings.

- **Related work challenges:**
  - Planck 2018 baseline: The results from ACT data challenge the predictions of Starobinsky-type inflation models.
  - Previous attempts to reconcile models with observations: Many models have been excluded by Planck data, necessitating new approaches.
  - Ref. [62]: N/A
  - Refs. [76–78]: N/A
  - Refs. [79–82]: N/A
  - KNP alignment mechanism: Identifying the heavy field direction in the alignment mechanism.
  - Weak gravity conjecture: Constraints on aligned natural inflation.
  - Ref. [73,96]: N/A
  - Ref. [97]: N/A
  - Ref. [102]: N/A
  - Ref. [60, 103–105]: N/A
  - Ref. [111]: N/A
  - Ref. [112]: N/A
  - Ref. [113, 114]: N/A
  - Previous studies on multifield inflation: Understanding non-geodesic motion and rapid turns in inflationary trajectories.
  - Refs. [77–79,111,117–136]: Embedding the setup into existing scenarios and realizing rapid turns within supergravity.
  - Refs. [116,137–139]: Analyzing consistency conditions associated with attractor behavior.
  - N/A: N/A
  - G. German and J.C. Hidalgo, Viability of generalized α-inflation from Planck, ACT, and DESI Data: N/A
  - S.V. Ketov, E.O. Pozdeeva and S.Y. Vernov, Inflation in F(R) gravity models revisited after ACT: N/A
  - Y. Zhu, Q. Gao, Y. Gong and Z. Yi, Inflationary Models with Gauss-Bonnet Coupling in Light of ACT Observations: N/A
  - N/A: N/A

### 3. Core Idea
- The introduction of an additional field with a Hubble-scale mass and a mixing coupling can lead to significant modifications in inflationary observables, allowing for the revival of previously excluded inflation models.

### 4. Method
- **Pipeline**: The study employs a two-field setup to analyze the dynamics of inflation with a focus on the effects of rapid turns and mixing couplings.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The method allows for the inclusion of a heavy field with large mixing, enhancing the analysis of inflationary observables.

### 5. Experiments
- **Datasets & Metrics**: The paper discusses the implications of the findings on inflationary observables such as n_s, r, and α_s, particularly in relation to ACT data.
- **Baselines**: Chaotic inflation, N/A, Natural inflation, Previous multifield inflation models, Standard inflationary models, Starobinsky inflation, Starobinsky-type inflation, Starobinsky-type inflation models
- **Main Results**: The findings suggest that large mixing couplings can reconcile Starobinsky-type inflation models with observations, predicting large non-Gaussianity.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The study acknowledges the challenges in embedding the model into supergravity and string theory frameworks.

### 6. Takeaways
- **Pros**: The framework allows for the revival of previously excluded inflation models., Enhanced non-Gaussianity signatures provide unique observational tests., The approach is applicable even in the presence of a heavy field.
- **Cons**: The mass and mixing couplings are treated as free parameters, raising questions about their realizability., Some regions of parameter space remain untested., The complexity of the models may hinder straightforward interpretations.
- **Future Work**: Further exploration of concrete models that realize the proposed scenarios., Testing the predictions of enhanced non-Gaussianity in future observations., Investigating the implications of heavy fields in other cosmological contexts.

</details>

### [VIM-GS: Visual-Inertial Monocular Gaussian Splatting via Object-level Guidance in Large Scenes](http://arxiv.org/pdf/2509.06685v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Monocular depth estimation and novel-view synthesis

### 2. Motivation & Gaps
- The paper addresses the challenge of converting sparse visual-inertial structure from motion (VI-SfM) and coarse foundation depths into dense, geometry-consistent maps.

- **Related work challenges:**
  - Existing GS approaches: Require reliable depth for initialization, often focusing on small-scale scenes due to depth-sensing limitations.
  - Large foundation models for monocular depth estimation: Suffer from cross-frame inconsistency and inaccuracies for distant scenes.
  - High-density LiDAR sensors: Costly and limited in consumer applications, making them impractical for large scene GS.
  - VI SLAM: Depth drift on tiny objects and boundaries.
  - Semantic Segmentation Models: Insufficient supervision for small object masks.
  - Previous depth estimation methods: Inability to handle dynamic regions effectively.
  - Monocular depth prediction models: Struggles with accuracy in the presence of dynamic objects.
  - Traditional depth propagation techniques: Often yield inconsistent depth maps due to texture variations.
  - Depth Anything V2: Lacks robustness in long-range, repetitive-texture areas.
  - Depth Pro: Insufficient accuracy in dynamic scenes.
  - ZoeDepth: Limited performance in outdoor environments.
  - DepthSplat: Struggles with depth accuracy in complex scenes.
  - N/A: N/A

### 3. Core Idea
- The proposed VIM-GS framework utilizes segment-aware primitive fitting and mask-wise calibration to enhance depth estimation and novel-view synthesis.

### 4. Method
- **Pipeline**: The method involves depth estimation from monocular images, followed by Gaussian splatting for rendering.
- **Architecture / Loss / Training**: Utilizes a hybrid supervision approach with affine and plane fitting, optimizing for depth accuracy and rendering quality.
- **Complexity / Resources**: Implemented on a single NVIDIA GeForce RTX 4090 GPU and Intel Xeon Platinum 8347C CPU, with resource usage characterized by the number of active Gaussian primitives and GPU memory footprint.

### 5. Experiments
- **Datasets & Metrics**: Evaluated on outdoor road scenes using metrics such as PSNR, SSIM, and LPIPS for rendering quality, and AbsRel and RMSE for depth accuracy.
- **Baselines**: Depth Anything V2, Depth Pro, DepthSplat, Existing monocular-supported GS approaches, Foundation models for monocular depth prediction, Intern-GS, MonoGS++, N/A, Ours, Traditional depth estimation methods, VINGS-Mono, ZoeDepth
- **Main Results**: VIM-GS outperforms monocular-supported baselines in large-scene novel-view synthesis quality.
- **Ablations**: Ablations highlight the contributions of pyramid strategies and dynamics handling, evidencing that both are critical for robust large-scene mapping.
- **Limitations / Stress Tests**: The method's performance is limited in highly dynamic scenes where transient objects may contaminate depth estimation.

### 6. Takeaways
- **Pros**: Improved depth estimation for monocular images., High-quality rendering in large scenes., Cost-effective solution compared to high-density LiDAR.
- **Cons**: Dependency on the accuracy of SfM for sparse depth., Potential challenges with dynamic object handling., Limited by the performance of large foundation models.
- **Future Work**: Explore further enhancements in depth estimation techniques., Investigate integration with other sensor modalities., Develop more robust algorithms for dynamic scene handling.

</details>

## avatar

### [Reconstruction and Reenactment Separated Method for Realistic Gaussian Head](http://arxiv.org/pdf/2509.05582v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Mapping audio sequences to motion sequences for lip synchronization

### 2. Motivation & Gaps
- The paper addresses the challenge of achieving accurate lip synchronization in 3D models driven by audio input.

- **Related work challenges:**
  - Goodfellow et al. (2014): Rely on deep convolutional networks and generative adversarial models, which can introduce latency issues.
  - Mildenhall et al. (2020): Methods rely on precise estimation of 3D pose, which can introduce errors leading to texture inaccuracies.
  - Guo et al. (2024): 2D end-to-end approaches struggle to reproduce subtle, natural expressions due to reliance on geometric structures.
  - 2D end-to-end image synthesis approaches: High latency and computational resource demands, leading to unrealistic distortions in identity features.
  - 3D explicit structural prior-based methods: Insufficient concrete 3D structural constraints limit free-viewpoint rendering capabilities.
  - NeRF-based methods: Require large amounts of training data, raising privacy concerns and limiting generalization.
  - Deng and others. 2024b: Previous methods did not leverage the advantages of larger scale and extensive training datasets.
  - Chu and others. 2024a: Existing methods may not effectively capture high-frequency details in rendered outputs.
  - He and others. 2025: Prior approaches may struggle with identity consistency in animated outputs.
  - Live Portrait (Guo and others. 2024): Maintaining high-quality texture details in generated images.
  - GFPGAN (Wang and others. 2021b): Achieving accurate expressions and poses consistent with driving images.
  - Previous methods in identity reenactment: Preserving identity consistency while enhancing image quality.
  - Wang and others. 2023: Existing methods struggle with fine-grained control over facial features.
  - Kaplan and others. 2020: Scaling laws indicate that larger models can improve performance, but current architectures may not fully leverage this.
  - Wav2Lip: Achieving high lip accuracy scores using sync score as supervisory loss.
  - HunyuanVideoAvatar: Utilizing large-scale parameters and data for improved performance.
  - MuseTalk: Maintaining competitive results in lip synchronization tasks.
  - N/A: N/A

### 3. Core Idea
- The technique synthesizes high-fidelity, real-time talking head video using a single portrait image, capturing intricate facial expressions and subtle nuances in movement.

### 4. Method
- **Pipeline**: The Gaussian Generator produces static and dynamic Gaussians for controllable 3D Gaussian generation.
- **Architecture / Loss / Training**: The model employs a mean square error (MSE) loss during training to align predictions with ground-truth mouth features.
- **Complexity / Resources**: The model is trained on a dataset of 1,000 professional single-speaker lecture videos, requiring significant computational resources for training.

### 5. Experiments
- **Datasets & Metrics**: The method is evaluated on the HDTF and VFHQ datasets.
- **Baselines**: 2D end-to-end image synthesis methods, 2D end-to-end models, 3D explicit structural prior-based methods, 3DGS, FLAME, GAGAvatar, GAGavatar, GPAvatar, HunyuanVideoAvatar, LAM, LivePortrait, MuseTalk, N/A, NeRF, NeRF-based methods, P4D, P4D-v2, PDFGC, RAR, Real3D, Real3DPortrait, StyleHEAT, StyleHeat, Wav2Lip
- **Main Results**: The generated videos exhibit lifelike clarity and realism.
- **Ablations**: Ablation studies showed that increasing the scale of the pre-trained backbone improves performance.
- **Limitations / Stress Tests**: The method's performance is contingent on the quality of the pre-trained models used.

### 6. Takeaways
- **Pros**: Decoupled architecture enhances reconstruction accuracy and reenactment speed., Ability to control facial features independently allows for natural expression reproduction., High frame-rate rendering at 90 FPS improves user experience in applications.
- **Cons**: Dependence on the quality of the input portrait image., Potential artifacts in high-frequency texture areas., Complexity in training the texture restoration module.
- **Future Work**: Explore further improvements in 3D pose estimation accuracy., Investigate additional applications in virtual reality and gaming., Enhance the model's ability to handle diverse facial features and expressions.

</details>

### [Evaluating Idle Animation Believability: a User Perspective](http://arxiv.org/pdf/2509.05023v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Evaluating Idle Animation Believability: a User Perspective

### 2. Motivation & Gaps
- The study investigates whether idle animations need to be recorded in a genuine manner to be perceived as real.

- **Related work challenges:**
  - EmotionGesture: Generating 3D gestures from audio with high accuracy.
  - TALKShow: Generating both body and hand animations as well as face animations over a 3D mesh.
  - DiffGesture: Effectively capturing cross-modal audio-to-gesture associations while preserving temporal coherence.
  - Egges et al. (2002): Created an idle motion engine based on Principal Component Analysis, which generates motion by combining small posture variations and change of balance.
  - Kocón (2023): Developed an idle motion synthesiser on a 3D human head model, which generates idle movements but lacks comprehensive datasets.
  - Cuijpers et al. (2023): Analyzed idle and meaningful motions in robots, emphasizing the importance of idle animation in social robotics.
  - Previous motion capture studies: Intrusiveness of motion capture suits affecting natural movement.
  - User studies on animation perception: Lack of understanding on how well users can distinguish between different types of idle motion.
  - Previous studies on animation perception: Lack of understanding on how different animation creation methods influence user perception.
  - Previous studies on animation believability: Lack of clear metrics for comparing idle animations.
  - Mixamo animations comparison: Determining perceptual differences between handcrafted and recorded animations.
  - N/A: N/A

### 3. Core Idea
- Acted idle animations can be perceived as real, while handcrafted animations are not perceived the same as recorded animations.

### 4. Method
- **Pipeline**: User study comparing real and acted idle animations.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Utilizes 4 Logitech c920 webcams and Freemocap software for motion capture.

### 5. Experiments
- **Datasets & Metrics**: User study 1 and User study 2 demographics
- **Baselines**: Acted animations, Handcrafted animations from Mixamo, Handmade animations, Mixamo, N/A, Previous motion capture techniques, Real animations, Recorded animations, Standard animation methods
- **Main Results**: No significant difference in perception between real and acted idle animations; significant difference between handcrafted and recorded animations.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The analysis of average accelerations was not straightforward, limiting direct conclusions.

### 6. Takeaways
- **Pros**: Simplifies the recording process for idle animations., Contributes to the understanding of user perception of animations., Provides a new dataset for future research.
- **Cons**: Limited availability of high-quality idle animation datasets., Challenges in capturing genuine idle movements., Ethical concerns in recording subjects without their knowledge.
- **Future Work**: Further research on the perception of idle animations., Development of more comprehensive idle animation datasets., Exploration of automated methods for generating idle animations.

</details>

### [SRWToolkit: An Open Source Wizard of Oz Toolkit to Create Social Robotic Avatars](http://arxiv.org/pdf/2509.04356v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Human-Robot Interaction (HRI) Evaluation

### 2. Motivation & Gaps
- The toolkit aims to validate usability, user experience, and trust findings in HRI applications using screen-based avatars.

- **Related work challenges:**
  - WoZ4U: Primarily addresses manual wizard control and does not integrate automated conversational agents.
  - Fang et al. (LLM Wizards): While reducing manual workload, it does not address the need for local LLM inference.
  - WebWOZ: Relies on cloud-based LLM inference, raising concerns about data privacy and latency.
  - Previous studies on social robots: Limited control over character design and interaction modes.
  - Existing LLM frameworks: Dependency on external services for speech-to-text and text-to-speech tasks.
  - Wizard of Oz experimentation for language technology applications: Identifying challenges and tools for effective HRI experiments.
  - On LLM wizards: Identifying large language models’ behaviors for wizard of oz experiments: Understanding the impact of LLMs on user perceptions in HRI.
  - Concerning trends in likert scale usage in human-robot interaction: Improving best practices in measuring user experience.

### 3. Core Idea
- To provide a reproducible toolkit for conducting HRI experiments with a focus on real-time performance and local processing capabilities.

### 4. Method
- **Pipeline**: The toolkit utilizes screen-based avatars to simulate robotic behavior and aims to migrate language and speech processing to local modules.
- **Architecture / Loss / Training**: The backend uses FastAPI for processing and communication with LLMs, while the frontend uses React.js for user interaction.
- **Complexity / Resources**: The toolkit is designed to be reproducible with complete source code and deployment instructions available.

### 5. Experiments
- **Datasets & Metrics**: User study with 11 participants evaluating usability, trust, and user experience.
- **Baselines**: Fang et al. (LLM Wizards), System Usability Scale (SUS), Trust in Automated Systems (TIA), User Experience Questionnaire (UEQ), User experience questionnaire, WebWOZ, Wizard of Oz technique, WoZ4U
- **Main Results**: Future research should investigate the impact of role types and design variables on user perceptions.
- **Ablations**: N/A
- **Limitations / Stress Tests**: Limited participant diversity and reliance on Google Cloud APIs for speech tasks.

### 6. Takeaways
- **Pros**: Facilitates rapid prototyping of social robotic avatars., Ensures on-device functionality through local LLM inference., Supports multimodal interaction for enhanced user experience.
- **Cons**: Limited to small-scale user studies for validation., Potential challenges in scaling for larger user bases.
- **Future Work**: Explore integration with more advanced LLMs., Investigate broader applications in different domains., Enhance user interface for better accessibility.

</details>

## video understanding

### [H$_{2}$OT: Hierarchical Hourglass Tokenizer for Efficient Video Pose Transformers](http://arxiv.org/pdf/2509.06956v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- 3D human pose estimation

### 2. Motivation & Gaps
- Existing Video Pose Transformers (VPTs) incur redundant computational costs that contribute little to estimation accuracy.

- **Related work challenges:**
  - Existing VPTs: High computational costs due to the quadratic growth of self-attention complexity with respect to the number of tokens.
  - Token pruning methods: Difficulties in estimating consecutive 3D poses due to reduced token numbers.
  - Current 2D-to-3D pose lifting methods: Small temporal receptive fields hinder accurate pose estimation.
  - PoseFormer: Heavy computation burden limits practical applications.
  - MHFormer: Improved performance comes with significant computational costs.
  - MotionBERT: Existing methods do not effectively reduce video redundancy.
  - VPose: Presents a fully convolutional architecture that processes multiple frames in parallel.
  - P-STMO: Proposes a temporal downsampling strategy on the input side to diminish data redundancy.
  - DynamicViT: Proposes a learnable prediction module to estimate the scores of tokens and prune redundant tokens.
  - Existing VPT models: High computational costs and redundancy in processing video frames.
  - Token Pruning methods: Inefficiencies in token selection and interpolation.
  - Transformer architectures: Difficulty in capturing long-range dependencies while maintaining efficiency.
  - Video Pose Transformers: High computational complexity due to the number of tokens and dimensions.
  - Human3.6M dataset: Limited efficiency in processing due to the need for repeated inputs.
  - MPI-INF-3DHP dataset: Diverse scenes and motions make it challenging for existing models.
  - MixSTE: Higher computational costs and lower FPS compared to seq2seq methods.
  - MotionBERT: Inefficiency in token processing leading to increased inference time.
  - MotionAGFormer: Limited performance improvements over existing methods.
  - MixSTE [15]: High FLOPs and reduced FPS.
  - HoT w. MixSTE [21]: Maintains performance but with increased computational costs.
  - MotionBERT [16]: High computational complexity while achieving SOTA performance.
  - MixSTE: High computational costs with limited performance improvement.
  - DiffPose: Maintaining performance while reducing computational costs.
  - MotionAGFormer: Balancing efficiency and accuracy in pose estimation.
  - 3D human pose estimation in rgbd images for robotic task learning: N/A
  - Human 3D pose estimation with a tilting camera for social mobile robot interaction: N/A
  - VNect: Real-time 3D human pose estimation with a single rgb camera: N/A
  - SPViT: Enabling faster vision transformers via latency-aware soft token pruning: N/A
  - Making vision transformers efficient from a token sparsification view: N/A
  - PPT: Token-pruned pose transformer for monocular and multi-view human pose estimation: N/A
  - TCFormer: Visual recognition via token clustering transformer: N/A
  - GTPT: Group-based token pruning transformer for efficient human pose estimation: N/A
  - Deep residual learning for image recognition: N/A
  - Very deep convolutional networks for large-scale image recognition: N/A
  - Study on density peaks clustering based on k-nearest neighbors and principal component analysis: N/A
  - A-ViT: Adaptive tokens for efficient vision transformer: N/A
  - Token pooling in vision transformers for image classification: N/A
  - Not all patches are what you need: Expediting vision transformers via token reorganizations: N/A
  - DiffRate: Differentiable compression rate for efficient vision transformers: N/A
  - Multi-hypothesis representation learning for transformer-based 3D human pose estimation: N/A
  - Monocular 3D human pose estimation in the wild using improved CNN supervision: N/A
  - GraphMLP: A graph MLP-like architecture for 3D human pose estimation: N/A
  - Locally connected network for monocular 3D human pose estimation: N/A
  - Monocular 3D pose estimation via pose grammar and data augmentation: N/A
  - Cascaded deep monocular 3D human pose estimation with evolutionary training data: N/A
  - Stacked hourglass networks for human pose estimation: N/A
  - 3D human pose estimation with spatio-temporal criss-cross attention: N/A
  - KTPFormer: Kinematics and trajectory prior knowledge-enhanced transformer for 3D human pose estimation: N/A
  - Diffusion-based 3D human pose estimation with multi-hypothesis aggregation: N/A
  - DiffPose: Toward more reliable 3D pose estimation: N/A

### 3. Core Idea
- H2OT is a hierarchical plug-and-play pruning-and-recovering framework that reduces the number of pose tokens needed for efficient 3D human pose estimation while maintaining accuracy.

### 4. Method
- **Pipeline**: seq2frame and seq2seq pipelines for 3D human pose estimation.
- **Architecture / Loss / Training**: Utilizes a hierarchical structure to prune and recover pose tokens.
- **Complexity / Resources**: Achieves a 57.4% reduction in FLOPs while maintaining competitive performance.

### 5. Experiments
- **Datasets & Metrics**: Evaluated on Human3.6M and MPI-INF-3DHP datasets using metrics like MPJPE and FPS.
- **Baselines**: D3DP [66], DiffPose [67], DynamicViT, Existing VPT models, HoT w. MixSTE [21], MHFormer, MixSTE, MixSTE [15], MotionAGFormer, MotionBERT, MotionBERT [16], N/A, P-STMO, PoseFormer, Traditional pose estimation methods, VPose
- **Main Results**: H2OT shows competitive performance with significant reductions in computational costs compared to existing methods.
- **Ablations**: Ablation studies demonstrate the impact of varying the number of recovered tokens on performance.
- **Limitations / Stress Tests**: Some failure cases in challenging scenarios due to partial body visibility and rare poses.

### 6. Takeaways
- **Pros**: Improved efficiency in video pose estimation., Reduced computational costs for resource-constrained devices., Maintains high estimation accuracy with fewer tokens.
- **Cons**: Potential loss of detailed spatio-temporal information., Dependency on the effectiveness of token pruning and recovering modules.
- **Future Work**: Explore further optimizations in token pruning strategies., Investigate the application of H2OT in other domains., Enhance compatibility with more VPT frameworks.

</details>

### [On the Same Wavelength? Evaluating Pragmatic Reasoning in Language Models across Broad Concepts](http://arxiv.org/pdf/2509.06952v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Pragmatic language comprehension and production

### 2. Motivation & Gaps
- A limitation on the modeling side is that, although RSA is a very general computational framework, we have only explored relatively straightforward ways of combining it with LMs.

- **Related work challenges:**
  - Hu et al., 2023: Existing studies find that large LMs can achieve high accuracy but may not match human performance in pragmatic reasoning.
  - Jian and Narayanaswamy, 2024: Even frontier LMs may not match human performance in communication settings.
  - Hu et al. (2023): Utilizes multiple-choice questions rather than graded judgments.
  - Lipkin et al. (2023): Focuses on one domain and studies one LM (OpenAI Codex).
  - Tsvilodub et al. (2025): Focuses only on the comprehension side and on a few specific pragmatic phenomena.
  - RSA framework: Incorporating probabilistic inference into language models.
  - CoT prompting: Improving model performance over direct prompting.
  - Human-like performance evaluation: Measuring the similarity between model distributions and human judgments.
  - RSA framework: Limited effectiveness in reshaping concentrated and spiky listener distributions.
  - CoT prompting: Does not necessarily improve performance in language production.
  - Human evaluation: Self-preference bias in model responses.
  - Lake et al., 2017: Improving humanlike reasoning capabilities of LMs.
  - Wong et al., 2023: Defining the set of alternative utterances in RSA.
  - Puri et al., 2025: Specifying base-level literal listener and speaker models.
  - N/A: More explorations of defining and utilizing utterance costs could be interesting for future LM research.
  - Evaluating statistical language models as pragmatic reasoners: N/A
  - Improving interpersonal communication by simulating audiences with language models: N/A
  - Pragmatics in the era of large language models: A survey on datasets, evaluation, opportunities and challenges: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The integration of the classical RSA framework with LMs enhances pragmatic language production by addressing fundamental challenges of traditional RSA.

### 4. Method
- **Pipeline**: Integrating RSA with LMs to improve language production tasks.
- **Architecture / Loss / Training**: Models include Llama3, Gemma3, Qwen3, and DeepSeek-V3, with API-only models like Gemini 2.0 Flash, Claude 3.7 Sonnet, and GPT-4.1.
- **Complexity / Resources**: The study is limited by the size of the stimuli set and the resources required for human production and comprehension studies.

### 5. Experiments
- **Datasets & Metrics**: WavelengthEval dataset with human judgments to study conceptual knowledge in both humans and LMs.
- **Baselines**: Chain-of-Thought prompting, Claude 3.7 Sonnet, CoT prompting, DeepSeek V3, Direct generation, Direct prompting, GPT-4.1, Gemini 2.0 Flash, Human performance, LM-RSA, N/A, Zero-shot CoT prompting
- **Main Results**: Pearson correlations and RMSE values for various models.
- **Ablations**: N/A
- **Limitations / Stress Tests**: A limitation on the modeling side is that, although RSA is a very general computational framework, we have only explored relatively straightforward ways of combining it with LMs.

### 6. Takeaways
- **Pros**: Larger models perform well in terms of accuracy and human correlations on the comprehension task., RSA-augmented LMs significantly improve production task performance., The study provides insights into conceptual representation and language processing.
- **Cons**: Smaller LMs do not achieve strong performance on language comprehension., All LMs show divergence from human judgment distributions.
- **Future Work**: Further exploration of RSA's potential in improving LMs' pragmatic reasoning., Investigating the nature of conceptual representation in LMs and humans., Developing more comprehensive benchmarks for evaluating pragmatic reasoning.

</details>
