# Daily Paper Digest · 2025-09-11
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## neural rendering

### [SAFT: Shape and Appearance of Fabrics from Template via Differentiable Physical Simulations from Monocular Video](http://arxiv.org/pdf/2509.08828v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- 3D Reconstruction and Appearance Estimation

### 2. Motivation & Gaps
- The paper addresses the challenges in geometry reconstruction and appearance estimation of synthesized scenes, particularly focusing on the limitations of existing methods like PG-SfT.

- **Related work challenges:**
  - Shape-from-template (SfT) methods: Addressing depth ambiguity where multiple plausible deformations can result in identical RGB renderings.
  - Non-rigid structure from motion (NRSfM) algorithms: Reconstructing arbitrary deformed surfaces with limited data.
  - Learning-based approaches for SVBRDF estimation: Dependence on specific lighting conditions and RGBD data.
  - Gaussian Garments: Relies on multi-view data.
  - PhysAvatar: Relies on multi-view data.
  - Better Together: Incorporates shading information directly into geometry deformations.
  - Tanet al.: Restricts template alignment with contours in image space.
  - ϕ-SfT: Uses sophisticated physics simulation for cloth deformation.
  - Neural cloth simulation: Reduces runtime at the expense of reconstruction quality.
  - ϕ-SfT: Limited handling of depth ambiguity in monocular data.
  - PG-SfT: Inadequate regularization leading to unrealistic cloth deformations.
  - ϕ-SfT [27]: Produces errors in textures and fails to follow sharp folds.
  - PG-SfT [62]: Generates overly smooth reconstructions and has a slower runtime.
  - ϕ-SfT: High chamfer distance between ground truth and reconstructed geometry.
  - PG-SfT: Inability to reproduce specular highlights from shiny materials.
  - Neural ordinary differential equations: N/A
  - Yarn-level simulation of woven cloth: N/A
  - Efficient simulation of knitted cloth using persistent contacts: N/A
  - Neural parametric gaussians for monocular non-rigid object reconstruction: N/A
  - Drapenet: Garment generation and self-supervised draping: N/A
  - Single-image svbrdf capture with a rendering-aware deep network: N/A
  - Differentiable projective dynamics: N/A
  - Learning-based bending stiffness parameter estimation by a drape tester: N/A
  - Texture-generic deep shape-from-template: N/A
  - Deep inverse rendering for high-resolution svbrdf estimation from an arbitrary number of images: N/A
  - Modeling the dynamics of pde systems with physics-constrained deep auto-regressive networks: N/A
  - Hdm-net: Monocular non-rigid 3d reconstruction with learned deformation model: N/A
  - Fine-grained differentiable physics: a yarn-level model for fabrics: N/A
  - Hierarchical graphs for generalized modelling of clothing dynamics: N/A
  - Real-time geometry, albedo, and motion reconstruction using a single rgb-d camera: N/A
  - Progressive acquisition of svbrdf and shape in motion: N/A
  - Shape, light, and material decomposition from images using monte carlo rendering and denoising: N/A
  - Differentiable programming for physical simulation: N/A
  - Estimating cloth simulation parameters from a static drape using neural networks: N/A
  - Shape-from-Template with a Physics-Based Deformation Model: N/A
  - Neural deformation fields meet the kirchhoff-love thin shell theory: N/A
  - Unified shape and appearance reconstruction with joint camera parameter refinement: N/A
  - Reconstructing object shape and appearance textures by adaptive detail transfer: N/A
  - Deep svbrdf acquisition and modelling: A survey: N/A
  - Segment anything: N/A
  - Modular primitives for high-performance differentiable rendering: N/A
  - Modeling surface appearance from a single photograph using self-augmented convolutional neural networks: N/A
  - Differentiable cloth simulation with dry frictional contact: N/A
  - Learning to reconstruct shape and spatially-varying reflectance from a single image: N/A
  - Differentiable cloth simulation for inverse problems: N/A
  - Shape and material capture at home: N/A
  - Better together: Joint reasoning for non-rigid 3d reconstruction with specularities and shading: N/A
  - A high-performance python framework for gpu simulation and graphics: N/A
  - Physical simulation layer for accurate 3d modeling: N/A
  - Extracting Triangular 3D Models, Materials, and Lighting From Images: N/A
  - Adaptive anisotropic remeshing for cloth simulation: N/A
  - Local non-rigid structure-from-motion from diffeomorphic mappings: N/A
  - Pytorch: An imperative style, high-performance deep learning library: N/A
  - Learning mesh-based simulation with graph network: N/A
  - N/A: N/A
  - Adversarial single-image svbrdf estimation with hybrid training: Previous methods struggle with accurate physical simulations and rendering gradients.
  - ϕ-SfT: Uses irregular meshes with high computational costs.
  - PG-SfT: Requires regular meshes and lacks texture mapping, resulting in distorted textures.
  - PG-SfT: Produces overly smooth geometries that do not capture high-frequency details.
  - ϕ-SfT: Creates unrealistic kinks and does not accurately reconstruct deformations.
  - PG-SfT: Inability to reconstruct deformation accurately, leading to unrealistic appearance optimization.
  - ϕ-SfT: Struggles with high-frequency features and metallic materials causing specular highlights.

### 3. Core Idea
- The proposed method enhances geometry reconstruction to achieve sharper textures and better appearance estimation compared to existing methods.

### 4. Method
- **Pipeline**: The method involves reconstructing geometry from video sequences and estimating appearance parameters based on the reconstructed geometry.
- **Architecture / Loss / Training**: Utilizes regularization terms to enhance gradients for better reconstruction.
- **Complexity / Resources**: Employs PyTorch for automatic differentiation and nvdiffrast for fast rendering.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize synthesized scenes and evaluate reconstruction quality using point-to-surface distances.
- **Baselines**: Better Together, Gaussian Garments, N/A, PG-SfT, PG-SfT [62], PhysAvatar, Previous cloth simulation methods, Standard rendering techniques, State-of-the-art methods in 3D reconstruction, ϕ-SfT, ϕ-SfT [27]
- **Main Results**: The proposed method shows significant improvements in reconstruction quality, particularly in non-metallic materials, achieving lower point-to-surface distances compared to baselines.
- **Ablations**: Experiments demonstrate the impact of physical parameter optimization on reconstruction quality.
- **Limitations / Stress Tests**: The method struggles with metallic materials and limited data views, affecting the accuracy of appearance estimation.

### 6. Takeaways
- **Pros**: Significantly improved plausibility and quality of reconstructed geometry., Ability to estimate detailed appearance parameters from a single video., Reduction in reconstruction error compared to previous techniques.
- **Cons**: Dependence on a single monocular RGB video may limit applicability., Potential challenges in handling highly dynamic scenes.
- **Future Work**: Explore applications to other types of deformable objects., Investigate improvements in runtime efficiency., Develop methods to handle more complex lighting conditions.

</details>

### [Using machine learning to downscale coarse-resolution environmental variables for understanding the spatial frequency of convective storms](http://arxiv.org/pdf/2509.08802v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Evaluate the effectiveness of convection-permitting regional climate models in predicting future precipitation changes.

### 2. Motivation & Gaps
- The study aims to assess whether convection-permitting models provide better projections of precipitation changes compared to traditional models.

- **Related work challenges:**
  - Global climate models (GCMs): Inability to resolve convection and cloud processes at kilometer scales.
  - Convection-permitting models: Computationally expensive and impractical for large ensemble runs.
  - Schulte et al., 2024: Identifying key environmental factors useful for distinguishing convective storm modes.
  - Convolutional Neural Networks: Highly sensitive to input grid size and spatial structure.
  - Linear Regression: Limited in capturing complex nonlinear interactions.
  - N/A: N/A
  - Previous studies on convective processes: Limited understanding of how environmental variables influence sub-grid-scale convection across different regions.
  - Convolutional neural network (CNN) architectures: Inability to generalize across different geographic regions due to reliance on spatial structures.
  - Bao and Zhang 2013: The model's inability to capture mid-latitude mountain convective processes.
  - Gochis et al. 2005; Boos and Pascale 2021: Misrepresentation of the North American Monsoon features.
  - Kodama and Tamaoki 2002: The model's failure to account for distinct convective processes associated with orographic influences.
  - Doswell et al., 1996: Limited understanding of the impact of environmental variables on convective frequency.
  - Peters et al., 2022: Need for improved models that can generalize across different climate regimes.
  - N/A: Struggle to generalize to mid-latitude continental regions.
  - Prein et al. (2015): Challenges in regional convection-permitting climate modeling.
  - Liu et al. (2016): Continental-scale modeling limitations.
  - Rasmussen et al. (2017): Changes in convective populations and environments.

### 3. Core Idea
- Convection-permitting models may enhance the accuracy of precipitation projections by better simulating convective processes.

### 4. Method
- **Pipeline**: The study utilizes a series of convection-permitting simulations to analyze precipitation changes.
- **Architecture / Loss / Training**: Simple, pixel-based MLP architectures.
- **Complexity / Resources**: The models require significant computational resources due to their high resolution.

### 5. Experiments
- **Datasets & Metrics**: The study uses various datasets to evaluate precipitation metrics across different regions.
- **Baselines**: Convolutional neural networks, Full-domain model, LR model, Linear Regression, Linear regression models, N/A, Previous convection-permitting models, Regionally trained models, Traditional climate models, Traditional statistical methods
- **Main Results**: Convection-permitting models show improved projections of extreme precipitation events.
- **Ablations**: Interactions among features are critical, highlighting the inherently interacting nature of the environmental–convection relationship.
- **Limitations / Stress Tests**: The study acknowledges limitations in model resolution and computational demands.

### 6. Takeaways
- **Pros**: Machine learning provides a computationally efficient method for predicting convective storms., The model can generalize across different environmental conditions., It offers insights into convective processes that are critical for understanding extreme weather.
- **Cons**: The model's performance is sensitive to input feature selection., Exclusion of specific regions can lead to performance declines., It may not capture all complexities of convective processes.
- **Future Work**: Further research on optimizing input features for better model performance., Exploration of additional environmental variables that influence convection., Application of the model across diverse climate scenarios and model grids.

</details>

### [An End-to-End Deep Learning Framework for Arsenicosis Diagnosis Using Mobile-Captured Skin Images](http://arxiv.org/pdf/2509.08780v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Automated classification of skin lesions

### 2. Motivation & Gaps
- The study aims to develop a deep learning framework for the classification of arsenic-induced skin lesions and other dermatological conditions using mobile phone-captured images.

- **Related work challenges:**
  - Traditional diagnostic workflows for arsenicosis: Reliance on invasive, costly, and logistically demanding methods such as measuring arsenic concentrations in biological matrices.
  - Existing diagnostic methods: Require laboratory-grade instrumentation and trained personnel, which are rarely available in resource-constrained and rural regions.
  - Existing computer-aided diagnostic (CAD) systems: Limited applicability in rural contexts due to reliance on specialized equipment and trained personnel.
  - Deep learning models for skin disease classification: Scarcity of suitable datasets for arsenic-related skin lesions.
  - Traditional dermatological diagnostic methods: Labor-intensive and prone to error, especially in rural communities.
  - Hsu et al. study on arsenic exposure prediction: Did not account for visually similar non-arsenic skin conditions, raising the risk of misdiagnosis.
  - Mehedi et al. ArsenicNet model: Focused on binary classification and relied on small datasets, limiting clinical applicability.
  - Existing studies on skin lesion classification: Predominantly rely on controlled dermoscopic images, not representing real-world mobile photography.
  - Prior studies on binary classification of skin diseases: Inability to differentiate arsenic-induced lesions from other dermatological conditions with overlapping visual characteristics.
  - Existing multiclass models: Lack of models specifically tailored to arsenic-related skin lesion classification.
  - Explainable AI (XAI): Providing human-interpretable insights into model predictions.
  - N/A: N/A
  - N/A: N/A
  - Swin Transformer: Misclassification due to fine-grained visual similarity among classes.
  - LIME and Grad-CAM: Errors linked to image quality and capture conditions.
  - Previous studies on skin lesion classification: Limited dataset sizes and class imbalances affecting model generalization.
  - Generative Adversarial Networks (GANs) for data augmentation: Poor quality of generated images leading to instability in training.
  - Transfer learning from ImageNet: Pretrained weights may not optimally represent dermatological features.
  - Existing CNN architectures: Achieving stable convergence and competitive accuracy.
  - Transformer-based models: Need for improved model interpretability.
  - External validation studies: Generalization beyond curated datasets.
  - N/A: N/A

### 3. Core Idea
- The proposed framework utilizes deep learning techniques, particularly the Swin Transformer, to classify skin lesions while incorporating explainable AI techniques to enhance interpretability.

### 4. Method
- **Pipeline**: Data collection, model training, and evaluation using various architectures.
- **Architecture / Loss / Training**: Multiple state-of-the-art architectures including CNNs and Transformer-based models were benchmarked.
- **Complexity / Resources**: The study highlights the need for larger, more diverse datasets and integration with clinical metadata.

### 5. Experiments
- **Datasets & Metrics**: A newly curated dataset of 20 classes of mobile phone-captured skin images was used for benchmarking.
- **Baselines**: CNNs, ConvNeXt, EfficientNet-B0, EfficientNetB0, Inception, Inception-V3, InceptionV3, MobileNet-V2, MobileNetV2, N/A, Other DL models, ResNet-152, ResNet-50, ResNet50, Swin, Swin Transformer, Traditional CNNs, Transformer-based models, Transformers, VGG-16, VGG16, ViT, ViTs, Vision Transformer, Vision Transformers, Xception
- **Main Results**: Transformer-based models, especially the Swin Transformer, outperformed CNN variants in accuracy and MCC.
- **Ablations**: Incorporation of XAI techniques like LIME and Grad-CAM for model interpretability.
- **Limitations / Stress Tests**: Modest dataset size, class imbalance, variability in image quality, and lack of geographically diverse data.

### 6. Takeaways
- **Pros**: Non-invasive and accessible diagnostic solution for arsenicosis., High accuracy achieved with the Swin Transformer model., Integration of model interpretability enhances clinical transparency.
- **Cons**: Dependence on mobile-captured images may limit diagnostic accuracy in poor lighting conditions., Potential variability in image quality based on user skill., Limited to the specific conditions represented in the curated dataset.
- **Future Work**: Expand the dataset to include more diverse skin conditions., Enhance the model's robustness against varying image qualities., Investigate the integration of additional diagnostic features beyond image analysis.

</details>

## Gaussian Splatting

### [Approximate Algorithms for Verifying Differential Privacy with Gaussian Distributions](http://arxiv.org/pdf/2509.08804v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Verifying differential privacy

### 2. Motivation & Gaps
- The paper addresses the need for efficient algorithms to verify differential privacy, particularly for programs utilizing Gaussian distributions.

- **Related work challenges:**
  - Existing automated tools for verifying differential privacy: Lack of effective analysis for programs incorporating Gaussian noise.
  - Algorithms and proofs in differential privacy: Many have been found flawed, leading to a need for better verification tools.
  - Decidability of differential privacy verification: The problem is undecidable for programs that only toss fair coins.
  - [3]: Previous work allows sampling from Gaussian distributions but does not focus on the computability of probabilities in loop-free programs.
  - Sparse Vector Technique (SVT): Original SVT uses Laplace noise which may not provide optimal utility.
  - Gaussian Mechanisms in Differential Privacy: Need for mechanisms that ensure better utility while maintaining privacy guarantees.
  - Previous works on differential privacy verification: Limited applicability to programs with continuous distributions.
  - Previous methods for verifying differential privacy: Exponential checks required for all subsets of outputs
  - Existing algorithms for differential privacy verification: Difficulty in computing exact probabilities for program outputs
  - Existing differential privacy verification methods: Many methods lack soundness and completeness in their verification processes.
  - N/A: N/A
  - Previous works on differential privacy verification: Limited scalability and computational efficiency in checking privacy guarantees.
  - Algorithms for differential privacy: Inability to handle complex integral expressions efficiently.
  - DiPC: Limited to verifying approximate differential privacy.
  - DiPC: DiPC does not support Gaussian distributions and can only check pure differential privacy for all values of 𝜖 > 0.
  - Automated verification methods: Most methods do not verify differential privacy for programs that sample from Gaussians.
  - Existing automated techniques: They often do not allow sampling from Gaussians and verify only pure differential privacy.
  - Differentially private Bayesian programming: Proving differential privacy in complex programs
  - DP-Finder: Finding Differential Privacy Violations: Identifying violations in large-scale systems
  - Privacy at Scale: Local Differential Privacy in Practice: Implementing privacy mechanisms effectively
  - Calibrating noise to sensitivity in private data analysis: N/A
  - On the complexity of differentially private data release: Efficient algorithms and hardness results: N/A
  - The Algorithmic Foundations of Differential Privacy: N/A
  - DiPC: Performance and efficiency in verifying differential privacy.
  - DiPApprox: Achieving differential privacy with minimal computational overhead.
  - CheckDP: Only verifies for fixed values of epsilon and does not support Gaussian distributions.

### 3. Core Idea
- The proposed algorithms pertain to verifying differential privacy by utilizing approximate methods that handle Gaussian distributions effectively.

### 4. Method
- **Pipeline**: The algorithms process input queries, apply noise, and determine the maximum or minimum values based on differential privacy checks.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The algorithms are designed to be efficient, with specific attention to time complexity and resource usage during execution.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize various datasets to evaluate the performance of the proposed algorithms against existing benchmarks.
- **Baselines**: CheckDP, DP-Finder, DiPApprox, DiPC, DiPCtool, Differentially private Bayesian programming, Existing differential privacy verification algorithms, Existing differential privacy verification methods, Laplace Mechanism, Laplace distribution verification tools, Local Differential Privacy, N/A, Noisy Max, Original Sparse Vector Technique, Sparse Vector Technique, Standard Gaussian mechanisms, k-Min-Max
- **Main Results**: The proposed algorithms demonstrate significant improvements in verification time compared to existing tools.
- **Ablations**: Ablation studies show the impact of various optimization techniques on the performance of the algorithms.
- **Limitations / Stress Tests**: The algorithms are limited by their performance under extreme input sizes and specific configurations of epsilon and delta.

### 6. Takeaways
- **Pros**: Provides a novel approach to verifying differential privacy with Gaussian distributions., Enhances scalability of verification algorithms., Validates effectiveness on established privacy-preserving algorithms.
- **Cons**: Limited to loop-free programs with finite domain inputs and outputs., Does not generalize to all types of distributions., Verification remains almost decidable, with exceptions.
- **Future Work**: Explore generalization to other distribution types., Improve the decidability of verification for broader classes of programs., Investigate integration with existing verification tools.

</details>

### [Parity Violation in Galaxy Shapes: Primordial Non-Gaussianity](http://arxiv.org/pdf/2509.08787v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- To explore how intrinsic alignments (IA) of galaxies can be used to probe parity-violating primordial non-Gaussianity.

### 2. Motivation & Gaps
- The study aims to establish intrinsic alignments as a novel and competitive probe of parity-violating physics in the early universe.

- **Related work challenges:**
  - Recent studies on parity violation in CMB temperature and E-mode polarization trispectra.: Higher-order statistics beyond two-point functions are needed to probe a violation of parity symmetry.
  - Studies on parity-odd components of the galaxy density four-point correlation function.: Constraints on parity violation using the parity-odd galaxy four-point function are still being explored.
  - Theoretical studies on using intrinsic galaxy shapes to constrain cosmological models.: Intrinsic alignment can contaminate weak lensing measurements, complicating the analysis.
  - Previous studies on tensor fossil effects: Limited focus on chiral gravitational waves and their effects on galaxy shapes.
  - Existing methods for probing galaxy shapes: Standard probes do not leverage three-dimensional information from spectroscopic surveys.
  - Ref. [55]: The simplicity and ease of implementation of the squeezed-type trispectrum model.
  - Ref. [2]: The introduction of the collapsed-type trispectrum and its relation to parity-odd components.
  - Recent analyses of the 4PCF of galaxy clustering: Placing constraints on amplitude parameters related to the trispectra.
  - N/A: N/A
  - Previous studies on galaxy shape statistics: Lack of consideration for nonlocal effects and parity-violating conditions.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Previous studies on trispectrum behavior: Difficulty in placing strong constraints on amplitude parameters due to kernel-trispectrum mismatch.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Ref. [88]: Measurement of the cross-power spectrum between the galaxy density field and the E-mode shape field.
  - Ref. [40]: Assumption of redshift dependence for bias parameters.
  - Ref. [97]: Analysis of the BGS sample to determine the fraction of red galaxies.
  - N/A: N/A
  - Ref. [44]: Studied parity-violating tensor fossil effects on intrinsic alignments.
  - Ref. [40]: Provided a fiducial redshift-independent value for the fraction of red galaxies.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Ref. [86]: Omission of parity-odd part in power spectra
  - Ref. [101]: Need for angular power spectra in Fisher analysis
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- Developed a flexible and efficient method to implement collapsed-type parity-odd trispectra into N-body initial conditions.

### 4. Method
- **Pipeline**: Combining effective field theory modeling, N-body simulations, and forecast analyses.
- **Architecture / Loss / Training**: Utilize an effective field theory (EFT) framework to derive analytic expressions and validate with simulations.
- **Complexity / Resources**: N-body simulations carried out on the freya and orion clusters.

### 5. Experiments
- **Datasets & Metrics**: Simulations confirmed expected scale-dependent enhancements and enabled precise determination of PNG-induced bias parameters.
- **Baselines**: BOSS, BOSS GC, CMB trispectrum analyses, Current bounds from galaxy four-point correlation analyses, Current limits from the CMB and galaxy clustering, Current limits on the amplitude of parity-violating PNG from galaxy four-point correlation and CMB trispectrum analyses., DESI, DESI IA (fid), DESI IA (opt), LSST, LSST IA (fid), LSST IA (opt), N/A, Planck, Previous models of galaxy shape statistics, Previous studies on trispectrum behavior
- **Main Results**: Fisher forecasts indicate that IA can provide constraints comparable to or potentially tighter than those from existing CMB and galaxy four-point correlation analyses.
- **Ablations**: Investigate the impact of different parity-odd trispectrum models on galaxy shape statistics.
- **Limitations / Stress Tests**: The covariance is dominated by shape noise, and observational systematics at larger scales remain a challenge.

### 6. Takeaways
- **Pros**: Galaxy shapes provide complementary information to other probes of primordial non-Gaussianity., The method developed allows for enhanced initial conditions for simulations., The study opens new avenues for exploring parity violation in cosmology.
- **Cons**: Intrinsic alignment can complicate weak lensing measurements., The dependence on undetermined EFT bias parameters introduces uncertainty., Current observational constraints may still be limited.
- **Future Work**: Further exploration of the implications of parity-violating signals in galaxy shapes., Development of more refined simulations to improve bias parameter estimation., Investigation of additional cosmological probes that may reveal parity violation.

</details>

### [ADHDeepNet From Raw EEG to Diagnosis: Improving ADHD Diagnosis through Temporal-Spatial Processing, Adaptive Attention Mechanisms, and Explainability in Raw EEG Signals](http://arxiv.org/pdf/2509.08779v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- ADHD detection using EEG signals

### 2. Motivation & Gaps
- The study focuses on the discrimination of linear and nonlinear effective connectivity patterns of EEG signals in children with ADHD and typically developing children.

- **Related work challenges:**
  - DeepFMRI for ADHD detection: Achieved only 73.1% accuracy on the ADHD-200 dataset.
  - K-Nearest Neighbor classifier on EEG data: Limited to specific conditions and did not generalize well.
  - LASSO with SVM classifier: Achieved high accuracy but may not be robust across different datasets.
  - Previous studies on ADHD detection using EEG signals: Need for manual feature extraction before classification.
  - CNN applications in ADHD detection: Transforming spatiotemporal properties of EEG signals into image-like formats.
  - LSTM and other classifiers for EEG signals: Achieving high accuracy while dealing with varying EEG data quality.
  - EEGNet: Limited preprocessing and feature extraction, which can lead to overfitting and reduced model generalizability.
  - MultiHeart: Robustness to missing or noisy inputs
  - Previous studies on EEG signal classification: Limited data availability and variability in EEG signals.
  - Data augmentation techniques in deep learning: Need for effective augmentation methods to enhance model performance.
  - EEGNet: Lower performance metrics compared to ADHDeepNet in ADHD detection.
  - Various studies on EEG-based ADHD detection: Reliance on manual feature extraction and within-subject validation.
  - Investigating the discrimination of linear and nonlinear effective connectivity patterns of EEG signals in children with ADHD.: Existing methods often require preprocessing and manual feature extraction.
  - A big-data-analytics framework for supporting classification of ADHD and healthy children via principal component analysis of EEG sleep spindles power spectra.: Previous frameworks may not leverage raw EEG data effectively.
  - A big-data-analytics framework for supporting classification of ADHD and healthy children via principal component analysis of EEG sleep spindles power spectra.: N/A
  - Detection of ADHD cases using CNN and classical classifiers of raw EEG.: N/A
  - EEG classification of ADHD and normal children using non-linear features and neural network.: N/A
  - N/A: N/A

### 3. Core Idea
- Utilizing EEG signals to classify and detect ADHD in children through various machine learning techniques.

### 4. Method
- **Pipeline**: The model processes raw EEG data segmented into four-second intervals, computes frequency responses, and utilizes t-SNE for visualization.
- **Architecture / Loss / Training**: The model is inspired by Inception/Xception architectures and incorporates attention modules from the SE network, employing data augmentation techniques during training.
- **Complexity / Resources**: The model's complexity is managed through the use of depth-wise convolutional layers and data augmentation strategies.

### 5. Experiments
- **Datasets & Metrics**: The model was evaluated on EEG datasets focusing on ADHD and healthy controls, using metrics such as accuracy and discriminatory power.
- **Baselines**: DeepFMRI, EEGNet, K-Nearest Neighbor, LASSO with SVM, Long Short-Term Memory (LSTM), Multilayer Perceptron (MLP), N/A, Other deep learning models requiring preprocessing, SVM classifier, Standard deep learning models without data augmentation, Traditional machine learning methods, Various existing EEG-based ADHD detection methods
- **Main Results**: ADHDeepNet demonstrated superior performance in distinguishing between ADHD and healthy control subjects, particularly in later layers.
- **Ablations**: Ablation studies indicated that the depth-wise convolutional layers significantly contributed to the model's performance.
- **Limitations / Stress Tests**: The model's generalizability across diverse populations and its reliance on specific EEG features were noted as limitations.

### 6. Takeaways
- **Pros**: High accuracy and sensitivity in ADHD diagnosis., Utilizes EEG signals which can be captured in real-world settings., Incorporates explainability to enhance trust in model decisions.
- **Cons**: Requires a substantial amount of data for training., Potential overfitting due to high model complexity., Dependence on the quality of EEG signal acquisition.
- **Future Work**: Expand the dataset to include more diverse populations., Investigate the integration of other neuroimaging modalities., Enhance model robustness through additional validation techniques.

</details>

## avatar

### [PanoLAM: Large Avatar Model for Gaussian Full-Head Synthesis from One-shot Unposed Image](http://arxiv.org/pdf/2509.07552v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- 3D reconstruction from single-view images

### 2. Motivation & Gaps
- The paper addresses the limitations of existing methods in reconstructing 3D representations from single-view images, particularly focusing on fidelity and generalization to real-world images.

- **Related work challenges:**
  - 3D Generative Adversarial Networks (3D-GANs): Require time-consuming GAN inversion and test-time optimization.
  - EG3D: Requires accurate camera pose for joint optimization.
  - Diffusion models: Multi-step diffusion process requires minutes of optimization.
  - EG3D: Requires time-consuming GAN inversion and test-time optimization for image-conditioned generation.
  - Diffusion models: Multi-step diffusion process is slow and computation-consuming during inference.
  - NeRF-based approaches: Slow rendering speed and low-resolution images lead to view inconsistencies.
  - FLAME model: Inability to model large deformations such as long hairs, glasses, and caps.
  - Previous methods: Require a network trained to upsample sparse points.
  - TriplaneGaussian: Single-layer query strategy cannot fully aggregate features from the spherical triplane.
  - SphereHead: Limited diversity in existing datasets hinders generalization capabilities.
  - Existing 3D head reconstruction methods: Dependence on accurate camera poses and complex optimization processes.
  - Gaussian shell maps for efficient 3D human generation: Inefficient feature aggregation leading to poor reconstruction quality.
  - Panohead: Geometry-aware 3D full-head synthesis in 360°: Limited ability to synthesize detailed 3D features from single queries.
  - Rignerf: Fully controllable neural 3D portraits: Challenges in accurately modeling complex 3D structures.
  - N/A: N/A
  - Towards unsupervised learning of generative models for 3d controllable image synthesis: Lack of effective methods for unsupervised learning in 3D synthesis.
  - Deep learning face attributes in the wild: Challenges in generalizing face attributes across diverse conditions.
  - 3D gaussian blendshapes for head avatar animation: Difficulty in achieving realistic head animations.
  - Next3d: Generative neural texture rasterization for 3d-aware head avatars: Limited fidelity in head avatar generation.
  - RODIN: A generative model for sculpting 3d digital avatars using diffusion: Challenges in achieving real-time performance.
  - Gaussian head avatar: Ultra high-fidelity head avatar via dynamic gaussians: Complexity in modeling dynamic facial expressions.
  - EG3D: Limited to rendering near-frontal images.
  - SphereHead: Biases in the dataset leading to poor reconstruction results for certain demographics.

### 3. Core Idea
- The proposed framework combines triplane representation with Gaussian splatting to enhance the quality and generalizability of 3D reconstructions from single-view images.

### 4. Method
- **Pipeline**: The method involves generating a large-scale dataset from trained 3D GANs, followed by training a network to reconstruct 3D representations.
- **Architecture / Loss / Training**: The architecture utilizes a triplane representation and Gaussian splatting, with a focus on minimizing reconstruction loss.
- **Complexity / Resources**: The method requires significant computational resources for training on large-scale datasets.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize a large-scale synthesized dataset and real-world images from the VFHQ dataset, measuring fidelity and artifact presence.
- **Baselines**: 32 points aggregation, 3D-GANs, Default configuration of existing 3D head reconstruction methods, Diffusion models, EG3D, Existing 3D avatar generation methods, FLAME model, Gaussian distribution weights, LGM, LGMHunyuan3D, N/A, NeRF-based approaches, PH-PTI, PanoHead-PTI, Previous state-of-the-art methods in head avatar generation., SH-PTI, Single feature sampling, SphereHead, SphereHead-PTI, Traditional animation techniques, TriplaneGaussian
- **Main Results**: The proposed framework achieves higher fidelity results with fewer artifacts compared to previous methods.
- **Ablations**: Ablation studies demonstrate the impact of different components of the framework on reconstruction quality.
- **Limitations / Stress Tests**: The framework shows limitations in reconstructing Asian faces and cartoon heads due to biases in the training datasets.

### 6. Takeaways
- **Pros**: Fast reconstruction and rendering of 3D avatars., High-fidelity Gaussian head reconstruction., Utilizes a large-scale synthetic dataset for training.
- **Cons**: Dependence on synthetic data may limit real-world applicability.
- **Future Work**: Explore real-world dataset integration for improved performance., Investigate further optimizations for rendering efficiency., Expand applications in AR/VR and gaming.

</details>

### [Reconstruction and Reenactment Separated Method for Realistic Gaussian Head](http://arxiv.org/pdf/2509.05582v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Mapping audio sequences to motion sequences for lip synchronization

### 2. Motivation & Gaps
- The paper addresses the challenge of achieving accurate lip synchronization in 3D models driven by audio input.

- **Related work challenges:**
  - Goodfellow and others. 2014; Isola and others. 2017; Karras and others. 2019, 2020; Guo and others. 2024: 2D-based approaches lack explicit 3D structural priors, leading to complex model structures and higher latency.
  - Mildenhall and others. 2020; Kerbl and others. 2023: Cutting-edge 3D synthesis technologies rely on precise estimation of 3D pose, introducing errors that cause texture inaccuracies.
  - 2D end-to-end image synthesis approaches: High latency and computational resource demands, leading to unrealistic distortions in identity features.
  - 3D morphable models (3DMM): Insufficient concrete 3D structural constraints for free-viewpoint rendering.
  - NeRF-based methods: Require large amounts of training data, raising privacy concerns and limiting generalization.
  - Deng and others. 2024b: Previous methods did not leverage the advantages of larger scale datasets for feature extraction.
  - Chu and others. 2024a: Existing methods struggle with high-frequency texture artifacts and camera pose errors.
  - He and others. 2025: Prior approaches lack efficient synthesis and rendering capabilities.
  - Live Portrait (Guo and others. 2024): Limited texture detail reconstruction.
  - GFPGAN (Wang and others. 2021b): Inconsistent identity preservation across frames.
  - LAM (He and others. 2025): Inefficient inference speed.
  - Wang and others. 2023: Existing methods lack fine-grained control over facial features during synthesis.
  - Kaplan and others. 2020: Scaling laws indicate potential for performance enhancement, but current methods do not fully leverage this.
  - Wav2Lip: Achieving high lip accuracy scores using sync score as a supervisory loss.
  - HunyuanVideoAvatar: Utilizing large-scale parameters and data for improved performance.
  - MuseTalk: Maintaining competitive results in lip synchronization tasks.
  - N/A: N/A

### 3. Core Idea
- The technique synthesizes high-fidelity, real-time talking head video using a single portrait image, capturing intricate facial expressions and subtle nuances in movement.

### 4. Method
- **Pipeline**: The Gaussian Generator produces static and dynamic Gaussians for controllable 3D Gaussian generation.
- **Architecture / Loss / Training**: The model employs a mean square error (MSE) loss during training to align predictions with ground-truth mouth features.
- **Complexity / Resources**: The model was trained on a dataset of 1,000 professional single-speaker lecture videos.

### 5. Experiments
- **Datasets & Metrics**: The method is evaluated on the HDTF and VFHQ datasets.
- **Baselines**: 2D end-to-end image synthesis, 2D end-to-end models, 3D morphable models, 3DGS, FLAME, GAGAvatar, GAGavatar, GPAvatar, HunyuanVideoAvatar, LAM, LivePortrait, MuseTalk, N/A, NeRF, NeRF-based methods, P4D, P4D-v2, PDFGC, RAR, Real3D, Real3DPortrait, StyleHEAT, StyleHeat, Wav2Lip
- **Main Results**: The generated videos exhibit lifelike clarity and realism.
- **Ablations**: Ablation studies showed that increasing the scale of the pre-trained backbone improves performance.
- **Limitations / Stress Tests**: The method's performance is contingent on the quality of the pre-trained models used.

### 6. Takeaways
- **Pros**: Decoupled architecture enhances reconstruction accuracy and reenactment speed., High frame-rate rendering at 90 FPS., Effective control over facial features and expressions.
- **Cons**: Dependence on the quality of the input portrait image., Potential for errors in 3D pose estimation., Complexity in training the texture restoration module.
- **Future Work**: Explore further improvements in 3D pose estimation accuracy., Investigate additional applications in real-time environments., Enhance the model's ability to handle diverse facial expressions.

</details>

### [Evaluating Idle Animation Believability: a User Perspective](http://arxiv.org/pdf/2509.05023v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Evaluating Idle Animation Believability: a User Perspective

### 2. Motivation & Gaps
- The study investigates the perception of idle animations, comparing genuine and acted animations to determine if they are perceived differently.

- **Related work challenges:**
  - EmotionGesture: Generating 3D gestures from audio while maintaining realism.
  - TALKShow: Generating body, hand, and face animations over a 3D mesh.
  - DiffGesture: Effectively capturing cross-modal audio-to-gesture associations.
  - Egges et al. (2002): Created an idle motion engine based on Principal Component Analysis, which generates motion by combining small posture variations and change of balance.
  - Koco´n (N/A): Developed an idle motion synthesiser on a 3D human head model, which generates idle movements but lacks comprehensive datasets.
  - Cuijpers et al. (N/A): Analyzed idle and meaningful motions in robots, emphasizing the importance of idle animation in social robotics.
  - Previous studies on motion capture and animation: Lack of understanding of how genuine and acted motions are perceived by humans.
  - Previous studies on animation perception: Lack of understanding on how different animation creation methods influence user perception.
  - Previous studies on animation believability: Lack of clear metrics for comparing idle animations.
  - IdlePose: A Dataset of Spontaneous Idle Motions: Understanding the perceptual differences between various types of idle animations.
  - Personalised real-time idle motion synthesis: Creating realistic idle animations that are indistinguishable from genuine ones.
  - N/A: N/A

### 3. Core Idea
- Acted idle animations can be perceived as real, suggesting they can be used to create idle datasets, while handcrafted animations are not perceived the same as recorded animations.

### 4. Method
- **Pipeline**: User study comparing genuine and acted idle animations.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Used a 3D model, lighting, camera view, and clip duration consistent across tests.

### 5. Experiments
- **Datasets & Metrics**: User study 1 and User study 2 demographics
- **Baselines**: Acted animations, Existing animation datasets, Handcrafted animations from Mixamo, Handmade animations, Handmade idle animations, Mixamo, N/A, Previous motion capture techniques, Real animations, Recorded animations, Recorded idle animations
- **Main Results**: No significant difference in perception between genuine and acted idle animations; significant difference between handcrafted and recorded animations.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The analysis of average accelerations is complex and does not yield straightforward conclusions.

### 6. Takeaways
- **Pros**: Recording idle animations can be simplified., Both acted and genuine animations are perceived as real., The study contributes to the creation of idle animation datasets.
- **Cons**: Recording genuine movements is ethically complex., Use of motion capture suits can affect genuineness., Limited availability of high-quality idle animation datasets.
- **Future Work**: Further research on capturing genuine idle movements., Development of more comprehensive idle animation datasets., Exploration of user perception in different contexts.

</details>

## video understanding

### [RewardDance: Reward Scaling in Visual Generation](http://arxiv.org/pdf/2509.08826v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Visual Reward Modeling for Diffusion-based Generation

### 2. Motivation & Gaps
- Existing methods for visual Reward Models (RMs) are constrained by architectural limitations or paradigm mismatches that preclude effective reward scaling.

- **Related work challenges:**
  - CLIP-based RMs: Suffer from architectural and input modality constraints.
  - Bradley-Terry losses: Fundamentally misaligned with the next-token prediction mechanism of Vision-Language Models (VLMs).
  - RLHF optimization process: Plagued by Reward Hacking issues.
  - ImageReward: Limited scalability due to dual-encoder architecture.
  - WorldPM: Inadequate exploration of scaling properties in reward models.
  - DDPO: Challenges in likelihood computation for optimizing diffusion outputs.
  - CLIP-based RM Architecture: Limited scalability and context utilization.
  - VLM-based RM Architecture: Ineffective reward feedback learning.
  - Existing state-of-the-art models: Limited performance improvements despite scaling reward models.
  - Reinforcement Learning approaches: Higher accuracy in reward models does not guarantee better RL performance.
  - Benchmark datasets: Need for better evaluation benchmarks that assess generalization capabilities.
  - SD3: Limited performance in complex generation tasks.
  - Imagen 3: Inability to achieve state-of-the-art results in diverse categories.
  - Midjourney V6.1: Struggles with semantic understanding and generative precision.
  - N/A: N/A
  - Vidu: a highly consistent, dynamic and skilled text-to-video generator with diffusion models.: Limited scalability in reward modeling.
  - Training diffusion models with reinforcement learning.: Inefficiencies in reward signal quality.
  - Improving image generation with better captions.: Inadequate integration of multimodal information.
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- Introduce RewardDance, a scalable RM framework that reframes reward prediction as a token generation task, enhancing model size and context richness.

### 4. Method
- **Pipeline**: The framework converts reward scores into a Vision-Language Model’s predicted probability for a 'yes' token.
- **Architecture / Loss / Training**: Utilizes an autoregressive mechanism for reward prediction.
- **Complexity / Resources**: Scales from 1B to 26B parameters with task-aware instructions and Chain-of-Thought reasoning.

### 5. Experiments
- **Datasets & Metrics**: Comprehensive experiments across text-to-image, text-to-video, and image-to-video tasks.
- **Baselines**: 2B reward model, 8B reward model, CLIP-based RM, CLIP-based models, DALL-E2, FLUX, FLUX.1-dev, LlamaGen, Midjourney V6.1, N/A, Previous generative reward models, SD3, Seedance, Seedream, VLM-based RM, VLM-based models, Wan2.1
- **Main Results**: The 8B reward model shows improved visual quality and temporal consistency compared to the 2B reward model.
- **Ablations**: Scaling along model size and context richness consistently improves reward signal quality.
- **Limitations / Stress Tests**: Architectural limitations in existing models hinder effective reward scaling.

### 6. Takeaways
- **Pros**: Scalable reward modeling framework., High reward variance during RL fine-tuning., Effective integration of task-specific instructions and examples.
- **Cons**: High computational resource requirements for larger models., Potential for overfitting with increased model complexity., Challenges in integrating diverse context information effectively.
- **Future Work**: Further exploration of generative paradigms in reward modeling., Investigation of additional scaling strategies., Development of clearer guidelines for designing superior RMs.

</details>

### [Building High-Quality Datasets for Portuguese LLMs: From Common Crawl Snapshots to Industrial-Grade Corpora](http://arxiv.org/pdf/2509.08824v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>📄 Paper Summary </summary>

### 1. Task / Problem
- Generative AI for Portuguese

### 2. Motivation & Gaps
- The paper addresses the need for improved generative AI models tailored for the Portuguese language, highlighting existing limitations in current models.

- **Related work challenges:**
  - mC4: Limited per-language representation and inconsistent data quality across languages.
  - BLOOM: Limited per-language representation and inconsistent data quality across languages.
  - MADLAD: Limited per-language representation and inconsistent data quality across languages.
  - CulturaX: Limited per-language representation and inconsistent data quality across languages.
  - CulturaX: Merging documents from multiple datasets while ensuring high data quality.
  - MADLAD-400: Formulating heuristics for document selection across various languages.
  - FineWeb: Creating high-quality datasets from Common Crawl while maintaining educational value.
  - WorldBench Moayeriet al. [2024]: Higher error rates in LLMs for countries with lower economic status.
  - Timely Events Benchmark (TiEBe) [Almeidaet al., 2025]: High disparity in LLM performance for factual recall of events from different regions.
  - Longpreet al. [2024]: Underrepresentation of South American-originated data in pretraining corpora.
  - MassiveWeb [Rae et al., 2021]: Rules remove approximately 20% of documents.
  - C4 [Raffel et al., 2020; Xue, 2020]: More aggressive rules resulting in a removal of around 43% of documents.
  - FineWeb [Penedo et al., 2024a]: Classifier trained on English data performs poorly on Portuguese.
  - Barbaresi, 2021: Removing noisy or irrelevant content from HTML pages.
  - Lee et al., 2021: Mitigating the negative effects of excessive duplicate content in training data.
  - Rae et al., 2021: Ensuring that filtering rules do not remove useful documents.
  - Almeida et al. 2025: Limited proportion of high education or STEM score documents in the dataset.
  - Almeida et al. 2025: Comparison of performance of different training regimens
  - Curió-1.1B and TinyLlama 2T: Different training paths leading to varied performance on Portuguese tasks
  - KenLM: Faster and Smaller Language Model Queries: Efficiency in querying language models.
  - Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets: Ensuring quality in multilingual datasets.
  - Datasets for Large Language Models: A Comprehensive Survey: Lack of comprehensive datasets for training large language models.
  - BERTimbau: Pretrained BERT Models for Brazilian Portuguese: Limited performance on specific Portuguese language tasks.
  - FaQuAD: Reading Comprehension Dataset in the Domain of Brazilian Higher Education: Lack of comprehensive datasets for training effective models.
  - Winogrande: An Adversarial Winograd Schema Challenge at Scale: Challenges in understanding and generating contextually relevant responses.
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The core idea is to develop an open decoder model specifically designed for generative tasks in Portuguese, leveraging advancements in neural architectures.

### 4. Method
- **Pipeline**: The method involves a multi-stage pipeline that includes data collection, model training, and evaluation on various Portuguese language tasks.
- **Architecture / Loss / Training**: Utilizes transformer-based architecture with a focus on minimizing loss through adaptive learning techniques.
- **Complexity / Resources**: The model is designed to be resource-efficient, requiring moderate computational resources for training and inference.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize datasets such as mC4, ClueWeb, and ClassiCC-PT, with metrics including accuracy and F1 score.
- **Baselines**: BERTimbau, ClassiCC-PT dataset, ClassiCC-PT-Edu, ClueWeb dataset, ClueWeb22-A [Overwijket al., 2022], Curió 1.1B, Curió-1.1B, Existing English datasets, Existing language modeling datasets, FineWeb-Edu, GPT-4o, Gigaverbo [Corrêaet al., 2024], Industry-grade corpora, N/A, Smaller multilingual datasets, TinyLlama, TinyLlama 1T, TinyLlama 2T, TinyLlama model trained on 1 trillion tokens in English, Tucano 1.1B, mC4 [Xue, 2020]
- **Main Results**: The model demonstrates significant improvements in generative tasks compared to baseline models, particularly in educational and STEM categories.
- **Ablations**: Ablation studies indicate that specific architectural choices contribute to enhanced performance.
- **Limitations / Stress Tests**: Tests reveal that while the model performs well, it still struggles with certain complex language constructs.

### 6. Takeaways
- **Pros**: High-quality, language-specific data leads to better model performance., Continual pretraining in the target language yields substantial performance gains., Developing language-specific classifiers enhances data quality.
- **Cons**: Limited focus on languages other than English., High computational costs associated with training LLMs., Challenges in ensuring consistent data quality across languages.
- **Future Work**: Replicate findings and methods for other underexplored languages., Further investigate the impact of language-specific classifiers., Explore cost-efficient methods for continual pretraining.

</details>
