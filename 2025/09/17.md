# Daily Paper Digest Â· 2025-09-17
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## neural rendering

### [How Theory-Informed Priors Affect DESI Evidence for Evolving Dark Energy](http://arxiv.org/pdf/2509.13318v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Assessing the impact of prior choices on evidence for evolving dark energy

### 2. Motivation & Gaps
- The study investigates how prior choices affect cosmological parameter inference, particularly regarding evolving dark energy (DE) evidence from DESI BAO results.

- **Related work challenges:**
  - Various studies reexamining evidence for time-varying dark energy: Inconsistencies in statistical significance of deviations from the standard Î›CDM model.
  - Analysis bypassing linear equation of state parameterization: Yielded weaker evidence for deviations from Î›CDM compared to CPL-based analyses.
  - Bayesian inference in cosmology: Disregarding theoretical constraints and physical plausibility can skew interpretations.
  - N/A: N/A
  - Current BAO measurements: Achieving percent-level precision while accounting for degeneracies in parameter space.
  - Existing observational analyses: Incorporating theory-informed priors without excluding significant regions of parameter space.
  - DESI analyses: Uniform priors on (w0, wa) are treated as 'uninformative' but are actually highly informative, skewing parameter inferences.
  - N/A: The choice of uniform priors is ill-suited for the parametrization of evolving dark energy.
  - DESI DR2 Results II: Measurements of Baryon Acoustic Oscillations and Cosmological Constraints: The apparent preference for evolving DE is influenced by the choice of priors, which can introduce bias.
  - Extended Dark Energy analysis using DESI DR2 BAO measurements: Uniform priors may mischaracterize the significance of evolving DE, especially in weak detection scenarios.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- We construct a theory-informed prior on the dark energy equation-of-state parameters (w0, wa) using a conditional normalizing flow (NF) trained on outputs from a theoretical model.

### 4. Method
- **Pipeline**: The NF models the conditional density Pth(w0, wa | Ï‰c, Ï‰b, H0), providing a smooth, non-Gaussian, and highly flexible representation of the theory predictions.
- **Architecture / Loss / Training**: The NF is implemented with the nflows library. The base distribution is a conditional diagonal Gaussian whose parameters are predicted by a fully connected residual network. The transformation consists of eight autoregressive coupling layers with various transforms and a reverse permutation applied between layers.
- **Complexity / Resources**: Training is performed in batches of 128 samples for up to 5000 epochs on a NVIDIA A100 GPU, with early stopping after 100 epochs if there is no improvement in the validation loss.

### 5. Experiments
- **Datasets & Metrics**: The study uses DESI DR2 BAO and Planck data to analyze the evidence for evolving DE.
- **Baselines**: Exponential potential prior, Exponential potential priors, Flat priors on quintessence parameters, Hilltop potential prior, Hilltop potential priors, N/A, Previous analyses using alternative approaches, Standard uniform priors on CPL parameters, Theory-informed priors, Uniform prior, Uniform priors, Uniform priors from DESI analyses, Î›CDM
- **Main Results**: The evidence for evolving DE is reduced from approximately 3.1Ïƒ to 1.8Ïƒ and 1.3Ïƒ under exponential and hilltop potential priors, respectively.
- **Ablations**: Analysis of combinations including Type Ia supernova data showed similar shifts toward the Î›CDM limit.
- **Limitations / Stress Tests**: The analysis highlights the potential for residual systematics in low-redshift supernova samples affecting results.

### 6. Takeaways
- **Pros**: Theory-informed priors lead to more robust cosmological inferences., Reduced tension with Î›CDM enhances the credibility of results., Scalable approach for testing diverse theoretical models.
- **Cons**: Dependence on the choice of prior can still introduce biases., Complexity in constructing appropriate theory-informed priors., Requires additional computational resources.
- **Future Work**: Further exploration of alternative parameterizations for dark energy., Investigation of other datasets to validate findings., Development of more sophisticated prior selection methods.

</details>

### [High-Dimensional Bayesian Model Comparison in Cosmology with GPU-accelerated Nested Sampling and Neural Emulators](http://arxiv.org/pdf/2509.13307v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Bayesian inference in cosmology

### 2. Motivation & Gaps
- This work focuses on enhancing the efficiency of nested sampling algorithms for cosmological inference by leveraging GPU capabilities and gradient information.

- **Related work challenges:**
  - Traditional CPU-based nested sampling implementations: Scalability limitations in high-dimensional settings.
  - Advanced MCMC techniques: Need for efficient computation of Bayesian evidence.
  - Machine learning-augmented approaches: Integration with GPU acceleration for improved performance.
  - Hoffman and Sountsov 2022: Deriving robust alternatives to existing methods that are more amenable to GPU hardware.
  - Handley et al. 2015: Nested sampling does not widely utilize gradients or SIMD parallelism in its implementations.
  - Piras and Spurio Mancini 2023: Achieving efficient emulation with neural-network surrogates while maintaining computational speed.
  - Piras and Spurio Mancini (2023): N/A
  - Piras et al. (2024): N/A
  - Planck Collaboration et al. (2020): N/A
  - Yallup et al. (2025): Nested sampling finds its biggest speed-up in CMB analysis.
  - Piras et al. (2024): Distributed MCMC chains improve variance estimates but not runtime.
  - Handley et al. (2015): Likelihood evaluations needed for nested sampling scale harshly with dimension.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- This work demonstrates that the combination of GPU-acceleration, JAX-based emulators, and a vectorized Nested Sampling algorithm removes the primary computational barrier in using Nested Sampling in high-dimensional problems.

### 4. Method
- **Pipeline**: The proposed method involves selecting k live points with the lowest likelihoods and evolving them in parallel, optimizing the use of GPU resources.
- **Architecture / Loss / Training**: The method employs a harmonic framework to train a normalizing flow on posterior samples for evidence computation.
- **Complexity / Resources**: The implementation is designed to run efficiently on modern hardware, utilizing JAX-based likelihoods and differentiable implementations.

### 5. Experiments
- **Datasets & Metrics**: The experiments include a cosmic variance-limited CMB power spectrum analysis and a cosmic shear analysis, focusing on their vectorization behavior and execution time.
- **Baselines**: GPU-NS, HMC, MCMC sampling methods, N/A, NUTS + harmonic, Traditional CPU-based nested sampling, polychord, traditional Boltzmann solvers like CAMB and CLASS
- **Main Results**: The framework achieves a speed-up of over two orders of magnitude on a cosmic-variance-only CMB analysis and reduces the runtime of a 39-dimensional cosmic shear analysis from months to days.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The current implementation does not support full-field level inference in cosmology.

### 6. Takeaways
- **Pros**: Significantly faster than CPU-based methods., Maintains accuracy in parameter inference., Offers a robust framework for model comparison.
- **Cons**: Requires access to GPU resources., Potentially complex implementation.
- **Future Work**: Further optimization of GPU algorithms., Integration with more complex cosmological models., Exploration of additional parallel processing techniques.

</details>

### [Uchimata: a toolkit for visualization of 3D genome structures on the web and in computational notebooks](http://arxiv.org/pdf/2509.13290v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Visualization of three-dimensional genome models

### 2. Motivation & Gaps
- The paper addresses the need for effective visualization of genomic data in three-dimensional space to gain insights into genome structure.

- **Related work challenges:**
  - Genome3D: Standalone application, difficult to integrate into notebook workflows.
  - 3DGB: Limited customization options beyond predefined visual choices.
  - HiC-3DViewer: Not designed for flexible integration with other software packages.
  - NumPy and pandas: Existing libraries are not optimized for 3D genome visualization.
  - DuckDB: Need for efficient querying of 3D structures.
  - Gosling grammar: Lack of support for 3D genome models in existing grammar-based tools.
  - Stevens et al. 2017: Encoding chromosome coordinates with a continuous color scale for better visualization.
  - GMOL: An Interactive Tool for 3D Genome Structure Visualization: N/A
  - Tasks, Techniques, and Tools for Genomic Data Visualization: N/A
  - GSDB: A Database of 3D Chromosome and Genome Structures Reconstructed from Hi-C Data: N/A
  - Bioframe: Operations on Genomic Intervals in Pandas Dataframes: N/A
  - DuckDB: N/A
  - The PyMOL Molecular Graphics System, Version 1.8: N/A
  - ChromoGen: Diffusion Model Predicts Single-Cell Chromatin Conformations: N/A
  - Mol* Viewer: Modern Web App for 3D Visualization and Analysis of Large Biomolecular Structures: N/A
  - 3D Structures of Individual Mammalian Genomes Studied by Single-Cell Hi-C: N/A
  - Three-Dimensional Genome Structures of Single Diploid Human Cells: N/A
  - CSynth: An Interactive Modelling and Visualization Tool for 3D Chromatin Structure: N/A
  - The Grammar of Graphics: N/A
  - Nucleome Browser: An Integrative and Multimodal Data Navigation Platform for 4D Nucleome: N/A

### 3. Core Idea
- Uchimata provides a software solution for visualizing 3D genome models, allowing for better understanding of genomic data through spatial representation.

### 4. Method
- **Pipeline**: The method involves cutting-plane operations and spherical neighborhood selection for visualizing genome structures.
- **Architecture / Loss / Training**: Utilizes Typescript for the core library, with rendering through three.js and WebGL.
- **Complexity / Resources**: Requires integration with Apache Arrow for in-memory data representation and DuckDB for querying.

### 5. Experiments
- **Datasets & Metrics**: The experiments utilize datasets from genomic structures and gene annotations to evaluate visualization effectiveness.
- **Baselines**: 3DGB, Genome3D, Heatmap representation of Hi-C data, HiC-3DViewer, Jupyter Notebooks, N/A, Observable Notebooks
- **Main Results**: The 3D structural representation offers complementary insights to traditional heatmap visualizations.
- **Ablations**: N/A
- **Limitations / Stress Tests**: N/A

### 6. Takeaways
- **Pros**: Highly integratable with existing biological tools., Supports composability for tailored user interfaces., Adopts a grammar-of-graphics approach for expressive visualizations.
- **Cons**: Limited to visualizing 3D models, other representations require specialized tools., Dependence on Javascript and Python ecosystems may limit accessibility.
- **Future Work**: Expand integration with more biological tools., Enhance user interface capabilities., Develop additional features for broader visualization needs.

</details>

## Gaussian Splatting

### [Comparing Minimal and Non-Minimal Quintessence Models to 2025 DESI Data](http://arxiv.org/pdf/2509.13302v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Exploration of quintessence models in light of DESI data

### 2. Motivation & Gaps
- This work explores a large range of quintessence models in light of the 2025 DESI data on dark energy.

- **Related work challenges:**
  - Î›CDM model: Requires an energy density that is in large tension with expected vacuum energy.
  - CPL parametrization: Not fundamental or generic, but serves as an approximation for the DESI data.
  - Non-minimally coupled scalar models: Need to evade constraints from tests of gravity while fitting the DESI data.
  - Ref. [19]: Focus on models near a hilltop, requiring reexamination in light of updated data.
  - N/A: N/A
  - Recent studies on scalar fields and gravity: Inconsistencies between required values of scalar field parameters and observational bounds.
  - Theoretical frameworks for scalar field theories: Need for additional ingredients to comply with observational constraints.
  - DESI analysis: Statistical significance is reduced compared to that reported by the DESI analysis in the entire w0, wa plane.
  - Non-minimally coupled models: Imply a new fifth force and a dynamical value for the effective Newtonâ€™s gravitational coupling G.
  - N/A: N/A

### 3. Core Idea
- Generic models of quintessence can provide moderate improvement in fitting the DESI data compared to a cosmological constant.

### 4. Method
- **Pipeline**: Exploration of parameter space for quintessence models.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: N/A

### 5. Experiments
- **Datasets & Metrics**: 2025 DESI data on dark energy.
- **Baselines**: Cosine potential, Cosmological constant, Double well potential, Gaussian decay potential, Inverse power law decay potential, Inverse square root decay potential, Linear monomial potential, N/A, Previous scalar field theories, Quadratic hilltop potential, Quadratic monomial potential, Quartic hilltop potential, Quartic monomial potential, Standard cosmological models, Î›CDM model
- **Main Results**: Some models show reasonable agreement, but none reach inside the 2Ïƒ region of the data.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The presence of additional parameters means that there should be a penalty in such models.

### 6. Takeaways
- **Pros**: Explores a wide range of quintessence models., Identifies potential for non-minimal coupling to improve fits., Addresses significant challenges in current dark energy models.
- **Cons**: Improvements in fitting are only modest., Non-minimal couplings may not evade all constraints., The models may not be the best candidates for explaining dark energy.
- **Future Work**: Further exploration of non-minimal coupling models., Investigate additional quintessence potentials., Assess compatibility with future observational data.

</details>

### [De Finetti + Sanov = Bayes](http://arxiv.org/pdf/2509.13283v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Develop a framework for operationalizing models and parameters by combining de Finettiâ€™s representation theorem with a conditional form of Sanovâ€™s theorem.

### 2. Motivation & Gaps
- The paper discusses the need for sharper finite-sample guarantees in Bayesian methods and the challenges posed by real-world constraints that often encode incomplete information.

- **Related work challenges:**
  - Conditional limit theorems: Show that conditioning on empirical averages drives predictive laws toward tilted distributions.
  - De Finettiâ€™s theorem: Reduces exchangeable dependence to random mixtures of i.i.d. components.
  - Gaussian scale mixtures: Once seen as consequences of symmetry, now underpin shrinkage priors and heavy-tailed models.
  - Jaynesâ€™ entropy concentration theorem: Clarifying the role of classical information-theoretic results
  - Sanovâ€™s theorem: Quantifying the likelihood of observing an empirical measure under a baseline law
  - Heath-Sudderth constructive proof of de Finettiâ€™s theorem: Merging with Gibbs conditioning principle
  - N/A: N/A
  - Diaconis and Freedman [15]: Exchangeability reduces high-dimensional problems to mixtures of i.i.d. models.
  - Jaynes [22]: Entropy maximization links to the method of types and empirical constraints.
  - N/A: N/A
  - PAC-Bayes inequalities: Connecting posterior contraction with generalization error.
  - Variational inference: Robustness under misspecification.
  - Entropy methods and neural attention mechanisms: Embedding structural constraints into the tilted de Finetti framework.
  - N/A: N/A

### 3. Core Idea
- The framework offers opportunities in machine learning by linking exponential tilting to fairness and robustness as information regularizers.

### 4. Method
- **Pipeline**: Combine a conditional form of Sanovâ€™s theorem with de Finettiâ€™s representation to show that Sanov plus de Finetti yields Bayes.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: N/A

### 5. Experiments
- **Datasets & Metrics**: Examples include Gaussian scale mixtures and Jaynesâ€™ Brandeis dice problem.
- **Baselines**: Dirichlet process prior, Gibbs conditioning, McMillan theorem, N/A, Shannon entropy, Uniform distribution
- **Main Results**: The empirical constraints force predictive concentration onto the I-projection.
- **Ablations**: N/A
- **Limitations / Stress Tests**: N/A

### 6. Takeaways
- **Pros**: Provides a probabilistic foundation for maximum entropy principles., Clarifies the ubiquity of exponential families., Unifies exchangeability, large deviations, and entropy concentration.
- **Cons**: Priors on infinite-dimensional spaces can be challenging., Posterior computations can be complex., Technical overhead in constrained Bayesian nonparametrics.
- **Future Work**: Explore further implications of the tilted de Finetti theorem., Investigate practical applications in various fields., Develop more efficient computational methods for Bayesian updating.

</details>

### [Bioluminescence in turbulence: intermittent straining lights up dinoflagellates](http://arxiv.org/pdf/2509.13273v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Analyze the flashing dynamics of dinoflagellates under turbulent conditions

### 2. Motivation & Gaps
- Understanding the relationship between turbulent flow and bioluminescence in dinoflagellates.

- **Related work challenges:**
  - Latz et al. experiments on shear stress and bioluminescence: Establishing the correlation between shear stress and illumination in various flow conditions.
  - Jalaal et al. phenomenological model: Quantifying the light emitted by dinoflagellates under varying extents and rates of deformation.
  - Balkovsky, Fouxon, and Lebedev's formalization: Understanding the connection between line element stretching and deformation of soft particles.
  - Jalaal et al. (2018): Previous models did not account for deformation thresholds for light emission onset and saturation.
  - Picardo et al. (2018): Existing models do not adequately capture the effects of extreme velocity-gradient fluctuations on luminescence.
  - Brunk et al. (2018): Lack of understanding of how turbulent straining affects the flashing dynamics of dinoflagellates.
  - Latz et al. (study of four different species): Species-specific thresholds for light emission.
  - Rohret al. (turbulent pipe flow experiments): Linear increase of light intensity with wall shear stress.
  - Blaser et al. (turbulent flow studies): Need for understanding the effects of extreme velocity-gradient fluctuations.
  - Latz and Rohr (1999): Mean light intensity emitted by dinoflagellates is the same in laminar and turbulent flow.
  - Deane and Stokes (N/A): Modeling flash-triggering as a Poisson process with fluid stress dependence.
  - N/A: Need to account for motility and shape of dinoflagellates in bioluminescence modeling.
  - Bioluminescence imaging of wave-induced turbulence: N/A
  - Bioluminescent response of the dinoflagellate lingulodinium polyedrum to developing flow: Tuning of sensitivity and the role of desensitization in controlling a defensive behavior of a planktonic cell
  - A quantitative model for flow-induced bioluminescence in dinoflagellates: N/A
  - Stress-induced dinoflagellate bioluminescence at the single cell level: N/A
  - Extreme velocity gradients in turbulent flows: N/A
  - Oceanic turbulence from a planktonic perspective: N/A
  - Shortcomings of the dissipation rate for understanding the turbulent environment of plankton: N/A

### 3. Core Idea
- Fluctuating and intermittent nature of small-scale turbulent straining enhances bioluminescence in dinoflagellates.

### 4. Method
- **Pipeline**: Analysis of light intensity response in turbulent flows using DNS and comparison with Gaussian-gradient flows.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The simulations utilize a direct numerical simulation (DNS) of homogeneous isotropic turbulent flow with a Taylor Reynolds number of 111.

### 5. Experiments
- **Datasets & Metrics**: Lagrangian trajectory database shared by Samriddhi Sankar Ray.
- **Baselines**: Extensional flow, Gaussian gradient models, Gaussian random flow, Gaussian-gradient flow, Laminar flow, N/A, Previous models of light emission in dinoflagellates, Turbulent flow, Uniform extensional flow
- **Main Results**: Mean waiting time for flashes is larger in intermittent turbulent flow, with increased flashing rate in intense turbulence.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The model does not account for decay and entrainment effects in the flashing dynamics.

### 6. Takeaways
- **Pros**: Enhanced understanding of bioluminescence mechanisms in turbulent environments., Insights into the role of turbulence in marine ecosystems., Potential applications in visualizing stress fields in fluid dynamics.
- **Cons**: Limited experimental validation of the model in real-world turbulent conditions., Assumptions made in the mechanical model may not capture all biological complexities., Potential oversimplification of the interaction between dinoflagellates and turbulence.
- **Future Work**: Further experimental studies to validate the model predictions., Exploration of bioluminescence in varying turbulent conditions., Investigation of other marine organisms' responses to turbulence.

</details>

## avatar

### [Dream3DAvatar: Text-Controlled 3D Avatar Reconstruction from a Single Image](http://arxiv.org/pdf/2509.13013v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D reconstruction and multi-view image synthesis

### 2. Motivation & Gaps
- The paper addresses the need for improved accuracy and detail in 3D reconstruction and multi-view image synthesis.

- **Related work challenges:**
  - Li et al. 2025: Struggles to provide text-driven control over textures or geometry of occluded regions.
  - Zhuang et al. 2025: Lacks controllability and diversity in reconstruction.
  - AlBahar et al. 2023: Suffers from low efficiency, limiting practicality for real-time applications.
  - Bhunia et al. (2023): Handling large articulations using pose conditioning.
  - PSHuman (Li et al. 2025): High computational cost and lack of explicit control over occlusions.
  - AniGS (Qiu et al. 2025b): Efficiency trade-offs in generating coherent multi-view sequences.
  - Wang et al. 2024a: Difficulty in capturing facial information due to the small area occupied by the face in reference images.
  - Huang et al. 2024: Challenges in maintaining body feature consistency and resolving ambiguities in multi-view inputs.
  - Zhuang et al. 2025: Artifacts on the face in generated 3D avatars due to low-resolution facial features.
  - SV3D: Poor detail preservation and multi-view consistency.
  - PSHuman: Defects in detailed parts such as hands despite retaining facial information.
  - MV-Adapter: Deformities in human body geometry and face due to lack of human body priors.
  - Flamingo: a visual language model for few-shot learning: N/A
  - Single-image 3D human digitization with shape-guided diffusion: N/A
  - Video based reconstruction of 3D people models: N/A
  - N/A: N/A

### 3. Core Idea
- A lightweight multi-view generation module based on SDXL that incorporates geometric and semantic constraints for view-consistent image synthesis.

### 4. Method
- **Pipeline**: A feedforward Transformer network equipped with an ID Adapter.
- **Architecture / Loss / Training**: The loss function includes components for RGB loss, LPIPS loss for both body and face images, with weighting coefficients to balance contributions.
- **Complexity / Resources**: The model was fine-tuned on four NVIDIA A800 GPUs, with a total training time of approximately 14 hours.

### 5. Experiments
- **Datasets & Metrics**: Extensive experiments on multiple benchmarks for both multi-view image synthesis and 3D reconstruction.
- **Baselines**: CRM, DreamGaussian, Existing methods in multi-view to 3D reconstruction, Existing methods in single-image to multi-view generation, IDOL, MV-Adapter, MagicMan, N/A, PSHuman, SDXL, SIFU, SV3D, Stable Diffusion
- **Main Results**: Achieves state-of-the-art performance.
- **Ablations**: Ablation studies demonstrated the contributions of the Pose-Adapter and ID-Adapter modules to the overall performance.
- **Limitations / Stress Tests**: The method's performance was evaluated under various challenging poses and conditions, highlighting its robustness.

### 6. Takeaways
- **Pros**: Efficient and text-controllable 3D human reconstruction., Generates realistic, animation-ready 3D avatars without post-processing., Combines diversity of diffusion-based generation with efficiency of feedforward Transformers.
- **Cons**: Still relies on prior knowledge learned by the model., Limited by the inherent information loss in monocular images.
- **Future Work**: Explore further improvements in controllability., Investigate real-time applications for the framework., Enhance the diversity of generated avatars.

</details>

### [Gesture Evaluation in Virtual Reality](http://arxiv.org/pdf/2509.12816v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Gesture generation evaluation

### 2. Motivation & Gaps
- The paper addresses the need for standardized evaluation practices in gesture generation models, particularly in the context of both monadic and dyadic interactions.

- **Related work challenges:**
  - Wolfert et al. [2024]: Comparison of evaluation methods for nonverbal behavior in dyadic settings.
  - Wolfert et al. [2022]: Review of gesture evaluation methods and trends in ECA studies.
  - Wolfert et al. [2022]: Identifying effective evaluation methods for co-speech gestures.
  - Kucherenko et al. [2023]: Evaluating speech-driven gesture generation systems in a comprehensive challenge.
  - Jonell et al. [2021]: Measuring human-likeness of virtual character motion without considering speech.
  - N/A: Most prior studies used plain backgrounds, which may not engage participants effectively.
  - N/A: N/A
  - GENEA Challenge: Evaluation of tests conducted online versus in a lab setting.
  - A Review of Evaluation Practices of Gesture Generation in Embodied Conversational Agents: Lack of comprehensive evaluation metrics and methodologies.
  - Exploring the Effectiveness of Evaluation Practices for Computer-Generated Nonverbal Behaviour: Inconsistencies in evaluation approaches across different studies.

### 3. Core Idea
- To provide a large-scale evaluation framework for gesture generation models, facilitating comparisons and improvements in the field.

### 4. Method
- **Pipeline**: The evaluation pipeline includes data collection, model training, and performance assessment using standardized metrics.
- **Architecture / Loss / Training**: Models are trained using a combination of loss functions tailored to gesture accuracy and naturalness.
- **Complexity / Resources**: The evaluation requires significant computational resources for model training and testing.

### 5. Experiments
- **Datasets & Metrics**: Utilized various datasets for gesture generation and assessed performance using metrics such as accuracy and user satisfaction.
- **Baselines**: GT system, Ground Truth (GT), Ground truth motion (motion capture), N/A, Previous gesture generation models, Random gesture generation, SF, SF model, SFDiffusion-based system, SG, SG model, SGDiffusion-based system, SJ, SJ model, SJTransformer-based system, Traditional 2D gesture evaluations
- **Main Results**: The results indicate significant improvements in gesture generation accuracy and user engagement compared to baseline models.
- **Ablations**: Ablation studies were conducted to assess the impact of different model components on performance.
- **Limitations / Stress Tests**: Limitations include the generalizability of results across different contexts and the need for more diverse datasets.

### 6. Takeaways
- **Pros**: VR enhances the perception of gestures compared to 2D., Immersive environments may lead to more authentic communication experiences., Consistent ranking of gesture generation models across settings.
- **Cons**: Limited impact of the VR setting on model performance., Potential for tester fatigue in lengthy evaluations., Challenges in achieving inter-rater reliability in questionnaire-based studies.
- **Future Work**: Further exploration of gesture evaluation methods in immersive environments., Investigation of additional gesture generation algorithms., Development of more effective communication agents leveraging VR.

</details>

### [The Adaptation Paradox: Agency vs. Mimicry in Companion Chatbots](http://arxiv.org/pdf/2509.12525v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Exploring user expectation and perception of an anthropomorphic LLM-based conversational agent

### 2. Motivation & Gaps
- The study investigates how users perceive and expect interactions with anthropomorphic conversational agents designed for well-being support.

- **Related work challenges:**
  - Nass and Moon (2000): Humanlike cues elicit social responses but their impact is context-dependent.
  - Ireland et al. (2011): Subconscious linguistic synchrony correlates with rapport, but invisible mimicry can be perceived as incoherent.
  - Schlimbach and Spill (2023): The distinction between user authorship and system adaptivity complicates design choices in AI interactions.
  - Blut et al., 2021: Understanding the impact of anthropomorphism on user interaction with conversational agents.
  - Yee and Bailenson, 2007: Exploring the Proteus Effect and its implications for user behavior in virtual environments.
  - Giles et al., 1991: Investigating Communication Accommodation Theory and its relevance to linguistic style matching.
  - Giles et al., 1991: N/A
  - Gonzales et al., 2010: N/A
  - Tausczik and Pennebaker, 2010: N/A
  - Spillner and Wenig, 2021: N/A
  - Klein, 2025: N/A
  - Nguyen et al., 2023: N/A
  - Frisch and Giulianelli, 2024: N/A
  - N/A: N/A
  - N/A: Understanding the divergence between objective system behavior and subjective user experience.
  - N/A: The adaptive linguistic style underperformed a static baseline on perceived personalization and satisfaction.
  - N/A: Incongruity between anthropomorphic visual cues and conversational cues leads to negative user perceptions.
  - N/A: Stability and legibility are crucial mediators in user satisfaction.
  - Horton and Wohl, 1956: The need for a stable and predictable persona in parasocial relationships.
  - Xie et al., 2023: Users developing psychological dependence on chatbots due to perceived instability.
  - Zellou and Holliday, 2024: Speech recognition systems' biases affecting the AI's ability to mimic user styles.
  - N/A: N/A
  - Guidelines for human-AI interaction: N/A
  - Rethinking feminized service bots: User responses to abstract and gender-ambiguous chatbot avatars: N/A
  - Understanding anthropomorphism in service provision: A meta-analysis of physical robots, chatbots, and other AI: N/A
  - Towards Automated Dialog Personalization using MBTI Personality Indicators: Limited understanding of how personality indicators can enhance dialog personalization.
  - The effect of perceived similarity in dominance on customer self-disclosure to chatbots: Need for deeper insights into customer self-disclosure dynamics in chatbot interactions.
  - Humanizing chatbots: The effects of visual, identity and conversational cues on humanness perceptions: Challenges in effectively humanizing chatbots to improve user engagement.
  - Trust in automation: Designing for appropriate reliance: Understanding how to design AI systems that users can trust.
  - Hi, Iâ€™m Cecil(y) the Smoking Cessation Chatbot: Evaluating the effectiveness of chatbots in behavioral change.
  - Why and why not explanations improve the intelligibility of context-aware intelligent systems: Identifying the role of explanations in user trust.
  - The Proteus effect: The effect of transformed self-representation on behavior: Understanding how self-representation in chatbots affects user behavior.
  - AI-based chatbots in conversational commerce and their effects on product and price perceptions: Examining the impact of chatbot characteristics on user perceptions.
  - Human-like communication in conversational agents: A literature review and research agenda: Identifying gaps in the literature regarding human-like interactions with chatbots.

### 3. Core Idea
- The research focuses on the expectations and perceptions of users interacting with an anthropomorphic LLM-based conversational agent aimed at providing well-being support.

### 4. Method
- **Pipeline**: The study employs a mixed-methods approach, combining qualitative and quantitative data collection techniques.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: N/A

### 5. Experiments
- **Datasets & Metrics**: The study utilizes user feedback and interaction data to assess expectations and perceptions.
- **Baselines**: Adaptive Language Style Matching, Adaptive chatbot, Human interactions, N/A, Non-anthropomorphic agents, Premade avatar, Static Language Style Matching, Static avatar, Static baseline, Static baseline chatbot, Static chatbot, Traditional chatbot interactions
- **Main Results**: Users reported higher satisfaction and engagement with the anthropomorphic agent compared to traditional chatbots.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The study acknowledges limitations in sample diversity and the generalizability of findings.

### 6. Takeaways
- **Pros**: User-visible agency boosts relational outcomes., Static style is perceived as more personal and satisfying., Avatar creation encourages more personal content in conversations.
- **Cons**: Adaptive LSM can lead to perceived incoherence., Invisible mimicry may not meet user expectations for coherence., Over-reliance on stylistic shifts can degrade user experience.
- **Future Work**: Further research on the balance between visibility and adaptivity in AI interactions., Exploration of other factors influencing user connection with AI companions., Development of guidelines for designing effective companion chatbots.

</details>

## video understanding

### [3D Aware Region Prompted Vision Language Model](http://arxiv.org/pdf/2509.13317v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- 3D-aware spatial reasoning

### 2. Motivation & Gaps
- The paper addresses the need for effective spatial reasoning in 3D environments using vision-language models.

- **Related work challenges:**
  - Foundational 2D VLMs: Lack mechanisms to capture complex 3D structural relationships.
  - Most 3D VLMs: Operate in fundamentally different representation spaces, making it difficult to leverage prior knowledge from 2D VLMs.
  - Region prompting in single-view VLMs: Extending region prompting to multi-view settings remains challenging due to varying visibility of objects.
  - RegionGPT: Struggles with resolution and aspect ratio constraints.
  - VSI-Bench: Focuses primarily on 2D images, with less exploration in multi-view spatial reasoning.
  - LLaVA-3D: Processes 3D and 2D data through separate pathways, risking overfitting to specific 3D tasks.
  - Prior architectures without dynamic tiling: Rely on feature refinement modules that may limit the ability to recover fine details.
  - Separate pathways for single- and multi-view data: Lead to inconsistent processing and integration of spatial reasoning.
  - SpatialRGPT: Limited performance in region-level recognition without dynamic tiling.
  - DynRefer: Inadequate integration of 3D positional features in existing models.
  - Blind LLMs: Limited to text-based reasoning without visual input.
  - VLMs with Language Referral: Struggle with tracking spatial relationships across frames.
  - Region-aware Video VLMs: Difficulty in processing specific image regions without text descriptions.
  - Video3dLLM: Maintaining performance with reconstructed point clouds.
  - Cut3R: Significant performance drop compared to ground-truth results.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: Current vision-language models struggle with accurately perceiving and interpreting spatial questions related to object orientation.
  - N/A: Incorporating positional embeddings to handle both static and dynamic inputs is non-trivial.
  - N/A: There is a consistent slight drop in performance for OCR-related tasks.

### 3. Core Idea
- SR-3D unifies single-view and multi-view data in a shared space to enhance spatial reasoning capabilities.

### 4. Method
- **Pipeline**: The method employs a tile-and-stitch approach to extract high-resolution region features.
- **Architecture / Loss / Training**: The architecture employs a combination of region-level classification and general question answering tasks, with specific loss functions tailored for spatial understanding.
- **Complexity / Resources**: The model requires substantial computational resources for training and evaluation, particularly for 3D benchmarks.

### 5. Experiments
- **Datasets & Metrics**: Evaluated on 2D vision-language and 3D spatial benchmarks, including Scan2Cap and ScanQA.
- **Baselines**: Blind LLMs, Cambrian, Cut3R, DynRefer, Hybrid ShareGPT4V-SFT, LLaVA-OneVision, Molmo, N/A, NVILA-Lite-8B, Osprey, Prior state-of-the-art methods in region-level tasks, Region-aware Video VLMs, RegionGPT, SpatialRGPT, SpatialRGPT-8B, The Cauldron, VLMs with Language Referral, Video-3D-LLM, Video3dLLM
- **Main Results**: SR-3D shows state-of-the-art performance on various benchmarks.
- **Ablations**: Incorporating 3D positional embeddings and single-view pre-training significantly enhances performance.
- **Limitations / Stress Tests**: The model struggles with zero-shot performance on width-related tasks due to differences in definition between single-view and multi-view settings.

### 6. Takeaways
- **Pros**: Achieves state-of-the-art performance in unifying 2D and 3D representation space., Supports flexible region prompting without exhaustive multi-frame labeling., Demonstrates strong zero-shot spatial reasoning in 3D scenes.
- **Cons**: Requires extensive data collection for 3D training., Cumbersome specification of spatial relationships in cluttered scenes.
- **Future Work**: Explore further integration of 3D data sources., Enhance the model's ability to generalize across diverse scenes., Investigate improvements in user interaction for region prompting.

</details>

### [Temporally Smooth Mesh Extraction for Procedural Scenes with Long-Range Camera Trajectories using Spacetime Octrees](http://arxiv.org/pdf/2509.13306v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Mesh extraction and rendering for procedural scenes

### 2. Motivation & Gaps
- The paper addresses the challenges of inconsistent results in mesh extraction and rendering, particularly in procedural scenes with long-range camera trajectories.

- **Related work challenges:**
  - OcMesher: Extracting a single global mesh can result in prohibitively large meshes for unbounded scenes.
  - Progressive meshes approach by Hoppe: While it allows smooth transitions, it requires decimating the full-resolution mesh, which can lead to challenges at block boundaries.
  - Marching cubes method: Extracts a mesh as an isosurface of an implicit function, limited to static meshes.
  - Dual contouring: Operates on multiresolution rectangular grids but does not handle dynamic LODs.
  - Geomorphs: Early algorithms address specific cases and do not generalize well to procedural scenes.
  - OcMesher: Limited to extracting meshes for subsequences without considering temporal coherence.
  - Spherical Mesher: Constructs uniform grids but lacks efficiency in handling complex scenes.
  - Spherical Mesher: Longest overall runtime and high mesh resolution leading to popping.
  - OcMesher-24: Faster mesh generation but increased risk of exceeding memory limits.
  - OcMesher-96: Creates larger meshes per frame, increasing rendering time.
  - OcMesher: Memory footprint increases with scene complexity and camera rotation speed.
  - Ray marching techniques: Inconsistent results due to varying step sizes.
  - Fuzzy camera paths: Difficulty in maintaining quality when the camera moves outside the fuzzy region.
  - Popping artifacts in mesh rendering: Minor popping artifacts caused by new polygonal structures emerging discontinuously.
  - N/A: N/A

### 3. Core Idea
- The proposed algorithm extends to fuzzy camera paths and ameliorates popping artifacts by using a spatio-temporal tree and extruding time-orthogonal faces into pyramidal volumes.

### 4. Method
- **Pipeline**: The algorithm processes a list of keyframe cameras with timestamps and samples cameras covering fuzzy regions.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The runtime depends on the size of the fuzzy region rather than the number of sampled cameras due to GPU parallelization.

### 5. Experiments
- **Datasets & Metrics**: The experiments include various procedural scenes such as Forest, Mountain, Arctic, and Cave, evaluated using SSIM metrics.
- **Baselines**: Dual contouring, Geomorphs, Marching cubes, N/A, OcMesher, OcMesher-24, OcMesher-96, Progressive meshes approach, Ray marching, Spherical Mesher, Traditional mesh extraction methods
- **Main Results**: The proposed method shows improved SSIM scores in most scenes, although the advantage is less pronounced in the Cave scene.
- **Ablations**: N/A
- **Limitations / Stress Tests**: Insufficient sampling in dark regions produces considerable visual noise, affecting SSIM scores.

### 6. Takeaways
- **Pros**: Produces temporally smooth meshes for long-range camera trajectories., Optimized for memory and computational efficiency., Better visual consistency compared to baseline methods.
- **Cons**: Complex implementation., Requires careful tuning of parameters., Limited to specific types of occupancy functions.
- **Future Work**: Explore further optimizations for real-time applications., Investigate additional use cases for the binary-octree structure., Develop methods to handle more complex scene geometries.

</details>

### [Mixed Triplet-Singlet Order Parameter in Decoupled Superconducting 1H Monolayers of Transition-Metal Dichalcogenides](http://arxiv.org/pdf/2509.13303v1)


<!--break-out-of-list-->
<details markdown="1">
<summary>ðŸ“„ Paper Summary </summary>

### 1. Task / Problem
- Investigate the superconducting properties and order parameters in 1H monolayers of transition-metal dichalcogenides.

### 2. Motivation & Gaps
- The study aims to explore the mixed triplet-singlet order parameter in superconducting materials, particularly focusing on the unique properties of 1H monolayers of transition-metal dichalcogenides.

- **Related work challenges:**
  - Various studies on unconventional superconductors: The precise mechanisms driving the pairing remain elusive.
  - Research on transition metal dichalcogenides (TMDCs): Not all candidate materials fit neatly into existing categories of superconductivity.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Physical Review B - Condensed Matter and Materials Physics: Understanding the complex order parameters in superconductors.
  - New Journal of Physics: Identifying the mechanisms behind superconductivity in low-dimensional materials.
  - Reviews of Modern Physics: Addressing the limitations of existing models in describing superconducting states.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The paper demonstrates how a multi-gap feature can appear in the Bogoliubov spectrum due to singlet-triplet mixing in a single layer of 2H-TaS2, and how interlayer coupling suppresses this mixing.

### 4. Method
- **Pipeline**: The research involves X-ray diffraction for crystallography, resistivity measurements, and gap fitting using both single and two-gap models.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The study utilizes high-resolution X-ray diffraction systems and advanced fitting techniques for data analysis.

### 5. Experiments
- **Datasets & Metrics**: The study uses a self-consistent calculation over the entire Brillouin zone with specific parameters for interaction and coupling.
- **Baselines**: 2H-TaS2, 4Hb-TaS2, BCS theory, Conventional superconductors, N/A, Single isotropic gap model, Two-gap model
- **Main Results**: The results show that under certain conditions, the isolated monolayer can develop significant anisotropy in momentum space, leading to strong multi-gap features in the tunneling density of states.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The study acknowledges the limitations of the single gap model in accurately describing the superconducting behavior.

### 6. Takeaways
- **Pros**: Establishes misfit compounds as a powerful platform for studying unconventional superconductivity., Reveals a multi-gap structure in the superconducting phase., Demonstrates the intrinsic superconductivity of the SnS layer.
- **Cons**: The precise mechanisms driving the unconventional order parameter remain unclear., Limited understanding of the influence of the environment on superconductivity., Challenges in categorizing materials within existing superconductivity frameworks.
- **Future Work**: Further investigation into the role of inter-layer interactions in superconductivity., Exploration of other misfit compounds for similar properties., Development of theoretical models to better understand unconventional pairing mechanisms.

</details>
