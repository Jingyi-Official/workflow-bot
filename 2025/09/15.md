# Daily Paper Digest 路 2025-09-15
> Auto-generated: Recent submissions from arXiv are fetched by topic and keyword (up to 3 papers per query).

## neural rendering

### [Standards in the Preparation of Biomedical Research Metadata: A Bridge2AI Perspective](http://arxiv.org/pdf/2509.10432v1)


<!--break-out-of-list-->
<details markdown="1">
<summary> Paper Summary </summary>

### 1. Task / Problem
- Creating metadata to promote AI readiness

### 2. Motivation & Gaps
- Having standardized metadata from our four distinct and highly multimodal data generators will provide a uniquely robust resource for developing and validating cross-domain computational techniques.

- **Related work challenges:**
  - Bridge2AI consortium: Lack of clear mechanisms for interoperability and standardization in metadata management.
  - AI/ML for Clinical Care: Integrating diverse data types from multiple medical centers into a unified dataset.
  - Functional Genomics: Ensuring metadata standards accommodate various data types and their specific requirements.
  - Precision Public Health: Developing standards that can be applied across different public health datasets.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: Improper metadata management presents significant challenges and risks.
  - N/A: Inaccuracies in data entry, inconsistent formats, and missing information can undermine the performance of AI algorithms.
  - N/A: Privacy and legal risks associated with detailed metadata can expose sensitive information if not properly secured.
  - Common Fund Data Ecosystem Integration: Alignment of underlying data models with GC needs and ensuring patient privacy.
  - N/A: N/A

### 3. Core Idea
- A common representational model for dataset metadata standardized across all GCs is envisioned to create significant synergies.

### 4. Method
- **Pipeline**: Data is organized and packaged according to the Clinical Dataset Structure (CDS), inspired by the Brain Imaging Data Structure (BIDS).
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The project utilizes a combination of existing standards and new extensions to accommodate diverse data types.

### 5. Experiments
- **Datasets & Metrics**: The AI-READi dataset includes over one thousand participants and 13 types of measurements, including survey data, physical metrics, retinal images, and environmental properties.
- **Baselines**: Croissant, Current practices in metadata management, Data Cards, Dataset Nutrition Labels, Datasheets, Digital Imaging and Communications in Medicine, Healthsheets, N/A, OMOP common data model, Waveform Database Software Package
- **Main Results**: The dataset is accessible in a secure enclave for permissioned users to analyze using a suite of tools.
- **Ablations**: N/A
- **Limitations / Stress Tests**: Data quality is assessed through standardized scripts for conformance, completeness, and plausibility.

### 6. Takeaways
- **Pros**: Standardization can improve AI-readiness of biomedical datasets., Clear guidelines can enhance metadata creation processes., Collaboration within the Bridge2AI consortium can lead to better practices.
- **Cons**: Existing standards may lack interoperability., Researchers may not have the necessary tools for metadata management., Bespoke standards may not be widely adopted.
- **Future Work**: Further research on effective metadata practices., Development of tools to facilitate metadata standardization., Expansion of guidelines to include more diverse data modalities.

</details>

### [Near-Hamiltonian dynamics and energy-like quantities of next-generation neural mass models](http://arxiv.org/pdf/2509.10428v1)


<!--break-out-of-list-->
<details markdown="1">
<summary> Paper Summary </summary>

### 1. Task / Problem
- Investigate transitions between energy states in neural mass models

### 2. Motivation & Gaps
- The study explores how external stimuli can induce transitions between energy states in neural mass models, drawing parallels with transcranial magnetic stimulation.

- **Related work challenges:**
  - Hopfield's work on memory forming networks: Energy functions used to study stability of equilibrium states are not directly related to neuronal populations.
  - Energy landscapes in EEG and fMRI analysis: These landscapes have no clear connection to the underlying neuronal populations.
  - Next-generation neural mass models: Linking their dynamics to energy considerations and approximating them with Hamiltonian descriptions has not been investigated.
  - N/A: N/A
  - Energy landscape theory: Estimates energy barriers and states by analyzing brain recordings, which may not directly derive the energy landscape.
  - Neural mass models: Understanding the dynamics of populations with varying excitability parameters and their implications for brain behavior.
  - Theory of protein folding: the energy landscape perspective: Understanding the dynamics of protein folding.
  - State-of-the-art estimation of protein model accuracy using AlphaFold: Accurate estimation of protein model accuracy.
  - Characterising Alzheimers disease with EEG-based energy landscape analysis: Characterizing complex neurological conditions.
  - N/A: N/A

### 3. Core Idea
- The study explores the dynamics of neural mass models using energy-like quantities and averaging techniques.

### 4. Method
- **Pipeline**: Modeling the neural mass system dynamics using energy-constant curves and analyzing transitions in response to stimuli.
- **Architecture / Loss / Training**: The model uses a Lorentzian distribution for individual excitabilities and incorporates parameters for synaptic strength and applied current.
- **Complexity / Resources**: The model complexity is influenced by the homogeneity of the neuronal population and the coupling strength.

### 5. Experiments
- **Datasets & Metrics**: Simulations of neural mass models with varying parameters to observe energy state transitions.
- **Baselines**: Energy landscape theory, N/A, Previous energy landscape theories, Standard neural mass models, Traditional neural mass models
- **Main Results**: The model successfully predicts transitions between energy states and demonstrates the role of kinetic energy in these transitions.
- **Ablations**: Testing the effects of varying parameters like synaptic strength and population heterogeneity on model behavior.
- **Limitations / Stress Tests**: The model's accuracy improves with smaller 未 values, indicating limitations in heterogeneous populations.

### 6. Takeaways
- **Pros**: Provides a new perspective on neuronal population dynamics using physics principles., Links energy landscape theory with neuronal behavior., Offers a framework for analyzing complex behaviors in neural mass models.
- **Cons**: The model may oversimplify the complexities of real neuronal populations., Assumptions about parameter distributions may not hold in all cases., The connection between energy landscapes and actual neuronal dynamics is still unclear.
- **Future Work**: Further exploration of the relationship between energy landscapes and neuronal dynamics., Investigation of the model's applicability to different types of neural populations., Development of more sophisticated models that incorporate additional biological realism.

</details>

### [Multiscaling in Wasserstein Spaces](http://arxiv.org/pdf/2509.10415v1)


<!--break-out-of-list-->
<details markdown="1">
<summary> Paper Summary </summary>

### 1. Task / Problem
- Analyzing learning dynamics of neural networks in Wasserstein space

### 2. Motivation & Gaps
- The study investigates the learning dynamics of neural networks through the lens of Wasserstein spaces, focusing on the convergence of measures during training.

- **Related work challenges:**
  - Recent mathematical advancements in Wasserstein spaces: Multiscale analysis has not been adequately addressed.
  - Wavelet multiresolution frameworks: Need for adaptation to Riemannian manifolds.
  - Computational algorithms in Wasserstein spaces: Lack of multiscale representation methods.
  - N/A: N/A
  - Transport subdivision schemes: Limited to discrete probability measures.
  - Interpolation methods for Wasserstein spaces: Existing methods may not adequately handle the complexities of absolutely continuous measures.
  - Previous studies on optimal transport theory: Limited understanding of how multiscale representations can enhance data compression and optimality analysis.
  - Research on discrete measures: Need for suitable modifications to apply multiscale transforms to discrete cases.
  - McCann's interpolating scheme: Non-uniqueness of the coupling matrix in real-world data.
  - Elementary subdivision scheme: Need for consistent average points across iterations.
  - Optimal transport theory: Establishing stability conditions for refinement rules in the context of multiscale analysis.
  - Previous studies on multiscale transforms: Understanding the implications of geometric decay in detail coefficients.
  - Previous studies on Gaussian measures: Limited understanding of the multiscale properties and their implications in Wasserstein spaces.
  - Research on optimal transport: Need for effective methods to analyze and visualize the transport between measures.
  - Coulomb's law application in vector fields: Understanding the behavior of particles in electric fields and their trajectories.
  - Elementary multiscale transform: Detecting the effects of large vector fields on point clouds.
  - Deep learning model analysis: Tracking discrete probability measures in neural networks.
  - Wasserstein regression: Understanding the smoothness of learning dynamics in high-dimensional spaces.
  - Statistical data analysis in Wasserstein space: Addressing the stochasticity in optimization methods affecting learning dynamics.
  - Fast and scalable Wasserstein-1 neural optimal transport solver: Efficiently predicting perturbations in single-cell data.
  - N/A: N/A

### 3. Core Idea
- The dynamics of neural network weights follow a smooth path in a high-dimensional space, converging to Dirac's measure over specific digits as learning progresses.

### 4. Method
- **Pipeline**: Utilizing a sequence of discrete probability measures to analyze learning dynamics across epochs.
- **Architecture / Loss / Training**: The architecture involves a neural network trained over 161 epochs with batch sizes of 128.
- **Complexity / Resources**: The analysis operates in a 2346-dimensional space, requiring significant computational resources.

### 5. Experiments
- **Datasets & Metrics**: The MNIST dataset is used for digit prediction, with metrics based on mean probabilities and detail coefficients.
- **Baselines**: Existing transport subdivision schemes, McCann's interpolating scheme, N/A, Non-interpolating corner-cutting scheme, Previous Wasserstein-based learning approaches, Previous multiscale analysis techniques, Previous multiscale methods, Standard Gaussian measures, Standard interpolation methods in Wasserstein spaces, Standard neural network training methods, Standard optimal transport methods, Traditional multiscale analysis methods, Wavelet transforms
- **Main Results**: The learning dynamics exhibit smooth convergence to Dirac's measure, with detail coefficients showing decay over scales.
- **Ablations**: Investigating the impact of different batch sizes and learning rates on the learning dynamics.
- **Limitations / Stress Tests**: The analysis is limited by the stochastic nature of the optimization methods used.

### 6. Takeaways
- **Pros**: Robustness and interpretability of the multiscale representation., Versatility in application across different types of measures., Theoretical guarantees on stability and geometric decay.
- **Cons**: Complexity in adapting methods for mixed types of measures., Potential computational challenges in large-scale applications., Limited exploration of practical applications beyond the examples provided.
- **Future Work**: Further exploration of multiscale analysis in other domains., Development of more efficient computational algorithms., Investigation of additional applications in deep learning.

</details>

## Gaussian Splatting

### [Differentially Private Decentralized Dataset Synthesis Through Randomized Mixing with Correlated Noise](http://arxiv.org/pdf/2509.10385v1)


<!--break-out-of-list-->
<details markdown="1">
<summary> Paper Summary </summary>

### 1. Task / Problem
- Differential Privacy in Federated Learning

### 2. Motivation & Gaps
- The paper addresses the challenge of maintaining differential privacy in federated learning settings, where data is distributed across multiple clients.

- **Related work challenges:**
  - Differentially Private Class-Centric Data Aggregation (DP-CDA): In a decentralized setting, limited sample size per client increases sensitivity of local computations, requiring higher noise injection which degrades utility.
  - Federated Learning (FL): Model updates can still leak sensitive information, and attacks specific to decentralized systems can exploit intermediate model updates.
  - Federated Learning: Significant privacy leakage during model parameter exchange.
  - Differential Privacy: Higher noise requirements in federated settings degrade utility.
  - CAPE Protocol: Need for effective noise management to maintain privacy while improving utility.
  - Conventional Federated DP-CDA: Increased noise degrades the utility of generated synthetic data as the number of clients grows.
  - Federated DP-CDA: Experiences performance degradation due to increased local noise in decentralized scenarios.
  - DP-Mix: Offers a better trade-off but still does not match the utility of centralized methods.
  - Local Perturbation: Ensures strong privacy but results in extreme utility loss.
  - Federated learning in non-iid settings aided by differentially private synthetic data: N/A
  - Generative models for effective ml on private, decentralized datasets: N/A
  - Federated learning: Challenges, methods, and future directions: N/A
  - Handling privacy-sensitive medical data with federated learning: challenges and future directions: N/A
  - Differentially private federated learning: A client level perspective: N/A
  - Gaussian Mechanism: Requires large noise injection at each client, degrading utility.
  - R茅nyi Differential Privacy: Complexity in ensuring privacy guarantees across decentralized data.
  - CAPE Protocol: Balancing local privacy with global utility.

### 3. Core Idea
- The CAPE protocol splits noise into local and correlated components to maintain privacy while preserving utility in federated settings.

### 4. Method
- **Pipeline**: Clients generate privatized estimates using local and correlated noise, which are then aggregated at the server.
- **Architecture / Loss / Training**: CNN model with a convolutional block followed by fully connected layers, trained with cross-entropy loss using Adam optimizer.
- **Complexity / Resources**: Overall computational complexity is O(T路S路l路dx), scaling linearly with the number of synthetic samples, clients, and feature dimensions.

### 5. Experiments
- **Datasets & Metrics**: MNIST and FashionMNIST datasets evaluated under various privacy budgets.
- **Baselines**: Centralized DP-CDA, Centralized Differential Privacy, Conventional Federated DP-CDA, DP-CDA, DP-Mix, Federated DP-CDA, Local Perturbation, N/A, Random Projection, Standard Federated Learning Approaches
- **Main Results**: CAPE achieves the same privacy guarantees as local mechanisms while restoring utility to centralized levels.
- **Ablations**: N/A
- **Limitations / Stress Tests**: N/A

### 6. Takeaways
- **Pros**: Improved privacy-utility trade-off in federated settings., Synthetic data generation preserves statistical structure without leaking private information., CAPE allows for limited collaboration among clients while maintaining privacy.
- **Cons**: Increased noise required in decentralized settings can degrade utility., Potential challenges in implementation across diverse client environments., Dependence on the effectiveness of the CAPE protocol.
- **Future Work**: Explore further optimizations in noise generation techniques., Investigate the application of this method in other sensitive domains., Develop more robust frameworks for privacy-preserving federated learning.

</details>

### [Goos-H$\ddot{a}$nchen shift of normally incident beam on magneto-optical meta-grating](http://arxiv.org/pdf/2509.10374v1)


<!--break-out-of-list-->
<details markdown="1">
<summary> Paper Summary </summary>

### 1. Task / Problem
- Study the Goos-Hanchen shift in magneto-optical meta-gratings

### 2. Motivation & Gaps
- The Goos-Hanchen shift in optical gratings arises from the excitation of resonant modes, which extract energy from the incident optical beam and propagate laterally before re-radiating the optical energy back into the surrounding medium.

- **Related work challenges:**
  - Previous researches about the GH shift: Require oblique incident of the optical beam, complicating application schemes.
  - Studies on quasi-BICs: Need to control the GH shift by tuning the external magnetic field.
  - Research on magneto-optical materials: Band structure becomes non-symmetric, complicating the understanding of GH shift.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - High-Q Supercavity Modes in Subwavelength Dielectric Resonators: N/A
  - From Fano to quasi-BIC resonances in individual dielectric nanoantennas: N/A
  - Resonant dual-grating metamembranes supporting spectrally narrow bound states in the continuum: N/A

### 3. Core Idea
- Component grating of magneto-optical rods induces quasi-BICs at the  point with large Q factor and nonzero group velocity, affecting the GH shift of the reflected beam.

### 4. Method
- **Pipeline**: Design a compound grating of magneto-optical rods and study its band structure and GH shift.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Utilizes Finite Element Method (FEM) in COMSOL for numerical calculations.

### 5. Experiments
- **Datasets & Metrics**: N/A
- **Baselines**: Momentum mismatch driven bound states in the continuum and ellipsometric phase singularities, N/A, Previous studies on GH shift, Research on optical gratings, Studies on resonant modes, Symmetry-protected dual bound states in the continuum in metamaterials, Tunable magneto-optical accidental bound states in the continuum with intrinsic chirality and nonreciprocal transmission
- **Main Results**: The GH shift of the reflected beam is dependent on the Q factor of the quasi-BIC and the beam width of the Gaussian beam.
- **Ablations**: N/A
- **Limitations / Stress Tests**: N/A

### 6. Takeaways
- **Pros**: The proposed method allows for a normally incident optical beam to have a sizable GH shift., The use of magneto-optical materials enables tuning of the band structure., The findings can be applied in diverse fields such as optical sensing and energy storage.
- **Cons**: The complexity of the design may limit practical applications., Dependence on precise tuning of structural parameters., Potential challenges in experimental validation of the theoretical results.
- **Future Work**: Explore other magneto-optical materials for enhanced performance., Investigate the application of the findings in real-world optical devices., Develop simpler methods for achieving GH shifts in optical systems.

</details>

## avatar

### [Using the Pepper Robot to Support Sign Language Communication](http://arxiv.org/pdf/2509.09889v1)


<!--break-out-of-list-->
<details markdown="1">
<summary> Paper Summary </summary>

### 1. Task / Problem
- Evaluating the recognition of Italian Sign Language (LIS) signs by the Pepper robot

### 2. Motivation & Gaps
- This research explores the use of the Pepper robot to facilitate communication for Deaf users in interactive environments, aiming to reduce communication barriers and foster inclusive interactions.

- **Related work challenges:**
  - Research on the use of social robots for sign language communication began in 2012.: Most social robots interact using speech synthesis and visual displays, which limits accessibility for Deaf individuals.
  - NAO H25 robot study: Limitations in the robots structure and mobility.
  - RASA robot for Persian Sign Language: Lack of facial expressions and mouth movements negatively affected sign clarity.
  - InMoov robot for autistic children: Limited signs programmed for engagement.
  - Existing methods for creating sign language animations: Manual creation is time-consuming and complex, requiring significant effort for each sign.
  - Previous studies on robotic sign language communication: Limited automation in generating signs, leading to inconsistencies and inefficiencies.
  - Previous studies on robot communication with Deaf individuals: Limited expressivity and intelligibility due to physical constraints of the robot.
  - Signavatars: A large-scale 3d dataset for holistic sign language production and understanding: N/A
  - A participatory design process of a robotic tutor of assistive sign language for children with autism: N/A
  - Prototyping and preliminary evaluation of sign language translation system in the railway domain: N/A

### 3. Core Idea
- The core idea is to utilize the Pepper robot to support sign language communication, particularly for Deaf users, by implementing a system that can understand and produce sign language.

### 4. Method
- **Pipeline**: Conducted recognition tests using binomial tests to evaluate sign recognition rates.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The study involved a small sample size of 12 participants, which limits statistical power.

### 5. Experiments
- **Datasets & Metrics**: Recognition accuracy was measured through binomial tests and qualitative notes on sign performance.
- **Baselines**: InMoov, Manual sign creation methods, N/A, NAO H25, NAO H25 robot for Turkish Sign Language, Previous robotic sign language recognition studies, RASA
- **Main Results**: Pepper showed significant recognition rates for several signs but struggled with full sentences due to complexity.
- **Ablations**: N/A
- **Limitations / Stress Tests**: The study faced limitations in participant recruitment and the robot's physical constraints affecting sign execution.

### 6. Takeaways
- **Pros**: Pepper can perform a subset of LIS signs intelligibly., The study contributes to the discussion on inclusive robotics., Future developments could enhance robot expressivity.
- **Cons**: Full sentence recognition is significantly lower., Pepper has physical limitations affecting sign production., Limited integration of Deaf users in the design process.
- **Future Work**: Address multi-modal enhancements like screen-based support., Involve Deaf users in participatory design., Refine robot expressivity and usability.

</details>

### [Merging Bodies, Dividing Conflict: Body-Swapping in Mixed Reality Increases Closeness Yet Weakens the Joint Simon Effect](http://arxiv.org/pdf/2509.09815v1)


<!--break-out-of-list-->
<details markdown="1">
<summary> Paper Summary </summary>

### 1. Task / Problem
- Investigate the effects of reciprocal body swapping on interpersonal closeness and action-level coordination in mixed reality environments.

### 2. Motivation & Gaps
- The study aims to understand how body ownership and self-concept clarity influence interpersonal dynamics in mixed reality settings.

- **Related work challenges:**
  - Previous research on Mixed Reality and body ownership.: Lack of studies examining real-time coordination among co-located users.
  - Classic studies on the Simon task.: Most studies stop at confirming the illusion's validity without exploring its implications.
  - BeAnotherLabs 'Machine to Be Another': Limited to one-way body-swapping.
  - Dollinger et al. VR body-swapping system: Does not assess social consequences of body-swapping.
  - Genay et al.: Did not test reciprocal body-swapping's effect on implicit action coupling.
  - Genay et al.: Stronger ownership for virtual hands in combined realvirtual environments than in purely virtual ones.
  - N/A: No significant differences in ownership ratings across virtual, augmented, and physical settings.
  - N/A: Individual differences in self-identity and personality significantly influence how users experience embodiment.
  - N/A: N/A
  - Previous studies on the Simon effect: Limited understanding of how body ownership influences spatial interference.
  - Research on avatar embodiment: Need for empirical evidence on the impact of avatar control on interpersonal closeness.
  - N/A: N/A
  - Self-Expansion Theory: Understanding how stable self-concept affects perspective-taking and interpersonal closeness.
  - Joint Simon Effect: Exploring the relationship between body ownership and action co-representation.
  - N/A: N/A
  - E. Wolf et al. (2020): Body weight perception of females using photorealistic avatars in virtual and augmented reality.
  - M. Zhu et al. (2024): Interplay of team member expertness and big five personality traits in virtual collaboration.

### 3. Core Idea
- Reciprocal body swapping enhances interpersonal closeness while reducing action-level coordination, suggesting a trade-off that can inform the design of multi-user XR systems.

### 4. Method
- **Pipeline**: Participants engaged in a body swapping task while their interpersonal closeness and coordination were measured.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: Analyses were conducted using Python 3.11 with libraries such as pandas, SciPy, and statsmodels.

### 5. Experiments
- **Datasets & Metrics**: Data collected from 33 participants using self-report measures and reaction time assessments.
- **Baselines**: Go/No-Go Task, Go/No-Go task, N/A, No body-swapping condition, Non-swapped avatar interaction, Self-Avatar condition, Standard Simon Task, Standard Simon task, Traditional avatar interaction
- **Main Results**: Body swapping increased interpersonal closeness, particularly for individuals with high self-concept clarity, but reduced action-level coordination.
- **Ablations**: N/A
- **Limitations / Stress Tests**: Limited sample size and focus on dyadic interactions; future studies should explore larger groups and neurophysiological measures.

### 6. Takeaways
- **Pros**: Enhances collaboration in Mixed Reality environments., Promotes empathy and social learning., Offers therapeutic interventions through shared embodiment.
- **Cons**: Limited exploration of long-term effects., Potential for misinterpretation of results., Dependence on specific experimental conditions.
- **Future Work**: Investigate long-term impacts of body-swapping., Explore applications in therapeutic settings., Examine effects on diverse populations.

</details>

### [Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis](http://arxiv.org/pdf/2509.09595v1)


<!--break-out-of-list-->
<details markdown="1">
<summary> Paper Summary </summary>

### 1. Task / Problem
- Long-duration avatar video generation

### 2. Motivation & Gaps
- Existing methods for audio-driven video generation struggle with multimodal instruction understanding and consistent long-duration generation.

- **Related work challenges:**
  - Video Diffusion Transformers (DiT): Insufficient for highly realistic portrait synthesis and often treat each conditional signal independently.
  - Prior work on facial expression and lip synchronization: Leads to semantic conflicts across modalities and affect.
  - Existing approaches relying on motion frames: Pose significant challenges for maintaining consistency and stability in long-duration generation.
  - Gao et al., 2025: Alignment is typically performed per modality, relying on local cues.
  - Fei et al., 2025: Shallow fusion at the generation stage limits expressive capabilities.
  - Wang et al., 2025a: Existing methods do not effectively manage emotional consistency across modalities.
  - OmniHuman: Identity drift and low-quality video generation.
  - HeyGen: Inconsistent lip synchronization and visual quality.
  - OmniHuman-1: Limited to fixed resolutions and lacks support for arbitrary input/output resolutions.
  - HeyGen: Produces videos with repetitive action patterns, harming vividness and diversity.
  - Diffusion Transformers: Primarily designed for general video generation, inadequate for speech-driven digital portrait modeling.
  - Jiang et al., 2025: Struggle with multimodal instruction understanding.
  - Gan et al., 2025: Reliance on local cues for alignment within each modality.
  - Huang et al., 2025: Inconsistent long-duration generation.
  - N/A: N/A

### 3. Core Idea
- A cascaded framework that unifies multimodal instruction understanding with long-duration generation of lifelike portrait videos.

### 4. Method
- **Pipeline**: Two-stage pipeline: first employs an MLLM director to produce a blueprint video, then synthesizes long videos through parallel sub-clip generation.
- **Architecture / Loss / Training**: Coupled with carefully curated data and practical training and inference strategies.
- **Complexity / Resources**: Preserves fine-grained details while faithfully realizing global semantics.

### 5. Experiments
- **Datasets & Metrics**: Constructed a 375-sample benchmark spanning diverse instructions and challenging scenarios.
- **Baselines**: Existing audio-driven video generation methods, HeyGen, N/A, OmniHuman, OmniHuman-1
- **Main Results**: Kling-Avatar delivers vivid, fluent videos up to 1080p and 48 fps, with precise lip synchronization and strong controllability.
- **Ablations**: Future work will include additional objective metrics to complement the GSB assessments.
- **Limitations / Stress Tests**: Human preferencebased metric comparisons confirm superior performance.

### 6. Takeaways
- **Pros**: Generates vivid, fluent, long-duration videos at up to 1080p and 48 fps., Maintains strong generalization to open-domain scenarios., Achieves superior performance across multiple dimensions.
- **Cons**: Dependency on high-quality training data., Potential for identity drift in long videos., Limited generalization to unseen character dynamics.
- **Future Work**: Further improvements in instruction understanding., Exploration of additional multimodal inputs., Enhancements in real-time generation capabilities.

</details>

## video understanding

### [Joint X-ray, kinetic Sunyaev-Zeldovich, and weak lensing measurements: toward a consensus picture of efficient gas expulsion from groups and clusters](http://arxiv.org/pdf/2509.10455v1)


<!--break-out-of-list-->
<details markdown="1">
<summary> Paper Summary </summary>

### 1. Task / Problem
- Analyze the kSZ effect profile in relation to stellar mass and feedback mechanisms

### 2. Motivation & Gaps
- The study investigates the discrepancies between spectroscopic and photometric measurements of the kSZ effect, particularly focusing on the required feedback levels for different stellar mass bins.

- **Related work challenges:**
  - FLAMINGO simulation: Inconsistency with observed eROSITA X-ray gas fractions and kSZ measurements.
  - Previous studies on gas expulsion: Moderate power suppression inferred from X-ray measurements does not align with recent observations.
  - Stacked measurements of the kSZ effect: Need for more robust constraints on gas content beyond several R500.
  - Bulbul et al. 2024: Gas mass measurements from the eROSITA all-sky survey.
  - Schaan et al. 2021: kSZ effect profiles from SDSS+ACT.
  - Guachalla et al. 2025: kSZ effect profiles from DESI+ACT.
  - Guachalla et al. (2025): Combining multiple ACT DR6 channels with Planck data.
  - Hadzhiyska et al. (2024b): Measuring kSZ effect profiles for different stellar mass bins.
  - FLAMINGO simulations: Inferring feedback strength from kSZ profile shapes.
  - Dalla Vecchia & Schaye 2012: Numerical overcooling due to large masses of gas particles.
  - Hu sko et al. 2022: Limited range of feedback strengths in jet mode AGN feedback.
  - Braspenning et al. 2024: Bias in inferred feedback strength due to mismatches in halo mass or redshift.
  - McCarthy et al. (2025): Inclusion of redshift marginalization in halo mass inference.
  - Ghirardini et al. (2024): Validation of halo masses using weak lensing calibrated scaling relations.
  - Hoekstra et al. (2012): Mitigating cluster member contamination in GGL measurements.
  - McCarthy et al. (2025): The strongest feedback simulation closely matches observations at lower redshifts.
  - Guachalla et al. (2025): Different feedback strengths required for high mass LRG bins compared to lower mass bins.
  - Hadzhiyska et al. (2024b): Incompatibility of measurements from spectroscopic and photometric methods.
  - MillenniumTNG: Does not expel enough gas beyond R500 from groups and clusters.
  - EAGLE: Exhibits milder feedback than the observations require.
  - FABLE: Similar issues with gas mass fraction discrepancies.
  - Popesso et al. 2024a: N/A
  - Bulbul et al. 2024: N/A
  - Pakmor et al. 2023: N/A
  - Schaye et al. 2015: N/A
  - Henden et al. 2018: N/A
  - Braspenning et al. 2024: Deviates from pre-eROSITA observed cluster scaling relations.
  - Bigwood et al. 2025: N/A
  - Hadzhiyska et al. 2024b: Photometric measurements are well described by the strongest feedback variant.
  - Guachalla et al. 2025: Spectroscopic measurements appear to require even stronger gas expulsion.
  - Seppi et al. 2022; Marini et al. 2024: X-ray detected samples are incomplete at lower masses and potentially biased.
  - Heydenreich et al. (2025): Establishing consistency between lensing surveys
  - Amon et al. (2023): Correcting the raw excess surface density estimator for known systematics
  - Li et al. (2023): Correcting mean redshifts of the HSC tomographic bins
  - Hirata & Seljak 2003: Estimating residual multiplicative biases as a function of signal-to-noise and resolution.
  - Li et al. 2022: Correcting for multiplicative and additive biases induced by selection criteria.
  - Ross et al. 2025: Reproducing the redshift distribution of observations using random catalogs.
  - Hoekstra et al. 2012: Cluster member contamination in GGL measurements due to photometric redshift uncertainties.
  - Gruen et al. 2014: Dilution of shear signal from background source galaxy samples.
  - Dietrich et al. 2019: Calibration of corrections against simulations to minimize contamination.
  - Zhou et al. (2023a): Photometric measurements require different feedback levels compared to spectroscopic measurements.
  - FLAMINGO simulation: Both measurement types require stronger feedback than the fiducial simulation, but differ on the extent of feedback needed.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- The analysis reveals that photometric kSZ measurements align well with the strongest feedback simulation, while spectroscopic measurements indicate a need for even stronger feedback in higher mass bins.

### 4. Method
- **Pipeline**: Stacked kSZ effect profile calculation from simulated galaxies matched to GGL measurements, marginalizing over redshift distributions.
- **Architecture / Loss / Training**: N/A
- **Complexity / Resources**: The method requires careful calibration and the use of multiple simulations to ensure accurate halo mass inference.

### 5. Experiments
- **Datasets & Metrics**: Utilized photometric and spectroscopic measurements of kSZ effect profiles across different stellar mass bins.
- **Baselines**: 1 Gpc3 hydrodynamical FLAMINGO simulation, DES Y3, DES Y3 shear catalog, DES shear catalog, EAGLE, FABLE, FLAMINGO fiducial radiative feedback, FLAMINGO simulation, FLAMINGO simulations, Ghirardini et al. (2024), Guachalla et al. (2025), Guachalla et al. 2025, HSC Y3, HSC shear catalog, Hadzhiyska et al. (2024b), KiDS 1000, McCarthy et al. (2025), MillenniumTNG, N/A, Schaan et al. 2021, Stronger jet feedback, Stronger radiative feedback, Strongest radiative feedback, blue shear catalog
- **Main Results**: Photometric measurements are well described by the strongest feedback simulation, while spectroscopic measurements require stronger feedback for the highest mass bins.
- **Ablations**: The analysis includes variations in GGL fitting processes and halo mass selection methods to assess their impact on results.
- **Limitations / Stress Tests**: Omitted highest mass LRG bins from primary analysis due to discrepancies in required feedback levels.

### 6. Takeaways
- **Pros**: Provides a comprehensive view of gas expulsion mechanisms., Highlights discrepancies between simulations and observations., Offers insights into the impact of baryon feedback on large-scale structure.
- **Cons**: Inconsistencies with existing simulations., Limited understanding of the physical mechanisms behind gas expulsion., Dependence on multi-probe measurements may introduce complexity.
- **Future Work**: Further exploration of complementary observables., Next-generation simulations to refine understanding of gas dynamics., Investigate the implications of findings on galaxy evolution and cosmology.

</details>

### [Euclid: Early Release Observations -- The star cluster systems of the Local Group dwarf galaxies IC 10 and NGC 6822](http://arxiv.org/pdf/2509.10440v1)


<!--break-out-of-list-->
<details markdown="1">
<summary> Paper Summary </summary>

### 1. Task / Problem
- Analysis of star cluster systems in dwarf galaxies NGC 6822 and IC 10

### 2. Motivation & Gaps
- The study aims to provide a detailed analysis of star cluster systems in two Local Group dwarf galaxies, NGC 6822 and IC 10, utilizing high-resolution imaging from the Euclid mission.

- **Related work challenges:**
  - Hubble Space Telescope studies: Limited field of view and focus on bright inner regions, potentially biasing the understanding of cluster populations.
  - Previous studies on star clusters: Lack of comprehensive views of star cluster populations in nearby galaxies.
  - Research on old globular clusters: Difficulty in identifying and analyzing old clusters that provide insights into galaxy assembly histories.
  - Brodie & Strader 2006: Understanding the timeline and nature of hierarchical galaxy growth through the identification and analysis of globular clusters (GCs).
  - Massari et al. 2019: Focusing on cluster kinematics, chemistry, and ages to identify accreted GCs in the Milky Way.
  - Foster et al. 2014: Recognizing accreted GCs outside the Milky Way through their association with tidal streams.
  - Huxor et al. (2013): Independent analysis of the same data to discover additional GCs.
  - Veljanoski et al. (2015): Inferring dynamical mass of NGC 6288s GC system.
  - Demers et al. (2004): Understanding the distribution of star populations in IC 10.
  - Huxor et al. 2008, 2014; Johnson et al. 2015: Automated or semi-automated methods of star cluster detection face significant challenges due to the complex appearance of clusters against varying stellar fields.
  - Gouliermis et al. (2010): Clusters defined as overdensities of point sources were not visually apparent in the Euclid image.
  - Hodge (1977): Older studies lacked published coordinates for cluster candidates.
  - Krienke & Hodge (2004): Coordinates did not always correspond to visible overdensities in the Euclid images.
  - Chandar et al. 2010: Major source of uncertainty in star cluster studies.
  - Cook et al. 2019: Methods to deal with uncertainties in aperture corrections.
  - Adamo et al. 2015: N/A
  - Deger et al. 2022: N/A
  - L15: N/A
  - BAGPIPES algorithm: Dealing with dust and foreground extinction in fitting cluster properties.
  - Previous studies on cluster sizes: Irregular profiles of clusters leading to undetermined half-light radii.
  - Completeness tests: Assessing the accuracy of measurements and recovery rates of synthetic clusters.
  - L15: Differences in age estimates and systematic offsets in cluster profile-fitting methodologies.
  - Veljanoski et al. (2015): N/A
  - Hwang et al. (2011): N/A
  - Huxor et al. (2013): N/A
  - Krienke & Hodge (2004): N/A
  - Larsen et al. (2022): N/A
  - Chandar et al. (2000): N/A
  - Hwang et al. (2014): N/A
  - Gatto et al. (2021): N/A
  - Bica et al. (2020): N/A
  - Fall & Zhang (2001): N/A
  - Elmegreen & Efremov (1997): N/A
  - Larsen (2009): N/A
  - Adamo et al. (2015): N/A
  - Johnson et al. (2017): N/A
  - Massey et al. (2007): N/A
  - Fusco et al. (2012): N/A
  - Lim & Lee (2015): N/A
  - Lim & Lee (2015): Comparison of SED-fit masses and ages with previous studies.
  - Gatto et al. (2021): Bias in areal coverage and systematic effects in age determination methods.
  - Chandar et al. (2005): Understanding the rapid gas expulsion and its effects on cluster disruption.
  - Georgiev et al. (2009): Candidate globular clusters (GCs) identified but not spectroscopically confirmed or age dated.
  - Huxor et al. (2014): Tentative evidence for a second peak in luminosity functions but low cluster numbers prevent strong conclusions.
  - Mackey et al. (2019): Comparison of luminosity functions with other galaxies shows variations that complicate understanding.
  - Lee et al. 2005: N/A
  - Chandar et al. 2016: N/A
  - Mackey & Gilmore 2003: N/A
  - Ryon et al. 2015: N/A
  - Bastian et al. 2012: N/A
  - Scheepmaker et al. 2007: N/A
  - Larsen 2004: N/A
  - Barmby et al. 2009: N/A
  - Forbes et al. (2018b): Lack of universally accepted definitions for GCs and accurate age information in extragalactic studies.
  - Eadie et al. (2022); Jones et al. (2023); Saifollahi et al. (2025): Diversity in GC populations of low-mass galaxies.
  - Gratton et al. (2019): Defining GCs in the Milky Way and its satellites versus extragalactic candidates.
  - Forbes et al. (2018b): Halo mass estimation for dwarf galaxies
  - Oh et al. (2015): Scaling relationship scatter at low-mass end
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - Fouesneau & Lan莽on (2010): Using continuous population models to analyse low-mass clusters often leads to age underestimation.
  - Popescu & Hanson (2010): Clusters may appear much redder and older than they would if their IMF was fully sampled.
  - Johnson et al. (2022): Comparison of CMD-derived parameters with SED-fitted ones provides a valuable assessment of stochastic modelling.
  - N/A: N/A

### 3. Core Idea
- The study explores the effects of stochasticity on the integrated colours and age estimates of low-mass star clusters.

### 4. Method
- **Pipeline**: The method involves dividing the circular aperture used for colour determination into halves and calculating colour variations.
- **Architecture / Loss / Training**: The method utilizes a Moffat profile for cluster representation and applies a logistic function for completeness estimation.
- **Complexity / Resources**: Utilized 9-band integrated photometry and BAGPIPESSED-fitting code for analysis.

### 5. Experiments
- **Datasets & Metrics**: The analysis includes photometry and SED-fitting of star clusters in NGC 6822 and IC 10.
- **Baselines**: BAGPIPES code, Bruzual & Charlot models, Continuous population models, Gatto et al. (2021), Georgiev et al. (2009), HST imaging, HST imaging campaigns, Hodge (1977), Hubble's identification of clusters, Hunt et al. (2025), Hunter (2001), Huxor et al. (2014), L15, Lim & Lee (2015), Mackey et al. (2019), N/A, Previous literature candidates, Previous star cluster candidates from literature, Previous studies of star clusters in NGC 6822, Previous studies on GC populations in dwarf galaxies, Previous studies on star clusters, Previous studies on star clusters in NGC 6822 and IC 10, SED fitting through CIGALE, Sharina et al. (2010), Spectroscopic analyses of star clusters, Standard fitting methods for cluster properties, Stochastic population models, ground-based observations
- **Main Results**: The study finds that measurement uncertainties are the dominant source of observed colour variations.
- **Ablations**: The impact of different extinction laws and priors on the fitting results was analyzed.
- **Limitations / Stress Tests**: The tests performed are limited and suggest further exploration is needed.

### 6. Takeaways
- **Pros**: Resolved star clusters into individual stars, enhancing identification and characterization., Compiled a comprehensive catalogue of star cluster candidates., Identified several old massive clusters, providing insights into galaxy evolution.
- **Cons**: Potential bias in previous studies due to limited observational focus., Challenges in identifying old clusters that are crucial for understanding galaxy assembly., Sample completeness may limit the generalizability of findings.
- **Future Work**: Further studies on the role of star clusters in galaxy evolution., Exploration of the relationship between star clusters and galaxy assembly histories., Utilization of additional data from Euclid for more comprehensive analyses.

</details>

### [Understanding Outer Optimizers in Local SGD: Learning Rates, Momentum, and Acceleration](http://arxiv.org/pdf/2509.10439v1)


<!--break-out-of-list-->
<details markdown="1">
<summary> Paper Summary </summary>

### 1. Task / Problem
- Analyze the convergence of Generalized Local SGD and derive optimal stepsizes.

### 2. Motivation & Gaps
- Existing analyses of Local SGD require specific conditions on the local stepsize, limiting their applicability in heterogeneous settings.

- **Related work challenges:**
  - FedOpt: Limited theoretical understanding of the Generalized Local SGD algorithm and the ideal learning rate pair.
  - Nesterov acceleration: Lack of clarity on why or how it improves convergence.
  - Konen媒 et al., 2016: Communication-efficient distributed optimization
  - Karimireddy et al., 2020: Data heterogeneity
  - Eichner et al., 2019: Intermittent client availability
  - Karimireddy et al. (2020): Provides convergence rates that do not recover those of vanilla Local SGD.
  - Jhunjhunwala, Wang, and Joshi (2023): Guarantees depend on the heterogeneity of iterates across clients.
  - Sun et al. (2024): Analysis is limited by the requirement to choose local stepsizes that scale as 1/LH.
  - Malinovsky and Richt谩rik, 2022: Convergence guarantees in the context of optimization
  - Li, Acharya, and Richt谩rik, 2024: Access to proximal operator for improved convergence
  - Sun et al., 2024: Use of momentum in optimization
  - N/A: N/A
  - Convergence and Accuracy Trade-Offs in Federated Learning and Meta-Learning: N/A
  - On the Outsized Importance of Learning Rates in Local Update Methods: N/A
  - Distributed Deep Learning in Open Collaborations: N/A
  - N/A: N/A
  - A Field Guide To Federated Optimization: N/A
  - Communication-Efficient Adaptive Federated Learning: N/A
  - Federated learning with differential privacy: Algorithms and performance analysis: N/A
  - Minibatch vs Local SGD for Heterogeneous Distributed Learning: N/A
  - Is Local SGD Better than Minibatch SGD?: N/A
  - SPD-CFL: Stepwise Parameter Dropout for Efficient Continual Federated Learning: N/A
  - Federated Accelerated Stochastic Gradient Descent: N/A
  - Minibatch vs Local SGD with Shuffling: Tight Convergence Bounds and Beyond: N/A
  - Towards Understanding Why Lookahead Generalizes Better Than SGD and Beyond: N/A
  - N/A: Decreasing cosine similarity between outer gradients as the number of replicas increases.
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A
  - N/A: N/A

### 3. Core Idea
- This paper studies the impact of the outer learning rate on the convergence of Local SGD through novel convergence theorems, balancing convergence speed and stochastic gradient variance.

### 4. Method
- **Pipeline**: The method involves analyzing the convergence of Generalized Local SGD with varying local and outer stepsizes over multiple communication rounds.
- **Architecture / Loss / Training**: Chinchilla-style decoder transformer architectures trained on the C4 dataset.
- **Complexity / Resources**: The analysis provides explicit expressions for optimal stepsizes based on problem parameters.

### 5. Experiments
- **Datasets & Metrics**: C4 dataset
- **Baselines**: Accelerated Gradient Descent, Averaging, Data-Parallel, DiLoCo (Nesterov outer optimizer), FedAC, FedProx, Federated Averaging, Gradient Descent, Local SGD, Minibatch SGD, N/A, Nesterov, SF-SGD, SGD(lr=1), Schedule-Free Gradient Descent, ScheduleFree-SGD (SF-SGD), Vanilla Local SGD
- **Main Results**: Constant outer learning rate is the best performing schedule.
- **Ablations**: Varying inner steps and replicas impact performance.
- **Limitations / Stress Tests**: Federated learning methods lose flops-efficiency as the number of replicas increases.

### 6. Takeaways
- **Pros**: Improved convergence rates with tuned outer learning rates., Increased robustness to hyperparameter tuning., Insights into the role of momentum in outer optimizers.
- **Cons**: Limited theoretical understanding of the ideal learning rate pair., Dependence on the specific configuration of outer optimizers., Potential challenges in decentralized settings.
- **Future Work**: Further exploration of outer optimizer configurations., Investigation of the impact of communication efficiency in decentralized training., Development of more comprehensive theoretical frameworks.

</details>
